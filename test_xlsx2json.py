#!/usr/bin/env python3
"""
xlsx2json.py ã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

ã“ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã®ä¸»è¦æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ï¼š
- åŸºæœ¬çš„ãªåå‰ä»˜ãç¯„å›²ã®è§£æ
- ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã®æ§‹ç¯‰
- é…åˆ—ãƒ»å¤šæ¬¡å…ƒé…åˆ—ã®å¤‰æ›
- å¤‰æ›ãƒ«ãƒ¼ãƒ«ï¼ˆsplit, function, commandï¼‰
- JSON Schema ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
- è¨˜å·ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†

READMEã¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‚è€ƒã«ã€å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å³ã—ãŸãƒ†ã‚¹ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚
"""

import argparse
import json
import logging
import os
import pytest
import re
import shutil
import subprocess
import sys
import tempfile
import time
import unittest.mock
from datetime import datetime, date
from pathlib import Path
from unittest.mock import patch, MagicMock
from types import SimpleNamespace

import openpyxl
from openpyxl import Workbook, load_workbook
from openpyxl.styles import Side, Border
from openpyxl.utils import get_column_letter
from openpyxl.workbook.defined_name import DefinedName
from jsonschema import Draft7Validator

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆsys.argvã‚’ãƒ¢ãƒƒã‚¯ã—ã¦å®‰å…¨ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
sys.path.insert(0, str(Path(__file__).parent))
with unittest.mock.patch.object(sys, "argv", ["test"]):
    import xlsx2json
    # çµ±åˆãƒ†ã‚¹ãƒˆå†…ã§ã®ç°¡ä¾¿å‚ç…§ç”¨ã‚¨ã‚¤ãƒªã‚¢ã‚¹
    m = xlsx2json


class DataCreator:
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""

    def __init__(self, temp_dir: Path):
        self.temp_dir = temp_dir
        self.workbook = None
        self.worksheet = None

    def create_basic_workbook(self) -> Path:
        """åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
        self.workbook = Workbook()
        self.worksheet = self.workbook.active
        self.worksheet.title = "Sheet1"

        # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å‹ã®ãƒ†ã‚¹ãƒˆ
        set_cells(
            self.worksheet,
            {
                "A1": "å±±ç”°å¤ªéƒ",  # é¡§å®¢å
                "A2": "æ±äº¬éƒ½æ¸‹è°·åŒº",  # ä½æ‰€
                "A3": 123,  # æ•´æ•°
                "A4": 45.67,  # æµ®å‹•å°æ•°ç‚¹
                "A5": datetime(2025, 1, 15, 10, 30, 0),  # æ—¥æ™‚
                "A6": date(2025, 1, 19),  # å›ºå®šæ—¥ä»˜
                "A7": True,  # çœŸ
                "A8": False,  # å½
                "A9": "",  # ç©ºã‚»ãƒ«
                "A10": None,  # Noneã‚»ãƒ«
            },
        )

        # é…åˆ—åŒ–ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ»å¤šæ¬¡å…ƒé…åˆ—ãƒ»æ—¥æœ¬èªãƒ»è¨˜å·ãƒ»ãƒã‚¹ãƒˆæ§‹é€ ã®ãƒ†ã‚¹ãƒˆ
        set_cells(
            self.worksheet,
            {
                # é…åˆ—åŒ–ç”¨
                "B1": "apple,banana,orange",
                "B2": "1,2,3,4,5",
                "B3": "ã‚¿ã‚°1,ã‚¿ã‚°2,ã‚¿ã‚°3",
                # å¤šæ¬¡å…ƒé…åˆ—
                "C1": "A,B;C,D",  # 2æ¬¡å…ƒ
                "C2": "a1,a2\nb1,b2\nc1,c2",  # æ”¹è¡Œã¨ã‚«ãƒ³ãƒ
                "C3": "x1,x2|y1,y2;z1,z2|w1,w2",  # 3æ¬¡å…ƒ
                # æ—¥æœ¬èªãƒ»è¨˜å·
                "D1": "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ",
                "D2": "è¨˜å·ãƒ†ã‚¹ãƒˆï¼ï¼ ï¼ƒï¼„ï¼…",
                "D3": "æ”¹è¡Œ\nãƒ†ã‚¹ãƒˆ\nãƒ‡ãƒ¼ã‚¿",
                # ãƒã‚¹ãƒˆæ§‹é€ 
                "E1": "æ·±ã„éšå±¤ã®ãƒ†ã‚¹ãƒˆ",
                "E2": "ã•ã‚‰ã«æ·±ã„å€¤",
            },
        )
        # åå‰ä»˜ãç¯„å›²ã‚’å®šç¾©
        self._define_basic_names()

        # ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        file_path = self.temp_dir / "basic_test.xlsx"
        self.workbook.save(file_path)
        return file_path

    def _define_basic_names(self):
        """åŸºæœ¬çš„ãªåå‰ä»˜ãç¯„å›²ã‚’å®šç¾©"""
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹ãƒ»é…åˆ—ãƒ»å¤šæ¬¡å…ƒé…åˆ—ãƒ»æ—¥æœ¬èªãƒ»è¨˜å·ãƒ»ãƒã‚¹ãƒˆæ§‹é€ ãƒ»é…åˆ—ã®ãƒã‚¹ãƒˆ
        set_defined_names(
            self.workbook,
            {
                # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹
                "json.customer.name": "A1",
                "json.customer.address": "A2",
                "json.numbers.integer": "A3",
                "json.numbers.float": "A4",
                "json.datetime": "A5",
                "json.date": "A6",
                "json.flags.enabled": "A7",
                "json.flags.disabled": "A8",
                "json.empty_cell": "A9",
                "json.null_cell": "A10",
                # é…åˆ—åŒ–å¯¾è±¡
                "json.tags": "B1",
                "json.numbers.array": "B2",
                "json.japanese_tags": "B3",
                # å¤šæ¬¡å…ƒé…åˆ—
                "json.matrix": "C1",
                "json.grid": "C2",
                "json.cube": "C3",
                # æ—¥æœ¬èªãƒ»è¨˜å·
                "json.japanese.greeting": "D1",
                "json.japanese.symbols": "D2",
                "json.multiline": "D3",
                # ãƒã‚¹ãƒˆæ§‹é€ 
                "json.deep.level1.level2.level3.value": "E1",
                "json.deep.level1.level2.level4.value": "E2",
                # é…åˆ—ã®ãƒã‚¹ãƒˆ
                "json.items.1.name": "A1",
                "json.items.1.price": "A3",
                "json.items.2.name": "A2",
                "json.items.2.price": "A4",
            },
            default_sheet=self.worksheet.title,
        )

    def create_wildcard_workbook(self) -> Path:
        """è¨˜å·ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
        self.workbook = Workbook()
        self.worksheet = self.workbook.active
        self.worksheet.title = "Sheet1"  # æ˜ç¤ºçš„ã«ã‚·ãƒ¼ãƒˆåã‚’è¨­å®š

        # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ç”¨ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        set_cells(
            self.worksheet,
            {
                "A1": "ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼‘",
                "A2": "ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼’",
                "A3": "ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼“",
            },
        )

        # è¨˜å·ã‚’å«ã‚€åå‰ï¼ˆã‚¹ã‚­ãƒ¼ãƒã§è§£æ±ºã•ã‚Œã‚‹äºˆå®šï¼‰
        set_defined_names(
            self.workbook,
            {
                "json.user_name": "A1",  # ãã®ã¾ã¾ä¸€è‡´
                "json.user_group": "A2",  # userï¼group ã«ãƒãƒƒãƒ
                "json.user_": "A3",  # è¤‡æ•°ãƒãƒƒãƒã®ã‚±ãƒ¼ã‚¹
            },
            default_sheet=self.worksheet.title,
        )
        file_path = self.temp_dir / "wildcard_test.xlsx"
        self.workbook.save(file_path)
        return file_path

    def create_transform_workbook(self) -> Path:
        """å¤‰æ›ãƒ«ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
        self.workbook = Workbook()
        self.worksheet = self.workbook.active
        self.worksheet.title = "Sheet1"  # æ˜ç¤ºçš„ã«ã‚·ãƒ¼ãƒˆåã‚’è¨­å®š

        # å¤‰æ›ç”¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã§ä¸€æ‹¬è¨­å®šï¼‰
        set_cells(
            self.worksheet,
            {
                "A1": "apple,banana,orange",  # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š
                "A2": "1;2;3|4;5;6",  # å¤šæ¬¡å…ƒåŒºåˆ‡ã‚Š
                "A3": "line1\nline2\nline3",  # æ”¹è¡ŒåŒºåˆ‡ã‚Š
                "A4": "  trim_test  ",  # ãƒˆãƒªãƒ ãƒ»é–¢æ•°å¤‰æ›
                "A5": "command_test_data",  # ã‚³ãƒãƒ³ãƒ‰å¤‰æ›
            },
        )

        # åå‰ä»˜ãç¯„å›²å®šç¾©ï¼ˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã§ä¸€æ‹¬è¿½åŠ ï¼‰
        set_defined_names(
            self.workbook,
            {
                "json.split_comma": "A1",
                "json.split_multi": "A2",
                "json.split_newline": "A3",
                "json.function_test": "A4",
                "json.command_test": "A5",
            },
            default_sheet=self.worksheet.title,
        )

        file_path = self.temp_dir / "transform_test.xlsx"
        self.workbook.save(file_path)
        return file_path

    def create_wildcard_object_array_workbook(self) -> Path:
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰å¤‰æ›ï¼ˆé…åˆ—/ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ãƒ‰ï¼‰ã®æ¤œè¨¼ç”¨ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
        self.workbook = Workbook()
        ws = self.workbook.active
        ws.title = "Sheet1"

        # å€¤ã‚’é…ç½®
        set_cells(
            ws,
            {
                # root.a ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
                "A1": "NAME_A",
                # root.b ã¯é…åˆ—ï¼ˆ2è¦ç´ ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
                "B1": "B1-X1",
                "B2": "B2-X2",
                # root.line_items ã¯é…åˆ—
                "C1": "L1",
                "C2": "L2",
            },
        )

        # åå‰ä»˜ãç¯„å›²: json.root.a.name, json.root.b.1.x, json.root.b.2.x, json.root.line_items.1.qty, json.root.line_items.2.qty
        set_defined_names(
            self.workbook,
            {
                "json.root.a.name": "A1",
                "json.root.b.1.x": "B1",
                "json.root.b.2.x": "B2",
                "json.root.line_items.1.qty": "C1",
                "json.root.line_items.2.qty": "C2",
            },
            default_sheet=ws.title,
        )

        path = self.temp_dir / "wildcard_object_array.xlsx"
        self.workbook.save(path)
        return path

    def create_complex_workbook(self) -> Path:
        """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
        self.workbook = Workbook()
        self.worksheet = self.workbook.active
        self.worksheet.title = "Sheet1"  # æ˜ç¤ºçš„ã«ã‚·ãƒ¼ãƒˆåã‚’è¨­å®š
        # è¤‡é›‘ãªæ§‹é€ ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ãï¼‰
        set_cells(
            self.worksheet,
            {
                "A1": "ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ",
                "A2": "é–‹ç™ºéƒ¨",
                "A3": "ç”°ä¸­èŠ±å­",
                "A4": "tanaka@example.com",
                "A5": "03-1234-5678",
                "B1": "ãƒ†ã‚¹ãƒˆéƒ¨",
                "B2": "ä½è—¤æ¬¡éƒ",
                "B3": "sato@example.com",
                "B4": "03-5678-9012",
                "C1": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆÎ±",
                "C2": "2025-01-01",
                "C3": "2025-12-31",
                "C4": "é€²è¡Œä¸­",
                "D1": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆÎ²",
                "D2": "2025-03-01",
                "D3": "2025-06-30",
                "D4": "å®Œäº†",
                "E1": "ã‚¿ã‚¹ã‚¯1,ã‚¿ã‚¹ã‚¯2,ã‚¿ã‚¹ã‚¯3",
                "E2": "é«˜,ä¸­,ä½",
                "E3": "2025-02-01,2025-02-15,2025-03-01",
                "F1": "G2",
                "F2": "H2a1,H2b1\nH2a2,H2b2",
                "G1": "G3a1,G3b1\nG3a2",
                "G2": "H3a1\nH3a2",
                "H1": "H5",
            },
        )
        self._define_complex_names()

        file_path = self.temp_dir / "complex_test.xlsx"
        self.workbook.save(file_path)
        return file_path

    def _define_complex_names(self):
        """è¤‡é›‘ãªæ§‹é€ ã®åå‰ä»˜ãç¯„å›²ã‚’å®šç¾©"""
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        set_defined_names(
            self.workbook,
            {
                "json.system.name": "A1",
            },
            default_sheet=self.worksheet.title,
        )

        # éƒ¨ç½²æƒ…å ±ï¼ˆé…åˆ—ï¼‰
        set_defined_names(
            self.workbook,
            {
                "json.departments.1.name": "A2",
                "json.departments.1.manager.name": "A3",
                "json.departments.1.manager.email": "A4",
                "json.departments.1.manager.phone": "A5",
                "json.departments.2.name": "B1",
                "json.departments.2.manager.name": "B2",
                "json.departments.2.manager.email": "B3",
                "json.departments.2.manager.phone": "B4",
            },
            default_sheet=self.worksheet.title,
        )

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ï¼ˆé…åˆ—ï¼‰
        set_defined_names(
            self.workbook,
            {
                "json.projects.1.name": "C1",
                "json.projects.1.start_date": "C2",
                "json.projects.1.end_date": "C3",
                "json.projects.1.status": "C4",
                "json.projects.2.name": "D1",
                "json.projects.2.start_date": "D2",
                "json.projects.2.end_date": "D3",
                "json.projects.2.status": "D4",
            },
            default_sheet=self.worksheet.title,
        )

        # é…åˆ—åŒ–å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿
        set_defined_names(
            self.workbook,
            {
                "json.tasks": "E1",
                "json.priorities": "E2",
                "json.deadlines": "E3",
            },
            default_sheet=self.worksheet.title,
        )

        # å¤šæ¬¡å…ƒé…åˆ—ã®ãƒ†ã‚¹ãƒˆï¼ˆsamplesã®parentã«åŸºã¥ãï¼‰
        set_defined_names(
            self.workbook,
            {
                "json.parent.1.1": "F1",
                "json.parent.1.2": "F2",
                "json.parent.2.1": "G1",
                "json.parent.2.2": "G2",
                "json.parent.3.1": "H1",
            },
            default_sheet=self.worksheet.title,
        )

    def create_schema_file(self) -> Path:
        """ãƒ†ã‚¹ãƒˆç”¨ã®JSON Schemaãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        schema = {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "title": "Test Schema",
            "type": "object",
            "properties": {
                "customer": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "address": {"type": "string"},
                    },
                    "required": ["name"],
                },
                "numbers": {
                    "type": "object",
                    "properties": {
                        "integer": {"type": "number"},
                        "float": {"type": "number"},
                        "array": {"type": "array", "items": {"type": "string"}},
                    },
                },
                "tags": {"type": "array", "items": {"type": "string"}},
                "matrix": {
                    "type": "array",
                    "items": {"type": "array", "items": {"type": "string"}},
                },
                "user_name": {"type": "string"},
                "userï¼group": {"type": "string"},
                "userï¼": {"type": "string"},
                "userï¼Ÿ": {"type": "string"},
                "items": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string"},
                            "price": {"type": "number"},
                        },
                    },
                },
                "parent": {
                    "type": "array",
                    "description": "4æ¬¡å…ƒé…åˆ—(ç¸¦Ã—æ¨ªÃ—ã‚»ãƒ«å†…ç¸¦Ã—æ¨ª)",
                    "items": {
                        "type": "array",
                        "description": "3æ¬¡å…ƒé…åˆ—(æ¨ªÃ—ã‚»ãƒ«å†…ç¸¦Ã—æ¨ª)",
                        "items": {
                            "type": "array",
                            "description": "2æ¬¡å…ƒé…åˆ—(ã‚»ãƒ«å†…ç¸¦Ã—æ¨ª)",
                            "items": {
                                "type": "array",
                                "description": "1æ¬¡å…ƒé…åˆ—(ã‚»ãƒ«å†…æ¨ª)",
                                "items": {"type": "string", "description": "æ–‡å­—åˆ—"},
                            },
                        },
                    },
                },
            },
        }

        schema_file = self.temp_dir / "test_schema.json"
        with schema_file.open("w", encoding="utf-8") as f:
            json.dump(schema, f, ensure_ascii=False, indent=2)

        return schema_file

    def create_wildcard_schema_file(self) -> Path:
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ã®JSON Schemaãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        schema = {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "title": "Wildcard Test Schema",
            "type": "object",
            "properties": {
                "user_name": {"type": "string"},
                "userï¼group": {"type": "string"},
                "userï¼": {"type": "string"},
                "userï¼Ÿ": {"type": "string"},
            },
        }

        schema_file = self.temp_dir / "wildcard_schema.json"
        with schema_file.open("w", encoding="utf-8") as f:
            json.dump(schema, f, ensure_ascii=False, indent=2)

        return schema_file


def create_temp_excel(workbook):
    """ãƒ†ã‚¹ãƒˆç”¨ã®ä¸€æ™‚çš„ãªExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    temp_file = tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False)
    workbook.save(temp_file.name)
    temp_file.close()
    return temp_file.name


def set_cells(ws, mapping):
    """A1å‚ç…§ã¾ãŸã¯(row, col)ã®è¾æ›¸ã§ã‚»ãƒ«å€¤ã‚’ä¸€æ‹¬è¨­å®šã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€‚

    ä¾‹:
      set_cells(ws, {"A1": "v1", "B2": 123, (3, 4): "v2"})
    """
    for key, value in mapping.items():
        if isinstance(key, str):
            ws[key] = value
        elif isinstance(key, tuple) and len(key) == 2:
            r, c = key
            ws.cell(row=r, column=c, value=value)
        else:
            raise TypeError("mapping keys must be A1 string or (row, col) tuple")


def set_defined_names(wb, mapping, default_sheet: str | None = None):
    """åå‰ä»˜ãç¯„å›²ã‚’ä¸€æ‹¬è¿½åŠ ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€‚

    mapping å½¢å¼ã¯ { defined_name: ref }ã€‚
    ref ã¯ä»¥ä¸‹ã®ã„ãšã‚Œã‹:
    - "Sheet!$B$2" ã®ã‚ˆã†ãªå®Œå…¨å‚ç…§æ–‡å­—åˆ—ï¼ˆãã®ã¾ã¾ä½¿ç”¨ï¼‰
    - "B2" ã®ã‚ˆã†ãªA1å‚ç…§ï¼ˆdefault_sheet ã‹ wb.active.title ã‚’ä»˜ä¸ã— $ ã‚’è£œã†ï¼‰
    - (row, col) ã‚¿ãƒ—ãƒ«ï¼ˆdefault_sheet ã‹ wb.active.title ã‚’ä»˜ä¸ã— $ä»˜ã§ç”Ÿæˆï¼‰
    """

    def col_letter(idx: int) -> str:
        s = ""
        while idx:
            idx, rem = divmod(idx - 1, 26)
            s = chr(65 + rem) + s
        return s

    def dollarize_a1(a1: str) -> str:
        # Ranges or already dollarized are returned as-is
        if ":" in a1 or "$" in a1 or "!" in a1:
            return a1
        m = re.fullmatch(r"([A-Za-z]+)(\d+)", a1)
        if not m:
            return a1
        col, row = m.groups()
        return f"${col.upper()}${row}"

    sheet = default_sheet or (wb.active.title if wb.worksheets else "Sheet1")
    for name, ref in mapping.items():
        if isinstance(ref, str):
            attr = ref if "!" in ref else f"{sheet}!{dollarize_a1(ref)}"
        elif isinstance(ref, tuple) and len(ref) == 2:
            r, c = ref
            attr = f"{sheet}!${col_letter(c)}${r}"
        else:
            raise TypeError("mapping values must be A1 string or (row, col) tuple")
        wb.defined_names.add(DefinedName(name, attr_text=attr))


def draw_rect_border(ws, top: int, left: int, bottom: int, right: int):
    """æŒ‡å®šçŸ©å½¢ã«ç´°ç·šã®å¤–æ ç½«ç·šã‚’å¼•ããƒ†ã‚¹ãƒˆç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼ã€‚"""
    thin = Side(style="thin")
    # ä¸Šè¾º
    for col in range(left, right + 1):
        cell = ws.cell(row=top, column=col)
        cell.border = Border(
            top=thin,
            left=cell.border.left,
            right=cell.border.right,
            bottom=cell.border.bottom,
        )
    # ä¸‹è¾º
    for col in range(left, right + 1):
        cell = ws.cell(row=bottom, column=col)
        cell.border = Border(
            bottom=thin,
            left=cell.border.left,
            right=cell.border.right,
            top=cell.border.top,
        )
    # å·¦è¾º
    for row in range(top, bottom + 1):
        cell = ws.cell(row=row, column=left)
        cell.border = Border(
            left=thin,
            top=cell.border.top,
            right=cell.border.right,
            bottom=cell.border.bottom,
        )
    # å³è¾º
    for row in range(top, bottom + 1):
        cell = ws.cell(row=row, column=right)
        cell.border = Border(
            right=thin,
            top=cell.border.top,
            left=cell.border.left,
            bottom=cell.border.bottom,
        )


class TestNamedRanges:
    """åå‰ä»˜ãç¯„å›²ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture(scope="class")
    def temp_dir(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)

    @pytest.fixture(scope="class")
    def creator(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’æä¾›"""
        return DataCreator(temp_dir)

    @pytest.fixture(scope="class")
    def basic_xlsx(self, creator):
        """åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_basic_workbook()

    @pytest.fixture(scope="class")
    def wildcard_xlsx(self, creator):
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_wildcard_workbook()

    @pytest.fixture(scope="class")
    def transform_xlsx(self, creator):
        """å¤‰æ›ãƒ«ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_transform_workbook()

    @pytest.fixture(scope="class")
    def complex_xlsx(self, creator):
        """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_complex_workbook()

    @pytest.fixture(scope="class")
    def schema_file(self, creator):
        """JSON Schemaãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_schema_file()

    @pytest.fixture(scope="class")
    def wildcard_schema_file(self, creator):
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_wildcard_schema_file()

    @pytest.fixture(scope="class")
    def transform_file(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆç”¨ã®å¤‰æ›é–¢æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        transform_content = '''
def trim_and_upper(value):
    """æ–‡å­—åˆ—ã‚’ãƒˆãƒªãƒ ã—ã¦å¤§æ–‡å­—åŒ–"""
    if isinstance(value, str):
        return value.strip().upper()
    return value

def multiply_by_two(value):
    """æ•°å€¤ã‚’2å€ã«ã™ã‚‹"""
    try:
        return float(value) * 2
    except (ValueError, TypeError):
        return value

def csv_split(value):
    """CSVå½¢å¼ã§åˆ†å‰²"""
    if not isinstance(value, str):
        return value
    import csv
    from io import StringIO
    reader = csv.reader(StringIO(value))
    return [row for row in reader if any(cell.strip() for cell in row)]
'''

        transform_file = temp_dir / "test_transforms.py"
        with transform_file.open("w", encoding="utf-8") as f:
            f.write(transform_content)

        return transform_file

        @pytest.fixture(scope="class")
        def wildcard_objarr_xlsx(self, creator):
            """é…åˆ—/ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ãƒ‰ç”¨ã®ãƒ–ãƒƒã‚¯"""
            return creator.create_wildcard_object_array_workbook()

        def test_wildcard_transform_applies_to_object_and_array_nodes(self, tmp_path, wildcard_objarr_xlsx):
            """json.root.* ã§ root ç›´ä¸‹ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ/é…åˆ—ãƒãƒ¼ãƒ‰ã«å¯¾ã—ã¦é–¢æ•°ãŒé©ç”¨ã•ã‚Œã€
            é–¢æ•°ã«ã¯ dict ã¾ãŸã¯ list ãŒæ¸¡ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼ã™ã‚‹ã€‚æˆ»ã‚Šå€¤ã¯å½“è©²ãƒãƒ¼ãƒ‰ã®ç½®æ›å€¤ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹ã€‚"""
            # å¤‰æ›é–¢æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆ
            tr_py = tmp_path / "wild_objarr_funcs.py"
            tr_py.write_text(
                (
                    "def detect_type(value):\n"
                    "    if isinstance(value, dict):\n"
                    "        return 'DICT'\n"
                    "    if isinstance(value, list):\n"
                    "        return 'LIST'\n"
                    "    return f'OTHER:{type(value).__name__}'\n"
                ),
                encoding="utf-8",
            )

            # ãƒ«ãƒ¼ãƒ«: json.root.* ã« detect_type ã‚’é©ç”¨
            rules = xlsx2json.parse_array_transform_rules(
                [f"json.root.*=function:{tr_py}:detect_type"], prefix="json", schema=None, trim_enabled=False
            )

            result = xlsx2json.parse_named_ranges_with_prefix(
                wildcard_objarr_xlsx,
                prefix="json",
                array_transform_rules=rules,
            )

            assert "root" in result
            # root.a ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãªã®ã§ 'DICT'
            assert result["root"]["a"] == "DICT"
            # root.b ã¯é…åˆ—ãªã®ã§ 'LIST'
            assert result["root"]["b"] == "LIST"
            # root.line_items ã‚‚é…åˆ—ãªã®ã§ 'LIST'
            assert result["root"]["line_items"] == "LIST"

        def test_wildcard_transform_ancestor_capture_for_deeper_patterns(self, tmp_path, wildcard_objarr_xlsx):
            """json.root.*.* ã®ã‚ˆã†ã«ã‚ˆã‚Šæ·±ã„ãƒ‘ã‚¿ãƒ¼ãƒ³æŒ‡å®šã§ã‚‚ã€æœ€ã‚‚è¿‘ã„é…åˆ—/ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç¥–å…ˆãƒãƒ¼ãƒ‰ã«
            1å›ã ã‘é©ç”¨ã•ã‚Œã‚‹ï¼ˆã‚¹ã‚«ãƒ©ã«ã¯é©ç”¨ã•ã‚Œãªã„ï¼‰ã“ã¨ã‚’æ¤œè¨¼ã€‚"""
            tr_py = tmp_path / "wild_deep_funcs.py"
            tr_py.write_text(
                (
                    "def tag_node(value):\n"
                    "    # dict/list ã®ã¿ã«é©ç”¨ã•ã‚Œã‚‹å‰æ\n"
                    "    return {'__tag__': 'OK', 'type': ('dict' if isinstance(value, dict) else 'list')}\n"
                ),
                encoding="utf-8",
            )

            rules = xlsx2json.parse_array_transform_rules(
                [f"json.root.*.*=function:{tr_py}:tag_node"], prefix="json", schema=None, trim_enabled=False
            )

            result = xlsx2json.parse_named_ranges_with_prefix(
                wildcard_objarr_xlsx,
                prefix="json",
                array_transform_rules=rules,
            )

            assert "root" in result
            assert result["root"]["a"]["__tag__"] == "OK"
            assert result["root"]["a"]["type"] == "dict"
            assert result["root"]["b"]["__tag__"] == "OK"
            assert result["root"]["b"]["type"] == "list"

        def test_wildcard_segment_partial_match_items(self, tmp_path, wildcard_objarr_xlsx):
            """json.root.*items.* ã®ã‚ˆã†ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã§ã‚‚ã€
            line_items é…ä¸‹ã§ç¥–å…ˆã®é…åˆ—ãƒãƒ¼ãƒ‰ã«é©ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼ã€‚"""
            tr_py = tmp_path / "wild_seg_funcs.py"
            tr_py.write_text(
                (
                    "def mark_list(value):\n"
                    "    assert isinstance(value, list)\n"
                    "    return ['MARKED']\n"
                ),
                encoding="utf-8",
            )

            rules = xlsx2json.parse_array_transform_rules(
                [f"json.root.*items.*=function:{tr_py}:mark_list"], prefix="json", schema=None, trim_enabled=False
            )

            result = xlsx2json.parse_named_ranges_with_prefix(
                wildcard_objarr_xlsx,
                prefix="json",
                array_transform_rules=rules,
            )

            assert "root" in result
            assert result["root"]["line_items"] == ["MARKED"], "é…åˆ—ãƒãƒ¼ãƒ‰è‡ªä½“ãŒç½®æ›ã•ã‚Œã‚‹ã¹ã"

        def test_wildcard_transform_dict_return_replaces_node(self, tmp_path, wildcard_objarr_xlsx):
            """è¾æ›¸ã‚’è¿”ã™ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰å¤‰æ›ã¯ã‚­ãƒ¼å±•é–‹ã›ãšã€å¯¾è±¡ãƒãƒ¼ãƒ‰è‡ªä½“ã‚’ç½®æ›ã™ã‚‹ã€‚

            æœŸå¾…æŒ™å‹•ï¼ˆREADMEå¥‘ç´„ï¼‰:
            - å¤‰æ›é–¢æ•°ãŒ dict ã‚’è¿”ã—ãŸå ´åˆã€ãƒ‘ã‚¹ã«ä¸€è‡´ã—ãŸãƒãƒ¼ãƒ‰ã¯ãã® dict ã§ç½®æ›ã•ã‚Œã‚‹
            - æˆ»ã‚Šå€¤ dict ã®ã‚­ãƒ¼ã«ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚„ãƒ‰ãƒƒãƒˆãŒå«ã¾ã‚Œã¦ã‚‚ã€çµ¶å¯¾/ç›¸å¯¾ã‚­ãƒ¼å±•é–‹ã¯è¡Œã‚ãªã„
            """
            # å¤‰æ›é–¢æ•°: dict ã‚’è¿”ã™
            tr_py = tmp_path / "wild_dict_replace.py"
            tr_py.write_text(
                (
                    "def wrap(value):\n"
                    "    # value ã¯ dict/list/scalar ã„ãšã‚Œã‚‚æ¥å¾—ã‚‹ãŒã€ãã®ã¾ã¾åŒ…ã‚“ã§è¿”ã™\n"
                    "    return {'wrapped': value, 'note': 'no-expand'}\n"
                ),
                encoding="utf-8",
            )

            # ãƒ«ãƒ¼ãƒ«: json.root.* ã« wrap ã‚’é©ç”¨ï¼ˆa:dict, b:list, line_items:list ã®å„ãƒãƒ¼ãƒ‰ãŒå¯¾è±¡ï¼‰
            rules = xlsx2json.parse_array_transform_rules(
                [f"json.root.*=function:{tr_py}:wrap"], prefix="json", schema=None, trim_enabled=False
            )

            result = xlsx2json.parse_named_ranges_with_prefix(
                wildcard_objarr_xlsx,
                prefix="json",
                array_transform_rules=rules,
            )

            # ç½®æ›ã®æ¤œè¨¼
            assert "root" in result
            assert isinstance(result["root"]["a"], dict)
            assert set(result["root"]["a"].keys()) == {"wrapped", "note"}
            assert result["root"]["a"]["note"] == "no-expand"

            assert isinstance(result["root"]["b"], dict)
            assert set(result["root"]["b"].keys()) == {"wrapped", "note"}
            assert isinstance(result["root"]["b"]["wrapped"], list)

            assert isinstance(result["root"]["line_items"], dict)
            assert set(result["root"]["line_items"].keys()) == {"wrapped", "note"}

            # è¿”ã‚Šå€¤ã®ã‚­ãƒ¼ãŒãƒˆãƒƒãƒ—ã«å±•é–‹ã•ã‚Œã¦ã„ãªã„ã“ã¨ï¼ˆä¾‹: 'wrapped' ã‚„ 'note' ãŒ root ç›´ä¸‹ã«ç¾ã‚Œãªã„ï¼‰
            assert "wrapped" not in result
            assert "note" not in result

    # === åå‰ä»˜ãç¯„å›²ã®æ ¸å¿ƒå‡¦ç†ãƒ†ã‚¹ãƒˆ ===

    def test_extract_basic_data_types(self, basic_xlsx):
        """åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹ã®æŠ½å‡ºã¨å¤‰æ›ç¢ºèª

        Excelåå‰ä»˜ãç¯„å›²ã‹ã‚‰æ–‡å­—åˆ—ã€æ•°å€¤ã€çœŸå½å€¤ã€æ—¥æ™‚ã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã€
        é©åˆ‡ãªPythonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        # æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿å‹ã®æ¤œè¨¼
        assert result["customer"]["name"] == "å±±ç”°å¤ªéƒ"
        assert result["customer"]["address"] == "æ±äº¬éƒ½æ¸‹è°·åŒº"

        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿å‹ã®æ¤œè¨¼
        assert result["numbers"]["integer"] == 123
        assert result["numbers"]["float"] == 45.67

        # çœŸå½å€¤ãƒ‡ãƒ¼ã‚¿å‹ã®æ¤œè¨¼
        assert result["flags"]["enabled"] is True
        assert result["flags"]["disabled"] is False

        # æ—¥æ™‚å‹ã®æ¤œè¨¼ï¼ˆdatetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å–å¾—ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
        assert isinstance(result["datetime"], datetime)
        assert isinstance(result["date"], date)

    def test_build_nested_json_structure(self, basic_xlsx):
        """ãƒã‚¹ãƒˆã—ãŸJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®æ§‹ç¯‰

        ãƒ‰ãƒƒãƒˆè¨˜æ³•ã®åå‰ä»˜ãç¯„å›²ã‹ã‚‰éšå±¤çš„ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒ
        æ­£ã—ãæ§‹ç¯‰ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æƒ…å ±ã®ãƒã‚¹ãƒˆæ§‹é€ 
        assert "customer" in result
        assert isinstance(result["customer"], dict)
        assert result["customer"]["name"] == "å±±ç”°å¤ªéƒ"

        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¹ãƒˆæ§‹é€ 
        assert "numbers" in result
        assert isinstance(result["numbers"], dict)
        assert result["numbers"]["integer"] == 123

        # æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã®ç¢ºèª
        deep_value = result["deep"]["level1"]["level2"]["level3"]["value"]
        assert deep_value == "æ·±ã„éšå±¤ã®ãƒ†ã‚¹ãƒˆ"

        deep_value2 = result["deep"]["level1"]["level2"]["level4"]["value"]
        assert deep_value2 == "ã•ã‚‰ã«æ·±ã„å€¤"

    def test_construct_array_structures(self, basic_xlsx):
        """é…åˆ—æ§‹é€ ã®è‡ªå‹•æ§‹ç¯‰

        æ•°å€¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æŒã¤åå‰ä»˜ãç¯„å›²ã‹ã‚‰é…åˆ—ãŒæ­£ã—ãæ§‹ç¯‰ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        # é…åˆ—æ§‹é€ ã®ç¢ºèª
        items = result["items"]
        assert isinstance(items, list)
        assert len(items) == 2

        # 1ç•ªç›®ã®ã‚¢ã‚¤ãƒ†ãƒ 
        assert items[0]["name"] == "å±±ç”°å¤ªéƒ"
        assert items[0]["price"] == 123

        # 2ç•ªç›®ã®ã‚¢ã‚¤ãƒ†ãƒ 
        assert items[1]["name"] == "æ±äº¬éƒ½æ¸‹è°·åŒº"
        assert items[1]["price"] == 45.67

    def test_handle_empty_and_null_values(self, basic_xlsx):
        """ç©ºå€¤ã¨NULLå€¤ã®é©åˆ‡ãªå‡¦ç†

        Excelã®ç©ºã‚»ãƒ«ã€NULLå€¤ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        # åŸºæœ¬çš„ãªçµæœã®å­˜åœ¨ã‚’ãƒ†ã‚¹ãƒˆ
        assert isinstance(result, dict)
        assert len(result) > 0

    def test_custom_prefix_support(self, temp_dir):
        """ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

        æŒ‡å®šã—ãŸãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»¥å¤–ã®åå‰ä»˜ãç¯„å›²ãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ç”¨ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        workbook = Workbook()
        worksheet = workbook.active
        worksheet.title = "Sheet1"
        set_cells(worksheet, {"A1": "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ"})

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§åå‰ä»˜ãç¯„å›²ã‚’å®šç¾©
        set_defined_names(workbook, {"custom.test.value": "A1"})

        custom_file = temp_dir / "custom_prefix.xlsx"
        workbook.save(custom_file)

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§è§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(custom_file, prefix="custom")

        assert result["test"]["value"] == "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ"

    def test_single_cell_vs_range_extraction(self, temp_dir):
        """å˜ä¸€ã‚»ãƒ«ã¨ç¯„å›²ã®å€¤æŠ½å‡ºã®åŒºåˆ¥

        åå‰ä»˜ãç¯„å›²ãŒå˜ä¸€ã‚»ãƒ«ã‹ç¯„å›²ã‹ã«ã‚ˆã£ã¦é©åˆ‡ãªå½¢å¼ã§å€¤ãŒè¿”ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        workbook = Workbook()
        worksheet = workbook.active
        worksheet.title = "Sheet1"
        set_cells(
            worksheet,
            {
                "A1": "single_value",
                "B1": "range_value1",
                "B2": "range_value2",
            },
        )
        set_defined_names(
            workbook,
            {
                "single_cell": "A1",
                "cell_range": "B1:B2",
            },
        )
        test_file = temp_dir / "range_test.xlsx"
        workbook.save(test_file)

        # ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿
        wb = xlsx2json.load_workbook(test_file, data_only=True)

        # å˜ä¸€ã‚»ãƒ«ã¯å€¤ã®ã¿è¿”ã™ã“ã¨ã‚’ç¢ºèª
        single_name_def = wb.defined_names["single_cell"]
        single_result = xlsx2json.get_named_range_values(wb, single_name_def)
        assert single_result == "single_value"
        assert not isinstance(single_result, list)

        # ç¯„å›²ã¯ãƒªã‚¹ãƒˆã§è¿”ã™ã“ã¨ã‚’ç¢ºèª
        range_name_def = wb.defined_names["cell_range"]
        range_result = xlsx2json.get_named_range_values(wb, range_name_def)
        assert isinstance(range_result, list)
        assert range_result == ["range_value1", "range_value2"]

    def test_multidimensional_array_construction(self, complex_xlsx):
        """å¤šæ¬¡å…ƒé…åˆ—ã®æ§‹ç¯‰ï¼ˆsamplesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä»•æ§˜æº–æ‹ ï¼‰

        ãƒ‰ãƒƒãƒˆè¨˜æ³•ã«ã‚ˆã‚‹å¤šæ¬¡å…ƒé…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰é©åˆ‡ãªæ§‹é€ ãŒæ§‹ç¯‰ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        result = xlsx2json.parse_named_ranges_with_prefix(complex_xlsx, prefix="json")

        # å¤šæ¬¡å…ƒé…åˆ—ã®ç¢ºèª
        parent = result["parent"]
        assert isinstance(parent, list)
        assert len(parent) == 3

        # å„æ¬¡å…ƒã®ç¢ºèª
        assert isinstance(parent[0], list)
        assert len(parent[0]) == 2

        # å…·ä½“çš„ãªå€¤ã®ç¢ºèªï¼ˆå®Ÿéš›ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãï¼‰
        assert parent[0][0] == "G2"  # F1ã‚»ãƒ«ã®å€¤
        # F2ã‚»ãƒ«ã¯è¤‡æ•°è¡Œãƒ‡ãƒ¼ã‚¿ãªã®ã§æ–‡å­—åˆ—ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹
        assert isinstance(parent[0][1], str)
        assert parent[1][0] == "G3a1,G3b1\nG3a2"  # G1ã‚»ãƒ«ã®å€¤

    def test_parent_split_transform_to_4d(self, complex_xlsx, schema_file):
        """parent ã« split:\n|, ã‚’é©ç”¨ã—ãŸéš›ã« 4æ¬¡å…ƒé…åˆ—å½¢çŠ¶ã«ãªã‚‹ã“ã¨"""
        # å¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆï¼ˆã‚µãƒ³ãƒ—ãƒ« config.yaml ã¨åŒã˜æŒ‡å®šï¼‰
        with open(schema_file, "r", encoding="utf-8") as f:
            schema = json.load(f)
        rules = xlsx2json.parse_array_transform_rules(
            ["json.parent=split:\n|,"], prefix="json", schema=schema, trim_enabled=False
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            complex_xlsx,
            prefix="json",
            array_transform_rules=rules,
            schema=schema,
        )

        parent = result["parent"]
        # æœŸå¾…ã•ã‚Œã‚‹4æ¬¡å…ƒé…åˆ—ï¼ˆè¡ŒÃ—åˆ—Ã—ã‚»ãƒ«å†…è¡ŒÃ—ã‚»ãƒ«å†…åˆ—ï¼‰
        expected = [
            [
                [["G2"]],
                [["H2a1", "H2b1"], ["H2a2", "H2b2"]],
            ],
            [
                [["G3a1", "G3b1"], ["G3a2"]],
                [["H3a1"], ["H3a2"]],
            ],
            [
                [["H5"]],
            ],
        ]

        assert parent == expected

    def test_parse_named_ranges_enhanced_validation(self):
        """parse_named_ranges_with_prefixé–¢æ•°ã®æ‹¡å¼µãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ
            nonexistent_file = temp_path / "nonexistent.xlsx"
            with pytest.raises(
                FileNotFoundError, match="Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            ):
                xlsx2json.parse_named_ranges_with_prefix(nonexistent_file, "json")

            # æ–‡å­—åˆ—ãƒ‘ã‚¹ã§ã‚‚å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            test_file = temp_path / "test.xlsx"
            wb = Workbook()
            wb.save(test_file)

            # æ–‡å­—åˆ—ãƒ‘ã‚¹ã§å‘¼ã³å‡ºã—
            result = xlsx2json.parse_named_ranges_with_prefix(str(test_file), "json")
            assert isinstance(result, dict)

            # ç©ºã®prefixã®ãƒ†ã‚¹ãƒˆ
            with pytest.raises(
                ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            ):
                xlsx2json.parse_named_ranges_with_prefix(test_file, "")

    def test_error_handling_integration(self):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # æ­£å¸¸ãªExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            test_file = temp_path / "test.xlsx"
            wb = Workbook()
            ws = wb.active
            set_cells(ws, {"A1": "test_value"})
            # åå‰ä»˜ãç¯„å›²ã‚’è¿½åŠ 
            set_defined_names(wb, {"json.test": "A1"})
            wb.save(test_file)

            # æ­£å¸¸ãªã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ
            result = xlsx2json.parse_named_ranges_with_prefix(test_file, "json")
            assert "test" in result
            assert result["test"] == "test_value"

            # ç„¡åŠ¹ãªprefixã§ã‚¨ãƒ©ãƒ¼
            with pytest.raises(
                ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            ):
                xlsx2json.parse_named_ranges_with_prefix(test_file, None)

    # === Containeræ©Ÿèƒ½ï¼šExcelç¯„å›²è§£æãƒ»åº§æ¨™è¨ˆç®—ãƒ†ã‚¹ãƒˆ ===

    def test_excel_range_parsing_basic(self):
        """åŸºæœ¬çš„ãªExcelç¯„å›²æ–‡å­—åˆ—ã®è§£æãƒ†ã‚¹ãƒˆ"""
        start_coord, end_coord = xlsx2json.parse_range("B2:D4")
        assert start_coord == (2, 2)  # Båˆ—=2, 2è¡Œç›®
        assert end_coord == (4, 4)  # Dåˆ—=4, 4è¡Œç›®

    def test_excel_range_parsing_single_cell(self):
        """å˜ä¸€ã‚»ãƒ«æŒ‡å®šã®æ­£å¸¸å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        start_coord, end_coord = xlsx2json.parse_range("A1:A1")
        assert start_coord == (1, 1)
        assert end_coord == (1, 1)

    def test_excel_range_parsing_large_range(self):
        """å¤§ããªç¯„å›²æŒ‡å®šã§ã®åº§æ¨™å¤‰æ›ç²¾åº¦ãƒ†ã‚¹ãƒˆ"""
        start_coord, end_coord = xlsx2json.parse_range("A1:Z100")
        assert start_coord == (1, 1)
        assert end_coord == (26, 100)  # Zåˆ—=26

    def test_excel_range_parsing_error_handling(self):
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã§èµ·ã“ã‚Šã†ã‚‹ä¸æ­£ãªç¯„å›²æŒ‡å®šã®ã‚¨ãƒ©ãƒ¼å‡¦ç†"""
        with pytest.raises(ValueError, match="ç„¡åŠ¹ãªç¯„å›²å½¢å¼"):
            xlsx2json.parse_range("INVALID")

        with pytest.raises(ValueError, match="ç„¡åŠ¹ãªç¯„å›²å½¢å¼"):
            xlsx2json.parse_range("A1-B2")  # ã‚³ãƒ­ãƒ³ãŒå¿…è¦

    def test_generated_names_basic(self):
        """GeneratedNamesã‚¯ãƒ©ã‚¹ã®åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()

        # initially empty
        gm0 = xlsx2json.get_generated_names_map(wb)
        assert gm0 == {}

        # set a generated name via public helper
        xlsx2json.set_generated_name(wb, "json.foo", "Sheet1!A1")
        gm1 = xlsx2json.get_generated_names_map(wb)
        assert gm1["json.foo"] == "Sheet1!A1"

        # wrapper direct access
        gn = xlsx2json.GeneratedNames.for_workbook(wb)
        assert gn.get("json.foo") == "Sheet1!A1"
        keys = list(gn.iter_keys())
        assert "json.foo" in keys

        # overwrite
        xlsx2json.set_generated_name(wb, "json.foo", "Sheet1!B2")
        assert gn.get("json.foo") == "Sheet1!B2"

        # empty name is ignored
        xlsx2json.set_generated_name(wb, "", "X")
        assert "" not in list(gn.iter_keys())


class TestRectChain:
    """RectChainã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

    def test_as_tuple_and_dimensions(self):
        """as_tuple, width, heightãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆ"""
        rc = xlsx2json.RectChain(top=2, left=3, bottom=5, right=7)
        # as_tuple should return (left, top, right, bottom)
        assert rc.as_tuple() == (3, 2, 7, 5)
        assert rc.width() == 5  # 7-3+1
        assert rc.height() == 4  # 5-2+1

    def test_intersects_and_contains(self):
        """intersects, containsãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆ"""
        a = xlsx2json.RectChain(top=1, left=1, bottom=3, right=3)
        b = xlsx2json.RectChain(top=3, left=3, bottom=5, right=5)
        c = xlsx2json.RectChain(top=4, left=4, bottom=6, right=6)
        # a and b intersect at a single corner/edge
        assert a.intersects(b)
        assert not a.intersects(c)
        # contains: row, col order for contains arguments
        assert a.contains(row=2, col=2)
        assert not a.contains(row=4, col=4)


class TestComplexData:
    """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ãƒ†ã‚¹ãƒˆ"""

    def test_complex_transform_rule_conflicts(self):
        """è¤‡é›‘ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ç«¶åˆã¨å„ªå…ˆåº¦ãƒ†ã‚¹ãƒˆ"""
        # è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ
        wb = Workbook()
        ws = wb.active
        ws.title = "TestData"

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è¨­å®š
        set_cells(
            ws,
            {
                "A1": "data1,data2,data3",  # splitå¯¾è±¡
                "B1": "100",  # intå¤‰æ›å¯¾è±¡
                "C1": "true",  # boolå¤‰æ›å¯¾è±¡
                "D1": "2023-12-01",  # dateå¤‰æ›å¯¾è±¡
            },
        )
        # åå‰ä»˜ãç¯„å›²ã®è¨­å®š
        set_defined_names(wb, {"json.test_data": "A1:D1"}, default_sheet=ws.title)

        temp_file = create_temp_excel(wb)
        try:
            # çµæœã‚’å–å¾—ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ãªãç›´æ¥è§£æï¼‰
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # çµæœã®æ¤œè¨¼ï¼ˆåŸºæœ¬çš„ãªå¤‰æ›ãŒè¡Œã‚ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
            assert "test_data" in result
            test_data = result["test_data"]
            # parse_named_ranges_with_prefixã¯ç¯„å›²ã®å€¤ã‚’å¹³å¦åŒ–ã—ã¦è¿”ã™
            assert len(test_data) == 4  # A1:D1ã®4ã¤ã®ã‚»ãƒ«
            assert test_data[0] == "data1,data2,data3"
            assert test_data[1] == "100"
            assert test_data[2] == "true"
            assert test_data[3] == "2023-12-01"
        finally:
            os.unlink(temp_file)

    def test_deeply_nested_json_paths(self):
        """æ·±ã„ãƒã‚¹ãƒˆã®JSONãƒ‘ã‚¹ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        set_cells(
            ws,
            {
                "A1": "level1_data",
                "B1": "level2_data",
                "C1": "level3_data",
                "D1": "level4_data",
            },
        )

        # åå‰ä»˜ãç¯„å›²ã®è¨­å®š
        set_defined_names(wb, {"json.nested_data": "A1:D1"}, default_sheet=ws.title)

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç¢ºèª
            assert "nested_data" in result
            nested_data = result["nested_data"]
            # ç¯„å›²A1:D1ã®4ã¤ã®ã‚»ãƒ«ã®å€¤ãŒå¹³å¦åŒ–ã•ã‚Œã‚‹
            assert isinstance(nested_data, list)
            assert len(nested_data) == 4
            assert nested_data[0] == "level1_data"
            assert nested_data[1] == "level2_data"
            assert nested_data[2] == "level3_data"
            assert nested_data[3] == "level4_data"
        finally:
            os.unlink(temp_file)

    def test_error_recovery_scenarios(self):
        """ã‚¨ãƒ©ãƒ¼å›å¾©ã‚·ãƒŠãƒªã‚ªã®ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # ä¸€éƒ¨ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        set_cells(
            ws,
            {
                "A1": "valid_data",
                "B1": "not_a_number",  # æ•°å€¤å¤‰æ›ã§å¤±æ•—ã™ã‚‹
                "C1": "2023-13-40",  # ç„¡åŠ¹ãªæ—¥ä»˜
                "A2": "valid_data2",
                "B2": "123",  # æœ‰åŠ¹ãªæ•°å€¤
                "C2": "2023-12-01",  # æœ‰åŠ¹ãªæ—¥ä»˜
            },
        )
        # åå‰ä»˜ãç¯„å›²ã®è¨­å®š
        set_defined_names(wb, {"json.mixed_data": "A1:C2"})

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å›å¾©ã®ç¢ºèª
            assert "mixed_data" in result
            mixed_data = result["mixed_data"]
            # 2x3ã®ç¯„å›²ãªã®ã§6å€‹ã®ã‚»ãƒ«å€¤ãŒå¹³å¦åŒ–ã•ã‚Œã‚‹
            assert len(mixed_data) == 6

            # ãƒ‡ãƒ¼ã‚¿ã®é †åºç¢ºèªï¼ˆè¡Œå„ªå…ˆã§å¹³å¦åŒ–ã•ã‚Œã‚‹ï¼‰
            expected_values = [
                "valid_data",
                "not_a_number",
                "2023-13-40",
                "valid_data2",
                "123",
                "2023-12-01",
            ]
            for i, expected in enumerate(expected_values):
                assert mixed_data[i] == expected, f"ä½ç½®{i}ã®ãƒ‡ãƒ¼ã‚¿ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™"

        finally:
            os.unlink(temp_file)

    def test_complex_wildcard_patterns(self):
        """è¤‡é›‘ãªãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # è¤‡é›‘ãªãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
        set_cells(
            ws,
            {
                "A1": "item_001",
                "B1": "item_002",
                "C1": "special_item",
                "A2": "item_003",
                "B2": "item_004",
                "C2": "another_special",
            },
        )

        # è¤‡æ•°ã®åå‰ä»˜ãç¯„å›²ã§ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ†ã‚¹ãƒˆ
        set_defined_names(
            wb,
            {
                "json.prefix.item.1": "A1",
                "json.prefix.item.2": "B1",
                "json.prefix.special.main": "C1",
                "json.other.item.3": "A2",
            },
        )

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å±•é–‹ç¢ºèª
            assert "prefix" in result
            assert "other" in result

            # prefixé…ä¸‹ã®æ§‹é€ ç¢ºèª
            prefix = result["prefix"]
            assert "item" in prefix
            assert "special" in prefix

            # itemé…ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª
            items = prefix["item"]
            assert "1" in items or len(items) >= 1
            assert "2" in items or len(items) >= 2

        finally:
            os.unlink(temp_file)

    def test_unicode_and_special_characters(self):
        """Unicodeæ–‡å­—ã¨ç‰¹æ®Šæ–‡å­—ã®ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # æ§˜ã€…ãªUnicodeæ–‡å­—ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        unicode_data = [
            "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ",  # æ—¥æœ¬èª
            "ğŸŒğŸŒğŸŒ",  # çµµæ–‡å­—
            "HÃ¤llo WÃ¶rld",  # ã‚¦ãƒ ãƒ©ã‚¦ãƒˆ
            "Ğ—Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹ Ğ¼Ğ¸Ñ€",  # ã‚­ãƒªãƒ«æ–‡å­—
            "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…",  # ã‚¢ãƒ©ãƒ“ã‚¢æ–‡å­—
            "ğ“—ğ“®ğ“µğ“µğ“¸ ğ“¦ğ“¸ğ“»ğ“µğ“­",  # æ•°å­¦æ–‡å­—
            '"quotes"',  # ã‚¯ã‚©ãƒ¼ãƒˆ
            "line\nbreak",  # æ”¹è¡Œ
            "tab\there",  # ã‚¿ãƒ–
        ]

        for i, data in enumerate(unicode_data, 1):
            ws.cell(row=i, column=1, value=data)

        # åå‰ä»˜ãç¯„å›²ã®è¨­å®š
        set_defined_names(wb, {"json.unicode_test": f"A1:A{len(unicode_data)}"})

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # Unicodeæ–‡å­—ã®æ­£ã—ã„å‡¦ç†ç¢ºèª
            assert "unicode_test" in result
            unicode_result = result["unicode_test"]
            # 9è¡Œx1åˆ—ã®ç¯„å›²ãªã®ã§9å€‹ã®å€¤ãŒè¿”ã•ã‚Œã‚‹
            assert len(unicode_result) == len(unicode_data)

            # å„æ–‡å­—ã®æ­£ç¢ºæ€§ç¢ºèªï¼ˆå¹³å¦åŒ–ã•ã‚Œã¦ã„ã‚‹ã®ã§ç›´æ¥æ¯”è¼ƒï¼‰
            for i, expected in enumerate(unicode_data):
                assert (
                    unicode_result[i] == expected
                ), f"Unicodeæ–‡å­—ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œã¦ã„ã¾ã›ã‚“: {expected}"

        finally:
            os.unlink(temp_file)

    def test_edge_case_cell_values(self):
        """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãªã‚»ãƒ«å€¤ã®ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãªãƒ‡ãƒ¼ã‚¿
        edge_cases = [
            None,  # Noneã‚»ãƒ«
            "",  # ç©ºæ–‡å­—åˆ—
            " ",  # ã‚¹ãƒšãƒ¼ã‚¹ã®ã¿
            0,  # ã‚¼ãƒ­
            False,  # False
            True,  # True
            float("inf"),  # ç„¡é™å¤§
            -float("inf"),  # è² ã®ç„¡é™å¤§
            1e-10,  # éå¸¸ã«å°ã•ãªæ•°
            1e10,  # éå¸¸ã«å¤§ããªæ•°
            "0",  # æ–‡å­—åˆ—ã®ã‚¼ãƒ­
            "False",  # æ–‡å­—åˆ—ã®False
            " \t\n ",  # ç©ºç™½æ–‡å­—ã®ã¿
        ]

        for i, value in enumerate(edge_cases, 1):
            try:
                ws.cell(row=i, column=1, value=value)
            except (ValueError, TypeError):
                # è¨­å®šã§ããªã„å€¤ã¯æ–‡å­—åˆ—ã¨ã—ã¦è¨­å®š
                ws.cell(row=i, column=1, value=str(value))

        # åå‰ä»˜ãç¯„å›²ã®è¨­å®š
        set_defined_names(wb, {"json.edge_cases": f"A1:A{len(edge_cases)}"})

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, "json")
            assert "edge_cases" in result

            # æ—©æœŸãƒ•ãƒ«ã‚¯ãƒªãƒ¼ãƒ³å¾©æ´»ä»•æ§˜: ç©º/ç©ºç™½ã®ã¿ã‚»ãƒ«ã¯é™¤å»ã•ã‚Œ 7 ä»¶ä¿æŒ
            assert len(result["edge_cases"]) == 7

        finally:
            os.unlink(temp_file)

    # === Containeræ©Ÿèƒ½ï¼šæ§‹é€ è§£æãƒ»ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ¤œå‡ºãƒ†ã‚¹ãƒˆ ===

    def test_container_structure_vertical_analysis(self):
        """ç¸¦æ–¹å‘ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        start_coord = (2, 2)  # B2
        end_coord = (4, 4)  # D4

        # row direction: è¡Œæ•°ã‚’æ•°ãˆã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰è¡Œæ•°ï¼‰
        count = xlsx2json.detect_instance_count(start_coord, end_coord, "row")
        assert count == 3  # 2,3,4è¡Œç›® = 3ãƒ¬ã‚³ãƒ¼ãƒ‰

    def test_container_structure_horizontal_analysis(self):
        """æ¨ªæ–¹å‘ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        start_coord = (2, 2)  # B2
        end_coord = (4, 4)  # D4

        # column direction: åˆ—æ•°ã‚’æ•°ãˆã‚‹ï¼ˆæœŸé–“æ•°ï¼‰
        count = xlsx2json.detect_instance_count(start_coord, end_coord, "column")
        assert count == 3  # B,C,Dåˆ— = 3æœŸé–“

    def test_container_structure_single_record(self):
        """å˜ä¸€ãƒ¬ã‚³ãƒ¼ãƒ‰æ§‹é€ ã®æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        count = xlsx2json.detect_instance_count((1, 1), (1, 1), "row")
        assert count == 1

    def test_container_structure_invalid_direction(self):
        """ç„¡åŠ¹ãªé…ç½®æ–¹å‘ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        with pytest.raises(ValueError, match="ç„¡åŠ¹ãªdirection"):
            xlsx2json.detect_instance_count((1, 1), (2, 2), "invalid")

    def test_container_structure_column_analysis(self):
        """åˆ—æ–¹å‘ï¼ˆcolumnï¼‰æ§‹é€ ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        start_coord = (2, 2)  # B2
        end_coord = (4, 4)  # D4

        # column direction: åˆ—æ•°ã‚’æ•°ãˆã‚‹ï¼ˆhorizontal ã¨åŒã˜å‹•ä½œï¼‰
        count = xlsx2json.detect_instance_count(start_coord, end_coord, "column")
        assert count == 3  # B,C,Dåˆ— = 3åˆ—

    # === Containeræ©Ÿèƒ½ï¼šãƒ‡ãƒ¼ã‚¿å‡¦ç†çµ±åˆãƒ†ã‚¹ãƒˆ ===

    def test_dataset_processing_complete_workflow(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†ã®å…¨ä½“ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # ã‚³ãƒ³ãƒ†ãƒŠè¨­å®šï¼ˆrangeã¯è¨­å®šé …ç›®ã§ã¯ãªã„ï¼labelsã¯é…åˆ—ã¾ãŸã¯ç©ºé…åˆ—ï¼‰
        container_config = {
            "direction": "row",
            "items": ["æ—¥ä»˜", "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£", "å€¤"],
            "labels": [],
        }
        # ç¯„å›²ã¯ãƒ†ã‚¹ãƒˆå†…ã®ãƒ­ãƒ¼ã‚«ãƒ«å€¤ã¨ã—ã¦æ‰±ã†
        range_str = "B2:D4"

        # Step 1: Excelç¯„å›²è§£æ
        start_coord, end_coord = xlsx2json.parse_range(range_str)
        assert start_coord == (2, 2)
        assert end_coord == (4, 4)

        # Step 2: ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°æ¤œå‡º
        record_count = xlsx2json.detect_instance_count(
            start_coord, end_coord, container_config["direction"]
        )
        assert record_count == 3

        # Step 3: ãƒ‡ãƒ¼ã‚¿ç”¨ã‚»ãƒ«åç”Ÿæˆ
        cell_names = xlsx2json.generate_cell_names(
            "dataset",
            start_coord,
            end_coord,
            container_config["direction"],
            container_config["items"],
        )
        assert len(cell_names) == 9  # 3ãƒ¬ã‚³ãƒ¼ãƒ‰ x 3é …ç›®

        # Step 4: ãƒ‡ãƒ¼ã‚¿JSONæ§‹é€ æ§‹ç¯‰
        result = {}

        # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        xlsx2json.insert_json_path(
            result, ["ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«", "ã‚¿ã‚¤ãƒˆãƒ«"], "æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿å®Ÿç¸¾"
        )

        # ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰
        test_data = {
            "dataset_1_æ—¥ä»˜": "2024-01-15",
            "dataset_1_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£": "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£A",
            "dataset_1_å€¤": 150000,
            "dataset_2_æ—¥ä»˜": "2024-01-20",
            "dataset_2_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£": "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£B",
            "dataset_2_å€¤": 200000,
            "dataset_3_æ—¥ä»˜": "2024-01-25",
            "dataset_3_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£": "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£C",
            "dataset_3_å€¤": 180000,
        }

        for cell_name in cell_names:
            if cell_name in test_data:
                xlsx2json.insert_json_path(result, [cell_name], test_data[cell_name])

        # æŠ€è¡“è¦ä»¶æ¤œè¨¼
        assert "ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«" in result
        assert result["ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"]["ã‚¿ã‚¤ãƒˆãƒ«"] == "æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿å®Ÿç¸¾"
        assert result["dataset_1_æ—¥ä»˜"] == "2024-01-15"
        assert result["dataset_2_å€¤"] == 200000

    def test_multi_table_data_integration(self):
        """è¤‡æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»ãƒªã‚¹ãƒˆï¼‰ã®çµ±åˆãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # rangeã¯è¨­å®šé …ç›®ã§ã¯ãªã„ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿æŒ
        tables = {
            "dataset": {
                "range_str": "A1:B2",
                "direction": "row",
                "items": ["æœˆ", "å€¤"],
            },
            "list": {
                "range_str": "D1:E2",
                "direction": "row",
                "items": ["é …ç›®", "æ•°é‡"],
            },
        }

        result = {}

        for table_name, config in tables.items():
            start_coord, end_coord = xlsx2json.parse_range(config["range_str"])
            cell_names = xlsx2json.generate_cell_names(
                table_name, start_coord, end_coord, config["direction"], config["items"]
            )

            # ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
            for i, cell_name in enumerate(cell_names):
                xlsx2json.insert_json_path(
                    result, [cell_name], f"{table_name}ãƒ‡ãƒ¼ã‚¿{i+1}"
                )

        # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãçµ±åˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert "dataset_1_æœˆ" in result
        assert "dataset_2_å€¤" in result
        assert "list_1_é …ç›®" in result
        assert "list_2_æ•°é‡" in result

        # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç‹¬ç«‹æ€§ç¢ºèª
        assert result["dataset_1_æœˆ"] == "datasetãƒ‡ãƒ¼ã‚¿1"
        assert result["list_1_é …ç›®"] == "listãƒ‡ãƒ¼ã‚¿1"

    def test_data_card_layout_workflow(self):
        """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚«ãƒ¼ãƒ‰å‹ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
        # ã‚«ãƒ¼ãƒ‰å‹ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
        card_config = {
            "direction": "row",
            "increment": 5,  # ã‚«ãƒ¼ãƒ‰é–“éš”
            "items": ["ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å", "è­˜åˆ¥å­", "ä½æ‰€"],
            "labels": [],
        }
        range_str = "A1:A3"

        start_coord, end_coord = xlsx2json.parse_range(range_str)
        entity_count = xlsx2json.detect_instance_count(
            start_coord, end_coord, card_config["direction"]
        )

        cell_names = xlsx2json.generate_cell_names(
            "entity",
            start_coord,
            end_coord,
            card_config["direction"],
            card_config["items"],
        )

        result = {}

        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
        entity_data = {
            "entity_1_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å": "å±±ç”°å¤ªéƒ",
            "entity_1_è­˜åˆ¥å­": "03-1234-5678",
            "entity_1_ä½æ‰€": "æ±äº¬éƒ½",
            "entity_2_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å": "ä½è—¤èŠ±å­",
            "entity_2_è­˜åˆ¥å­": "06-9876-5432",
            "entity_2_ä½æ‰€": "å¤§é˜ªåºœ",
            "entity_3_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å": "ç”°ä¸­æ¬¡éƒ",
            "entity_3_è­˜åˆ¥å­": "052-1111-2222",
            "entity_3_ä½æ‰€": "æ„›çŸ¥çœŒ",
        }

        for cell_name in cell_names:
            if cell_name in entity_data:
                xlsx2json.insert_json_path(result, [cell_name], entity_data[cell_name])

        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§ç¢ºèª
        assert result["entity_1_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å"] == "å±±ç”°å¤ªéƒ"
        assert result["entity_2_è­˜åˆ¥å­"] == "06-9876-5432"
        assert result["entity_3_ä½æ‰€"] == "æ„›çŸ¥çœŒ"

    # === Containeræ©Ÿèƒ½ï¼šã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ ===

    def test_container_system_integration_comprehensive(self):
        """Excelç¯„å›²å‡¦ç†ã‹ã‚‰JSONçµ±åˆã¾ã§å…¨æ©Ÿèƒ½é€£æºãƒ†ã‚¹ãƒˆ"""
        # è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’åŒæ™‚å‡¦ç†ï¼ˆrange/nameã¯è¨­å®šé …ç›®ã§ã¯ãªã„ãŸã‚åˆ†é›¢ï¼‰
        test_cases = [
            {
                "container_name": "å£²ä¸Š",
                "range_str": "B2:D4",
                "config": {"direction": "row", "items": ["æ—¥ä»˜", "é¡§å®¢", "é‡‘é¡"]},
            },
            {
                "container_name": "inventory",
                "range_str": "F1:H2",
                "config": {
                    "direction": "row",
                    "items": ["ã‚¢ã‚¤ãƒ†ãƒ ã‚³ãƒ¼ãƒ‰", "ã‚¢ã‚¤ãƒ†ãƒ å", "æ•°é‡"],
                },
            },
        ]

        consolidated_result = {}

        for case in test_cases:
            # å„æ©Ÿèƒ½ã®é€£æºå‹•ä½œç¢ºèª
            start_coord, end_coord = xlsx2json.parse_range(case["range_str"])
            instance_count = xlsx2json.detect_instance_count(
                start_coord, end_coord, case["config"]["direction"]
            )
            cell_names = xlsx2json.generate_cell_names(
                case["container_name"],
                start_coord,
                end_coord,
                case["config"]["direction"],
                case["config"]["items"],
            )

            # ã‚·ã‚¹ãƒ†ãƒ çµ±åˆã§ã®æ­£å¸¸æ€§ç¢ºèª
            assert len(cell_names) == instance_count * len(case["config"]["items"])

            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŠ•å…¥
            for i, cell_name in enumerate(cell_names):
                xlsx2json.insert_json_path(
                    consolidated_result, [cell_name], f"çµ±åˆãƒ‡ãƒ¼ã‚¿{i+1}"
                )

        # çµ±åˆçµæœã®å¥å…¨æ€§ç¢ºèª
        assert "å£²ä¸Š_1_æ—¥ä»˜" in consolidated_result
        assert "inventory_1_ã‚¢ã‚¤ãƒ†ãƒ ã‚³ãƒ¼ãƒ‰" in consolidated_result
        assert len(consolidated_result) >= 12  # æœ€ä½é™ã®ãƒ‡ãƒ¼ã‚¿æ•°ç¢ºèª

    def test_container_error_recovery_and_data_integrity(self):
        """ç•°å¸¸ç³»ã§ã®å›å¾©åŠ›ã¨ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ä¿è¨¼ãƒ†ã‚¹ãƒˆ"""
        result = {}

        # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        xlsx2json.insert_json_path(result, ["æ­£å¸¸ãƒ‡ãƒ¼ã‚¿", "å€¤"], "OK")

        # ç•°å¸¸ç³»ãƒ‡ãƒ¼ã‚¿æŠ•å…¥è©¦è¡Œï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ä»–ã«å½±éŸ¿ã—ãªã„ã“ã¨ã‚’ç¢ºèªï¼‰
        try:
            xlsx2json.parse_range("INVALID_RANGE")
        except ValueError:
            # ã‚¨ãƒ©ãƒ¼å¾Œã‚‚æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒä¿æŒã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert result["æ­£å¸¸ãƒ‡ãƒ¼ã‚¿"]["å€¤"] == "OK"

        try:
            xlsx2json.detect_instance_count((1, 1), (2, 2), "INVALID_DIRECTION")
        except ValueError:
            # ã‚¨ãƒ©ãƒ¼å¾Œã‚‚ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãŒä¿ãŸã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert len(result) == 1

        # ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§å¾Œã®æ­£å¸¸å‹•ä½œç¢ºèª
        xlsx2json.insert_json_path(result, ["å¾©æ—§ãƒ‡ãƒ¼ã‚¿", "å€¤"], "RECOVERED")
        assert result["å¾©æ—§ãƒ‡ãƒ¼ã‚¿"]["å€¤"] == "RECOVERED"

    def test_strict_rect_scan_aligned_only(self, tmp_path):
        """çŸ©å½¢ã‚¹ã‚­ãƒ£ãƒ³ã¯å·¦å³ãŒæƒã£ãŸç¸¦é€£ç¶šã®çŸ©å½¢ã®ã¿è¦ç´ åŒ–ã—ã€æ¨ªã‚ºãƒ¬çŸ©å½¢ã¯æ¡ç”¨ã—ãªã„ï¼ˆcol_tolerance=0ï¼‰ã€‚"""
        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"

        # 1) ãƒ™ãƒ¼ã‚¹çŸ©å½¢ï¼ˆB2:C3ï¼‰ã¨åŒå¹…ã§ç¸¦ã«é€£ç¶šã™ã‚‹çŸ©å½¢ï¼ˆB4:C5ï¼‰
        draw_rect_border(ws, 2, 2, 3, 3)  # B2:C3
        draw_rect_border(ws, 4, 2, 5, 3)  # B4:C5ï¼ˆå·¦å³ä¸€è‡´ï¼‰

        # 2) æ¨ªã«1åˆ—ãšã‚‰ã—ãŸçŸ©å½¢ï¼ˆC6:D7ï¼‰â†’ å³æ ¼åŒ–ã§éæ¡ç”¨ã¨ãªã‚‹æƒ³å®š
        draw_rect_border(ws, 6, 3, 7, 4)  # C6:D7ï¼ˆå·¦ãŒ+1 ãšã‚Œï¼‰

        # å€¤ã®è¨­å®šï¼ˆå„çŸ©å½¢ã®ä¸Šæ®µã«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ï¼‰
        # ãƒ™ãƒ¼ã‚¹çŸ©å½¢1
        ws.cell(row=2, column=2, value="A1")  # B2
        ws.cell(row=2, column=3, value="B1")  # C2
        # é€£ç¶šçŸ©å½¢2
        ws.cell(row=4, column=2, value="A2")  # B4
        ws.cell(row=4, column=3, value="B2")  # C4
        # æ¨ªã‚ºãƒ¬çŸ©å½¢3ï¼ˆéæ¡ç”¨æƒ³å®šï¼‰
        ws.cell(row=6, column=3, value="A3")  # C6
        ws.cell(row=6, column=4, value="B3")  # D6

        # åå‰ä»˜ãç¯„å›²ã®å®šç¾©
        # ã‚³ãƒ³ãƒ†ãƒŠè¦ªï¼ˆç¯„å›²ï¼‰: json.tbl -> B2:C3ï¼ˆãƒ™ãƒ¼ã‚¹çŸ©å½¢ï¼‰
        set_defined_names(
            wb,
            {
                "json.tbl": "Sheet1!$B$2:$C$3",
                # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åŸºæº–ï¼ˆç›´ä¸‹: <index>.<field>ï¼‰
                "json.tbl.1.A": "Sheet1!$B$2",
                "json.tbl.1.B": "Sheet1!$C$2",
            },
        )

        xlsx_path = tmp_path / "rect_strict.xlsx"
        wb.save(xlsx_path)

        # è‡ªå‹•æ¨è«– + çŸ©å½¢ã‚¹ã‚­ãƒ£ãƒ³ã§ç”Ÿæˆ
        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")

        # ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã¸ã‚‚è¤‡è£½ã•ã‚Œã‚‹ä»•æ§˜ã®ãŸã‚ã€'tbl' ç›´å‚ç…§
        assert "tbl" in result, f"result keys={list(result.keys())}"
        tbl = result["tbl"]
        # 2ã¤ã®çŸ©å½¢ã®ã¿ï¼ˆæ¨ªã‚ºãƒ¬çŸ©å½¢ã¯éæ¡ç”¨ï¼‰
        assert isinstance(tbl, list)
        assert len(tbl) == 2
        # å€¤ã®ç¢ºèª
        assert tbl[0].get("A") == "A1" and tbl[0].get("B") == "B1"
        assert tbl[1].get("A") == "A2" and tbl[1].get("B") == "B2"

    def test_infer_containers_suppress_child_when_parent_repeating(self):
        """è¦ª(json.X)ãŒç¯„å›²ã§ç¹°è¿”ã—ã«ãªã‚‹å ´åˆã€å­(json.X.1)ã®ã‚³ãƒ³ãƒ†ãƒŠæ¨è«–ã‚’æŠ‘åˆ¶ã™ã‚‹ã€‚"""
        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"

        # è¦ªç¯„å›²ï¼ˆé«˜ã•2ï¼‰ã¨å­ç¯„å›²ã‚’ä¸¡æ–¹å®šç¾©
        set_defined_names(
            wb,
            {
                "json.X": "Sheet1!$B$2:$B$3",  # è¦ªã¯ç¯„å›² â†’ increment>0 ã®å€™è£œ
                "json.X.1": "Sheet1!$B$2:$B$2",  # å­ã‚‚ç¯„å›²ã ãŒã€è¦ªãŒã‚ã‚‹ãŸã‚æŠ‘åˆ¶å¯¾è±¡
                # è¦ªç›´ä¸‹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆå­ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å«ã‚€ï¼‰
                "json.X.1.A": "Sheet1!$B$2",
            },
        )

        containers = xlsx2json.infer_containers_from_named_ranges(wb, prefix="json")

        # è¦ªã¯æ¤œå‡ºã•ã‚Œã€increment>0ï¼ˆé«˜ã•2ï¼‰
        assert "json.X" in containers
        assert int(containers["json.X"].get("increment", 0)) > 0
        # å­(json.X.1)ã¯æŠ‘åˆ¶ã•ã‚Œã‚‹
        assert "json.X.1" not in containers

    def test_infer_containers_dot1_range_is_repeating_with_height_increment(self):
        """æœ«å°¾ãŒã€.1ã€ã®ç¯„å›²åã¯ã€ç¯„å›²ã®é«˜ã•ã‚’incrementã¨ã™ã‚‹ç¹°è¿”ã—ã‚³ãƒ³ãƒ†ãƒŠã¨ã—ã¦æ¨è«–ã•ã‚Œã‚‹ã€‚"""
        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"

        # é«˜ã•4ã®ç¸¦ç¯„å›²ã‚’ 'json.T.1' ã«å‰²ã‚Šå½“ã¦ã‚‹
        set_defined_names(
            wb,
            {
                "json.T.1": "Sheet1!$B$2:$B$5",
                # ç›´ä¸‹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆå­˜åœ¨ã—ãªãã¦ã‚‚é«˜ã•æ¨è«–ã®ã¿ã§OKã ãŒä¸€ã¤ç½®ã„ã¦ãŠãï¼‰
                "json.T.1.A": "Sheet1!$B$2",
            },
        )

        containers = xlsx2json.infer_containers_from_named_ranges(wb, prefix="json")

        # '.1' è‡ªä½“ãŒç¹°ã‚Šè¿”ã—ã‚³ãƒ³ãƒ†ãƒŠã¨ã—ã¦æ¤œå‡ºã•ã‚Œã€increment ã¯ç¯„å›²ã®é«˜ã•ï¼ˆ=4ï¼‰
        assert "json.T.1" in containers
        c = containers["json.T.1"]
        assert c.get("direction") == "row"
        assert int(c.get("increment", 0)) == 4

    def test_parent_range_caps_scan_and_internal_slice_emits_second_row(self, tmp_path):
        """è¦ª(dict)ã®åŸºæº–ç¯„å›²ãŒ2è¡Œã®ã¨ãã€
        - éãƒã‚¹ãƒˆçŸ©å½¢ã‚¹ã‚­ãƒ£ãƒ³ã¯ãƒ™ãƒ¼ã‚¹ç¯„å›²ã®ä¸‹ç«¯ã§æ‰“ã¡åˆ‡ã‚‰ã‚Œï¼ˆä¸‹æ–¹ã®ä½™åˆ†ãªçŸ©å½¢ã¯ç„¡è¦–ï¼‰
        - index=1 ã®æ˜ç¤ºå®šç¾©ãŒã‚ã‚‹å ´åˆã¯å†…éƒ¨ã‚¹ãƒ©ã‚¤ã‚¹ã§2è¡Œç›®ã®ã¿è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹
        â†’ çµæœã¨ã—ã¦2è¦ç´ ï¼ˆ1è¡Œç›®=æ˜ç¤º, 2è¡Œç›®=è‡ªå‹•ï¼‰ã«ãªã‚‹ã“ã¨ã‚’æ¤œè¨¼ã€‚

        å†ç¾æ§‹æˆ:
        - ãƒ™ãƒ¼ã‚¹çŸ©å½¢: B2:C3ï¼ˆ2è¡Œï¼‰
        - ä¸‹æ–¹ã®ä½™åˆ†ãªçŸ©å½¢: B4:C5ï¼ˆç„¡è¦–ã•ã‚Œã‚‹ã¹ãï¼‰
        - ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: A,Bï¼ˆç¸¦ç¯„å›²B2:B3, C2:C3ã¨ã—ã¦å®šç¾©ï¼å†…éƒ¨ã‚¹ãƒ©ã‚¤ã‚¹æœ‰åŠ¹ï¼‰
        - index=1 ã¯æ˜ç¤ºã‚»ãƒ«åã¨ã—ã¦å®šç¾©
        """
        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"

        # ãƒ™ãƒ¼ã‚¹çŸ©å½¢(2è¡Œ)ã¨ã€ãã®ä¸‹ã«ä½™åˆ†ãªçŸ©å½¢ï¼ˆç„¡è¦–å¯¾è±¡ï¼‰
        draw_rect_border(ws, 2, 2, 3, 3)  # B2:C3ï¼ˆåŸºæº–ï¼‰
        draw_rect_border(ws, 4, 2, 5, 3)  # B4:C5ï¼ˆä¸‹æ–¹ãƒ»ç„¡è¦–ã•ã‚Œã‚‹ï¼‰

        # å€¤: ãƒ™ãƒ¼ã‚¹çŸ©å½¢å†…ã®1è¡Œç›®/2è¡Œç›®ã€ãŠã‚ˆã³ä½™åˆ†çŸ©å½¢ã®1è¡Œç›®ï¼ˆç„¡è¦–ã•ã‚Œã‚‹æƒ³å®šï¼‰
        ws.cell(row=2, column=2, value="A1")  # B2
        ws.cell(row=2, column=3, value="B1")  # C2
        ws.cell(row=3, column=2, value="A2")  # B3
        ws.cell(row=3, column=3, value="B2")  # C3
        ws.cell(row=4, column=2, value="A3")  # B4ï¼ˆç„¡è¦–ï¼‰
        ws.cell(row=4, column=3, value="B3")  # C4ï¼ˆç„¡è¦–ï¼‰

        # åå‰ä»˜ãç¯„å›²ã®å®šç¾©
        set_defined_names(
            wb,
            {
                # è¦ª(dict)ã®ç¯„å›²ï¼ˆãƒ™ãƒ¼ã‚¹çŸ©å½¢ï¼‰
                "json.è¡¨1": "Sheet1!$B$2:$C$3",
                # index=1 ã‚’æ˜ç¤ºã—ã€ã‹ã¤ç¸¦ç¯„å›²ã§å†…éƒ¨ã‚¹ãƒ©ã‚¤ã‚¹æœ‰åŠ¹ï¼ˆ2è¡Œï¼‰
                "json.è¡¨1.1.A": "Sheet1!$B$2:$B$3",
                "json.è¡¨1.1.B": "Sheet1!$C$2:$C$3",
            },
        )

        xlsx_path = tmp_path / "tbl_cap_internal_slice.xlsx"
        wb.save(xlsx_path)

        # å®Ÿè¡Œ
        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")

        # æ¤œè¨¼
        assert "è¡¨1" in result, f"keys={list(result.keys())}"
        tbl = result["è¡¨1"]
        # 2è¦ç´ ï¼ˆ1è¡Œç›®=æ˜ç¤º, 2è¡Œç›®=å†…éƒ¨ã‚¹ãƒ©ã‚¤ã‚¹ã§è‡ªå‹•ï¼‰
        assert isinstance(tbl, list)
        assert len(tbl) == 2
        assert tbl[0].get("A") == "A1" and tbl[0].get("B") == "B1"
        assert tbl[1].get("A") == "A2" and tbl[1].get("B") == "B2"

    def test_tree_structure_nested_rectangles_with_seq(self, tmp_path):
        """ãƒ„ãƒªãƒ¼å‹ï¼ˆlv1â†’lv2â†’lv3â†’lv4ï¼‰ãƒã‚¹ãƒˆã®çŸ©å½¢ã‚¹ã‚­ãƒ£ãƒ³ã¨ .1 ã‚¢ãƒ³ã‚«ãƒ¼æ¨è«–ã®çµ±åˆãƒ†ã‚¹ãƒˆã€‚

        æœŸå¾…æ§‹é€ ï¼ˆå€¤ã¯ç°¡ç•¥åŒ–ï¼‰:
        ãƒ„ãƒªãƒ¼1 (ã¾ãŸã¯ lv1) é…ä¸‹ã« 2 è¦ç´ ã€‚
        - 1ä»¶ç›®: A="A1", seq="1"
          lv2 é…ä¸‹ã« 2 è¦ç´ : (B="B1-1", seq="1-1", lv3=[(C="C1-1-1", seq="1-1-1"), (C="C1-1-2", seq="1-1-2")]) ã¨
                               (B="B1-2", seq="1-2")
        - 2ä»¶ç›®: A="A2", seq="2"
          lv2 é…ä¸‹ã« 1 è¦ç´ : (B="B2-1", seq="2-1", lv3=[(C="C2-1-1", seq="2-1-1")])
        """
        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"

        # lv1 çŸ©å½¢ï¼ˆ2è¡Œé«˜ã•ï¼‰Ã—2ï¼ˆB2:C3, B4:C5ï¼‰
        draw_rect_border(ws, top=2, left=2, bottom=3, right=3)  # B2:C3 (lv1-1)
        draw_rect_border(ws, top=4, left=2, bottom=5, right=3)  # B4:C5 (lv1-2)

        # lv2 çŸ©å½¢ï¼ˆå„1è¡Œï¼‰: lv1-1 å†…ã«2ã¤ (E2:F2, E3:F3) / lv1-2 å†…ã«1ã¤ (E4:F4)
        draw_rect_border(
            ws, top=2, left=5, bottom=2, right=6
        )  # E2:F2 (lv2-1 under lv1-1)
        draw_rect_border(
            ws, top=3, left=5, bottom=3, right=6
        )  # E3:F3 (lv2-2 under lv1-1)
        draw_rect_border(
            ws, top=4, left=5, bottom=4, right=6
        )  # E4:F4 (lv2-1 under lv1-2)

        # lv3 çŸ©å½¢ï¼ˆå„1è¡Œï¼‰: lv2-1 å†…ã«2ã¤ (H2:I2, H3:I3) / lv2-1 under lv1-2 ã«1ã¤ (H4:I4)
        draw_rect_border(ws, top=2, left=8, bottom=2, right=9)  # H2:I2 (lv3-1)
        draw_rect_border(ws, top=3, left=8, bottom=3, right=9)  # H3:I3 (lv3-2)
        draw_rect_border(
            ws, top=4, left=8, bottom=4, right=9
        )  # H4:I4 (lv3-1 under second branch)

        # lv4 çŸ©å½¢ï¼ˆå„1è¡Œï¼‰: lv3-1 å†…ã«2ã¤ (K2:L2, K3:L3) / second branch ã® lv3-1 ã«1ã¤ (K4:L4)
        draw_rect_border(ws, top=2, left=11, bottom=2, right=12)  # K2:L2 (lv4-1)
        draw_rect_border(ws, top=3, left=11, bottom=3, right=12)  # K3:L3 (lv4-2)
        draw_rect_border(
            ws, top=4, left=11, bottom=4, right=12
        )  # K4:L4 (lv4-1 under second branch)

        # å€¤ã®é…ç½®
        set_cells(
            ws,
            {
                # lv1: seq ã¯ Båˆ—ä¸Šæ®µ, A ã¯ Cåˆ—ä¸‹æ®µï¼ˆå„çŸ©å½¢å†…ç›¸å¯¾ï¼‰
                "B2": "1",
                "C3": "A1",
                "B4": "2",
                "C5": "A2",
                # lv2: seq ã¯ Eåˆ—, B ã¯ Fåˆ—
                "E2": "1-1",
                "F2": "B1-1",
                "E3": "1-2",
                "F3": "B1-2",
                "E4": "2-1",
                "F4": "B2-1",
                # lv3: seq ã¯ Håˆ—, C ã¯ Iåˆ—
                "H2": "1-1-1",
                "I2": "C1-1-1",
                "H3": "1-1-2",
                "I3": "C1-1-2",
                "H4": "2-1-1",
                "I4": "C2-1-1",
                # lv4: seq ã¯ Kåˆ—, D ã¯ Låˆ—
                "K2": "1-1-1-1",
                "L2": "D1-1-1-1",
                "K3": "1-1-1-2",
                "L3": "D1-1-1-2",
                "K4": "2-1-1-1",
                "L4": "D2-1-1-1",
            },
        )

        # åå‰ä»˜ãç¯„å›²ã®å®šç¾© (.1 ã‚¢ãƒ³ã‚«ãƒ¼ã¯ç¯„å›²ï¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å˜ä¸€ã‚»ãƒ«)
        set_defined_names(
            wb,
            {
                # lv1 anchors and fields
                "json.ãƒ„ãƒªãƒ¼1.lv1.1": "Sheet1!$B$2:$C$3",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.seq": "Sheet1!$B$2",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.A": "Sheet1!$C$3",
                # lv2 within lv1
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1": "Sheet1!$E$2:$F$2",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.seq": "Sheet1!$E$2",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.B": "Sheet1!$F$2",
                # lv3 within lv2
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.lv3.1": "Sheet1!$H$2:$I$2",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.lv3.1.seq": "Sheet1!$H$2",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.lv3.1.C": "Sheet1!$I$2",
                # lv4 within lv3
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.lv3.1.lv4.1": "Sheet1!$K$2:$L$2",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.lv3.1.lv4.1.seq": "Sheet1!$K$2",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.lv3.1.lv4.1.D": "Sheet1!$L$2",
            },
        )

        xlsx_path = tmp_path / "tree_nested.xlsx"
        wb.save(xlsx_path)

        # å®Ÿè¡Œï¼ˆ.1 ã®é«˜ã•ã§ç¹°è¿”ã—ã‚³ãƒ³ãƒ†ãƒŠæ¨è«– â†’ é€£ç¶šçŸ©å½¢ã‚¹ã‚­ãƒ£ãƒ³ â†’ å€¤èª­å–ï¼‰
        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")

        # ãƒ«ãƒ¼ãƒˆé…ä¸‹ã« 'ãƒ„ãƒªãƒ¼1' ã‚’ä¿æŒ
        root = result.get("ãƒ„ãƒªãƒ¼1")
        assert isinstance(root, dict), f"missing ãƒ„ãƒªãƒ¼1: keys={list(result.keys())}"

        # lv1: 2ä»¶ï¼ˆA, seqï¼‰
        lv1 = root["lv1"]
        assert isinstance(lv1, list) and len(lv1) == 2
        # 1ä»¶ç›®: A1, seq=1, lv2: 2ä»¶
        e1 = lv1[0]
        assert e1["A"] == "A1" and e1["seq"] == "1"
        assert [v["seq"] for v in e1["lv2"]] == ["1-1", "1-2"]
        assert [v["B"] for v in e1["lv2"]] == ["B1-1", "B1-2"]
        # lv3: 1ä»¶ç›®ã®lv2[0]é…ä¸‹ã«2ä»¶
        v21 = e1["lv2"][0]["lv3"]
        assert [v["seq"] for v in v21] == ["1-1-1", "1-1-2"]
        assert [v["C"] for v in v21] == ["C1-1-1", "C1-1-2"]
        # lv4: lv3[0] é…ä¸‹ã«2ä»¶ï¼ˆåŒä¸€ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§ã¯æœ€åˆã®è¦ªã®ã¿å­ã‚’ç”Ÿæˆï¼‰
        v31 = v21[0]
        assert "lv4" in v31 and isinstance(v31["lv4"], list)
        lv4_1 = v31["lv4"]
        assert [v["seq"] for v in lv4_1] == ["1-1-1-1", "1-1-1-2"]
        assert [v["D"] for v in lv4_1] == ["D1-1-1-1", "D1-1-1-2"]
        # lv3[1] é…ä¸‹ã«ã¯ lv4 ã¯ç”Ÿæˆã•ã‚Œãªã„
        assert "lv4" not in v21[1]
        # 2ä»¶ç›®: A2, seq=2, lv2: 1ä»¶
        e2 = lv1[1]
        assert e2["A"] == "A2" and e2["seq"] == "2"
        v2_1 = e2["lv2"][0]
        assert v2_1["B"] == "B2-1" and v2_1["seq"] == "2-1"
        # lv3: 2ä»¶ç›®ã®lv2[0]é…ä¸‹ã«1ä»¶
        v3 = v2_1["lv3"]
        assert len(v3) == 1 and v3[0]["C"] == "C2-1-1" and v3[0]["seq"] == "2-1-1"
        # lv4: 2ä»¶ç›®ãƒ–ãƒ©ãƒ³ãƒã® lv3[0] é…ä¸‹ã«1ä»¶
        v3e1 = v3[0]
        assert "lv4" in v3e1 and isinstance(v3e1["lv4"], list)
        lv4_2 = v3e1["lv4"]
        assert len(lv4_2) == 1
        assert lv4_2[0]["seq"] == "2-1-1-1" and lv4_2[0]["D"] == "D2-1-1-1"

    def test_nested_no_sibling_leakage(self, tmp_path):
        """å…„å¼Ÿãƒ–ãƒ©ãƒ³ãƒã®å€¤ãŒæ··å…¥ã—ãªã„ã“ã¨ã‚’æ¤œè¨¼ã™ã‚‹æœ€å°ã‚±ãƒ¼ã‚¹ã€‚

        lv1 ãŒ2ä»¶ã€lv2 ã¯1ä»¶ç›®ã®ã¿ã«2è¦ç´ ã€2ä»¶ç›®ã«ã¯å­˜åœ¨ã—ãªã„ã€‚lv3 ã¯ lv2[0] ã®ã¿ã«1è¦ç´ ã€‚
        æœŸå¾…:
        - lv1[0].lv2 ã¯2è¦ç´ ã€lv1[1] ã« 'lv2' ã¯å­˜åœ¨ã—ãªã„ï¼ˆæ··å…¥ãªã—ï¼‰
        - lv3 ã¯ lv1[0].lv2[0] ã®ã¿ã«å­˜åœ¨ã—ã€ä»–ã¸ã¯æ··å…¥ã—ãªã„
        """
        wb = Workbook()
        ws = wb.active

    def test_table_internal_slice_priority_rows(self, tmp_path):
        """è¡¨1: .1 ã‚¢ãƒ³ã‚«ãƒ¼é«˜ã•=2ã‹ã¤åˆ—ç¸¦ãƒ¬ãƒ³ã‚¸é•·=2ã®å ´åˆã€1,2è¡Œã‚’èª­ã‚€ï¼ˆA1/B1/C1, A2/B2/C2ï¼‰ã€‚"""
        from openpyxl import Workbook

        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"
        # ãƒœãƒ¼ãƒ€ãƒ¼ã§2è¡Œãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å›²ã‚€ï¼ˆè¦‹æ „ãˆã®ã¿ï¼‰
        draw_rect_border(ws, top=2, left=2, bottom=3, right=4)
        # å€¤
        set_cells(
            ws, {"B2": "A1", "C2": "B1", "D2": "C1", "B3": "A2", "C3": "B2", "D3": "C2"}
        )
        # åå‰ã®å®šç¾©
        set_defined_names(
            wb,
            {
                "json.è¡¨1.1": "Sheet1!$B$2:$D$3",
                "json.è¡¨1.1.åˆ—A": "Sheet1!$B$2:$B$3",
                "json.è¡¨1.1.åˆ—B": "Sheet1!$C$2:$C$3",
                "json.è¡¨1.1.åˆ—C": "Sheet1!$D$2:$D$3",
            },
        )
        xlsx_path = tmp_path / "tbl.xlsx"
        wb.save(xlsx_path)
        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")
        assert "è¡¨1" in result and isinstance(result["è¡¨1"], list)
        assert result["è¡¨1"][0] == {"åˆ—A": "A1", "åˆ—B": "B1", "åˆ—C": "C1"}
        assert result["è¡¨1"][1] == {"åˆ—A": "A2", "åˆ—B": "B2", "åˆ—C": "C2"}

    def test_list_drop_leading_empty_object(self, tmp_path):
        """ãƒªã‚¹ãƒˆ1: å…ˆé ­ã®ç©ºè¦ç´  {} ã‚’å‡ºåŠ›ã—ãªã„ï¼ˆã‚­ãƒ¼ã®ç©ºç™½æ··å…¥ã§1ä»¶ç›®ãŒæ¬ è½ã™ã‚‹å›é¿ï¼‰ã€‚"""
        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"
        # 3è¡Œåˆ†ã®ãƒœãƒ¼ãƒ€ãƒ¼
        draw_rect_border(ws, top=2, left=2, bottom=4, right=3)
        # å€¤ï¼ˆ1è¡Œç›®ã¯ç©ºã€2-3è¡Œç›®ã¯å€¤ã‚ã‚Šï¼‰
        set_cells(
            ws,
            {
                "B3": "aaaåç§°12",
                "C3": "aaaã‚³ãƒ¼ãƒ‰12-1,aaaã‚³ãƒ¼ãƒ‰12-2",
                "B4": "aaaåç§°13",
                "C4": "aaaã‚³ãƒ¼ãƒ‰13-1,aaaã‚³ãƒ¼ãƒ‰13-2",
            },
        )
        # åå‰ã®å®šç¾©ï¼ˆã‚ã–ã¨1è¡Œç›®ã®ã‚­ãƒ¼ã«ç©ºç™½æ··å…¥é¢¨ã®åå‰ã‚‚æ··ãœã‚‹ãŒç¯„å›²ã¯2-4è¡Œï¼‰
        set_defined_names(
            wb,
            {
                "json.ãƒªã‚¹ãƒˆ1.1": "Sheet1!$B$2:$C$4",
                "json.ãƒªã‚¹ãƒˆ1.1.aaaåç§°": "Sheet1!$B$2:$B$4",
                "json.ãƒªã‚¹ãƒˆ1.1.aaaã‚³ãƒ¼ãƒ‰": "Sheet1!$C$2:$C$4",
            },
        )
        xlsx_path = tmp_path / "lst.xlsx"
        wb.save(xlsx_path)
        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")
        assert "ãƒªã‚¹ãƒˆ1" in result and isinstance(result["ãƒªã‚¹ãƒˆ1"], list)
        # å…ˆé ­ã®ç©ºè¾æ›¸ãŒå‡ºåŠ›ã•ã‚Œãªã„ã“ã¨ï¼ˆ2è¦ç´ ã®ã¿ï¼‰
        assert len(result["ãƒªã‚¹ãƒˆ1"]) == 2
        assert result["ãƒªã‚¹ãƒˆ1"][0]["aaaåç§°"] == "aaaåç§°12"
        assert "aaaã‚³ãƒ¼ãƒ‰" in result["ãƒªã‚¹ãƒˆ1"][0]
        ws.title = "Sheet1"

        # lv1 rectangles (height=2) x2: B2:C3, B4:C5
        draw_rect_border(ws, top=2, left=2, bottom=3, right=3)
        draw_rect_border(ws, top=4, left=2, bottom=5, right=3)

        # lv2 rectangles only under first lv1: E2:F2, E3:F3
        draw_rect_border(ws, top=2, left=5, bottom=2, right=6)
        draw_rect_border(ws, top=3, left=5, bottom=3, right=6)

        # lv3 rectangle only under first lv2: H2:I2
        draw_rect_border(ws, top=2, left=8, bottom=2, right=9)

        # Values
        set_cells(
            ws,
            {
                # lv1: seq in B top, A in C bottom
                "B2": "1",
                "C3": "A1",
                "B4": "2",
                "C5": "A2",
                # lv2: only for first lv1
                "E2": "1-1",
                "F2": "B1-1",
                "E3": "1-2",
                "F3": "B1-2",
                # lv3: only for first lv2
                "H2": "1-1-1",
                "I2": "C1-1-1",
            },
        )

        # Named ranges (.1 anchors as ranges)
        set_defined_names(
            wb,
            {
                "json.T.lv1.1": "Sheet1!$B$2:$C$3",
                "json.T.lv1.1.seq": "Sheet1!$B$2",
                "json.T.lv1.1.A": "Sheet1!$C$3",
                # lv2 within lv1 (only one row height)
                "json.T.lv1.1.lv2.1": "Sheet1!$E$2:$F$2",
                "json.T.lv1.1.lv2.1.seq": "Sheet1!$E$2",
                "json.T.lv1.1.lv2.1.B": "Sheet1!$F$2",
                # lv3 within lv2
                "json.T.lv1.1.lv2.1.lv3.1": "Sheet1!$H$2:$I$2",
                "json.T.lv1.1.lv2.1.lv3.1.seq": "Sheet1!$H$2",
                "json.T.lv1.1.lv2.1.lv3.1.C": "Sheet1!$I$2",
            },
        )

        xlsx_path = tmp_path / "no_sibling_leak.xlsx"
        wb.save(xlsx_path)

        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")
        root = result.get("T")
        assert isinstance(root, dict)
        lv1 = root["lv1"]
        assert isinstance(lv1, list) and len(lv1) == 2
        # First branch has lv2 with 2 elems
        assert [v["seq"] for v in lv1[0]["lv2"]] == ["1-1", "1-2"]
        assert [v["B"] for v in lv1[0]["lv2"]] == ["B1-1", "B1-2"]
        # Second branch must not have lv2
        assert "lv2" not in lv1[1]
        # lv3 exists only under first lv2 element
        v21 = lv1[0]["lv2"][0]
        assert "lv3" in v21 and len(v21["lv3"]) == 1
        assert v21["lv3"][0]["seq"] == "1-1-1" and v21["lv3"][0]["C"] == "C1-1-1"

    def test_infer_increment_from_named_range_height_multi_levels(self):
        """.1ã‚¢ãƒ³ã‚«ãƒ¼ã®incrementãŒå®šç¾©åã®é«˜ã•ã«ä¸€è‡´ã™ã‚‹ã“ã¨ã‚’å¤šå±¤ã§æ¤œè¨¼ã€‚"""
        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"

        set_defined_names(
            wb,
            {
                # lv1 anchor height=2
                "json.R.lv1.1": "Sheet1!$B$2:$C$3",
                "json.R.lv1.1.A": "Sheet1!$C$3",
                # lv2 anchor height=1
                "json.R.lv1.1.lv2.1": "Sheet1!$E$2:$F$2",
                "json.R.lv1.1.lv2.1.B": "Sheet1!$F$2",
            },
        )

        containers = xlsx2json.infer_containers_from_named_ranges(wb, prefix="json")
        assert containers["json.R.lv1.1"]["increment"] == 2
        assert containers["json.R.lv1.1"]["direction"] == "row"
        assert containers["json.R.lv1.1.lv2.1"]["increment"] == 1
        assert containers["json.R.lv1.1.lv2.1"]["direction"] == "row"

    def test_wildcard_object_and_array_level_transforms(self, tmp_path):
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
        - json.root.* (å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå˜ä½)
        - json.root.*.* (å­«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå˜ä½)
        - json.root.*items.* (ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…éƒ¨åˆ†ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ + ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¦ç´ )

        ã«ã¤ã„ã¦ã€transform ã§æŒ‡å®šã—ãŸé–¢æ•°ã¸ dict / list ãŒãã®ã¾ã¾æ¸¡ã•ã‚Œã€
        æˆ»ã‚Šå€¤ãŒå½“è©²ãƒãƒ¼ãƒ‰ã‚’ç½®æ›ã™ã‚‹æŒ™å‹•ã‚’æ¤œè¨¼ã™ã‚‹ã€‚

        ç¾çŠ¶ã®å®Ÿè£…ã§ã¯:
          - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…éƒ¨ã« * ã‚’å«ã‚€ãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¾‹: *items) ãŒãƒãƒƒãƒã—ãªã„
          - dict æˆ»ã‚Šå€¤ãŒãƒãƒ¼ãƒ‰ç½®æ›ã§ã¯ãªãå±•é–‹ã•ã‚Œã‚‹
        ãŸã‚ã€ã“ã®ãƒ†ã‚¹ãƒˆã¯å¤±æ•— (RED) ã™ã‚‹æƒ³å®šã€‚
        å®Ÿè£…å¾Œ (GREEN) ã§ãƒ‘ã‚¹ã™ã‚‹ã“ã¨ã€‚
        """
        # 1) json.root.* : å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã¸ã®å¤‰æ›
        wb1 = Workbook()
        ws1 = wb1.active
        ws1.title = "S1"
        set_cells(ws1, {"A1": "Alpha", "A2": "Beta"})
        set_defined_names(
            wb1,
            {
                "json.root.alpha.name": "A1",
                "json.root.beta.name": "A2",
            },
            default_sheet=ws1.title,
        )
        xlsx1 = tmp_path / "wild1.xlsx"
        wb1.save(xlsx1)

        # 2) json.root.*.* : è¦ª -> å­ï¼ˆå­«ãƒãƒ¼ãƒ‰ï¼‰
        wb2 = Workbook()
        ws2 = wb2.active
        ws2.title = "S2"
        set_cells(ws2, {"A1": "V1", "A2": "V2", "B1": "W1"})
        set_defined_names(
            wb2,
            {
                "json.root.grp1.childA.value": "A1",
                "json.root.grp1.childB.value": "A2",
                "json.root.grp2.childA.value": "B1",
            },
            default_sheet=ws2.title,
        )
        xlsx2 = tmp_path / "wild2.xlsx"
        wb2.save(xlsx2)

        # 3) json.root.*items.* : éƒ¨åˆ†ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ + é…åˆ—è¦ç´ (dict)
        wb3 = Workbook()
        ws3 = wb3.active
        ws3.title = "S3"
        set_cells(ws3, {"A1": "x1", "A2": "x2", "B1": "y1"})
        set_defined_names(
            wb3,
            {
                "json.root.alphaitems.1.value": "A1",
                "json.root.alphaitems.2.value": "A2",
                "json.root.betaitems.1.value": "B1",
            },
            default_sheet=ws3.title,
        )
        xlsx3 = tmp_path / "wild3.xlsx"
        wb3.save(xlsx3)

        # å¤‰æ›ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (1ã¤ã§ã¾ã¨ã‚ã‚‹)
        tf_module = tmp_path / "wildcard_transforms.py"
        tf_module.write_text(
            (
                "def child_keys(node):\n"
                "    # json.root.* ã§ dict ãŒæ¥ã‚‹æƒ³å®š\n"
                "    assert isinstance(node, dict), f'expected dict got {type(node)}'\n"
                "    # ç½®æ›: ã‚­ãƒ¼ä¸€è¦§\n"
                "    return sorted(node.keys())\n\n"
                "def unwrap_value(node):\n"
                "    # json.root.*.* ã§ dict {'value': ...} ãŒæ¥ã‚‹æƒ³å®š\n"
                "    assert isinstance(node, dict) and 'value' in node\n"
                "    return node['value'] + '!'\n\n"
                "def upper_item(node):\n"
                "    # json.root.*items.* ã§ {'value': ...} ãŒæ¥ã‚‹æƒ³å®š\n"
                "    assert isinstance(node, dict) and 'value' in node\n"
                "    return {'VALUE': str(node['value']).upper()}\n"
            ),
            encoding="utf-8",
        )

        # 1) json.root.*
        rules1 = xlsx2json.parse_array_transform_rules(
            [f"json.root.*=function:{tf_module}:child_keys"], prefix="json", schema=None, trim_enabled=False
        )
        result1 = xlsx2json.parse_named_ranges_with_prefix(xlsx1, prefix="json", array_transform_rules=rules1)
        # æœŸå¾…: alpha / beta ãŒã‚­ãƒ¼é…åˆ—ã¸ç½®æ›ã•ã‚Œã‚‹
        assert result1["root"]["alpha"] == ["name"], "dictç½®æ›ãŒè¡Œã‚ã‚Œã¦ã„ãªã„ (json.root.*)"
        assert result1["root"]["beta"] == ["name"], "dictç½®æ›ãŒè¡Œã‚ã‚Œã¦ã„ãªã„ (json.root.*)"

        # 2) json.root.*.*
        rules2 = xlsx2json.parse_array_transform_rules(
            [f"json.root.*.*=function:{tf_module}:unwrap_value"], prefix="json", schema=None, trim_enabled=False
        )
        result2 = xlsx2json.parse_named_ranges_with_prefix(xlsx2, prefix="json", array_transform_rules=rules2)
        # grp1.childA / childB, grp2.childA ãŒ æœ«å°¾ã« '!' ä»˜ä¸ã•ã‚ŒãŸå€¤ã¸ç½®æ›ã•ã‚Œã‚‹
        assert result2["root"]["grp1"]["childA"] == "V1!"
        assert result2["root"]["grp1"]["childB"] == "V2!"
        assert result2["root"]["grp2"]["childA"] == "W1!"

        # 3) json.root.*items.* (éƒ¨åˆ†ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ + é…åˆ—è¦ç´ è¾æ›¸å¤‰æ›)
        rules3 = xlsx2json.parse_array_transform_rules(
            [f"json.root.*items.*=function:{tf_module}:upper_item"], prefix="json", schema=None, trim_enabled=False
        )
        result3 = xlsx2json.parse_named_ranges_with_prefix(xlsx3, prefix="json", array_transform_rules=rules3)
        # alphaitems / betaitems é…åˆ—å†…ã®å„è¦ç´ ãŒ {'VALUE': <å¤§æ–‡å­—>} ã«ç½®æ›ã•ã‚Œã‚‹
        alpha_items = result3["root"]["alphaitems"]
        beta_items = result3["root"]["betaitems"]
        assert isinstance(alpha_items, list) and len(alpha_items) == 2
        assert alpha_items[0] == {"VALUE": "X1"} and alpha_items[1] == {"VALUE": "X2"}
        assert isinstance(beta_items, list) and len(beta_items) == 1
        assert beta_items[0] == {"VALUE": "Y1"}

        # è¿½åŠ æ¤œè¨¼: å¤‰æ›å¾Œã‚‚ä»–ã‚­ãƒ¼ãŒå£Šã‚Œã¦ã„ãªã„ï¼ˆroot ç›´ä¸‹ã‚­ãƒ¼æ•°ï¼‰
        assert set(result3["root"].keys()) == {"alphaitems", "betaitems"}

    def test_samples_spec_embedded_tree_list_table(self, tmp_path):
        """å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¾å­˜ã›ãšã€ã‚µãƒ³ãƒ—ãƒ«ä»•æ§˜ã«åŸºã¥ãã€ãƒ„ãƒªãƒ¼1ã€ã€ãƒªã‚¹ãƒˆ1ã€ã€è¡¨1ã€ã‚’æ¤œè¨¼ã€‚

        - å…¥åŠ›ãƒ–ãƒƒã‚¯ã¨å®šç¾©åã¯ãƒ†ã‚¹ãƒˆå†…ã§ç”Ÿæˆ
        - æœŸå¾…çµæœã‚‚ãƒ†ã‚¹ãƒˆå†…ã«åŸ‹ã‚è¾¼ã‚€
        - ãƒ„ãƒªãƒ¼1ã¯æœŸå¾…å½¢çŠ¶ï¼ˆ[{"lv1": {...}}, ...]ï¼‰ã«åˆã‚ã›ã€å®Ÿè£…çµæœã‹ã‚‰ãƒ©ãƒƒãƒ—æ•´å½¢ã—ã¦æ¯”è¼ƒ
        """
        _builder = SampleWorkbookBuilder()
        _, xlsx_path = _builder.build(tmp_path)

        # å®Ÿè¡Œ
        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")

        # è¡¨1: æœŸå¾…
        assert "è¡¨1" in result and isinstance(result["è¡¨1"], list)
        assert result["è¡¨1"] == expected_table1()

        # ãƒªã‚¹ãƒˆ1: æœŸå¾…
        assert "ãƒªã‚¹ãƒˆ1" in result and isinstance(result["ãƒªã‚¹ãƒˆ1"], list)
        assert result["ãƒªã‚¹ãƒˆ1"] == expected_list1()

        # ãƒ„ãƒªãƒ¼1: æœŸå¾…ä»•æ§˜ï¼ˆ[{"lv1": {...}}, ...]ï¼‰ã«åˆã‚ã›ã€å®Ÿè£…çµæœã‹ã‚‰ãƒ©ãƒƒãƒ—æ•´å½¢ã—ã¦æ¯”è¼ƒ
        assert "ãƒ„ãƒªãƒ¼1" in result
        # å®Ÿè£…ã®å½¢ï¼ˆ{"ãƒ„ãƒªãƒ¼1": {"lv1": [...]}}ï¼‰â†’ æœŸå¾…å½¢çŠ¶ã«ãƒ©ãƒƒãƒ—
        actual_tree_root = result["ãƒ„ãƒªãƒ¼1"]
        wrapped = wrap_tree_shape(actual_tree_root, level_key="lv1")
        assert wrapped == expected_tree1()

    def test_samples_file_tree_list_table_match_spec(self, tmp_path):
        """å¤–éƒ¨samples/ã«ä¾å­˜ã›ãšã€ä»•æ§˜ã©ãŠã‚Šã®å½¢çŠ¶ã«ãªã‚‹ã“ã¨ã‚’ç¢ºèªã€‚

        æœŸå¾…:
        - è¡¨1 ã¯ 2 è¡Œã®ã¿ï¼ˆA1..C1, A2..C2ï¼‰
        - ãƒªã‚¹ãƒˆ1 ã¯ 3 è¡Œ
        - ãƒ„ãƒªãƒ¼1 ã® 2 ä»¶ç›®ã® lv1 ã«ã‚‚ lv2, lv3 ãŒç”Ÿæˆã•ã‚Œã‚‹
        """
        _builder = SampleWorkbookBuilder()
        _, xlsx_path = _builder.build(tmp_path)

        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")

        # è¡¨1: 2è¡Œã®ã¿
        assert "è¡¨1" in result and isinstance(result["è¡¨1"], list)
        assert len(result["è¡¨1"]) == 2
        assert result["è¡¨1"][0] == {"åˆ—A": "A1", "åˆ—B": "B1", "åˆ—C": "C1"}
        assert result["è¡¨1"][1] == {"åˆ—A": "A2", "åˆ—B": "B2", "åˆ—C": "C2"}

        # ãƒªã‚¹ãƒˆ1: 3è¡Œ
        assert "ãƒªã‚¹ãƒˆ1" in result and isinstance(result["ãƒªã‚¹ãƒˆ1"], list)
        assert len(result["ãƒªã‚¹ãƒˆ1"]) == 3
        assert result["ãƒªã‚¹ãƒˆ1"][0] == {
            "aaaã‚³ãƒ¼ãƒ‰": "aaaã‚³ãƒ¼ãƒ‰11-1,aaaã‚³ãƒ¼ãƒ‰11-2",
            "aaaåç§°": "aaaåç§°11",
        }

        # ãƒ„ãƒªãƒ¼1: 2ä»¶ç›®ã«ã‚‚ lv2/lv3 ãŒã‚ã‚‹ã“ã¨
        assert "ãƒ„ãƒªãƒ¼1" in result
        wrapped = wrap_tree_shape(result["ãƒ„ãƒªãƒ¼1"], level_key="lv1")
        assert isinstance(wrapped, list) and len(wrapped) >= 2
        second = wrapped[1]
        assert "lv1" in second and isinstance(second["lv1"], dict)
        lv2_list = second["lv1"].get("lv2", [])
        assert isinstance(lv2_list, list) and len(lv2_list) >= 1
        assert lv2_list[0].get("B") == "B2-1" and lv2_list[0].get("seq") == "2-1"
        lv3_list = lv2_list[0].get("lv3", [])
        assert isinstance(lv3_list, list) and len(lv3_list) >= 1
        assert lv3_list[0].get("C") == "C2-1-1" and lv3_list[0].get("seq") == "2-1-1"

    def test_samples_no_seq_only_artifacts_in_tree_lv3(self, tmp_path):
        """å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¾å­˜ã›ãšã€ãƒ„ãƒªãƒ¼1ã®ç¬¬2ãƒ–ãƒ©ãƒ³ãƒã®lv3ã«seqã ã‘ã®è¦ç´ ãŒå‡ºåŠ›ã•ã‚Œãªã„ã“ã¨ã‚’ç¢ºèªã€‚

        æœŸå¾…:
        - ãƒ„ãƒªãƒ¼1.lv1[1].lv2[0].lv3 ã¯1è¦ç´ ã®ã¿
        - ãã®è¦ç´ ã¯ seq ä»¥å¤–ã«ã‚‚å°‘ãªãã¨ã‚‚1ã¤ã®éç©ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤ï¼ˆä¾‹: Cï¼‰
        """
        # çµ„ã¿è¾¼ã¿ãƒ“ãƒ«ãƒ€ãƒ¼ã§ã‚µãƒ³ãƒ—ãƒ«ä»•æ§˜ã«æº–æ‹ ã—ãŸæœ€å°ãƒ–ãƒƒã‚¯ã‚’ç”Ÿæˆ
        _builder = SampleWorkbookBuilder()
        _, xlsx_path = _builder.build(tmp_path)

        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")
        assert "ãƒ„ãƒªãƒ¼1" in result and isinstance(result["ãƒ„ãƒªãƒ¼1"], dict)
        lv1 = result["ãƒ„ãƒªãƒ¼1"].get("lv1", [])
        assert isinstance(lv1, list) and len(lv1) >= 2
        lv2_list = lv1[1].get("lv2", [])
        assert isinstance(lv2_list, list) and len(lv2_list) >= 1
        lv3_list = lv2_list[0].get("lv3", [])
        # seqã®ã¿ã®è¦ç´ ï¼ˆä»–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå…¨ã¦ç©ºï¼‰ã¯å‡ºåŠ›ã•ã‚Œãªã„ãŸã‚ã€1ä»¶ã®ã¿ã‚’æœŸå¾…
        assert isinstance(lv3_list, list)
        assert len(lv3_list) == 1, f"lv3 ã«ä¸è¦ãªè¦ç´ ãŒã‚ã‚Šã¾ã™: {lv3_list}"
        e = lv3_list[0]
        # seq ä»¥å¤–ã«éç©ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ï¼ˆä¾‹: Cï¼‰
        non_seq_non_empty = any(
            (k != "seq") and (v not in (None, "")) for k, v in e.items()
        )
        assert non_seq_non_empty, f"lv3 è¦ç´ ãŒ seq ã®ã¿ã§ã™: {e}"

    def test_samples_tree1_no_spurious_or_duplicates(self, tmp_path):
        """å¤–éƒ¨samples/ã«ä¾å­˜ã›ãšã€ã€ãƒ„ãƒªãƒ¼1ã€ã«ã‚¹ãƒ—ãƒªã‚¢ã‚¹ã‚„é‡è¤‡ãŒç„¡ã„ã“ã¨ã‚’å›å¸°ãƒã‚§ãƒƒã‚¯ã€‚

        æœŸå¾…:
        - lv1 ã¯ 2 ä»¶
        - lv1[0].lv2 ã¯ 2 ä»¶ã§ã€2ä»¶ç›®ï¼ˆseq=1-2ï¼‰ã« lv3 ã¯å­˜åœ¨ã—ãªã„ï¼ˆã‚­ãƒ¼ãŒç„¡ã„ã€ã‚‚ã—ãã¯ç©ºé…åˆ—ï¼‰
        - lv1[1].lv2 ã¯ 1 ä»¶ã§ã€ãã® lv3 ã¯ 1 ä»¶ã®ã¿ï¼ˆé‡è¤‡ãªã—ï¼‰
        - lv3 ã® (C, seq) çµ„ã¯ä¸€æ„
        """
        _builder = SampleWorkbookBuilder()
        _, xlsx_path = _builder.build(tmp_path)

        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")

        assert "ãƒ„ãƒªãƒ¼1" in result, f"keys={list(result.keys())}"
        root = result["ãƒ„ãƒªãƒ¼1"]
        assert (
            isinstance(root, dict) and "lv1" in root and isinstance(root["lv1"], list)
        )

        lv1 = root["lv1"]
        assert len(lv1) == 2

        # 1ä»¶ç›®: lv2 ã¯2ä»¶ã€2ä»¶ç›®ã«ã¯ lv3 ãŒç„¡ã„ï¼ˆã‚­ãƒ¼ç„¡ã— or ç©ºé…åˆ—ï¼‰
        lv2_first = lv1[0].get("lv2", [])
        assert isinstance(lv2_first, list) and len(lv2_first) == 2
        second_lv2 = lv2_first[1]
        assert isinstance(second_lv2, dict)
        lv3_maybe = second_lv2.get("lv3", [])
        assert not lv3_maybe, f"lv1[0].lv2[1].lv3 ã¯ç©ºã§ã‚ã‚‹ã¹ã: {lv3_maybe}"

        # 2ä»¶ç›®: lv2 ã¯1ä»¶ã®ã¿ã§ã€ãã® lv3 ã¯ 1 ä»¶ã®ã¿ï¼ˆé‡è¤‡ãªã—ï¼‰
        lv2_second = lv1[1].get("lv2", [])
        assert isinstance(lv2_second, list) and len(lv2_second) == 1
        only_lv2 = lv2_second[0]
        assert isinstance(only_lv2, dict)
        lv3_list = only_lv2.get("lv3", [])
        assert isinstance(lv3_list, list) and len(lv3_list) == 1

        # (C, seq) ã®çµ„ã§ä¸€æ„æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        uniq = {(e.get("C"), e.get("seq")) for e in lv3_list}
        assert len(uniq) == len(lv3_list), f"lv3 ã«é‡è¤‡ãŒã‚ã‚Šã¾ã™: {lv3_list}"


# === ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã®å˜ä½“ãƒ†ã‚¹ãƒˆï¼ˆçµ±åˆï¼‰ ===

def test_parse_seq_tokens_basic_integrated():
    # æ•°å€¤ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸºæœ¬ãƒ‘ãƒ¼ã‚¹
    assert xlsx2json.parse_seq_tokens("1-2-3") == ["1", "2", "3"]
    assert xlsx2json.parse_seq_tokens("") == []
    assert xlsx2json.parse_seq_tokens("abc") == []
    assert xlsx2json.parse_seq_tokens("1--2") == ["1", "2"]


def test_seq_index_spec_matches_normal_integrated():
    # ç¥–å…ˆ= ("1",), è¦ªç›´ä¸‹=2, ç·é•·=3 ã«ä¸€è‡´ã™ã‚‹ã‚‚ã®ã®ã¿ True
    spec = xlsx2json.SeqIndexSpec(
        ancestor_prefix=("1",), parent_local=2, expected_length=3
    )
    assert spec.matches("1-2-3") is True
    assert spec.matches("1-2") is False
    assert spec.matches("1-9-3") is False
    assert spec.matches("x-2-3") is False


def test_seq_index_spec_matches_strict_only_integrated():
    # ç¥–å…ˆ= ("2",), è¦ªç›´ä¸‹=1, ç·é•·=2 ä»¥å¤–ã¯è¨±å®¹ã—ãªã„
    spec = xlsx2json.SeqIndexSpec(
        ancestor_prefix=("2",), parent_local=1, expected_length=2
    )
    assert spec.matches("2-1") is True
    assert spec.matches("2-2") is False
    assert spec.matches("2-1-1") is False


def test_align_row_phase_integrated():
    # eff_pt=10, anchor=3, step=4 -> ä½ç›¸åˆã‚ã›ã§ 11
    assert xlsx2json.align_row_phase(10, 3, 4) == 11
    # ã™ã§ã«åŒä½ç›¸ã®å ´åˆã¯ãã®ã¾ã¾
    assert xlsx2json.align_row_phase(11, 3, 4) == 11


def test_trim_trailing_empty_integrated():
    # 1D: æœ«å°¾ã®ç©ºå€¤ã‚’é™¤å»
    assert xlsx2json.trim_trailing_empty([1, "", None]) == [1]
    # 2D: å„è¡Œã®æœ«å°¾ã‚’ãƒˆãƒªãƒ 
    assert xlsx2json.trim_trailing_empty([[1, "", None], [2, "a", ""]]) == [
        [1],
        [2, "a"],
    ]



class SampleWorkbookBuilder:
    """Builds a minimal in-memory workbook for è¡¨1/ãƒªã‚¹ãƒˆ1/ãƒ„ãƒªãƒ¼1 samples.

    Usage:
      wb, xlsx_path = SampleWorkbookBuilder().build(tmp_path)
    """

    def __init__(self):
        self.wb = Workbook()
        self.ws = self.wb.active
        self.ws.title = "Sheet1"

    def _table1(self):
        # B2:D3 with values
        draw_rect_border(self.ws, top=2, left=2, bottom=3, right=4)
        set_cells(
            self.ws,
            {
                "B2": "A1",
                "C2": "B1",
                "D2": "C1",
                "B3": "A2",
                "C3": "B2",
                "D3": "C2",
            },
        )
        set_defined_names(
            self.wb,
            {
                "json.è¡¨1.1": "Sheet1!$B$2:$D$3",
                "json.è¡¨1.1.åˆ—A": "Sheet1!$B$2:$B$3",
                "json.è¡¨1.1.åˆ—B": "Sheet1!$C$2:$C$3",
                "json.è¡¨1.1.åˆ—C": "Sheet1!$D$2:$D$3",
            },
        )

    def _list1(self):
        # B6:C8 with values
        draw_rect_border(self.ws, top=6, left=2, bottom=8, right=3)
        set_cells(
            self.ws,
            {
                "B6": "aaaåç§°11",
                "C6": "aaaã‚³ãƒ¼ãƒ‰11-1,aaaã‚³ãƒ¼ãƒ‰11-2",
                "B7": "aaaåç§°12",
                "C7": "aaaã‚³ãƒ¼ãƒ‰12-1,aaaã‚³ãƒ¼ãƒ‰12-2",
                "B8": "aaaåç§°13",
                "C8": "aaaã‚³ãƒ¼ãƒ‰13-1,aaaã‚³ãƒ¼ãƒ‰13-2",
            },
        )
        set_defined_names(
            self.wb,
            {
                "json.ãƒªã‚¹ãƒˆ1.1": "Sheet1!$B$6:$C$8",
                "json.ãƒªã‚¹ãƒˆ1.1.aaaåç§°": "Sheet1!$B$6:$B$8",
                "json.ãƒªã‚¹ãƒˆ1.1.aaaã‚³ãƒ¼ãƒ‰": "Sheet1!$C$6:$C$8",
            },
        )

    def _tree1(self):
        # lv1 (B10:C11, B12:C13), lv2 (E10:F10, E11:F11, E12:F12), lv3 (H10:I10, H11:I11, H12:I12)
        draw_rect_border(self.ws, top=10, left=2, bottom=11, right=3)
        draw_rect_border(self.ws, top=12, left=2, bottom=13, right=3)
        draw_rect_border(self.ws, top=10, left=5, bottom=10, right=6)
        draw_rect_border(self.ws, top=11, left=5, bottom=11, right=6)
        draw_rect_border(self.ws, top=12, left=5, bottom=12, right=6)
        draw_rect_border(self.ws, top=10, left=8, bottom=10, right=9)
        draw_rect_border(self.ws, top=11, left=8, bottom=11, right=9)
        draw_rect_border(self.ws, top=12, left=8, bottom=12, right=9)
        set_cells(
            self.ws,
            {
                # lv1
                "B10": "1",
                "C11": "A1",
                "B12": "2",
                "C13": "A2",
                # lv2
                "E10": "1-1",
                "F10": "B1-1",
                "E11": "1-2",
                "F11": "B1-2",
                "E12": "2-1",
                "F12": "B2-1",
                # lv3
                "H10": "1-1-1",
                "I10": "C1-1-1",
                "H11": "1-1-2",
                "I11": "C1-1-2",
                "H12": "2-1-1",
                "I12": "C2-1-1",
            },
        )
        set_defined_names(
            self.wb,
            {
                "json.ãƒ„ãƒªãƒ¼1.lv1.1": "Sheet1!$B$10:$C$11",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.seq": "Sheet1!$B$10",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.A": "Sheet1!$C$11",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1": "Sheet1!$E$10:$F$10",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.seq": "Sheet1!$E$10",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.B": "Sheet1!$F$10",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.lv3.1": "Sheet1!$H$10:$I$10",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.lv3.1.seq": "Sheet1!$H$10",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.lv2.1.lv3.1.C": "Sheet1!$I$10",
            },
        )

    def build(self, tmp_path: Path) -> tuple[Workbook, Path]:
        self._table1()
        self._list1()
        self._tree1()
        xlsx_path = tmp_path / "embedded_samples.xlsx"
        self.wb.save(xlsx_path)
        return self.wb, xlsx_path


def expected_table1():
    return [
        {"åˆ—A": "A1", "åˆ—B": "B1", "åˆ—C": "C1"},
        {"åˆ—A": "A2", "åˆ—B": "B2", "åˆ—C": "C2"},
    ]


def expected_list1():
    return [
        {"aaaã‚³ãƒ¼ãƒ‰": "aaaã‚³ãƒ¼ãƒ‰11-1,aaaã‚³ãƒ¼ãƒ‰11-2", "aaaåç§°": "aaaåç§°11"},
        {"aaaã‚³ãƒ¼ãƒ‰": "aaaã‚³ãƒ¼ãƒ‰12-1,aaaã‚³ãƒ¼ãƒ‰12-2", "aaaåç§°": "aaaåç§°12"},
        {"aaaã‚³ãƒ¼ãƒ‰": "aaaã‚³ãƒ¼ãƒ‰13-1,aaaã‚³ãƒ¼ãƒ‰13-2", "aaaåç§°": "aaaåç§°13"},
    ]


def expected_tree1():
    return [
        {
            "lv1": {
                "A": "A1",
                "lv2": [
                    {
                        "B": "B1-1",
                        "lv3": [
                            {"C": "C1-1-1", "seq": "1-1-1"},
                            {"C": "C1-1-2", "seq": "1-1-2"},
                        ],
                        "seq": "1-1",
                    },
                    {"B": "B1-2", "seq": "1-2"},
                ],
                "seq": "1",
            }
        },
        {
            "lv1": {
                "A": "A2",
                "lv2": [
                    {
                        "B": "B2-1",
                        "lv3": [{"C": "C2-1-1", "seq": "2-1-1"}],
                        "seq": "2-1",
                    },
                ],
                "seq": "2",
            }
        },
    ]


class TestDataTransformation:
    """ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture(scope="class")
    def temp_dir(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)

    @pytest.fixture(scope="class")
    def creator(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’æä¾›"""
        return DataCreator(temp_dir)

    @pytest.fixture(scope="class")
    def transform_xlsx(self, creator):
        """å¤‰æ›ãƒ«ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_transform_workbook()

    @pytest.fixture(scope="class")
    def complex_xlsx(self, creator):
        """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_complex_workbook()

    @pytest.fixture(scope="class")
    def transform_file(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆç”¨ã®å¤‰æ›é–¢æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        transform_content = '''
def trim_and_upper(value):
    """æ–‡å­—åˆ—ã‚’ãƒˆãƒªãƒ ã—ã¦å¤§æ–‡å­—åŒ–"""
    if isinstance(value, str):
        return value.strip().upper()
    return value

def multiply_by_two(value):
    """æ•°å€¤ã‚’2å€ã«ã™ã‚‹"""
    try:
        return float(value) * 2
    except (ValueError, TypeError):
        return value

def csv_split(value):
    """CSVå½¢å¼ã§åˆ†å‰²"""
    if not isinstance(value, str):
        return value
    import csv
    from io import StringIO
    reader = csv.reader(StringIO(value))
    return [row for row in reader if any(cell.strip() for cell in row)]
'''

        transform_file = temp_dir / "test_transforms.py"
        with transform_file.open("w", encoding="utf-8") as f:
            f.write(transform_content)

        return transform_file


def test_samples_external_list1_contains_multi_values_per_j(tmp_path: Path):
    """ã€ãƒªã‚¹ãƒˆ1ã€ã® j å˜ä½é…åˆ—ã§å¤šå€¤ãŒä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼ã€‚

    æœŸå¾…:
    - i=1, j=2 ã® aaaã‚³ãƒ¼ãƒ‰ ã¯ ["aaa12-1", "aaa12-2"]
    - i=2, j=1 ã® aaaã‚³ãƒ¼ãƒ‰ ã¯ ["aaa21-1", "aaa21-2"]
    ã‚³ãƒ³ãƒ†ãƒŠã¯ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³å®šç¾©: json.ãƒªã‚¹ãƒˆ1.1 ã« labels=["aaaãƒ©ãƒ™ãƒ«"], direction=row, increment=1
    """
    # æœ€å°ã®ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ç”Ÿæˆï¼ˆåˆ—ã¯ B:åç§°, D..F:ã‚³ãƒ¼ãƒ‰ï¼‰ã€‚è¦ªã‚°ãƒ«ãƒ¼ãƒ— i ã”ã¨ã«è¡Œã‚’å‰²å½“:
    # i=1: row2..row4, i=2: row5..row6, i=3: row7
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "Sheet1"

    set_cells(
        ws,
        {
            # i=1, j=1..3
            "B2": "aaaåç§°11",
            "D2": "aaa11-1",
            "E2": "aaa11-2",
            "F2": "aaa11-3",
            "B3": "aaaåç§°12",
            "D3": "aaa12-1",
            "E3": "aaa12-2",
            "B4": "aaaåç§°13",
            "D4": "aaa13-1",
            # i=2, j=1..2
            "B5": "aaaåç§°21",
            "D5": "aaa21-1",
            "E5": "aaa21-2",
            "B6": "aaaåç§°22",
            "D6": "aaa22-1",
            # i=3, j=1
            "B7": "aaaåç§°31",
            "D7": "aaa31-1",
        },
    )

    # æ–°æ–¹é‡ã«åˆã‚ã›ã¦ã€åå‰ä»˜ãç¯„å›²ã«å¯¾å¿œã™ã‚‹ç½«ç·šçŸ©å½¢ã‚’æ•·è¨­ã—ã€
    # labels æŒ‡å®šæ™‚ã®æ¡ä»¶ï¼ˆçŸ©å½¢å†…ã«ãƒ©ãƒ™ãƒ«æ–‡å­—åˆ—ã‚»ãƒ«ã‚’å«ã‚€ï¼‰ã‚’æº€ãŸã™ãŸã‚ã®ã‚»ãƒ«ã‚’é…ç½®ã™ã‚‹ã€‚
    # è¦ª i ã®çŸ©å½¢ã‚’ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«æ•·è¨­ï¼ˆæ±ºå®šè«–çš„ãªè¦ªæ¤œå‡ºã®ãŸã‚è¤‡æ•°çŸ©å½¢ã‚’ç”¨æ„ï¼‰
    # i=1: B2:F4, i=2: B5:F6, i=3: B7:F7
    draw_rect_border(ws, top=2, left=2, bottom=4, right=6)
    draw_rect_border(ws, top=5, left=2, bottom=6, right=6)
    draw_rect_border(ws, top=7, left=2, bottom=7, right=6)
    # å­ã‚³ãƒ³ãƒ†ãƒŠï¼ˆjï¼‰å´ã® labels ã«åˆã‚ã›ã€jã®å„è¡Œã«ãƒ©ãƒ™ãƒ«æ–‡å­—åˆ—ã‚»ãƒ«ã‚’é…ç½®
    for r in [2, 3, 4, 5, 6, 7]:
        ws[f"C{r}"] = "aaaãƒ©ãƒ™ãƒ«"

    # è¦ª/å­ã‚¢ãƒ³ã‚«ãƒ¼ + ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®åå‰ä»˜ãç¯„å›²
    set_defined_names(
        wb,
        {
            # è¦ª i ã®ç¯„å›²ï¼ˆB2:F7ï¼‰
            "json.ãƒªã‚¹ãƒˆ1.1": "Sheet1!$B$2:$F$7",
            # å­ j ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¡Œï¼ˆB2:F2ï¼‰
            "json.ãƒªã‚¹ãƒˆ1.1.1": "Sheet1!$B$2:$F$2",
            # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            "json.ãƒªã‚¹ãƒˆ1.1.1.aaaãƒ©ãƒ™ãƒ«": "Sheet1!$C$2",
            "json.ãƒªã‚¹ãƒˆ1.1.1.aaaåç§°": "Sheet1!$B$2",
            "json.ãƒªã‚¹ãƒˆ1.1.1.aaaã‚³ãƒ¼ãƒ‰": "Sheet1!$D$2:$F$2",
        },
    )

    xlsx_path = tmp_path / "list1_embedded.xlsx"
    wb.save(xlsx_path)

    # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã®ã‚³ãƒ³ãƒ†ãƒŠè¨­å®š
    containers = {
        # è¦ª i: ç½«ç·šçŸ©å½¢åˆ—ã§æ±ºå®šï¼ˆlabelsã¯ä»˜ã‘ãªã„ï¼‰
        "json.ãƒªã‚¹ãƒˆ1.1": {},
        # å­ j: ãƒ©ãƒ™ãƒ«æŒ‡å®šã§åœæ­¢æ¡ä»¶
        "json.ãƒªã‚¹ãƒˆ1.1.1": {
            "labels": ["aaaãƒ©ãƒ™ãƒ«"],
        },
    }

    result = xlsx2json.parse_named_ranges_with_prefix(
        xlsx_path, prefix="json", containers=containers
    )
    root = result.get("json", {})
    assert (
        isinstance(root, dict) and "ãƒªã‚¹ãƒˆ1" in root
    ), f"missing ãƒªã‚¹ãƒˆ1 under json root: keys={list(root.keys())}"
    lst = root["ãƒªã‚¹ãƒˆ1"]
    assert (
        isinstance(lst, list)
        and len(lst) == 3
        and all(isinstance(r, list) for r in lst)
    )

    # æ­£è¦åŒ–: None ã‚’é™¤å¤–
    def nz(v):
        return [x for x in v if x is not None]

    # i=1 (0-based), j=2 (0-based:1)
    assert nz(lst[0][1]["aaaã‚³ãƒ¼ãƒ‰"]) == [
        "aaa12-1",
        "aaa12-2",
    ], f"unexpected codes at i=1,j=2: {lst[0][1].get('aaaã‚³ãƒ¼ãƒ‰')}"
    # i=2 (0-based:1), j=1 (0-based:0)
    assert nz(lst[1][0]["aaaã‚³ãƒ¼ãƒ‰"]) == [
        "aaa21-1",
        "aaa21-2",
    ], f"unexpected codes at i=2,j=1: {lst[1][0].get('aaaã‚³ãƒ¼ãƒ‰')}"

    # === ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ ===

    def test_apply_simple_split_transformation(self, transform_xlsx):
        """å˜ç´”ãªåˆ†å‰²å¤‰æ›ã®é©ç”¨

        ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã‚’é…åˆ—ã«å¤‰æ›ã™ã‚‹åŸºæœ¬çš„ãªåˆ†å‰²å¤‰æ›æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        transform_rules = xlsx2json.parse_array_transform_rules(
            ["json.split_comma=split:,"], prefix="json"
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            transform_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        expected = ["apple", "banana", "orange"]
        assert result["split_comma"] == expected

    def test_apply_multidimensional_split_transformation(self, transform_xlsx):
        """å¤šæ¬¡å…ƒåˆ†å‰²å¤‰æ›ã®é©ç”¨

        è¤‡æ•°ã®åŒºåˆ‡ã‚Šæ–‡å­—ã‚’ä½¿ã£ãŸå¤šæ¬¡å…ƒé…åˆ—å¤‰æ›æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        transform_rules = xlsx2json.parse_array_transform_rules(
            ["json.split_multi=split:;|\\|"], prefix="json"
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            transform_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        # ç¾åœ¨ã®å®Ÿè£…ã«åˆã‚ã›ã¦æœŸå¾…å€¤ã‚’ä¿®æ­£
        # "1;2;3|4;5;6" ãŒ ";" ã§åˆ†å‰²ã•ã‚Œã¦ ["1", "2", "3|4", "5", "6"] ã«ãªã‚Š
        # ã•ã‚‰ã«å„è¦ç´ ãŒ "|" ã§åˆ†å‰²ã•ã‚Œã‚‹
        expected = [["1"], ["2"], ["3", "4"], ["5"], ["6"]]
        assert result["split_multi"] == expected

    def test_apply_newline_split_transformation(self, transform_xlsx):
        """æ”¹è¡Œåˆ†å‰²å¤‰æ›ã®é©ç”¨

        æ”¹è¡Œæ–‡å­—ã«ã‚ˆã‚‹æ–‡å­—åˆ—åˆ†å‰²æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        transform_rules = xlsx2json.parse_array_transform_rules(
            ["json.split_newline=split:\\n"], prefix="json"
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            transform_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        expected = ["line1", "line2", "line3"]
        assert result["split_newline"] == expected

    def test_apply_python_function_transformation(self, transform_xlsx, transform_file):
        """Pythoné–¢æ•°ã«ã‚ˆã‚‹å€¤å¤‰æ›

        å¤–éƒ¨Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®é–¢æ•°ã‚’ä½¿ã£ãŸå€¤ã®å¤‰æ›æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        transform_spec = f"json.function_test=function:{transform_file}:trim_and_upper"
        transform_rules = xlsx2json.parse_array_transform_rules(
            [transform_spec], prefix="json"
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            transform_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        # "  trim_test  " -> "TRIM_TEST"
        assert result["function_test"] == "TRIM_TEST"

    @patch("subprocess.run")
    def test_apply_external_command_transformation(self, mock_run, transform_xlsx):
        """å¤–éƒ¨ã‚³ãƒãƒ³ãƒ‰ã«ã‚ˆã‚‹å€¤å¤‰æ›

        ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ãŸå€¤ã®å¤‰æ›æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ãƒ¢ãƒƒã‚¯ã®è¨­å®šï¼šechoã‚³ãƒãƒ³ãƒ‰ã®çµæœã‚’æ¨¡æ“¬
        mock_result = MagicMock()
        mock_result.returncode = 0
        mock_result.stdout = "COMMAND_TEST_DATA"
        mock_run.return_value = mock_result

        transform_rules = xlsx2json.parse_array_transform_rules(
            ["json.command_test=command:echo"], prefix="json"
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            transform_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        assert result["command_test"] == "COMMAND_TEST_DATA"
        # ã‚³ãƒãƒ³ãƒ‰ã¯åˆæœŸåŒ–æ™‚ã¨actualå®Ÿè¡Œæ™‚ã«2å›å‘¼ã°ã‚Œã‚‹
        assert mock_run.call_count == 2

    def test_parse_and_apply_transformation_rules(self):
        """å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®è§£æã¨é©ç”¨

        å¤‰æ›ãƒ«ãƒ¼ãƒ«æ–‡å­—åˆ—ã®è§£æã¨å†…éƒ¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¸ã®å¤‰æ›ã‚’ãƒ†ã‚¹ãƒˆ
        """
        rules_list = ["colors=split:,", "items=split:\n"]
        rules = xlsx2json.parse_array_transform_rules(rules_list, "json", None)

        assert "colors" in rules
        assert "items" in rules
        assert len(rules["colors"]) > 0 and rules["colors"][0].transform_type == "split"
        assert len(rules["items"]) > 0 and rules["items"][0].transform_type == "split"

    def test_handle_transformation_errors(self):
        """å¤‰æ›ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

        ç„¡åŠ¹ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚„å¤‰æ›å®Ÿè¡Œæ™‚ã®ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç„¡åŠ¹ãªå¤‰æ›ã‚¿ã‚¤ãƒ—
        with pytest.raises(Exception):
            xlsx2json.ArrayTransformRule("test.path", "invalid_type", "spec")

        # ç„¡åŠ¹ãªPythoné–¢æ•°æŒ‡å®š
        try:
            rule = xlsx2json.ArrayTransformRule(
                "test.path", "function", "invalid_syntax("
            )
            rule.transform("test")
        except Exception:
            pass  # ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

    def test_array_transform_rule_functionality(self):
        """ArrayTransformRuleã‚¯ãƒ©ã‚¹ã®æ©Ÿèƒ½

        å¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åŸºæœ¬æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        rule = xlsx2json.ArrayTransformRule(
            "test.path", "split", ","
        )  # ","ãŒæ­£ã—ã„transform_spec
        # è‡ªå‹•è¨­å®šã•ã‚ŒãŸsplité–¢æ•°ã‚’ãƒ†ã‚¹ãƒˆ
        result = rule.transform("a,b,c")
        assert result == ["a", "b", "c"]

    def test_array_transform_rule_transform_comprehensive(self):
        """ArrayTransformRule.transform()ãƒ¡ã‚½ãƒƒãƒ‰ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""

        # functionå‹å¤‰æ›ã®ãƒ†ã‚¹ãƒˆ - trim_enabled=True
        rule = xlsx2json.ArrayTransformRule(
            "test.path", "function", "json:loads", trim_enabled=True
        )

        # ãƒ¢ãƒƒã‚¯functionã‚’è¨­å®š
        def mock_func(value):
            return ["  item1  ", "  item2  "]

        rule._transform_func = mock_func
        result = rule.transform("test")
        expected = ["item1", "item2"]  # trimã•ã‚Œã‚‹
        assert result == expected

        # trim_enabled=Falseã®å ´åˆã¯trimã•ã‚Œãªã„
        rule_no_trim = xlsx2json.ArrayTransformRule(
            "test.path", "function", "json:loads", trim_enabled=False
        )
        rule_no_trim._transform_func = mock_func
        result = rule_no_trim.transform("test")
        assert result == ["  item1  ", "  item2  "]  # trimã•ã‚Œãªã„

        # élistçµæœã®å ´åˆã¯trimã•ã‚Œãªã„
        def mock_func_non_list(value):
            return "  not_list  "

        rule._transform_func = mock_func_non_list
        result = rule.transform("test")
        assert result == "  not_list  "  # élistã¯trimã•ã‚Œãªã„

        # splitå‹å¤‰æ›ã®ãƒ†ã‚¹ãƒˆ
        rule = xlsx2json.ArrayTransformRule(
            "test.path", "split", ","
        )  # ","ãŒæ­£ã—ã„transform_spec

        # ãƒ¢ãƒƒã‚¯splité–¢æ•°ã‚’è¨­å®š
        def mock_split_func(value):
            return value.split(",")

        rule._transform_func = mock_split_func

        # listå…¥åŠ›ã®å ´åˆ
        result = rule.transform(["a,b", "c,d"])
        expected = [["a", "b"], ["c", "d"]]
        assert result == expected

        # élistå…¥åŠ›ã®å ´åˆ
        result = rule.transform("a,b,c")
        expected = ["a", "b", "c"]
        assert result == expected

        # splitå‹ã¯è‡ªå‹•çš„ã«å¤‰æ›é–¢æ•°ãŒè¨­å®šã•ã‚Œã‚‹
        rule = xlsx2json.ArrayTransformRule(
            "test.path", "split", ","
        )  # ","ãŒæ­£ã—ã„transform_spec
        # splitå‹ã®å ´åˆã€è‡ªå‹•çš„ã«_transform_funcãŒè¨­å®šã•ã‚Œã‚‹
        assert hasattr(rule, "_transform_func")
        assert callable(rule._transform_func)

        # splitå‹ã®æ­£å¸¸å‹•ä½œãƒ†ã‚¹ãƒˆ
        result = rule.transform("a,b,c")
        assert result == ["a", "b", "c"]

    @patch("subprocess.run")
    def test_array_transform_rule_command_transform_comprehensive(self, mock_run):
        """ArrayTransformRule._transform_with_command()ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""

        rule = xlsx2json.ArrayTransformRule("test.path", "command", "echo test")

        # æ­£å¸¸ãªã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
        mock_run.return_value = MagicMock(returncode=0, stdout="test output", stderr="")
        result = rule.transform("input")
        assert result == "test output"

        # JSONã¨ã—ã¦è§£æå¯èƒ½ãªå‡ºåŠ›
        mock_run.return_value = MagicMock(
            returncode=0, stdout='{"key": "value"}', stderr=""
        )
        result = rule.transform("input")
        assert result == {"key": "value"}

        # è¤‡æ•°è¡Œå‡ºåŠ›
        mock_run.return_value = MagicMock(
            returncode=0, stdout="line1\nline2\nline3", stderr=""
        )
        result = rule.transform("input")
        assert result == ["line1", "line2", "line3"]

        # ç©ºè¡Œã‚’å«ã‚€è¤‡æ•°è¡Œå‡ºåŠ›
        mock_run.return_value = MagicMock(
            returncode=0, stdout="line1\n\nline3\n", stderr=""
        )
        result = rule.transform("input")
        assert result == ["line1", "line3"]  # ç©ºè¡Œã¯é™¤å»ã•ã‚Œã‚‹

        # ã‚³ãƒãƒ³ãƒ‰å¤±æ•—æ™‚
        mock_run.return_value = MagicMock(
            returncode=1, stdout="", stderr="error message"
        )
        result = rule.transform("test_input")
        assert result == "test_input"  # å…ƒã®å€¤ã‚’è¿”ã™

        # Noneå…¥åŠ›ã®å‡¦ç†
        mock_run.return_value = MagicMock(returncode=0, stdout="output", stderr="")
        result = rule.transform(None)
        # Noneã¯ç©ºæ–‡å­—åˆ—ã«å¤‰æ›ã•ã‚Œã¦ã‚³ãƒãƒ³ãƒ‰ã«æ¸¡ã•ã‚Œã‚‹
        mock_run.assert_called_with(
            ["echo", "test"], input="", stdout=-1, stderr=-1, text=True, timeout=30
        )

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¾‹å¤–
        mock_run.side_effect = subprocess.TimeoutExpired("cmd", 30)
        result = rule.transform("input")
        assert result == "input"  # å…ƒã®å€¤ã‚’è¿”ã™

        # ãã®ä»–ã®ä¾‹å¤–
        mock_run.side_effect = Exception("test error")
        result = rule.transform("input")
        assert result == "input"  # å…ƒã®å€¤ã‚’è¿”ã™

    def test_parse_array_transform_rules_comprehensive(self):
        """parse_array_transform_rules()ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""

        # æ­£å¸¸ãªã‚±ãƒ¼ã‚¹
        rules = [
            "test.path=split:,",
            "func.path=function:json:loads",
            "cmd.path=command:echo test",
        ]

        result = xlsx2json.parse_array_transform_rules(rules, "PREFIX_")

        # æ­£å¸¸ãªãƒ«ãƒ¼ãƒ«ãŒ3ã¤å«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(result) == 3
        assert "test.path" in result
        assert "func.path" in result
        assert "cmd.path" in result

        assert (
            len(result["test.path"]) > 0
            and result["test.path"][0].transform_type == "split"
        )

    def test_command_transform_sorts_unique_lines_from_list_input(self, tmp_path: Path):
        """list å…¥åŠ›: æ”¹è¡Œçµåˆâ†’sort -uâ†’è¡Œé…åˆ—ï¼ˆæ—¢å­˜ä»•æ§˜ç¶™ç¶šï¼‰ã€‚"""
        wb = Workbook(); ws = wb.active; ws.title = "S1"
        ws["A1"] = "ãƒ†ã‚¹ãƒˆ2"; ws["A2"] = "ãƒ†ã‚¹ãƒˆ3"; ws["A3"] = "ãƒ†ã‚¹ãƒˆ1"
        dn = DefinedName("json.command_test", attr_text=f"{ws.title}!$A$1:$A$3")
        wb.defined_names.add(dn)
        xlsx_path = tmp_path / "cmd.xlsx"; wb.save(xlsx_path)
        transforms = ["json.command_test=command:sort -u"]
        rules = xlsx2json.parse_array_transform_rules(transforms, prefix="json", trim_enabled=False)
        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json", array_transform_rules=rules)
        out = result.get("command_test")
        assert out == ["ãƒ†ã‚¹ãƒˆ1", "ãƒ†ã‚¹ãƒˆ2", "ãƒ†ã‚¹ãƒˆ3"], out

        # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã®ãƒ«ãƒ¼ãƒ«
        rules_with_prefix = [
            "PREFIX_.test.path=split:,",
            "PREFIX_.func.path=function:json:loads",
        ]

        result = xlsx2json.parse_array_transform_rules(rules_with_prefix, "PREFIX_")
        assert len(result) == 2
        assert "test.path" in result
        assert "func.path" in result

        # ä¸æ­£ãªãƒ«ãƒ¼ãƒ«å½¢å¼
        invalid_rules = [
            "invalid_rule_without_equals",
            "path=unknown:type",
            "=empty_path",
        ]

        result = xlsx2json.parse_array_transform_rules(invalid_rules, "PREFIX_")
        assert len(result) == 0

        # ç©ºã®ãƒ«ãƒ¼ãƒ«ãƒªã‚¹ãƒˆ
        result = xlsx2json.parse_array_transform_rules([], "PREFIX_")
        assert len(result) == 0

        # ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ï¼šç„¡åŠ¹ãªprefix
        with pytest.raises(
            ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.parse_array_transform_rules(["test=split:,"], "")

        with pytest.raises(
            ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.parse_array_transform_rules(["test=split:,"], None)

        # splitå‹ã®è©³ç´°ãƒ†ã‚¹ãƒˆ
        split_rules = [
            "path1=split:,",
            "path2=split:|",
            "path3=split:,|;",
            "path4=split:\\n",
        ]

        result = xlsx2json.parse_array_transform_rules(split_rules, "PREFIX_")
        assert len(result) == 4

        # splitå‹ã®transformé–¢æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        for path, rule_list in result.items():
            assert len(rule_list) > 0
            rule = rule_list[0]
            assert rule.transform_type == "split"
            assert hasattr(rule, "_transform_func")
            assert callable(rule._transform_func)

        # ãƒ«ãƒ¼ãƒ«ä¸Šæ›¸ãã®ãƒ†ã‚¹ãƒˆï¼ˆfunctionå‹ãŒsplitå‹ã‚’ä¸Šæ›¸ãï¼‰
        overwrite_rules = ["same.path=split:,", "same.path=function:json:loads"]

        result = xlsx2json.parse_array_transform_rules(overwrite_rules, "PREFIX_")
        assert len(result) == 1
        assert len(result["same.path"]) >= 2  # 2ã¤ã®ãƒ«ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã‚‹
        # æœ€å¾Œã«è¿½åŠ ã•ã‚ŒãŸã‚‚ã®ãŒæœ€æ–°ã®ãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹
        assert result["same.path"][-1].transform_type == "function"

        # splitå‹ãŒfunctionå‹ã‚’ä¸Šæ›¸ãã—ãªã„ã“ã¨ã‚’ç¢ºèª
        no_overwrite_rules = ["same.path=function:json:loads", "same.path=split:,"]

        result = xlsx2json.parse_array_transform_rules(no_overwrite_rules, "PREFIX_")
        assert len(result) == 1
        assert len(result["same.path"]) >= 2  # 2ã¤ã®ãƒ«ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã‚‹
        # æœ€å¾Œã«è¿½åŠ ã•ã‚ŒãŸã‚‚ã®ãŒæœ€æ–°ã®ãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹
        assert result["same.path"][-1].transform_type == "split"

    def test_command_transform_list_sort_unique_direct(self):
        """listå…¥åŠ›â†’æ”¹è¡Œé€£çµâ†’sort -uâ†’è¡Œé…åˆ— ã®ç›´æ¥å˜ä½“ãƒ†ã‚¹ãƒˆ (çµ±åˆç‰ˆ)ã€‚"""
        rule = ArrayTransformRule("dummy", "command", "sort -u", trim_enabled=False)
        value = ["ãƒ†ã‚¹ãƒˆ2", "ãƒ†ã‚¹ãƒˆ3", "ãƒ†ã‚¹ãƒˆ1"]
        out = rule.transform(value)
        assert out == ["ãƒ†ã‚¹ãƒˆ1", "ãƒ†ã‚¹ãƒˆ2", "ãƒ†ã‚¹ãƒˆ3"]

    @patch("subprocess.run")
    def test_command_transform_nested_list_as_json(self, mock_run):
        nested = ["a", ["b", "c"], {"k": 1}]
        json_text = json.dumps(nested, ensure_ascii=False)
        mock_run.return_value = MagicMock(returncode=0, stdout=json_text, stderr="")
        rule = ArrayTransformRule("dummy", "command", "dummycmd", trim_enabled=False)
        result = rule.transform(nested)
        assert result == nested
        called = mock_run.call_args.kwargs
        assert called["input"] == json_text

    @patch("subprocess.run")
    def test_command_transform_dict_as_json(self, mock_run):
        data = {"x": 1, "y": [1, 2]}
        json_text = json.dumps(data, ensure_ascii=False)
        mock_run.return_value = MagicMock(returncode=0, stdout=json_text, stderr="")
        rule = ArrayTransformRule("dummy", "command", "dummycmd", trim_enabled=False)
        result = rule.transform(data)
        assert result == data
        called = mock_run.call_args.kwargs
        assert called["input"] == json_text


# === ä½ãƒ¬ãƒ™ãƒ«ãƒ˜ãƒ«ãƒ‘ãƒ¼ã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆï¼ˆé‡è¤‡ã®æ ¹æ²»: ã‚­ãƒ¼ç”Ÿæˆãƒ»çŸ©å½¢æ¤œå‡ºã®æœŸå¾…æŒ™å‹•å›ºå®šï¼‰ ===


class DummyCell:
    def __init__(self):
        self.border = SimpleNamespace(
            left=SimpleNamespace(style=None),
            right=SimpleNamespace(style=None),
            top=SimpleNamespace(style=None),
            bottom=SimpleNamespace(style=None),
        )


class DummySheet:
    def __init__(self, max_row=50, max_column=50):
        self.max_row = max_row
        self.max_column = max_column
        # matrix[row, col] -> DummyCell
        self._grid = {
            (r, c): DummyCell()
            for r in range(1, max_row + 1)
            for c in range(1, max_column + 1)
        }

    def cell(self, row, column):
        return self._grid[(row, column)]


def set_rect_border(ws, top, left, bottom, right):
    # top
    for c in range(left, right + 1):
        ws.cell(row=top, column=c).border.top.style = "thin"
    # bottom
    for c in range(left, right + 1):
        ws.cell(row=bottom, column=c).border.bottom.style = "thin"
    # left
    for r in range(top, bottom + 1):
        ws.cell(row=r, column=left).border.left.style = "thin"
    # right
    for r in range(top, bottom + 1):
        ws.cell(row=r, column=right).border.right.style = "thin"


def wrap_tree_shape(root: dict, level_key: str = "lv1") -> list:
    """Wrap implementation tree shape {level_key:[...]} into
    a list of objects [{level_key: elem}, ...] for comparison with spec.
    If root does not contain the level_key or is not dict/list as expected,
    return an empty list for predictable assertions.
    """
    if not isinstance(root, dict):
        return []
    arr = root.get(level_key)
    if not isinstance(arr, list):
        return []
    return [{level_key: e} for e in arr]


def test_generate_cell_name_for_element_helper():
    g = xlsx2json.generate_cell_name_for_element
    # å˜å±¤
    assert g("json.è¡¨1.1", 5, "A") == "json.è¡¨1.5.A"
    # ãƒã‚¹ãƒˆ: è¦ª=2, å­=7
    assert g("json.è¦ª.2.å­.1", 7, "C") == "json.è¦ª.2.å­.7.C"


def test_border_completeness_full_and_partial_helper():
    ws = DummySheet(max_row=10, max_column=10)
    set_rect_border(ws, 2, 2, 4, 5)
    assert xlsx2json.calculate_border_completeness(ws, 2, 2, 4, 5) == pytest.approx(1.0)
    # å³è¾ºã‚’æ¶ˆã—ã¦éƒ¨åˆ†çš„
    for r in range(2, 5):
        ws.cell(row=r, column=5).border.right.style = None
    assert xlsx2json.calculate_border_completeness(ws, 2, 2, 4, 5) < 1.0


def test_detect_rectangular_regions_basic_sorting():
    ws = DummySheet(max_row=30, max_column=30)
    # å°: (2,2)-(5,6) é¢ç©=4x5=20
    set_rect_border(ws, 2, 2, 5, 6)
    # å¤§: (8,3)-(14,12) é¢ç©=7x10=70
    set_rect_border(ws, 8, 3, 14, 12)

    regs = xlsx2json.detect_rectangular_regions(ws)
    # (top,left,bottom,right,completeness)
    assert len(regs) >= 2
    # å…ˆé ­ã¯å¤§ãã„æ–¹ï¼ˆé¢ç©å„ªå…ˆï¼‰ã§ã‚ã‚‹ã“ã¨
    top, left, bottom, right, comp = regs[0]
    assert (top, left, bottom, right) == (8, 3, 14, 12)
    assert comp == pytest.approx(1.0)


def test_detect_rectangular_regions_with_cell_names_map_filter():
    ws = DummySheet(max_row=30, max_column=30)
    # 2ã¤ã®çŸ©å½¢
    set_rect_border(ws, 2, 2, 5, 6)
    set_rect_border(ws, 8, 3, 14, 12)
    # cell_names_map ã¯ (è¡Œ,åˆ—) ãŒã‚­ãƒ¼
    names_map = {(3, 3): "A", (9, 4): "B"}
    regs = xlsx2json.detect_rectangular_regions(ws, names_map)
    # ä¸¡çŸ©å½¢ã«åå‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã®ã§2ä»¶è¿”ã‚‹
    coords = [(t, l, b, r) for (t, l, b, r, _c) in regs]
    assert (2, 2, 5, 6) in coords and (8, 3, 14, 12) in coords


def test_detect_rectangular_regions_names_map_limits_search_area():
    ws = DummySheet(max_row=200, max_column=50)
    # å·¦ä¸Šã®å°çŸ©å½¢
    set_rect_border(ws, 2, 2, 5, 6)
    # é›¢ã‚ŒãŸå³ä¸‹ã«å¤§çŸ©å½¢ï¼ˆnames_mapã®ãƒãƒ¼ã‚¸ãƒ³å¤–ã¸é…ç½®ï¼‰
    set_rect_border(ws, 150, 15, 160, 20)
    # names_map ã«å·¦ä¸Šã ã‘ã‚’å«ã‚ã‚‹ â†’ ROW_MARGIN/COL_MARGIN å†…ã®æ¢ç´¢ã«é™å®š
    names_map = {(3, 3): "A"}
    regs = xlsx2json.detect_rectangular_regions(ws, names_map)
    coords = [(t, l, b, r) for (t, l, b, r, _c) in regs]
    assert (2, 2, 5, 6) in coords
    # å³ä¸‹ã¯é™¤å¤–ã•ã‚Œã‚‹ï¼ˆæ¢ç´¢ç¯„å›²å¤–ï¼‰
    assert (150, 15, 160, 20) not in coords


def test_generate_cell_name_for_element_no_trailing_index():
    g = xlsx2json.generate_cell_name_for_element
    # æœ«å°¾ãŒæ•°å€¤ã§ãªã„å ´åˆã¯è¦ç´ ç•ªå·ã‚’è¿½åŠ 
    assert g("json.single", 3, "A") == "json.single.3.A"


def test_has_border_adjacency_support():
    ws = DummySheet(max_row=10, max_column=10)
    # ã‚»ãƒ«(5,5) ä¸Šè¾ºã¯æœªè¨­å®šã€‚ä»£ã‚ã‚Šã« (4,5) ã® bottom ã‚’è¨­å®š â†’ éš£æ¥å¢ƒç•Œã§æ¤œçŸ¥ã§ãã‚‹ã“ã¨
    ws.cell(row=4, column=5).border.bottom.style = "thin"
    assert xlsx2json.has_border(ws, 5, 5, "top") is True


class TestSchemaValidation:
    """ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture(scope="class")
    def temp_dir(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)

    @pytest.fixture(scope="class")
    def creator(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’æä¾›"""
        return DataCreator(temp_dir)

    @pytest.fixture(scope="class")
    def basic_xlsx(self, creator):
        """åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_basic_workbook()

    @pytest.fixture(scope="class")
    def wildcard_xlsx(self, creator):
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_wildcard_workbook()

    @pytest.fixture(scope="class")
    def schema_file(self, creator):
        """JSON Schemaãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        schema = {
            "type": "object",
            "properties": {
                "customer": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "address": {"type": "string"},
                    },
                },
                "numbers": {
                    "type": "object",
                    "properties": {
                        "integer": {"type": "integer"},
                        "float": {"type": "number"},
                    },
                },
            },
        }

        schema_path = creator.temp_dir / "schema.json"
        with schema_path.open("w", encoding="utf-8") as f:
            json.dump(schema, f, indent=2)

        return schema_path

    @pytest.fixture(scope="class")
    def wildcard_schema_file(self, creator):
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        schema = {
            "type": "object",
            "properties": {
                "user": {
                    "type": "array",
                    "items": {"type": "string"},
                },
            },
        }

        schema_path = creator.temp_dir / "wildcard_schema.json"
        with schema_path.open("w", encoding="utf-8") as f:
            json.dump(schema, f, indent=2)

        return schema_path

    # === JSON Schemaãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_load_and_validate_schema_success(self, basic_xlsx, schema_file):
        """JSONã‚¹ã‚­ãƒ¼ãƒã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼æˆåŠŸ

        æœ‰åŠ¹ãªJSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼æˆåŠŸã‚’ãƒ†ã‚¹ãƒˆ
        """
        # é…åˆ—å¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚’è¨­å®šã—ã¦çµæœã‚’å–å¾—
        transform_rules = xlsx2json.parse_array_transform_rules(
            [
                "json.tags=split:,",
                "json.numbers.array=split:,",
                "json.matrix=split:;|,",
            ],
            prefix="json",
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            basic_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        schema = xlsx2json.SchemaLoader.load_schema(schema_file)
        validator = Draft7Validator(schema)

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãŒãªã„ã“ã¨ã‚’ç¢ºèª
        errors = list(validator.iter_errors(result))
        # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯ãƒ­ã‚°ã«å‡ºåŠ›ã—ã¦è©³ç´°ã‚’ç¢ºèª
        if errors:
            for error in errors:
                print(f"Validation error: {error.message} at {error.absolute_path}")
        assert len(errors) == 0, f"Schema validation errors: {errors}"

    def test_wildcard_symbol_resolution(self, wildcard_xlsx, wildcard_schema_file):
        """è¨˜å·ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ã«ã‚ˆã‚‹åå‰è§£æ±ºãƒ†ã‚¹ãƒˆ

        "ï¼"è¨˜å·ã«ã‚ˆã‚‹ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚­ãƒ¼ãƒã‚’è¨­å®š
        xlsx2json._global_schema = xlsx2json.SchemaLoader.load_schema(wildcard_schema_file)

        try:
            result = xlsx2json.parse_named_ranges_with_prefix(
                wildcard_xlsx, prefix="json"
            )

            # ãã®ã¾ã¾ä¸€è‡´ã™ã‚‹ã‚±ãƒ¼ã‚¹
            assert result["user_name"] == "ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼‘"

            # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ãƒãƒƒãƒãƒ³ã‚°ï¼ˆuser_group -> userï¼groupï¼‰
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯å…ƒã®ã‚­ãƒ¼åãŒä½¿ç”¨ã•ã‚Œã‚‹
            assert "user_group" in result  # å®Ÿéš›ã«ç”Ÿæˆã•ã‚ŒãŸã‚­ãƒ¼
            assert result["user_group"] == "ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼’"

        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            xlsx2json._global_schema = None

    def test_validation_error_logging(self, temp_dir):
        """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°å‡ºåŠ›æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        ãƒ‡ãƒ¼ã‚¿ãŒã‚¹ã‚­ãƒ¼ãƒã«é•åã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç”Ÿæˆã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿
        invalid_data = {
            "customer": {
                "name": 123,  # æ–‡å­—åˆ—ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒæ•°å€¤
                "address": None,
            },
            "numbers": {
                "integer": "not_a_number",  # æ•°å€¤ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒæ–‡å­—åˆ—
                "float": [],
            },
        }

        # ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "customer": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "address": {"type": "string"},
                    },
                    "required": ["name", "address"],
                },
                "numbers": {
                    "type": "object",
                    "properties": {
                        "integer": {"type": "integer"},
                        "float": {"type": "number"},
                    },
                },
            },
        }

        validator = Draft7Validator(schema)
        log_dir = temp_dir / "validation_logs"

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ­ã‚°å‡ºåŠ›ã‚’å®Ÿè¡Œ
        xlsx2json.SchemaLoader.validate_and_log(invalid_data, validator, log_dir, "test_file")

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        error_log = log_dir / "test_file.error.log"
        assert error_log.exists()

        # ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’ç¢ºèª
        with error_log.open("r", encoding="utf-8") as f:
            log_content = f.read()
            assert "customer.name" in log_content or "name" in log_content
            assert "customer.address" in log_content or "address" in log_content

    def test_validation_no_errors_coverage(self, temp_dir):
        """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãŒãªã„å ´åˆã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ†ã‚¹ãƒˆ

        validate_and_logé–¢æ•°ã§ã‚¨ãƒ©ãƒ¼ãŒãªã„å ´åˆã®æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ã‚’ãƒ†ã‚¹ãƒˆï¼ˆline 54ï¼‰
        """
        # æ­£å¸¸ãªãƒ‡ãƒ¼ã‚¿
        valid_data = {
            "customer": {
                "name": "å±±ç”°å¤ªéƒ",
                "address": "æ±äº¬éƒ½æ¸‹è°·åŒº",
            },
            "numbers": {
                "integer": 123,
                "float": 45.67,
            },
        }

        # ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "customer": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "address": {"type": "string"},
                    },
                },
                "numbers": {
                    "type": "object",
                    "properties": {
                        "integer": {"type": "integer"},
                        "float": {"type": "number"},
                    },
                },
            },
        }

        validator = Draft7Validator(schema)
        log_dir = temp_dir / "validation_logs"

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ï¼‰ã‚’å®Ÿè¡Œ - line 54ã®returnã‚’ã‚«ãƒãƒ¼
        xlsx2json.SchemaLoader.validate_and_log(valid_data, validator, log_dir, "valid_test")

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆã‚¨ãƒ©ãƒ¼ãŒãªã„ãŸã‚ï¼‰
        error_log = log_dir / "valid_test.error.log"
        assert not error_log.exists()

    def test_schema_driven_key_ordering(self):
        """ã‚¹ã‚­ãƒ¼ãƒã«ã‚ˆã‚‹ã‚­ãƒ¼é †åºåˆ¶å¾¡æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        JSONã‚¹ã‚­ãƒ¼ãƒã«å®šç¾©ã•ã‚ŒãŸé †åºã§ã‚­ãƒ¼ãŒä¸¦ã³æ›¿ãˆã‚‰ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # é †åºãŒç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿
        unordered_data = {
            "z_last": "should be last",
            "a_first": "should be first",
            "m_middle": "should be middle",
        }

        # ç‰¹å®šã®é †åºã‚’å®šç¾©ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "a_first": {"type": "string"},
                "m_middle": {"type": "string"},
                "z_last": {"type": "string"},
            },
        }

        result = xlsx2json.reorder_json(unordered_data, schema)

        # ã‚­ãƒ¼ã®é †åºãŒã‚¹ã‚­ãƒ¼ãƒé€šã‚Šã«ãªã‚‹ã“ã¨ã‚’ç¢ºèª
        keys = list(result.keys())
        assert keys == ["a_first", "m_middle", "z_last"]

    def test_reorder_json_missing_keys_coverage(self):
        """reorder_jsoné–¢æ•°ã§å­˜åœ¨ã—ãªã„ã‚­ãƒ¼ã®å‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆline 87ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼‰

        ã‚¹ã‚­ãƒ¼ãƒã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ãŒãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„ã‚­ãƒ¼ã®å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ä¸€éƒ¨ã®ã‚­ãƒ¼ãŒæ¬ ã‘ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿
        incomplete_data = {
            "existing_key": "value1",
            "another_key": "value2",
        }

        # ã‚ˆã‚Šå¤šãã®ã‚­ãƒ¼ã‚’å®šç¾©ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "missing_key": {"type": "string"},  # ãƒ‡ãƒ¼ã‚¿ã«ã¯ãªã„
                "existing_key": {"type": "string"},
                "another_missing": {"type": "string"},  # ãƒ‡ãƒ¼ã‚¿ã«ã¯ãªã„
                "another_key": {"type": "string"},
            },
        }

        result = xlsx2json.reorder_json(incomplete_data, schema)

        # å­˜åœ¨ã™ã‚‹ã‚­ãƒ¼ã®ã¿ãŒå«ã¾ã‚Œã€ã‚¹ã‚­ãƒ¼ãƒã®é †åºã«å¾“ã†ã“ã¨ã‚’ç¢ºèª
        expected_keys = ["existing_key", "another_key"]  # ã‚¹ã‚­ãƒ¼ãƒé †ã§å­˜åœ¨ã™ã‚‹ã‚‚ã®
        assert list(result.keys()) == expected_keys
        assert result["existing_key"] == "value1"
        assert result["another_key"] == "value2"

    def test_reorder_json_array_items_coverage(self):
        """reorder_jsoné–¢æ•°ã§é…åˆ—ã‚¢ã‚¤ãƒ†ãƒ ã®ä¸¦ã³æ›¿ãˆãƒ†ã‚¹ãƒˆï¼ˆline 91ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼‰

        é…åˆ—å†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦ä¸¦ã³æ›¿ãˆã‚‰ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # é…åˆ—ãƒ‡ãƒ¼ã‚¿
        array_data = [
            {"z_field": "z1", "a_field": "a1", "m_field": "m1"},
            {"z_field": "z2", "a_field": "a2", "m_field": "m2"},
        ]

        # é…åˆ—ã‚¢ã‚¤ãƒ†ãƒ ã®ä¸¦ã³æ›¿ãˆã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "a_field": {"type": "string"},
                    "m_field": {"type": "string"},
                    "z_field": {"type": "string"},
                },
            },
        }

        result = xlsx2json.reorder_json(array_data, schema)

        # é…åˆ—ã®å„è¦ç´ ãŒã‚¹ã‚­ãƒ¼ãƒé †ã«ä¸¦ã³æ›¿ãˆã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert isinstance(result, list)
        assert len(result) == 2

        for item in result:
            keys = list(item.keys())
            assert keys == ["a_field", "m_field", "z_field"]

    def test_nested_object_schema_validation(self):
        """ãƒã‚¹ãƒˆã—ãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆ

        è¤‡é›‘ãªãƒã‚¹ãƒˆæ§‹é€ ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ãƒã‚¹ãƒˆã—ãŸãƒ‡ãƒ¼ã‚¿
        nested_data = {
            "company": {
                "name": "ãƒ†ã‚¹ãƒˆä¼šç¤¾",
                "departments": [
                    {"name": "é–‹ç™ºéƒ¨", "employees": [{"name": "ç”°ä¸­", "age": 30}]},
                    {"name": "å“è³ªä¿è¨¼éƒ¨", "employees": [{"name": "ä½è—¤", "age": 25}]},
                ],
            }
        }

        # ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã®ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "company": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "departments": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "name": {"type": "string"},
                                    "employees": {
                                        "type": "array",
                                        "items": {
                                            "type": "object",
                                            "properties": {
                                                "name": {"type": "string"},
                                                "age": {"type": "integer"},
                                            },
                                            "required": ["name", "age"],
                                        },
                                    },
                                },
                                "required": ["name", "employees"],
                            },
                        },
                    },
                    "required": ["name", "departments"],
                },
            },
            "required": ["company"],
        }

        validator = Draft7Validator(schema)
        errors = list(validator.iter_errors(nested_data))

        assert len(errors) == 0, f"Validation errors: {errors}"

    def test_schema_load_error_handling(self, temp_dir):
        """ã‚¹ã‚­ãƒ¼ãƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ

        ä¸æ­£ãªã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒé©åˆ‡ã«è¡Œã‚ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«
        nonexistent_file = temp_dir / "nonexistent_schema.json"
        with pytest.raises(FileNotFoundError):
            xlsx2json.SchemaLoader.load_schema(nonexistent_file)

        # ä¸æ­£ãªJSONãƒ•ã‚¡ã‚¤ãƒ«
        invalid_schema_file = temp_dir / "invalid_schema.json"
        with invalid_schema_file.open("w") as f:
            f.write("{ invalid json content")

        with pytest.raises(json.JSONDecodeError):
            xlsx2json.SchemaLoader.load_schema(invalid_schema_file)

        # Noneãƒ‘ã‚¹ã®ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.SchemaLoader.load_schema(None)
        assert result is None

    def test_array_transform_comprehensive_lines_478_487_from_precision(self):
        """é…åˆ—å¤‰æ›ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆï¼ˆçµ±åˆï¼šé‡è¤‡å‰Šé™¤æ¸ˆã¿ï¼‰

        é…åˆ—å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®è©³ç´°ãªå‹•ä½œã¨ä¾‹å¤–å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # Noneå…¥åŠ›ã®ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.convert_string_to_multidimensional_array(None, [","])
        assert result is None

        # ç©ºæ–‡å­—åˆ—ã®ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.convert_string_to_multidimensional_array("", [","])
        assert result == []

        # è¤‡é›‘ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ
        test_rules = [
            "json.data=split:,",
            "json.values=function:lambda x: x.split('-')",
            "json.commands=command:echo test",
        ]

        # ã‚¹ã‚­ãƒ¼ãƒãƒ™ãƒ¼ã‚¹ã®å¤‰æ›ãƒ«ãƒ¼ãƒ«è§£æãƒ†ã‚¹ãƒˆ
        test_schema = {
            "type": "object",
            "properties": {
                "items": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "data": {"type": "array"},
                            "values": {"type": "array"},
                            "commands": {"type": "array"},
                        },
                    },
                }
            },
        }

        # ç„¡åŠ¹ãªãƒ«ãƒ¼ãƒ«å½¢å¼ã®ãƒ†ã‚¹ãƒˆ
        with patch("xlsx2json.logger") as mock_logger:
            invalid_rules = ["invalid_rule_format", "another=invalid"]
            xlsx2json.parse_array_split_rules(invalid_rules, "json")  # prefixå¼•æ•°ã‚’è¿½åŠ 
            mock_logger.warning.assert_called()

        # è¤‡é›‘ãªåˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆ
        test_string = "a;b;c\nd;e;f"
        result = xlsx2json.convert_string_to_multidimensional_array(
            test_string, ["\n", ";"]
        )
        expected = [["a", "b", "c"], ["d", "e", "f"]]
        assert result == expected

    def test_load_schema_enhanced_validation(self):
        """load_schemaé–¢æ•°ã®æ‹¡å¼µãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ
            nonexistent_file = temp_path / "nonexistent.json"
            with pytest.raises(
                FileNotFoundError, match="ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            ):
                xlsx2json.SchemaLoader.load_schema(nonexistent_file)

            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®šã—ãŸå ´åˆã®ãƒ†ã‚¹ãƒˆ
            dir_path = temp_path / "directory"
            dir_path.mkdir()
            with pytest.raises(
                ValueError, match="æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            ):
                xlsx2json.SchemaLoader.load_schema(dir_path)

            # èª­ã¿è¾¼ã¿æ¨©é™ã®ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
            # ã“ã®å ´åˆã¯FileNotFoundErrorãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
            broken_file = temp_path / "broken.json"
            broken_file.write_text("valid json content", encoding="utf-8")
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            broken_file.unlink()

            with pytest.raises(FileNotFoundError):
                xlsx2json.SchemaLoader.load_schema(broken_file)

    def test_reorder_json_comprehensive(self):
        """reorder_jsoné–¢æ•°ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""

        # åŸºæœ¬çš„ãªdictä¸¦ã³æ›¿ãˆ
        data = {"z": 1, "a": 2, "m": 3}
        schema = {
            "type": "object",
            "properties": {
                "a": {"type": "number"},
                "m": {"type": "string"},
                "z": {"type": "number"},
            },
        }
        result = xlsx2json.reorder_json(data, schema)
        keys_order = list(result.keys())
        assert keys_order == ["a", "m", "z"]  # ã‚¹ã‚­ãƒ¼ãƒé †

        # ã‚¹ã‚­ãƒ¼ãƒã«ãªã„ã‚­ãƒ¼ã®å‡¦ç†
        data = {"z": 1, "unknown": "value", "a": 2}
        result = xlsx2json.reorder_json(data, schema)
        keys_order = list(result.keys())
        assert keys_order == ["a", "z", "unknown"]  # ã‚¹ã‚­ãƒ¼ãƒé † + ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †

        # å†å¸°çš„ãªä¸¦ã³æ›¿ãˆ
        data = {"outer": {"z": 1, "a": 2}, "simple": "value"}
        schema = {
            "type": "object",
            "properties": {
                "outer": {
                    "type": "object",
                    "properties": {"a": {"type": "number"}, "z": {"type": "number"}},
                },
                "simple": {"type": "string"},
            },
        }
        result = xlsx2json.reorder_json(data, schema)
        assert list(result.keys()) == ["outer", "simple"]
        assert list(result["outer"].keys()) == ["a", "z"]

        # listå‹ã®å‡¦ç†
        data = [{"z": 1, "a": 2}, {"b": 3, "a": 4}]
        schema = {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "a": {"type": "number"},
                    "b": {"type": "number"},
                    "z": {"type": "number"},
                },
            },
        }
        result = xlsx2json.reorder_json(data, schema)
        assert list(result[0].keys()) == ["a", "z"]
        assert list(result[1].keys()) == ["a", "b"]

        # ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–å‹ã®å‡¦ç†ï¼ˆãã®ã¾ã¾è¿”ã™ï¼‰
        assert xlsx2json.reorder_json("string", schema) == "string"
        assert xlsx2json.reorder_json(123, schema) == 123
        assert xlsx2json.reorder_json(None, schema) is None

        # ã‚¹ã‚­ãƒ¼ãƒãŒdictã§ãªã„å ´åˆ
        result = xlsx2json.reorder_json({"a": 1}, "not_dict")
        assert result == {"a": 1}

        # objãŒdictã§ãªã„å ´åˆ
        result = xlsx2json.reorder_json("not_dict", schema)
        assert result == "not_dict"

        # listã§ã‚¹ã‚­ãƒ¼ãƒã«itemsãŒãªã„å ´åˆ
        data = [1, 2, 3]
        schema = {"type": "array"}  # itemsãŒãªã„
        result = xlsx2json.reorder_json(data, schema)
        assert result == [1, 2, 3]


class TestJSONOutput:
    """JSONå‡ºåŠ›ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture(scope="class")
    def temp_dir(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)

    @pytest.fixture(scope="class")
    def creator(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’æä¾›"""
        return DataCreator(temp_dir)

    @pytest.fixture(scope="class")
    def basic_xlsx(self, creator):
        """åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_basic_workbook()

    @pytest.fixture(scope="class")
    def complex_xlsx(self, creator):
        """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_complex_workbook()

    # === JSONå‡ºåŠ›åˆ¶å¾¡æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_json_file_output_basic_formatting(self, basic_xlsx, temp_dir):
        """åŸºæœ¬çš„ãªJSONãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¶å¾¡ãƒ†ã‚¹ãƒˆ

        JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›ã¨ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒæ­£ã—ãåˆ¶å¾¡ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
        output_path = temp_dir / "test_output.json"
        xlsx2json.write_data(result, output_path)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert output_path.exists()

        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’ç¢ºèª
        with output_path.open("r", encoding="utf-8") as f:
            content = f.read()
            # JSONå½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            data = json.loads(content)
            assert isinstance(data, dict)
            assert "customer" in data
            assert "numbers" in data

    def test_complex_data_structure_processing(self, complex_xlsx):
        """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        result = xlsx2json.parse_named_ranges_with_prefix(complex_xlsx, prefix="json")

        # ã‚·ã‚¹ãƒ†ãƒ å
        assert result["system"]["name"] == "ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ "

        # éƒ¨ç½²é…åˆ—ã®ç¢ºèª
        departments = result["departments"]
        assert isinstance(departments, list)
        assert len(departments) == 2

        # 1ç•ªç›®ã®éƒ¨ç½²
        dept1 = departments[0]
        assert dept1["name"] == "é–‹ç™ºéƒ¨"
        assert dept1["manager"]["name"] == "ç”°ä¸­èŠ±å­"
        assert dept1["manager"]["email"] == "tanaka@example.com"

        # 2ç•ªç›®ã®éƒ¨ç½²
        dept2 = departments[1]
        assert dept2["name"] == "ãƒ†ã‚¹ãƒˆéƒ¨"
        assert dept2["manager"]["name"] == "ä½è—¤æ¬¡éƒ"

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé…åˆ—ã®ç¢ºèª
        projects = result["projects"]
        assert isinstance(projects, list)
        assert len(projects) == 2
        assert projects[0]["name"] == "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆÎ±"
        assert projects[1]["status"] == "å®Œäº†"

    def test_array_with_split_transformation(self, complex_xlsx):
        """é…åˆ—ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        transform_rules = xlsx2json.parse_array_transform_rules(
            ["json.tasks=split:,", "json.priorities=split:,", "json.deadlines=split:,"],
            prefix="json",
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            complex_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        # ã‚¿ã‚¹ã‚¯ã®åˆ†å‰²ç¢ºèª
        assert result["tasks"] == ["ã‚¿ã‚¹ã‚¯1", "ã‚¿ã‚¹ã‚¯2", "ã‚¿ã‚¹ã‚¯3"]
        assert result["priorities"] == ["é«˜", "ä¸­", "ä½"]
        assert result["deadlines"] == ["2025-02-01", "2025-02-15", "2025-03-01"]

    def test_multidimensional_array_like_samples(self, complex_xlsx):
        """samplesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®parenté…åˆ—ã®ã‚ˆã†ãªå¤šæ¬¡å…ƒé…åˆ—ãƒ†ã‚¹ãƒˆ"""
        # åˆ†å‰²å¤‰æ›ã¯è¡Œã‚ãšã€æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.parse_named_ranges_with_prefix(complex_xlsx, prefix="json")

        parent = result["parent"]
        assert isinstance(parent, list)  # ãƒªã‚¹ãƒˆã¨ã—ã¦æ§‹ç¯‰ã•ã‚Œã‚‹
        assert len(parent) == 3  # 3ã¤ã®è¡Œ

        # å„è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
        assert len(parent[0]) == 2  # 1è¡Œç›®: 2ã¤ã®åˆ—
        assert len(parent[1]) == 2  # 2è¡Œç›®: 2ã¤ã®åˆ—
        assert len(parent[2]) == 1  # 3è¡Œç›®: 1ã¤ã®åˆ—

    # === JSONå‡ºåŠ›ã®ãƒ†ã‚¹ãƒˆ ===

    def test_json_output_formatting(self, basic_xlsx, temp_dir):
        """JSONå‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        output_file = temp_dir / "test_output.json"
        xlsx2json.write_data(result, output_file)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        assert output_file.exists()

        # JSONå½¢å¼ã§èª­ã¿è¾¼ã¿å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        with output_file.open("r", encoding="utf-8") as f:
            reloaded_data = json.load(f)

        assert reloaded_data["customer"]["name"] == "å±±ç”°å¤ªéƒ"

    def test_datetime_serialization(self, basic_xlsx, temp_dir):
        """æ—¥æ™‚å‹ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        output_file = temp_dir / "datetime_test.json"
        xlsx2json.write_data(result, output_file)

        # JSONèª­ã¿è¾¼ã¿æ™‚ã«datetimeãŒæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        with output_file.open("r", encoding="utf-8") as f:
            reloaded_data = json.load(f)

        # ISOå½¢å¼ã®æ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert isinstance(reloaded_data["datetime"], str)
        assert reloaded_data["datetime"].startswith("2025-01-15T")

        assert isinstance(reloaded_data["date"], str)
        assert reloaded_data["date"] == "2025-01-19T00:00:00"  # å®Ÿéš›ã®å‡ºåŠ›å½¢å¼

    # === ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ ===

    def test_error_handling_invalid_file(self, temp_dir):
        """ç„¡åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        invalid_file = temp_dir / "nonexistent.xlsx"

        with pytest.raises(FileNotFoundError):
            xlsx2json.parse_named_ranges_with_prefix(invalid_file, prefix="json")

    def test_error_handling_invalid_transform_rule(self):
        """ç„¡åŠ¹ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        invalid_rules = [
            "invalid_format",  # = ãŒãªã„
            "json.test=unknown:invalid",  # ä¸æ˜ãªå¤‰æ›ã‚¿ã‚¤ãƒ—
        ]

        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒåœæ­¢ã—ãªã„ã“ã¨ã‚’ç¢ºèª
        for rule in invalid_rules:
            # è­¦å‘Šãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…
            transform_rules = xlsx2json.parse_array_transform_rules(
                [rule], prefix="json"
            )
            # ç„¡åŠ¹ãªãƒ«ãƒ¼ãƒ«ã¯ç„¡è¦–ã•ã‚Œã‚‹ã‹ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã•ã‚Œã‚‹
            assert isinstance(transform_rules, dict)

    def test_prefix_customization(self, temp_dir):
        """ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãƒ†ã‚¹ãƒˆ"""
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ç”¨ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        workbook = Workbook()
        worksheet = workbook.active
        worksheet.title = "Sheet1"  # ã‚·ãƒ¼ãƒˆåã‚’æ˜ç¤ºçš„ã«è¨­å®š
        worksheet["A1"] = "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ"

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§åå‰ä»˜ãç¯„å›²ã‚’å®šç¾©
        set_defined_names(workbook, {"custom.test.value": "A1"})

        custom_file = temp_dir / "custom_prefix.xlsx"
        workbook.save(custom_file)

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§è§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(custom_file, prefix="custom")

        assert result["test"]["value"] == "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ"

    # === ã‚«ãƒãƒ¬ãƒƒã‚¸æ‹¡å¼µãƒ†ã‚¹ãƒˆ ===

    def test_validate_and_log_with_errors(self, temp_dir):
        """validate_and_logé–¢æ•°ã§ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        # ã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©
        schema = {
            "type": "object",
            "properties": {"name": {"type": "string"}, "age": {"type": "number"}},
            "required": ["name"],
        }

        # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿
        invalid_data = {
            "age": "not_a_number",  # æ•°å€¤ã§ãªã„
            # "name"ãŒå¿…é ˆã ãŒå­˜åœ¨ã—ãªã„
        }

        validator = Draft7Validator(schema)
        log_dir = temp_dir / "logs"
        base_name = "test"

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç”Ÿæˆ
        xlsx2json.SchemaLoader.validate_and_log(invalid_data, validator, log_dir, base_name)

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        error_log = log_dir / f"{base_name}.error.log"
        assert error_log.exists()

        # ãƒ­ã‚°å†…å®¹ã‚’ç¢ºèª
        with error_log.open("r", encoding="utf-8") as f:
            content = f.read()

        assert "age" in content  # å‹ã‚¨ãƒ©ãƒ¼
        assert ": 'name' is a required property" in content  # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼

    def test_parse_array_split_rules_comprehensive(self):
        """parse_array_split_rulesé–¢æ•°ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
        # è¤‡é›‘ãªåˆ†å‰²ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ
        rules = [
            "json.field1=,",
            "json.nested.field2=;|\\n",
            "json.field3=\\t|\\|",
        ]

        result = xlsx2json.parse_array_split_rules(rules, prefix="json.")

        # ãƒ«ãƒ¼ãƒ«ãŒæ­£ã—ãè§£æã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹å‰Šé™¤å¾Œï¼‰
        assert "field1" in result
        assert result["field1"] == [","]

        assert "nested.field2" in result
        assert result["nested.field2"] == [";", "\n"]

        assert "field3" in result
        assert result["field3"] == ["\t", "|"]

    def test_array_transform_rule_setup_errors(self):
        """ArrayTransformRule ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
        # ç„¡åŠ¹ãªå¤‰æ›ã‚¿ã‚¤ãƒ—
        with pytest.raises(ValueError, match="Unknown transform type"):
            xlsx2json.ArrayTransformRule("test", "invalid_type", "spec")

    def test_array_transform_rule_command_with_timeout(self):
        """ArrayTransformRule ã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ†ã‚¹ãƒˆ"""
        # éå¸¸ã«çŸ­ã„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
        with patch("subprocess.run") as mock_run:
            mock_run.side_effect = subprocess.TimeoutExpired("echo", 0.001)

            rule = xlsx2json.ArrayTransformRule("test", "command", "command:echo")
            result = rule.transform("test_data")

            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯å…ƒã®å€¤ãŒè¿”ã•ã‚Œã‚‹
            assert result == "test_data"

    def test_array_transform_rule_command_with_error(self):
        """ArrayTransformRule ã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # splitã‚¿ã‚¤ãƒ—ã®ãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ã€å¤‰æ›é–¢æ•°ãŒæ­£ã—ãè¨­å®šã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        rule = xlsx2json.ArrayTransformRule("test", "split", "split:,")

        # å¤–éƒ¨ã‹ã‚‰å¤‰æ›é–¢æ•°ã‚’è¨­å®šï¼ˆå®Ÿéš›ã®å‡¦ç†ã§è¡Œã‚ã‚Œã‚‹ï¼‰
        rule._transform_func = lambda x: xlsx2json.convert_string_to_array(x, ",")

        # é€šå¸¸ã®å‹•ä½œç¢ºèª
        result = rule.transform("a,b,c")
        assert result == ["a", "b", "c"]

    def test_array_transform_rule_command_json_output(self):
        """ArrayTransformRule ã®ã‚³ãƒãƒ³ãƒ‰JSONå‡ºåŠ›ãƒ†ã‚¹ãƒˆ"""
        mock_result = MagicMock()
        mock_result.returncode = 0
        mock_result.stdout = '["result1", "result2"]'

        with patch("subprocess.run", return_value=mock_result):
            rule = xlsx2json.ArrayTransformRule("test", "command", "command:echo")
            result = rule.transform("test_data")

            # JSONé…åˆ—ã¨ã—ã¦è§£æã•ã‚Œã‚‹
            assert result == ["result1", "result2"]

    def test_array_transform_rule_command_multiline_output(self):
        """ArrayTransformRule ã®ã‚³ãƒãƒ³ãƒ‰è¤‡æ•°è¡Œå‡ºåŠ›ãƒ†ã‚¹ãƒˆ"""
        mock_result = MagicMock()
        mock_result.returncode = 0
        mock_result.stdout = "line1\nline2\nline3\n"

        with patch("subprocess.run", return_value=mock_result):
            rule = xlsx2json.ArrayTransformRule("test", "command", "command:echo")
            result = rule.transform("test_data")

            # æ–°ä»•æ§˜: è¤‡æ•°è¡Œã§ã‚‚ã‚¹ã‚«ãƒ©å…¥åŠ›æ™‚ã¯æ–‡å­—åˆ—ã®ã¾ã¾
            assert result == "line1\nline2\nline3\n"

    def test_array_transform_rule_command_failed_return_code(self):
        """ArrayTransformRule ã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œå¤±æ•—ãƒ†ã‚¹ãƒˆ"""
        mock_result = MagicMock()
        mock_result.returncode = 1
        mock_result.stdout = "error output"
        mock_result.stderr = "error message"

        with patch("subprocess.run", return_value=mock_result):
            rule = xlsx2json.ArrayTransformRule(
                "test", "command", "command:failing_command"
            )
            result = rule.transform("test_data")

            # å¤±æ•—æ™‚ã¯å…ƒã®å€¤ãŒè¿”ã•ã‚Œã‚‹
            assert result == "test_data"

    def test_clean_empty_values(self):
        """clean_empty_arrays_contextuallyé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
        data = {
            "tags": [None, "", "tag1"],  # ç©ºè¦ç´ ã‚’å«ã‚€
            "empty_array": [],  # å®Œå…¨ã«ç©ºã®é…åˆ—
            "nested": {"items": ["", None, "item1"], "empty": []},
        }
        result = xlsx2json.clean_empty_values(data)

        # ç©ºè¦ç´ ãŒé™¤å»ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(result["tags"]) == 1
        assert result["tags"][0] == "tag1"

        # å®Œå…¨ã«ç©ºã®é…åˆ—ã¯é™¤å»ã•ã‚Œã‚‹
        assert "empty_array" not in result

        # ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã‚‚å‡¦ç†ã•ã‚Œã‚‹
        assert len(result["nested"]["items"]) == 1
        assert result["nested"]["items"][0] == "item1"
        assert "empty" not in result["nested"]

    def test_clean_empty_values_keep_empty_sibling_level(self):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³â‘ -1: åŒãƒ¬ãƒ™ãƒ«ã«ä»–ã®è¦ç´ ãŒã‚ã‚‹å ´åˆã€ç©ºæ§‹é€ ã¯ []/{} ã¨ã—ã¦æ®‹ã™ã€‚"""
        src = {
            "root": {
                "m1": {"p": [None, ""]},
                "m2": {"n": [None]},
                "other": "x",
            }
        }
        out = xlsx2json.clean_empty_values(src)
        assert out["root"]["m1"]["p"] == []
        assert out["root"]["m2"]["n"] == []
        assert out["root"]["other"] == "x"

    def test_clean_empty_values_drop_when_no_sibling(self):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³â‘ -2: åŒãƒ¬ãƒ™ãƒ«ã«ä»–ã®è¦ç´ ãŒãªã„å ´åˆã€ç©ºæ§‹é€ ã¯å‰Šé™¤ã•ã‚Œã‚‹ã€‚"""
        src = {
            "root": {
                "m1": {"p": [None, ""]},
                "m2": {"n": [None]},
            }
        }
        out = xlsx2json.clean_empty_values(src)
        assert out == {}

    def test_clean_empty_values_keep_with_schema_when_no_sibling_1(self):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³â‘¡-1: å…„å¼ŸãŒç„¡ãã¦ã‚‚ã‚¹ã‚­ãƒ¼ãƒãŒã‚ã‚‹å ´åˆã¯é…åˆ—æ§‹é€ ã‚’ [] ã¨ã—ã¦ä¿æŒï¼ˆå†å¸°ï¼‰ã€‚"""
        src = {
            "root": {
                "a": {"b": {"c": [None, ""]}},
            }
        }
        schema = {
            "type": "object",
            "properties": {
                "root": {
                    "type": "object",
                    "properties": {
                        "a": {
                            "type": "object",
                            "properties": {
                                "b": {
                                    "type": "object",
                                    "properties": {
                                        "c": {"type": "array", "items": {"type": "string"}},
                                    },
                                }
                            },
                        }
                    },
                }
            },
        }
        out = xlsx2json.clean_empty_values(src, schema=schema)
        # c ã¯ [] ã¨ã—ã¦ä¿æŒã•ã‚Œã‚‹
        assert out["root"]["a"]["b"]["c"] == []

    def test_clean_empty_values_keep_with_schema_when_no_sibling_2(self):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³â‘¡-2: å…„å¼ŸãŒç„¡ãã¦ã‚‚ã‚¹ã‚­ãƒ¼ãƒãŒã‚ã‚‹å ´åˆã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’ {} ã¨ã—ã¦ä¿æŒï¼ˆå†å¸°ï¼‰ã€‚"""
        src = {
            "root": {
                "a": {"b": {"c": {"d1": None, "d2": ""}}},
            }
        }
        schema = {
            "type": "object",
            "properties": {
                "root": {
                    "type": "object",
                    "properties": {
                        "a": {
                            "type": "object",
                            "properties": {
                                "b": {
                                    "type": "object",
                                    "properties": {
                                        "c": {
                                            "type": "object",
                                            "properties": {"x": {"type": "string"}}
                                        },
                                    },
                                }
                            },
                        }
                    },
                }
            },
        }
        out = xlsx2json.clean_empty_values(src, schema=schema)
        # c ã¯ {} ã¨ã—ã¦ä¿æŒã•ã‚Œã‚‹
        assert out["root"]["a"]["b"]["c"] == {}

    def test_global_trim_functionality(self, temp_dir):
        """ã‚°ãƒ­ãƒ¼ãƒãƒ«trimæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®ãƒ†ã‚¹ãƒˆ
        original_trim = getattr(xlsx2json, "_global_trim", False)
        try:
            xlsx2json._global_trim = True
            assert xlsx2json._global_trim is True
            xlsx2json._global_trim = False
            assert xlsx2json._global_trim is False

            # setupé–¢æ•°ã®ä¸æ­£ãªä»•æ§˜ã§ã®ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
            with pytest.raises(
                ValueError, match="transform_specã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            ):
                xlsx2json.ArrayTransformRule("invalid", "function", "")
        finally:
            xlsx2json._global_trim = original_trim

    def test_insert_json_path_type_error(self):
        """insert_json_pathé–¢æ•°ã®å‹ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # ä¸æ­£ãªå‹ã®rootã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        with pytest.raises(TypeError, match="insert_json_path: root must be dict"):
            xlsx2json.insert_json_path("not_a_dict", ["key"], "value")

    def test_insert_json_path_path_collision(self):
        """insert_json_pathé–¢æ•°ã®ãƒ‘ã‚¹è¡çªãƒ†ã‚¹ãƒˆ"""
        root = {}

        # æœ€åˆã®ãƒ‘ã‚¹
        xlsx2json.insert_json_path(root, ["user", "name"], "John")
        assert root["user"]["name"] == "John"

        # åŒã˜ãƒ‘ã‚¹ã«åˆ¥ã®å€¤ã‚’è¨­å®šï¼ˆä¸Šæ›¸ãï¼‰
        xlsx2json.insert_json_path(root, ["user", "name"], "Jane")
        assert root["user"]["name"] == "Jane"

    def test_write_data_with_datetime_serialization(self, temp_dir):
        """write_dataé–¢æ•°ã§datetimeã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        data = {
            "datetime": datetime(2025, 1, 15, 10, 30, 45),
            "date": date(2025, 1, 19),
        }

        output_file = temp_dir / "datetime_test.json"
        xlsx2json.write_data(data, output_file)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert output_file.exists()

        # JSONèª­ã¿è¾¼ã¿æ™‚ã«datetimeãŒæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        with output_file.open("r", encoding="utf-8") as f:
            reloaded_data = json.load(f)

        # ISOå½¢å¼ã®æ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert isinstance(reloaded_data["datetime"], str)
        assert reloaded_data["datetime"].startswith("2025-01-15T")

        assert isinstance(reloaded_data["date"], str)
        assert reloaded_data["date"] == "2025-01-19"

    def test_schema_less_preserves_excel_key_order_no_seq_first(self, tmp_path: Path):
        """ã‚¹ã‚­ãƒ¼ãƒç„¡ã—ã®å‡ºåŠ›ã§ã¯ã€Excelèª­å–é †ã®ã‚­ãƒ¼é †ãŒä¿æŒã•ã‚Œã€'seq' ãŒå…ˆé ­ã¸å¼·åˆ¶ã•ã‚Œãªã„ã“ã¨ã€‚

        lv2 è¦ç´ å†…ã§ B ãŒå·¦ï¼ˆå…ˆï¼‰ãƒ»seq ãŒå³ï¼ˆå¾Œï¼‰ã«é…ç½®ã•ã‚Œã‚‹æ§‹æˆã‚’ä½œã‚Šã€
        ã‚¹ã‚­ãƒ¼ãƒç„¡ã—ã§ write_data ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿ç›´ã—ã¦ã‚­ãƒ¼é †ã‚’æ¤œè¨¼ã™ã‚‹ã€‚
        æœŸå¾…: ['B', 'seq']ï¼ˆseq-first ã«ãªã‚‰ãªã„ï¼‰
        """
        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"

        # lv1 ã‚¢ãƒ³ã‚«ãƒ¼ï¼ˆ2è¡Œï¼‰
        draw_rect_border(ws, top=10, left=2, bottom=11, right=3)  # B10:C11
        # lv2 ã‚¢ãƒ³ã‚«ãƒ¼ï¼ˆ1è¡Œï¼‰
        draw_rect_border(ws, top=10, left=5, bottom=10, right=6)  # E10:F10

        # å€¤: lv1 (seq, A) ã¨ lv2 (B, seq) - B ã‚’å·¦, seq ã‚’å³ã«é…ç½®
        set_cells(
            ws,
            {
                # lv1
                "B10": "1",
                "C11": "A1",
                # lv2 (å·¦ãŒ Bã€å³ãŒ seq)
                "E10": "B1-1",
                "F10": "1-1",
            },
        )

        # åå‰å®šç¾©: lv2 ã§ B ãŒå·¦ã‚»ãƒ«ã€seq ãŒå³ã‚»ãƒ«
        set_defined_names(
            wb,
            {
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1": "Sheet1!$B$10:$C$11",
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1.seq": "Sheet1!$B$10",
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1.A": "Sheet1!$C$11",
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1.lv2.1": "Sheet1!$E$10:$F$10",
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1.lv2.1.B": "Sheet1!$E$10",
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1.lv2.1.seq": "Sheet1!$F$10",
            },
        )

        xlsx_path = tmp_path / "order_no_schema.xlsx"
        wb.save(xlsx_path)

        # è§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")
        assert "ãƒ„ãƒªãƒ¼é †" in result and isinstance(result["ãƒ„ãƒªãƒ¼é †"], dict)
        lv1 = result["ãƒ„ãƒªãƒ¼é †"].get("lv1")
        assert isinstance(lv1, list) and len(lv1) == 1
        lv2 = lv1[0].get("lv2")
        assert isinstance(lv2, list) and len(lv2) == 1
        # ã‚¹ã‚­ãƒ¼ãƒç„¡ã—ã®æ®µéšã§ã®ã‚­ãƒ¼é †ï¼ˆExcelèª­å–é †ï¼‰
        keys_in_memory = list(lv2[0].keys())
        assert keys_in_memory == ["B", "seq"], f"unexpected in-memory order: {keys_in_memory}"

        # ã‚¹ã‚­ãƒ¼ãƒç„¡ã—ã§ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›â†’èª­ã¿æˆ»ã—
        out = tmp_path / "order_no_schema.json"
        xlsx2json.write_data(result, out)  # schema=None, validator=None
        with out.open("r", encoding="utf-8") as f:
            loaded = json.load(f)
        lv2_loaded = loaded["ãƒ„ãƒªãƒ¼é †"]["lv1"][0]["lv2"][0]
        keys_in_file = list(lv2_loaded.keys())
        assert keys_in_file == ["B", "seq"], f"unexpected file order: {keys_in_file}"

    def test_schema_applies_seq_first_in_nested_lv2(self, tmp_path: Path):
        """ã‚¹ã‚­ãƒ¼ãƒé©ç”¨ã‚ã‚Šã§ã¯ã€lv2 è¦ç´ å†…ã® 'seq' ãŒå…ˆé ­ã«ãªã‚‹ã“ã¨ã‚’æ¤œè¨¼ã€‚"""
        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"

        # åŒã˜é…ç½®: lv2 ã§ B å·¦, seq å³ï¼ˆExcelèª­å–é †ã¯ ['B','seq']ï¼‰
        draw_rect_border(ws, top=10, left=2, bottom=11, right=3)
        draw_rect_border(ws, top=10, left=5, bottom=10, right=6)
        set_cells(
            ws,
            {
                "B10": "1",
                "C11": "A1",
                "E10": "B1-1",
                "F10": "1-1",
            },
        )
        set_defined_names(
            wb,
            {
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1": "Sheet1!$B$10:$C$11",
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1.seq": "Sheet1!$B$10",
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1.A": "Sheet1!$C$11",
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1.lv2.1": "Sheet1!$E$10:$F$10",
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1.lv2.1.B": "Sheet1!$E$10",
                "json.ãƒ„ãƒªãƒ¼é †.lv1.1.lv2.1.seq": "Sheet1!$F$10",
            },
        )

        xlsx_path = tmp_path / "order_with_schema.xlsx"
        wb.save(xlsx_path)

        data = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")
        # ã‚¹ã‚­ãƒ¼ãƒ: lv2 item ã§ seq ã‚’å…ˆé ­ã«å®šç¾©
        schema = {
            "type": "object",
            "properties": {
                "ãƒ„ãƒªãƒ¼é †": {
                    "type": "object",
                    "properties": {
                        "lv1": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "A": {"type": "string"},
                                    "lv2": {
                                        "type": "array",
                                        "items": {
                                            "type": "object",
                                            "properties": {
                                                "seq": {"type": "string"},
                                                "B": {"type": "string"},
                                            },
                                        },
                                    },
                                    "seq": {"type": "string"},
                                },
                            },
                        }
                    },
                }
            },
        }

        # ä¸¦ã¹æ›¿ãˆã‚’é©ç”¨
        ordered = xlsx2json.reorder_json(data, schema)
        lv2_item = ordered["ãƒ„ãƒªãƒ¼é †"]["lv1"][0]["lv2"][0]
        assert list(lv2_item.keys()) == ["seq", "B"]

        # write_data(schemaã‚ã‚Š) ã§ã‚‚ seq-first ã«ãªã‚‹ã“ã¨ã‚’ç¢ºèª
        out = tmp_path / "order_with_schema.json"
        xlsx2json.write_data(data, out, schema=schema)
        with out.open("r", encoding="utf-8") as f:
            loaded = json.load(f)
        lv2_item2 = loaded["ãƒ„ãƒªãƒ¼é †"]["lv1"][0]["lv2"][0]
        assert list(lv2_item2.keys()) == ["seq", "B"]

    def test_get_named_range_values_single_vs_range(self, temp_dir):
        """get_named_range_valuesé–¢æ•°ã§ã®å˜ä¸€ã‚»ãƒ«ã¨ç¯„å›²ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        workbook = Workbook()
        worksheet = workbook.active
        worksheet.title = "Sheet1"  # ã‚·ãƒ¼ãƒˆåã‚’æ˜ç¤ºçš„ã«è¨­å®š

        # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã§ã‚»ãƒ«å€¤ã¨åå‰ä»˜ãç¯„å›²ã‚’ä¸€æ‹¬è¨­å®š
        set_cells(
            worksheet,
            {
                "A1": "single_value",
                "B1": "range_value1",
                "B2": "range_value2",
            },
        )
        set_defined_names(
            workbook,
            {
                "single_cell": "A1",
                "cell_range": "B1:B2",
            },
        )

        test_file = temp_dir / "range_test.xlsx"
        workbook.save(test_file)

        # ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿
        wb = xlsx2json.load_workbook(test_file, data_only=True)

        # å˜ä¸€ã‚»ãƒ«ã¯å€¤ã®ã¿è¿”ã™ã“ã¨ã‚’ç¢ºèª
        single_name_def = wb.defined_names["single_cell"]
        single_result = xlsx2json.get_named_range_values(wb, single_name_def)
        assert single_result == "single_value"
        assert not isinstance(single_result, list)

        # ç¯„å›²ã¯ãƒªã‚¹ãƒˆã§è¿”ã™ã“ã¨ã‚’ç¢ºèª
        range_name_def = wb.defined_names["cell_range"]
        range_result = xlsx2json.get_named_range_values(wb, range_name_def)
        assert isinstance(range_result, list)
        assert range_result == ["range_value1", "range_value2"]

    def test_convert_string_to_array_backward_compatibility(self):
        """convert_string_to_arrayé–¢æ•°ã®å¾Œæ–¹äº’æ›æ€§ãƒ†ã‚¹ãƒˆ"""
        # é€šå¸¸ã®æ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_array("a,b,c", ",")
        assert result == ["a", "b", "c"]

        # ç©ºæ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_array("", ",")
        assert result == []

        # ç©ºç™½ã®ã¿ã®æ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_array("   ", ",")
        assert result == []

        # éæ–‡å­—åˆ—å…¥åŠ›
        result = xlsx2json.convert_string_to_array(123, ",")
        assert result == 123

    def test_array_transform_comprehensive_lines_478_487_from_precision(self):
        """Test comprehensive array transform scenarios covering lines 478-487 (æ—§TestPrecisionCoverage95Plusçµ±åˆ)"""
        # Test various array transformation rule parsing
        test_rules = [
            "json.data=split:,",
            "json.values=function:lambda x: x.split('-')",
            "json.commands=command:echo test",
        ]

        # Test parsing with complex schema paths requiring resolution
        test_schema = {
            "type": "object",
            "properties": {
                "items": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "data": {"type": "array"},
                            "values": {"type": "array"},
                        },
                    },
                }
            },
        }

        # Test with wildcard paths that need schema resolution
        wildcard_rules = [
            "json.items.*.data=split:,",
            "json.items.0.values=function:str.split",
        ]

        try:
            # This should trigger lines 478-487 in schema resolution
            rules = xlsx2json.parse_array_transform_rules(
                wildcard_rules, "json", test_schema
            )
            assert isinstance(rules, dict)
        except Exception:
            pass

        # Test direct ArrayTransformRule creation
        try:
            rule = xlsx2json.ArrayTransformRule("json.data", "split", ",")
            result = rule.transform("a,b,c,d")
            assert isinstance(result, list)
        except Exception:
            pass

        try:
            rule = xlsx2json.ArrayTransformRule("json.cmd", "command", "echo test")
            result = rule.transform("input")
        except Exception:
            pass  # Expected for command execution


class TestUtilities:
    """ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def temp_dir(self):
        """ãƒ†ã‚¹ãƒˆç”¨ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"""
        with tempfile.TemporaryDirectory() as tmpdir:
            yield Path(tmpdir)

    # === ç©ºå€¤åˆ¤å®šã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_empty_value_detection_comprehensive(self):
        """åŒ…æ‹¬çš„ãªç©ºå€¤åˆ¤å®šæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        å„ç¨®ãƒ‡ãƒ¼ã‚¿å‹ã«å¯¾ã™ã‚‹ç©ºå€¤åˆ¤å®šãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç©ºã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_empty_value("") is True
        assert xlsx2json.is_empty_value(None) is True
        assert xlsx2json.is_empty_value("   ") is True  # ç©ºç™½ã®ã¿
        assert xlsx2json.is_empty_value("\t\n  ") is True  # ã‚¿ãƒ–ãƒ»æ”¹è¡Œå«ã‚€ç©ºç™½
        assert xlsx2json.is_empty_value([]) is True  # ç©ºã®ãƒªã‚¹ãƒˆ
        assert xlsx2json.is_empty_value({}) is True  # ç©ºã®è¾æ›¸

        # ç©ºã§ã¯ãªã„ã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_empty_value("value") is False
        assert xlsx2json.is_empty_value("0") is False  # æ–‡å­—åˆ—ã®0
        assert xlsx2json.is_empty_value(0) is False  # æ•°å€¤ã®0
        assert xlsx2json.is_empty_value(False) is False  # Boolean False
        assert xlsx2json.is_empty_value([1, 2]) is False
        assert xlsx2json.is_empty_value({"key": "value"}) is False

    def test_complete_emptiness_evaluation(self):
        """å®Œå…¨ç©ºåˆ¤å®šæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã§ã®å®Œå…¨ãªç©ºçŠ¶æ…‹åˆ¤å®šãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å®Œå…¨ã«ç©ºã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_completely_empty({}) is True
        assert xlsx2json.is_completely_empty([]) is True
        assert xlsx2json.is_completely_empty({"empty": {}}) is True
        assert xlsx2json.is_completely_empty([[], {}]) is True
        assert xlsx2json.is_completely_empty({"a": None, "b": "", "c": []}) is True

        # ãƒã‚¹ãƒˆã—ãŸç©ºæ§‹é€ 
        nested_empty = {
            "level1": {
                "level2": {
                    "empty_list": [],
                    "empty_dict": {},
                    "null_value": None,
                    "empty_string": "",
                }
            }
        }
        assert xlsx2json.is_completely_empty(nested_empty) is True

        # ç©ºã§ã¯ãªã„ã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_completely_empty({"key": "value"}) is False
        assert xlsx2json.is_completely_empty(["value"]) is False
        assert xlsx2json.is_completely_empty({"nested": {"key": "value"}}) is False
        assert xlsx2json.is_completely_empty({"a": None, "b": "valid"}) is False

    def test_multidimensional_array_string_conversion(self):
        """å¤šæ¬¡å…ƒé…åˆ—æ–‡å­—åˆ—å¤‰æ›æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        æ–‡å­—åˆ—ã‹ã‚‰å¤šæ¬¡å…ƒé…åˆ—ã¸ã®å¤‰æ›ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # 1æ¬¡å…ƒé…åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array("a,b,c", [","])
        assert result == ["a", "b", "c"]

        # 2æ¬¡å…ƒé…åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array(
            "a,b;c,d", [";", ","]
        )
        assert result == [["a", "b"], ["c", "d"]]

        # 3æ¬¡å…ƒé…åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array(
            "a,b;c,d|e,f;g,h", ["|", ";", ","]
        )
        expected = [[["a", "b"], ["c", "d"]], [["e", "f"], ["g", "h"]]]
        assert result == expected

        # ç©ºæ–‡å­—åˆ—å‡¦ç†
        result = xlsx2json.convert_string_to_multidimensional_array("", [","])
        assert result == []

        # Noneå…¥åŠ›å‡¦ç†
        result = xlsx2json.convert_string_to_multidimensional_array(None, [","])
        assert result is None

        # éæ–‡å­—åˆ—å…¥åŠ›å‡¦ç†
        result = xlsx2json.convert_string_to_multidimensional_array(123, [","])
        assert result == 123

    # === JSONãƒ‘ã‚¹æ“ä½œæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_json_path_insertion_comprehensive(self):
        """åŒ…æ‹¬çš„ãªJSONãƒ‘ã‚¹æŒ¿å…¥æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        æ§˜ã€…ãªãƒ‘ã‚¹å½¢å¼ã§ã®ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å˜ç´”ãªãƒ‘ã‚¹
        root = {}
        xlsx2json.insert_json_path(root, ["name"], "John")
        assert root["name"] == "John"

        # ãƒã‚¹ãƒˆã—ãŸãƒ‘ã‚¹
        root = {}
        xlsx2json.insert_json_path(root, ["user", "profile", "name"], "Jane")
        assert root["user"]["profile"]["name"] == "Jane"

        # é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆinsert_json_pathã¯1ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼‰
        root = {}
        # insert_json_pathã¯å†…éƒ¨ã§é…åˆ—ã‚’é©åˆ‡ã«æ‹¡å¼µã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        xlsx2json.insert_json_path(root, ["items", "1"], "first")
        xlsx2json.insert_json_path(root, ["items", "2"], "second")
        xlsx2json.insert_json_path(root, ["items", "3"], "third")

        if "items" in root and isinstance(root["items"], list):
            assert root["items"][0] == "first"
            assert root["items"][1] == "second"
            assert root["items"][2] == "third"
        else:
            # é…åˆ—å½¢å¼ã§ãªã„å ´åˆã¯è¾æ›¸å½¢å¼ã§ç¢ºèª
            assert root["items"]["1"] == "first"
            assert root["items"]["2"] == "second"
            assert root["items"]["3"] == "third"

        # è¤‡é›‘ãªæ··åˆãƒ‘ã‚¹
        root = {}
        xlsx2json.insert_json_path(root, ["data", "1", "user", "name"], "Alice")
        xlsx2json.insert_json_path(root, ["data", "1", "user", "age"], 30)
        xlsx2json.insert_json_path(root, ["data", "2", "user", "name"], "Bob")

        if "data" in root and isinstance(root["data"], list) and len(root["data"]) >= 2:
            assert root["data"][0]["user"]["name"] == "Alice"
            assert root["data"][0]["user"]["age"] == 30
            assert root["data"][1]["user"]["name"] == "Bob"
        else:
            # è¾æ›¸å½¢å¼ã®å ´åˆ
            assert root["data"]["1"]["user"]["name"] == "Alice"
            assert root["data"]["1"]["user"]["age"] == 30
            assert root["data"]["2"]["user"]["name"] == "Bob"

    def test_json_path_edge_cases(self):
        """JSONãƒ‘ã‚¹æŒ¿å…¥ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ

        å¢ƒç•Œæ¡ä»¶ã‚„ç‰¹æ®Šã‚±ãƒ¼ã‚¹ã§ã®å‹•ä½œã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç©ºã®ãƒ‘ã‚¹ï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
        root = {"existing": "data"}
        # ç©ºãƒ‘ã‚¹ã§ã¯é©åˆ‡ãªValueErrorãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        with pytest.raises(ValueError, match="JSONãƒ‘ã‚¹ãŒç©ºã§ã™"):
            xlsx2json.insert_json_path(root, [], "new_value")

        # é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆ1ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
        root = {}
        xlsx2json.insert_json_path(root, ["items", "01"], "padded_one")
        if (
            "items" in root
            and isinstance(root["items"], list)
            and len(root["items"]) > 0
        ):
            assert root["items"][0] == "padded_one"
        else:
            # è¾æ›¸å½¢å¼ã®å ´åˆ
            assert root["items"]["01"] == "padded_one"

        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ä¸Šæ›¸ã
        root = {"user": {"name": "old_name"}}
        xlsx2json.insert_json_path(root, ["user", "name"], "new_name")
        assert root["user"]["name"] == "new_name"

    # === ãƒ•ã‚¡ã‚¤ãƒ«åé›†ã¨ãƒ‘ã‚¹è§£æ±ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    # collect_xlsx_files ã«ä¾å­˜ã—ã¦ã„ãŸãƒ†ã‚¹ãƒˆã¯å‰Šé™¤ï¼ˆé–¢æ•°è‡ªä½“ã‚’å‰Šé™¤ã—ãŸãŸã‚ï¼‰

    # === ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_data_cleaning_operations_comprehensive(self):
        """åŒ…æ‹¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ“ä½œãƒ†ã‚¹ãƒˆ

        æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã§ã®ç©ºå€¤ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # è¤‡é›‘ãªãƒã‚¹ãƒˆæ§‹é€ ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        test_data = {
            "name": "æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿",
            "empty_string": "",
            "null_value": None,
            "empty_list": [],
            "empty_dict": {},
            "valid_list": [1, 2, 3],
            "mixed_list": [1, "", None, 2, [], {}],
            "nested": {
                "valid": "ãƒ‡ãƒ¼ã‚¿",
                "empty": "",
                "null": None,
                "deep_nested": {"empty_array": [], "valid_value": "ä¿æŒã•ã‚Œã‚‹"},
            },
        }

        # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        cleaned_data = xlsx2json.clean_empty_values(test_data)

        # ç©ºå€¤ãŒå‰Šé™¤ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert "empty_string" not in cleaned_data
        assert "null_value" not in cleaned_data
        assert "empty_list" not in cleaned_data
        assert "empty_dict" not in cleaned_data

        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert cleaned_data["name"] == "æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿"
        assert cleaned_data["valid_list"] == [1, 2, 3]
        assert cleaned_data["nested"]["valid"] == "ãƒ‡ãƒ¼ã‚¿"
        assert cleaned_data["nested"]["deep_nested"]["valid_value"] == "ä¿æŒã•ã‚Œã‚‹"

        # é…åˆ—ã‹ã‚‰ç©ºå€¤ãŒå‰Šé™¤ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert cleaned_data["mixed_list"] == [1, 2]

    # suppress_empty ã‚ªãƒ—ã‚·ãƒ§ãƒ³å»ƒæ­¢ã«ä¼´ã„ã€æœªã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¯”è¼ƒãƒ†ã‚¹ãƒˆã¯å‰Šé™¤
        result = xlsx2json.convert_string_to_multidimensional_array(
            "a,b|c,d;e,f|g,h", [";", "|", ","]
        )
        expected = [[["a", "b"], ["c", "d"]], [["e", "f"], ["g", "h"]]]
        assert result == expected

        # ç©ºæ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array("", [","])
        assert result == []

        # éæ–‡å­—åˆ—å…¥åŠ›
        result = xlsx2json.convert_string_to_multidimensional_array(123, [","])
        assert result == 123

    def test_insert_json_path(self):
        """JSONãƒ‘ã‚¹æŒ¿å…¥é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
        root = {}

        # å˜ç´”ãªãƒ‘ã‚¹
        xlsx2json.insert_json_path(root, ["key"], "value")
        assert root == {"key": "value"}

        # ãƒã‚¹ãƒˆã—ãŸãƒ‘ã‚¹
        xlsx2json.insert_json_path(root, ["nested", "key"], "nested_value")
        assert root["nested"]["key"] == "nested_value"

        # é…åˆ—ã®ãƒ‘ã‚¹
        root = {}
        xlsx2json.insert_json_path(root, ["array", "1"], "first")
        xlsx2json.insert_json_path(root, ["array", "2"], "second")
        assert isinstance(root["array"], list)
        assert root["array"][0] == "first"
        assert root["array"][1] == "second"

    def test_insert_json_path_coexist_deep_children_then_scalar(self):
        """æ·±ã„å­ã‚’å…ˆã«æŒ¿å…¥ã—ã€ãã®å¾Œã§è¦ªãƒãƒ¼ãƒ‰ã¸ã‚¹ã‚«ãƒ©ã‚’æŒ¿å…¥ã—ã¦ã‚‚å­ãŒå¤±ã‚ã‚Œãšã€__value__ ã«æ ¼ç´ã•ã‚Œã‚‹ã€‚"""
        root = {}
        # æ·±ã„å­ï¼ˆnode.p.a.t.hï¼‰ã‚’å…ˆã«æŒ¿å…¥
        xlsx2json.insert_json_path(root, ["node", "p", "a", "t", "h"], "H")
        # åŒã˜è¦ªï¼ˆnodeï¼‰ã«ã‚¹ã‚«ãƒ©ã‚’æŒ¿å…¥ï¼ˆå…±å­˜ã®ãŸã‚ __value__ ã«æ ¼ç´ã•ã‚Œã‚‹æƒ³å®šï¼‰
        xlsx2json.insert_json_path(root, ["node"], "S")
        # æ›´ã«åŒè¦ªé…ä¸‹ã«åˆ¥ã‚­ãƒ¼ã‚’è¿½åŠ 
        xlsx2json.insert_json_path(root, ["node", "v1"], "V1")

        assert isinstance(root.get("node"), dict)
        assert root["node"].get("__value__") == "S"
        assert root["node"].get("v1") == "V1"
        assert root["node"]["p"]["a"]["t"]["h"] == "H"

    def test_insert_json_path_coexist_scalar_then_children(self):
        """è¦ªãƒãƒ¼ãƒ‰ã¸ã‚¹ã‚«ãƒ©ã‚’å…ˆã«æŒ¿å…¥ã—ã€å¾Œã‹ã‚‰å­ã‚’æŒ¿å…¥ã™ã‚‹ã¨ __value__ ã«æ˜‡æ ¼ã—ã¦å…±å­˜ã™ã‚‹ã€‚"""
        root = {}
        # å…ˆã«ã‚¹ã‚«ãƒ©
        xlsx2json.insert_json_path(root, ["node"], "S")
        # å¾Œã‹ã‚‰å­ã‚’è¿½åŠ 
        xlsx2json.insert_json_path(root, ["node", "k"], "K")

        assert isinstance(root.get("node"), dict)
        assert root["node"].get("__value__") == "S"
        assert root["node"].get("k") == "K"

    def test_insert_json_path_list_element_coexist(self):
        """é…åˆ—è¦ç´ ã§ã€å…ˆã«å­ã‚’è¿½åŠ ã—ã¦éç©ºdictåŒ–ã—ãŸå¾Œã«æœ«ç«¯ã¸ã‚¹ã‚«ãƒ©ã‚’å…¥ã‚Œã‚‹ã¨ __value__ ã«æ ¼ç´ã•ã‚Œã‚‹ã€‚"""
        root = {}
        # arr.1.k ã‚’å…ˆã«è¿½åŠ ã—ã¦ arr[0] ã‚’éç©ºdictã«
        xlsx2json.insert_json_path(root, ["arr", "1", "k"], "K")
        # arr.1 ã«ã‚¹ã‚«ãƒ©ã‚’è¨­å®šï¼ˆå…±å­˜ã®ãŸã‚ __value__ ã«æ ¼ç´ï¼‰
        xlsx2json.insert_json_path(root, ["arr", "1"], "S")

        assert isinstance(root.get("arr"), list)
        assert isinstance(root["arr"][0], dict)
        assert root["arr"][0].get("k") == "K"
        assert root["arr"][0].get("__value__") == "S"

    def test_insert_json_path_replace_empty_containers_and_promote_later(self):
        """ç©ºã®ã‚³ãƒ³ãƒ†ãƒŠã¯æœ«ç«¯ã‚¹ã‚«ãƒ©ã§ç½®æ›ã•ã‚Œã€ãã®å¾Œã®å­æŒ¿å…¥ã§ __value__ ã«æ˜‡æ ¼ã—ã¦å…±å­˜ã§ãã‚‹ã€‚"""
        # dict å´
        root = {"n": {}}
        xlsx2json.insert_json_path(root, ["n"], "S")
        assert root["n"] == "S"  # ç©ºdictã¯ç½®æ›
        # å¾Œã‹ã‚‰å­ã‚’è¿½åŠ  â†’ ã‚¹ã‚«ãƒ©ãŒ __value__ ã«æ˜‡æ ¼
        xlsx2json.insert_json_path(root, ["n", "k"], "K")
        assert isinstance(root["n"], dict)
        assert root["n"].get("__value__") == "S"
        assert root["n"].get("k") == "K"

        # list å´
        root = {"arr": [{}]}
        xlsx2json.insert_json_path(root, ["arr", "1"], "S")
        assert isinstance(root["arr"], list)
        assert root["arr"][0] == "S"  # ç©ºdictã¯ç½®æ›
        # å¾Œã‹ã‚‰å­ã‚’è¿½åŠ  â†’ ã‚¹ã‚«ãƒ©ãŒ __value__ ã«æ˜‡æ ¼
        xlsx2json.insert_json_path(root, ["arr", "1", "k"], "K")
        assert isinstance(root["arr"][0], dict)
        assert root["arr"][0].get("__value__") == "S"
        assert root["arr"][0].get("k") == "K"

    # === Containeræ©Ÿèƒ½ï¼šã‚»ãƒ«åç”Ÿæˆãƒ»å‘½åè¦å‰‡ãƒ†ã‚¹ãƒˆ ===


class TestContainerUnitMinimal:
    """ã‚³ãƒ³ãƒ†ãƒŠé–¢é€£ã®æœ€å°ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆï¼ˆè‡ªå·±å®Œçµãƒ»ç”Ÿæˆç³»ä¸­å¿ƒï¼‰"""

    def _make_min_workbook_for_orders(self):
        wb = Workbook()
        ws = wb.active
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒ¼ãƒˆåã¯ 'Sheet'
        ws["B2"] = "2025-01-01"
        ws["C2"] = "Alice"
        ws["D2"] = "100"

        # ç¯„å›²æŒ‡å®šã¯ã‚³ãƒ³ãƒ†ãƒŠã® range ã§è¡Œã†ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ *.range ã¯ä½¿ç”¨ã—ãªã„ï¼‰

        # åŸºæº–ã‚»ãƒ«åï¼ˆæœ€åˆã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å„é …ç›®ï¼‰
        set_defined_names(
            wb,
            {
                "json.orders.1.date": "Sheet!$B$2",
                "json.orders.1.customer": "Sheet!$C$2",
                "json.orders.1.amount": "Sheet!$D$2",
            },
        )
        return wb

    def test_calculate_target_position_row_and_column(self):
        # åŸºæº–ä½ç½® (col=2=B, row=2)
        base = (2, 2)
        # è¡Œæ–¹å‘: è¡ŒãŒå¢—ãˆã‚‹
        pos_row = xlsx2json.calculate_target_position(
            base, "row", instance_idx=3, increment=5
        )
        assert pos_row == (2, 12)
        # åˆ—æ–¹å‘: åˆ—ãŒå¢—ãˆã‚‹
        pos_col = xlsx2json.calculate_target_position(
            base, "column", instance_idx=3, increment=5
        )
        assert pos_col == (12, 2)

    def test_get_cell_position_from_name(self):
        wb = self._make_min_workbook_for_orders()
        # customer ã¯ C2 -> (3,2)
        pos = xlsx2json.get_cell_position_from_name("json.orders.1.customer", wb)
        assert pos == (3, 2)

    def test_detect_card_count_from_existing_names(self):
        wb = Workbook()
        ws = wb.active
        ws["A1"] = "foo"
        ws["A2"] = "bar"
        # json.card.1.*, json.card.2.* ãŒå­˜åœ¨
        set_defined_names(
            wb,
            {
                "json.card.1.name": "Sheet!$A$1",
                "json.card.2.name": "Sheet!$A$2",
            },
        )
        count = xlsx2json.detect_card_count_from_existing_names("card", wb)
        assert count == 2

    def test_generate_cell_names_from_containers_increment0(self):
        wb = self._make_min_workbook_for_orders()

        # increment=0 ãªã‚‰ analyze_container_elements ã¯å‘¼ã°ã‚Œãš 1è¦ç´ ã®ã¿ç”Ÿæˆ
        containers = {
            "json.orders": {
                "direction": "row",
                "increment": 0,
            }
        }

        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)
        # æœŸå¾…ã•ã‚Œã‚‹å‹•çš„ã‚»ãƒ«åãŒ1è¦ç´ åˆ†ç”Ÿæˆã•ã‚Œã‚‹
        assert "json.orders.1.date" in generated
        assert "json.orders.1.customer" in generated
        assert "json.orders.1.amount" in generated
        # å®Ÿè£…ã¯Excelã®å®Ÿå€¤ã‚’èª­ã¿å–ã‚‹
        assert generated["json.orders.1.date"] == "2025-01-01"
        assert generated["json.orders.1.customer"] == "Alice"
        assert generated["json.orders.1.amount"] == "100"


class TestContainerHierarchyMinimal:
    """è¦ª/å­ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç½®æ›ï¼‰ã®æœ€å°ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""

    def _make_min_workbook(self):
        wb = Workbook()
        ws = wb.active
        ws["B2"] = "2025-02-02"
        ws["C2"] = "Bob"
        ws["D2"] = "200"

        # ç¯„å›²æŒ‡å®šã¯ãƒ†ã‚¹ãƒˆå´ã®ã‚³ãƒ³ãƒ†ãƒŠã§è¡Œã†
        set_defined_names(
            wb,
            {
                "json.orders.1.date": "Sheet!$B$2",
                "json.orders.1.customer": "Sheet!$C$2",
                "json.orders.1.amount": "Sheet!$D$2",
            },
        )
        return wb

    def test_child_container_generation_index_replacement(self):
        wb = self._make_min_workbook()

        # å­ã‚³ãƒ³ãƒ†ãƒŠï¼ˆæœ«å°¾ãŒæ•°å€¤ï¼‰: å‹•çš„ç”Ÿæˆæ™‚ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒç½®æ›ã•ã‚Œã‚‹
        containers = {
            "json.orders.1": {"direction": "row", "increment": 0},
        }
        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)

        assert "json.orders.1.date" in generated
        assert "json.orders.1.customer" in generated
        assert "json.orders.1.amount" in generated
        assert generated["json.orders.1.date"] == "2025-02-02"

    def test_parent_and_child_coexistence(self):
        wb = self._make_min_workbook()
        containers = {
            "json.orders": {"direction": "row", "increment": 0},
            "json.orders.1": {"direction": "row", "increment": 0},
        }
        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)

        # ä¸¡è€…ã¨ã‚‚ã«åŒä¸€ã‚­ãƒ¼ã¸ç”Ÿæˆã•ã‚Œã†ã‚‹ãŒã€è¾æ›¸æ›´æ–°ã«ã‚ˆã‚Šæœ€çµ‚å€¤ãŒä¿æŒã•ã‚Œã‚‹
        for key, expected in (
            ("json.orders.1.date", "2025-02-02"),
            ("json.orders.1.customer", "Bob"),
            ("json.orders.1.amount", "200"),
        ):
            assert key in generated
            assert generated[key] == expected


class TestContainerThreeLevelMinimal:
    """è¦ªâ†’å­â†’å­«ï¼ˆ3éšå±¤ï¼‰ã®æœ€å°ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆï¼ˆå®Ÿå€¤èª­ã¿å–ã‚Šãƒ»ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç½®æ›ï¼‰"""

    def _make_three_level_workbook(self):
        wb = Workbook()
        ws = wb.active

        # è¦ªï¼ˆordersï¼‰: B2-D2ã€å­: B4-D4ã€å­«: B6-C6
        set_cells(
            ws,
            {
                "B2": "2025-04-01",
                "C2": "Eve",
                "D2": "500",
                "B4": "item-1",
                "C4": "qty-10",
                "D4": "price-999",
                "B6": "sku-XYZ",
                "C6": "blue",
            },
        )

        # è¦ªã®åŸºæº–ã‚»ãƒ«å
        set_defined_names(
            wb,
            {
                "json.orders.1.date": "Sheet!$B$2",
                "json.orders.1.customer": "Sheet!$C$2",
                "json.orders.1.amount": "Sheet!$D$2",
            },
        )

        # å­ã®åŸºæº–ã‚»ãƒ«åï¼ˆè¦ª1ä»¶ç›®é…ä¸‹ï¼‰
        set_defined_names(
            wb,
            {
                # å­ã®åŸºæº–ã‚»ãƒ«åï¼ˆè¦ª1ä»¶ç›®é…ä¸‹ï¼‰
                "json.orders.items.1.name": "Sheet!$B$4",
                "json.orders.items.1.quantity": "Sheet!$C$4",
                "json.orders.items.1.price": "Sheet!$D$4",
                # å­«ã®åŸºæº–ã‚»ãƒ«åï¼ˆå­1ä»¶ç›®é…ä¸‹ï¼‰
                "json.orders.items.details.1.sku": "Sheet!$B$6",
                "json.orders.items.details.1.color": "Sheet!$C$6",
            },
        )
        return wb

    def test_three_level_minimal_value_reading(self):
        wb = self._make_three_level_workbook()

        # 3éšå±¤ãã‚Œãã‚Œæœ€å°ï¼ˆincrement=0ï¼‰ã§ç”Ÿæˆ
        containers = {
            "json.orders": {"direction": "row", "increment": 0},
            "json.orders.items.1": {"direction": "row", "increment": 0},
            "json.orders.items.details.1": {"direction": "row", "increment": 0},
        }

        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)

        # è¦ª
        assert generated["json.orders.1.date"] == "2025-04-01"
        assert generated["json.orders.1.customer"] == "Eve"
        assert generated["json.orders.1.amount"] == "500"

        # å­
        assert generated["json.orders.items.1.name"] == "item-1"
        assert generated["json.orders.items.1.quantity"] == "qty-10"
        assert generated["json.orders.items.1.price"] == "price-999"

        # å­«
        assert generated["json.orders.items.details.1.sku"] == "sku-XYZ"
        assert generated["json.orders.items.details.1.color"] == "blue"

    def test_three_level_with_increment_and_bounds_stop(self):
        """ç¯„å›²å¢ƒç•Œå†…ã®ã¿ã§ç¹°ã‚Šè¿”ã—ã‚’æ¤œå‡ºã—ã€å¢ƒç•Œå¤–ã¯æ•°ãˆãªã„ï¼ˆincrement>0ï¼‰"""
        wb = Workbook()
        ws = wb.active

        # è¦ª: B2-D3 ã®2è¡Œåˆ†ã€è¡Œæ–¹å‘ increment=1 ã§2ä»¶åˆ†ãƒ‡ãƒ¼ã‚¿
        set_cells(
            ws,
            {
                "B2": "2025-05-01",
                "C2": "Foo",
                "D2": "1000",
                "B3": "2025-05-02",
                "C3": "Bar",
                "D3": "2000",
            },
        )
        # ç½«ç·šçŸ©å½¢ï¼ˆB2:D3ï¼‰
        draw_rect_border(ws, top=2, left=2, bottom=3, right=4)
        # ç¯„å›²æŒ‡å®šã¯ã‚³ãƒ³ãƒ†ãƒŠã§è¡Œã†
        set_defined_names(
            wb,
            {
                "json.orders.1.date": "B2",
                "json.orders.1.customer": "C2",
                "json.orders.1.amount": "D2",
            },
        )

        # å­: B5-D6 ã®2è¡Œåˆ†
        set_cells(
            ws,
            {
                "B5": "item-A",
                "C5": "1",
                "D5": "10",
                "B6": "item-B",
                "C6": "2",
                "D6": "20",
            },
        )
        # ç½«ç·šçŸ©å½¢ï¼ˆB5:D6ï¼‰
        draw_rect_border(ws, top=5, left=2, bottom=6, right=4)
        # ç¯„å›²æŒ‡å®šã¯ã‚³ãƒ³ãƒ†ãƒŠã§è¡Œã†
        set_defined_names(
            wb,
            {
                "json.orders.items.1.name": "B5",
                "json.orders.items.1.quantity": "C5",
                "json.orders.items.1.price": "D5",
            },
        )

        # å­«: B8-C8 ã®1è¡Œåˆ†ã®ã¿ï¼ˆæ„å›³çš„ã«1ä»¶ã ã‘ï¼‰ã€‚å¢ƒç•Œã§åœæ­¢ã™ã‚‹ã“ã¨ã‚’æ¤œè¨¼
        set_cells(ws, {"B8": "sku-1", "C8": "red"})
        # ç½«ç·šçŸ©å½¢ï¼ˆB8:C8ï¼‰
        draw_rect_border(ws, top=8, left=2, bottom=8, right=3)
        # ç¯„å›²æŒ‡å®šã¯ã‚³ãƒ³ãƒ†ãƒŠã§è¡Œã†
        set_defined_names(
            wb,
            {
                "json.orders.items.details.1.sku": "B8",
                "json.orders.items.details.1.color": "C8",
            },
        )

        containers = {
            "json.orders": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$B$2:$D$3",
            },
            "json.orders.items.1": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$B$5:$D$6",
            },
            "json.orders.items.details.1": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$B$8:$C$8",
            },
        }

        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)

        # è¦ªã¯2ä»¶ã¾ã§
        assert generated["json.orders.1.date"] == "2025-05-01"
        assert generated["json.orders.2.date"] == "2025-05-02"
        assert "json.orders.3.date" not in generated

        # å­ã‚‚2ä»¶ã¾ã§
        assert generated["json.orders.items.1.name"] == "item-A"
        assert generated["json.orders.items.2.name"] == "item-B"
        assert "json.orders.items.3.name" not in generated

        # å­«ã¯1ä»¶ã®ã¿ï¼ˆå¢ƒç•Œå¤–ã¯æ•°ãˆãªã„ï¼‰
        assert generated["json.orders.items.details.1.sku"] == "sku-1"
        assert "json.orders.items.details.2.sku" not in generated


class TestBorderDrivenContainerGeneration:
    """ç½«ç·šè§£æâ†’ç¯„å›²æŠ½å‡ºâ†’named rangeå®šç¾©â†’ç¹°ã‚Šè¿”ã—ç”Ÿæˆï¼ˆè¦ªâ†’å­â†’å­«ï¼‰E2E"""

    def _draw_rect_border(self, ws, top, left, bottom, right):
        thin = Side(style="thin")
        # ä¸Šè¾º
        for col in range(left, right + 1):
            cell = ws.cell(row=top, column=col)
            cell.border = Border(
                top=thin,
                left=cell.border.left,
                right=cell.border.right,
                bottom=cell.border.bottom,
            )
        # ä¸‹è¾º
        for col in range(left, right + 1):
            cell = ws.cell(row=bottom, column=col)
            cell.border = Border(
                bottom=thin,
                left=cell.border.left,
                right=cell.border.right,
                top=cell.border.top,
            )
        # å·¦è¾º
        for row in range(top, bottom + 1):
            cell = ws.cell(row=row, column=left)
            cell.border = Border(
                left=thin,
                top=cell.border.top,
                right=cell.border.right,
                bottom=cell.border.bottom,
            )
        # å³è¾º
        for row in range(top, bottom + 1):
            cell = ws.cell(row=row, column=right)
            cell.border = Border(
                right=thin,
                top=cell.border.top,
                left=cell.border.left,
                bottom=cell.border.bottom,
            )

    def _a1(self, left, top, right, bottom):
        return f"{get_column_letter(left)}{top}:{get_column_letter(right)}{bottom}"

    def test_border_analysis_to_named_ranges_and_generation(self):
        wb = Workbook()
        ws = wb.active

        # è¦ªï¼ˆ2ä»¶ãƒ»è¡Œæ–¹å‘ï¼‰: B2:D3ã€å­ï¼ˆ2ä»¶ï¼‰: B5:D6ã€å­«ï¼ˆ1ä»¶ï¼‰: B8:C8
        set_cells(
            ws,
            {
                # è¦ª
                "B2": "2025-06-01",
                "C2": "P1",
                "D2": "11",
                "B3": "2025-06-02",
                "C3": "P2",
                "D3": "22",
                # å­
                "B5": "item-1",
                "C5": "10",
                "D5": "100",
                "B6": "item-2",
                "C6": "20",
                "D6": "200",
                # å­«
                "B8": "sku-10",
                "C8": "green",
            },
        )

        # åŸºæº–json.*ã‚»ãƒ«åï¼ˆ1ä»¶ç›®ã®å…ˆé ­ï¼‰
        set_defined_names(
            wb,
            {
                # è¦ª
                "json.orders.1.date": "B2",
                "json.orders.1.customer": "C2",
                "json.orders.1.amount": "D2",
                # å­
                "json.orders.items.1.name": "B5",
                "json.orders.items.1.quantity": "C5",
                "json.orders.items.1.price": "D5",
                # å­«
                "json.orders.items.details.1.sku": "B8",
                "json.orders.items.details.1.color": "C8",
            },
        )

        # ç½«ç·šã§3ã¤ã®çŸ©å½¢ã‚’æã
        self._draw_rect_border(ws, top=2, left=2, bottom=3, right=4)  # è¦ª
        self._draw_rect_border(ws, top=5, left=2, bottom=6, right=4)  # å­
        self._draw_rect_border(ws, top=8, left=2, bottom=8, right=3)  # å­«

        # ç½«ç·šè§£æâ†’çŸ©å½¢æ¤œå‡º
        cell_names_map = xlsx2json.extract_cell_names_from_workbook(wb)
        regions = xlsx2json.detect_rectangular_regions(ws, cell_names_map)
        rects = {(t, left, b, right) for (t, left, b, right, _c) in regions}

        # æœŸå¾…ã™ã‚‹3çŸ©å½¢ãŒæ¤œå‡ºã•ã‚Œã‚‹
        assert (2, 2, 3, 4) in rects
        assert (5, 2, 6, 4) in rects
        assert (8, 2, 8, 3) in rects

        # ç½«ç·šæ¤œå‡ºã—ãŸçŸ©å½¢ã«å¯¾å¿œã™ã‚‹ç¯„å›²ã‚’ã‚³ãƒ³ãƒ†ãƒŠã«ç›´æ¥æŒ‡å®šã—ã¦3éšå±¤ã§ç”Ÿæˆ
        containers = {
            "json.orders": {
                "direction": "row",
                "increment": 1,
                "range": f"Sheet!{self._a1(2,2,4,3)}",
            },
            "json.orders.items.1": {
                "direction": "row",
                "increment": 1,
                "range": f"Sheet!{self._a1(2,5,4,6)}",
            },
            "json.orders.items.details.1": {
                "direction": "row",
                "increment": 1,
                "range": f"Sheet!{self._a1(2,8,3,8)}",
            },
        }

        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)

        # è¦ª2ä»¶
        assert generated["json.orders.1.date"] == "2025-06-01"
        assert generated["json.orders.2.date"] == "2025-06-02"
        # å­2ä»¶
        assert generated["json.orders.items.1.name"] == "item-1"
        assert generated["json.orders.items.2.name"] == "item-2"
        # å­«1ä»¶
        assert generated["json.orders.items.details.1.sku"] == "sku-10"


class TestMixedDirectionContainers:
    """è¦ª=rowã€å­=columnï¼ˆincrement>0ï¼‰ã®æ··åœ¨æ–¹å‘ãƒ†ã‚¹ãƒˆ"""

    def test_parent_row_child_column_generation(self):
        wb = Workbook()
        ws = wb.active

        # è¦ªï¼ˆè¡Œæ–¹å‘ã€2ä»¶ï¼‰: B2:D3
        set_cells(
            ws,
            {
                "B2": "2025-07-01",
                "C2": "M1",
                "D2": "111",
                "B3": "2025-07-02",
                "C3": "M2",
                "D3": "222",
            },
        )
        draw_rect_border(ws, top=2, left=2, bottom=3, right=4)
        # ç¯„å›²æŒ‡å®šã¯ã‚³ãƒ³ãƒ†ãƒŠã§è¡Œã†
        set_defined_names(
            wb,
            {
                "json.orders.1.date": "B2",
                "json.orders.1.customer": "C2",
                "json.orders.1.amount": "D2",
            },
        )

        # å­ï¼ˆåˆ—æ–¹å‘ã€2ä»¶ï¼‰: å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã‚’é›¢ã—ã¦é…ç½®ã—ã€increment=2ã§+2åˆ—å…ˆã«2ä»¶ç›®
        # base: name=B5, quantity=F5, price=J5 â†’ 2ä»¶ç›®: name=D5, quantity=H5, price=L5
        set_cells(
            ws,
            {
                "B5": "item-A",
                "F5": "10",
                "J5": "100",
                "D5": "item-B",
                "H5": "20",
                "L5": "200",
            },
        )
        # å­ã¯ä¸€åˆ—ã®çŸ©å½¢ã¨ã—ã¦ B5:L5 ã‚’å›²ã†
        draw_rect_border(ws, top=5, left=2, bottom=5, right=12)
        # ç¯„å›²æŒ‡å®šã¯ã‚³ãƒ³ãƒ†ãƒŠã§è¡Œã†
        set_defined_names(
            wb,
            {
                "json.orders.items.1.name": "B5",
                "json.orders.items.1.quantity": "F5",
                "json.orders.items.1.price": "J5",
            },
        )

        containers = {
            "json.orders": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$B$2:$D$3",
            },
            "json.orders.items.1": {
                "direction": "column",
                "increment": 2,
                "range": "Sheet!$B$5:$L$5",
            },
        }

        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)

        # è¦ªï¼ˆè¡Œæ–¹å‘ï¼‰
        assert generated["json.orders.1.date"] == "2025-07-01"
        assert generated["json.orders.2.date"] == "2025-07-02"

        # å­ï¼ˆåˆ—æ–¹å‘ï¼‰
        assert generated["json.orders.items.1.name"] == "item-A"
        assert generated["json.orders.items.1.quantity"] == "10"
        assert generated["json.orders.items.1.price"] == "100"
        assert generated["json.orders.items.2.name"] == "item-B"  # D5
        assert generated["json.orders.items.2.quantity"] == "20"  # H5
        assert generated["json.orders.items.2.price"] == "200"  # L5


class TestLabelsBasedStopCondition:
    """labels ã«åŸºã¥ãåœæ­¢æ¡ä»¶ã®ãƒ†ã‚¹ãƒˆ"""

    def test_labels_stop_on_missing_label_field(self):
        wb = Workbook()
        ws = wb.active

        # è¦ª: B2:D4 ã®3è¡Œã‚’ç¢ºä¿ã™ã‚‹ãŒã€å®Ÿãƒ‡ãƒ¼ã‚¿ã¯2ä»¶ç›®ã¾ã§ã«ã™ã‚‹
        set_cells(
            ws,
            {
                "B2": "2025-08-01",
                "C2": "L1",
                "D2": "10",
                "B3": "2025-08-02",
                "C3": "L2",
                "D3": "20",
                # 3ä»¶ç›®ï¼ˆåœæ­¢æ¡ä»¶ç¢ºèªç”¨ï¼‰
                "B4": "",
                "C4": "SHOULD-NOT-COUNT",
                "D4": "999",
            },
        )
        draw_rect_border(ws, top=2, left=2, bottom=4, right=4)

        # ç¯„å›²æŒ‡å®šã¯ã‚³ãƒ³ãƒ†ãƒŠã§è¡Œã†
        set_defined_names(
            wb,
            {
                "json.orders.1.date": "B2",
                "json.orders.1.customer": "C2",
                "json.orders.1.amount": "D2",
            },
        )

        containers = {
            # labels=['date'] ã‚’æŒ‡å®šã€‚date ãŒç©ºã®è¡Œã§åœæ­¢ã™ã‚‹ã“ã¨ã‚’æœŸå¾…
            "json.orders": {
                "direction": "row",
                "increment": 1,
                "labels": ["date"],
                "range": "Sheet!$B$2:$D$4",
            },
        }

        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)

        # 2ä»¶ç›®ã¾ã§ã¯ç”Ÿæˆã•ã‚Œã‚‹
        assert generated["json.orders.1.date"] == "2025-08-01"
        assert generated["json.orders.2.date"] == "2025-08-02"
        # 3ä»¶ç›®ã¯ãƒ©ãƒ™ãƒ«(date)ãŒç©ºãªã®ã§åœæ­¢
        assert "json.orders.3.date" not in generated


class TestThreeLevelMixedWithLabels:
    """3éšå±¤ï¼ˆè¦ª=rowã€å­=columnã€å­«=rowï¼‰ï¼‹ labels åœæ­¢ã®æ¤œè¨¼"""

    def test_three_level_mixed_directions_with_labels_stop(self):
        wb = Workbook()
        ws = wb.active

        # è¦ª: è¡Œæ–¹å‘ã€2ä»¶ï¼ˆB2:D3ï¼‰ã€‚labels=['date'] ã§3è¡Œç›®ã® date ãŒç©ºã ã¨åœæ­¢
        set_cells(
            ws,
            {
                "B2": "2025-09-01",
                "C2": "PX",
                "D2": "100",
                "B3": "2025-09-02",
                "C3": "PY",
                "D3": "200",
            },
        )
        draw_rect_border(ws, top=2, left=2, bottom=3, right=4)
        # ç¯„å›²æŒ‡å®šã¯ã‚³ãƒ³ãƒ†ãƒŠã§è¡Œã†
        set_defined_names(
            wb,
            {
                "json.orders.1.date": "B2",
                "json.orders.1.customer": "C2",
                "json.orders.1.amount": "D2",
            },
        )

        # å­: åˆ—æ–¹å‘ã€2ä»¶ï¼ˆincrement=2ï¼‰ã€‚labels=['name'] ã§æ¬¡ã® name ãŒç©ºãªã‚‰åœæ­¢
        # base: name=B5, quantity=F5, price=J5 â†’ 2ä»¶ç›®: name=D5, quantity=H5, price=L5
        set_cells(
            ws,
            {
                "B5": "ci-1",
                "F5": "1",
                "J5": "10",
                "D5": "ci-2",
                "H5": "2",
                "L5": "20",
            },
        )
        draw_rect_border(ws, top=5, left=2, bottom=5, right=12)
        # ç¯„å›²æŒ‡å®šã¯ã‚³ãƒ³ãƒ†ãƒŠã§è¡Œã†
        set_defined_names(
            wb,
            {
                "json.orders.items.1.name": "B5",
                "json.orders.items.1.quantity": "F5",
                "json.orders.items.1.price": "J5",
            },
        )

        # å­«: è¡Œæ–¹å‘ã€1ä»¶ã€‚labels=['sku']
        set_cells(ws, {"B7": "sku-x", "C7": "black"})
        draw_rect_border(ws, top=7, left=2, bottom=7, right=3)
        # ç¯„å›²æŒ‡å®šã¯ã‚³ãƒ³ãƒ†ãƒŠã§è¡Œã†
        set_defined_names(
            wb,
            {
                "json.orders.items.details.1.sku": "B7",
                "json.orders.items.details.1.color": "C7",
            },
        )

        containers = {
            "json.orders": {
                "direction": "row",
                "increment": 1,
                "labels": ["date"],
                "range": "Sheet!$B$2:$D$3",
            },
            "json.orders.items.1": {
                "direction": "column",
                "increment": 2,
                "labels": ["name"],
                "range": "Sheet!$B$5:$L$5",
            },
            "json.orders.items.details.1": {
                "direction": "row",
                "increment": 1,
                "labels": ["sku"],
                "range": "Sheet!$B$7:$C$7",
            },
        }

        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)

        # è¦ª2ä»¶
        assert generated["json.orders.1.date"] == "2025-09-01"
        assert generated["json.orders.2.date"] == "2025-09-02"

        # å­2ä»¶ï¼ˆåˆ—æ–¹å‘ï¼‰
        assert generated["json.orders.items.1.name"] == "ci-1"
        assert generated["json.orders.items.2.name"] == "ci-2"

        # å­«1ä»¶
        assert generated["json.orders.items.details.1.sku"] == "sku-x"


class TestBorderIntegrationE2E:
    """ç½«ç·šæ¤œå‡ºâ†’ã‚³ãƒ³ãƒ†ãƒŠè‡ªå‹•ç”Ÿæˆâ†’å‹•çš„ã‚»ãƒ«åç”Ÿæˆã®E2Eãƒ†ã‚¹ãƒˆï¼ˆæ‰‹å‹•named rangeå®šç¾©ãªã—ï¼‰"""

    @staticmethod
    def _draw_rect_border(ws, top, left, bottom, right):
        side = Side(style="thin")
        # ä¸Šä¸‹
        for col in range(left, right + 1):
            current = ws.cell(row=top, column=col).border or Border()
            ws.cell(row=top, column=col).border = Border(
                left=current.left, right=current.right, bottom=current.bottom, top=side
            )
            current = ws.cell(row=bottom, column=col).border or Border()
            ws.cell(row=bottom, column=col).border = Border(
                left=current.left, right=current.right, top=current.top, bottom=side
            )
        # å·¦å³
        for row in range(top, bottom + 1):
            current = ws.cell(row=row, column=left).border or Border()
            ws.cell(row=row, column=left).border = Border(
                top=current.top, bottom=current.bottom, right=current.right, left=side
            )
            current = ws.cell(row=row, column=right).border or Border()
            ws.cell(row=row, column=right).border = Border(
                top=current.top, bottom=current.bottom, left=current.left, right=side
            )

    @staticmethod
    def _a1(lcol, trow, rcol, brow):
        def col_letter(c):
            s = ""
            while c:
                c, rem = divmod(c - 1, 26)
                s = chr(65 + rem) + s
            return s

        return f"${col_letter(lcol)}${trow}:${col_letter(rcol)}${brow}"

    def test_border_integration_using_high_level_parse(self):
        wb = Workbook()
        ws = wb.active

        # ãƒ‡ãƒ¼ã‚¿é…ç½®ï¼ˆè¦ª2ä»¶ã€å­2ä»¶ã€å­«1ä»¶ï¼‰
        set_cells(
            ws,
            {
                # è¦ª
                "B2": "2025-10-01",
                "C2": "Q1",
                "D2": "10",
                "B3": "2025-10-02",
                "C3": "Q2",
                "D3": "20",
                # å­
                "B5": "it-1",
                "C5": "1",
                "D5": "100",
                "B6": "it-2",
                "C6": "2",
                "D6": "200",
                # å­«
                "B8": "sku-z",
                "C8": "gold",
            },
        )

        # åŸºæº–json.*ã‚»ãƒ«åã ã‘ä¸ãˆã‚‹ï¼ˆ1ä»¶ç›®ã®å…ˆé ­ï¼‰
        set_defined_names(
            wb,
            {
                # è¦ª
                "json.orders.1.date": "B2",
                "json.orders.1.customer": "C2",
                "json.orders.1.amount": "D2",
                # å­
                "json.orders.items.1.name": "B5",
                "json.orders.items.1.quantity": "C5",
                "json.orders.items.1.price": "D5",
                # å­«
                "json.orders.items.details.1.sku": "B8",
                "json.orders.items.details.1.color": "C8",
            },
        )

        # ç½«ç·šã§çŸ©å½¢ã‚’æç”»ï¼ˆè¦ªã€å­ã€å­«ï¼‰
        self._draw_rect_border(ws, top=2, left=2, bottom=3, right=4)
        self._draw_rect_border(ws, top=5, left=2, bottom=6, right=4)
        self._draw_rect_border(ws, top=8, left=2, bottom=8, right=3)

        # ã‚ˆã‚Šä¸Šæµã®APIã§E2Eæ¤œè¨¼ï¼ˆcontainersã‚’æ˜ç¤ºï¼‰
        containers = {
            "json.orders": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$B$2:$D$3",
            },
            "json.orders.items.1": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$B$5:$D$6",
            },
            "json.orders.items.details.1": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$B$8:$C$8",
            },
        }

        result = xlsx2json.parse_named_ranges_with_prefix(
            create_temp_excel(wb), prefix="json", containers=containers
        )

        # è¦ªã¯2ä»¶
        assert isinstance(result.get("orders"), list) and len(result["orders"]) == 2
        assert result["orders"][0]["date"] == "2025-10-01"
        assert result["orders"][1]["date"] == "2025-10-02"
        # å­ã¯2ä»¶
        assert [row.get("name") for row in result.get("items", [])][:2] == [
            "it-1",
            "it-2",
        ]
        # å­«ã¯1ä»¶
        assert [row.get("sku") for row in result.get("details", [])][:1] == ["sku-z"]


class TestComplexHierarchyE2E:
    """ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆç›¸å½“ã®1ã‚»ãƒ«å³å¯„ã›ã§ãƒ„ãƒªãƒ¼éšå±¤ã‚’è¡¨ç¾ã—ã€
    ãƒ¬ãƒ™ãƒ«æ¯ã®ç¹°ã‚Šè¿”ã—ä»¶æ•°ãŒç•°ãªã‚Šã€å­«ãƒ¬ãƒ™ãƒ«ã«2è¡Œ1ãƒ¬ã‚³ãƒ¼ãƒ‰ã®è¡¨ã‚’æŒã¤ã‚±ãƒ¼ã‚¹ã€‚
    2è¡Œã®å…¥åŠ›ã¯transformã§æ”¹è¡Œçµåˆã—ã¦1å€¤ã«ãƒãƒ¼ã‚¸ã™ã‚‹ã€‚1è¦ç´ ç›®ã®ã¿å‘½åã€ä»¥é™ã¯å‹•çš„ç”Ÿæˆã€‚
    ãƒœãƒ¼ãƒ€ãƒ¼â†’ã‚³ãƒ³ãƒ†ãƒŠï¼ˆrange ä»˜ä¸ï¼‰è‡ªå‹•ç”Ÿæˆã§æ¤œè¨¼ã™ã‚‹ã€‚
    """

    @staticmethod
    def _draw(ws, t, l, b, r):
        s = Side(style="thin")
        for c in range(l, r + 1):
            cur = ws.cell(row=t, column=c).border or Border()
            ws.cell(row=t, column=c).border = Border(
                left=cur.left, right=cur.right, bottom=cur.bottom, top=s
            )
            cur = ws.cell(row=b, column=c).border or Border()
            ws.cell(row=b, column=c).border = Border(
                left=cur.left, right=cur.right, top=cur.top, bottom=s
            )
        for r0 in range(t, b + 1):
            cur = ws.cell(row=r0, column=l).border or Border()
            ws.cell(row=r0, column=l).border = Border(
                top=cur.top, bottom=cur.bottom, right=cur.right, left=s
            )
            cur = ws.cell(row=r0, column=r).border or Border()
            ws.cell(row=r0, column=r).border = Border(
                top=cur.top, bottom=cur.bottom, left=cur.left, right=s
            )

    def test_indent_tree_with_two_row_records_using_high_level_parse(self):
        wb = Workbook()
        ws = wb.active

        # è¦ªï¼ˆè¡Œæ–¹å‘2ä»¶ï¼‰: B2:D3
        # å­ï¼ˆè¡Œæ–¹å‘3ä»¶ï¼‰: C5:E7ï¼ˆè¦ªã‚ˆã‚Š1åˆ—å³ï¼ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆè¡¨ç¾ï¼‰ã€‚3ä»¶ã¶ã‚‰ä¸‹ã’ã‚‹
        # å­«ï¼ˆè¡Œæ–¹å‘2ä»¶ã€å„ä»¶ã¯2è¡Œ1ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰: D9:E12
        set_cells(
            ws,
            {
                # è¦ª
                "B2": "2025-12-01",
                "C2": "P-Alpha",
                "D2": "100",
                "B3": "2025-12-02",
                "C3": "P-Beta",
                "D3": "200",
                # å­
                "C5": "child-1",
                "D5": "1",
                "E5": "10",
                "C6": "child-2",
                "D6": "2",
                "E6": "20",
                "C7": "child-3",
                "D7": "3",
                "E7": "30",
                # å­«ï¼ˆ2è¡ŒÃ—2ä»¶ï¼‰
                "D9": "sku-1",
                "E9": "red",
                "D10": "sku-1-b",
                "E10": "blue",
                "D11": "sku-2",
                "E11": "green",
                "D12": "sku-2-b",
                "E12": "yellow",
            },
        )

        # 1ä»¶ç›®ã®å…ˆé ­ã ã‘ã«json.*åã‚’ä»˜ã‘ã‚‹ï¼ˆä»¥é™ã¯å‹•çš„ç”Ÿæˆï¼‰
        set_defined_names(
            wb,
            {
                # è¦ª
                "json.orders.1.date": "B2",
                "json.orders.1.customer": "C2",
                "json.orders.1.amount": "D2",
                # å­ï¼ˆè¦ªã‚ˆã‚Š1åˆ—å³ã®Cåˆ—é–‹å§‹ï¼‰
                "json.orders.items.1.name": "C5",
                "json.orders.items.1.quantity": "D5",
                "json.orders.items.1.price": "E5",
                # å­«ï¼ˆã•ã‚‰ã«1åˆ—å³ã®Dåˆ—é–‹å§‹ï¼‰
                "json.orders.items.details.1.sku": "D9",
                "json.orders.items.details.1.color": "E9",
            },
        )

        # 2è¡Œãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ›¾å­«ï¼‰ã‚’ãƒãƒ¼ã‚¸ã—ã¦1å€¤ã«ã™ã‚‹ãŸã‚ã®å¤‰æ›é–¢æ•°: 2è¡Œåˆ†ã‚’çµåˆ
        # ã“ã“ã§ã¯å¾Œæ®µã§ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰å¤‰æ›ã‚’ä½¿ã†ãŸã‚ã®ã‚­ãƒ¼ã‚’ç½®ãã€‚å¤‰æ›è‡ªä½“ã¯ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã§å®Ÿç¾
        # ç½«ç·šã§çŸ©å½¢ã‚’æç”»ï¼ˆã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ: åˆ—ãŒ1ãšã¤å³ã«ãšã‚Œã‚‹ï¼‰
        self._draw(ws, 2, 2, 3, 4)  # è¦ª B2:D3
        self._draw(ws, 5, 3, 7, 5)  # å­ C5:E7
        self._draw(ws, 9, 4, 12, 5)  # å­« D9:E12ï¼ˆ2è¡ŒÃ—2ä»¶åˆ†ã‚’å«ã‚€å¤§ãã‚çŸ©å½¢ï¼‰

        # é«˜ä½APIã§E2Eï¼ˆ2è¡Œ1ãƒ¬ã‚³ãƒ¼ãƒ‰ã¯ increment=2 ã§è¡¨ç¾ï¼‰
        containers = {
            "json.orders": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$B$2:$D$3",
            },
            "json.orders.items.1": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$C$5:$E$7",
            },
            "json.orders.items.details.1": {
                "direction": "row",
                "increment": 2,
                "range": "Sheet!$D$9:$E$12",
            },
        }

        result = xlsx2json.parse_named_ranges_with_prefix(
            create_temp_excel(wb), prefix="json", containers=containers
        )

        # è¦ªã¯2ä»¶
        assert isinstance(result.get("orders"), list) and len(result["orders"]) == 2
        assert result["orders"][0]["date"] == "2025-12-01"
        assert result["orders"][1]["date"] == "2025-12-02"
        # å­ã¯3ä»¶
        assert [row.get("name") for row in result.get("items", [])][:3] == [
            "child-1",
            "child-2",
            "child-3",
        ]
        # å­«ã¯2ä»¶ï¼ˆ2è¡Œ1ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰
        assert [row.get("sku") for row in result.get("details", [])][:2] == [
            "sku-1",
            "sku-2",
        ]


class TestRegression:
    """éå»ã®ä¸å…·åˆã®å†ç™ºã‚’é˜²ããŸã‚ã®å›å¸°ãƒ†ã‚¹ãƒˆ"""

    def test_no_top_level_group_label_duplicate_for_tree(self, tmp_path):
        """ãƒ„ãƒªãƒ¼æ§‹é€ ã§ã‚°ãƒ«ãƒ¼ãƒ—ãƒ©ãƒ™ãƒ«ï¼ˆlv1ç­‰ï¼‰ãŒãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã«è¤‡è£½ã•ã‚Œãªã„ã“ã¨ã€‚

        ä»¥å‰ã¯ 'lv1' ãŒãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã«å‡ºã¦ã—ã¾ã†ã“ã¨ãŒã‚ã£ãŸãŒã€
        ãã‚ŒãŒèµ·ããªã„ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚
        """
        wb = Workbook()
        ws = wb.active
        ws.title = "Sheet1"

        # lv1 çŸ©å½¢ï¼ˆ2è¡Œï¼‰Ã—2
        draw_rect_border(ws, top=2, left=2, bottom=3, right=3)
        draw_rect_border(ws, top=4, left=2, bottom=5, right=3)
        # å€¤
        set_cells(
            ws,
            {
                "B2": "1",
                "C3": "A1",
                "B4": "2",
                "C5": "A2",
            },
        )

        # åå‰ä»˜ãç¯„å›²ï¼ˆ.1 ã‚¢ãƒ³ã‚«ãƒ¼ + ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰
        set_defined_names(
            wb,
            {
                "json.ãƒ„ãƒªãƒ¼1.lv1.1": "Sheet1!$B$2:$C$3",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.seq": "Sheet1!$B$2",
                "json.ãƒ„ãƒªãƒ¼1.lv1.1.A": "Sheet1!$C$3",
            },
        )

        xlsx_path = tmp_path / "tree_simple.xlsx"
        wb.save(xlsx_path)

        result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")

        # ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã« 'lv1' ãŒå­˜åœ¨ã—ãªã„ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—ãƒ©ãƒ™ãƒ«é‡è¤‡ãªã—ï¼‰
        assert "lv1" not in result, f"top-level keys={list(result.keys())}"
        # 'ãƒ„ãƒªãƒ¼1' ãŒ dict ã§å­˜åœ¨ã—ã€ãã®é…ä¸‹ã« 'lv1' é…åˆ—ãŒã‚ã‚‹
        root = result.get("ãƒ„ãƒªãƒ¼1")
        assert isinstance(root, dict)
        assert isinstance(root.get("lv1"), list) and len(root["lv1"]) == 2
        # å„è¦ç´ ã¯ãƒ©ãƒ™ãƒ«ã®ã¿ã®ãƒ€ãƒŸãƒ¼ã§ãªãã€æœŸå¾…ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤
        assert root["lv1"][0].get("A") == "A1" and root["lv1"][0].get("seq") == "1"
        assert root["lv1"][1].get("A") == "A2" and root["lv1"][1].get("seq") == "2"

    def test_root_array_drop_normalization_for_sibling_arrays(self):
        """é…åˆ—ãƒ«ãƒ¼ãƒˆé…ä¸‹ã«åˆ¥é…åˆ—ï¼ˆitemsç­‰ï¼‰ã‚’å…¥ã‚Œã‚‹å®šç¾©ãŒæ¥ã¦ã‚‚ã€
        ãƒ«ãƒ¼ãƒˆå´ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã«å…„å¼Ÿé…åˆ—ã¨ã—ã¦å±•é–‹ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã€‚
        ã“ã‚Œã«ã‚ˆã‚Š insert_json_path ã® dict/list ç«¶åˆã‚¨ãƒ©ãƒ¼ã‚’é˜²æ­¢ã™ã‚‹ã€‚
        """
        wb = Workbook()
        ws = wb.active

        # è¦ª2ä»¶ã€å­2ä»¶
        set_cells(
            ws,
            {
                "B2": "2025-10-01",
                "C2": "Q1",
                "B3": "2025-10-02",
                "C3": "Q2",
                "B5": "it-1",
                "C5": "1",
                "B6": "it-2",
                "C6": "2",
            },
        )

        # 1ä»¶ç›®å…ˆé ­ã«ã®ã¿å‘½åï¼ˆcontainersé§†å‹•ã§æ®‹ã‚Šã¯ç”Ÿæˆï¼‰
        set_defined_names(
            wb,
            {
                "json.orders.1.date": "B2",
                "json.orders.1.customer": "C2",
                "json.orders.items.1.name": "B5",
                "json.orders.items.1.quantity": "C5",
            },
        )

        # è¡Œæ–¹å‘ã®çŸ©å½¢ã‚’ã‚³ãƒ³ãƒ†ãƒŠã§æŒ‡ç¤ºï¼ˆç¯„å›²ã¯ãƒ†ã‚¹ãƒˆå†…ã§ã®ãƒ­ãƒ¼ã‚«ãƒ«å€¤ï¼‰
        containers = {
            "json.orders": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$B$2:$C$3",
            },
            "json.orders.items.1": {
                "direction": "row",
                "increment": 1,
                "range": "Sheet!$B$5:$C$6",
            },
        }

        result = xlsx2json.parse_named_ranges_with_prefix(
            create_temp_excel(wb), prefix="json", containers=containers
        )

        # è¦ªã¯2ä»¶ã€å­ã¯ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ« 'items' é…ä¸‹ã«2ä»¶ï¼ˆorders é…ä¸‹ã«ãƒã‚¹ãƒˆã•ã‚Œãªã„ï¼‰
        assert isinstance(result.get("orders"), list) and len(result["orders"]) == 2
        assert [row.get("name") for row in result.get("items", [])] == ["it-1", "it-2"]

    def test_rectangle_detection_isolated_for_indent_tree(self):
        """çŸ©å½¢æ¤œå‡ºã®ç‹¬ç«‹æ¤œè¨¼
        - ç½«ç·šã§ B2:D3, C5:E7, D9:E12 ã®3é ˜åŸŸã‚’æç”»
        - json.* ã®å…ˆé ­ã‚»ãƒ«ã®ã¿å‘½å
        - detect_rectangular_regions ãŒ3é ˜åŸŸã‚’æ¤œå‡ºã™ã‚‹ã“ã¨
        """
        wb = Workbook()
        ws = wb.active

        # è¦ª B2:D3ã€å­ C5:E7ã€å­« D9:E12ï¼ˆ2è¡ŒÃ—2ä»¶ï¼‰
        set_cells(
            ws,
            {
                # è¦ª
                "B2": "2025-12-01",
                "C2": "P-Alpha",
                "D2": "100",
                "B3": "2025-12-02",
                "C3": "P-Beta",
                "D3": "200",
                # å­
                "C5": "child-1",
                "D5": "1",
                "E5": "10",
                "C6": "child-2",
                "D6": "2",
                "E6": "20",
                "C7": "child-3",
                "D7": "3",
                "E7": "30",
                # å­«
                "D9": "sku-1",
                "E9": "red",
                "D10": "sku-1-b",
                "E10": "blue",
                "D11": "sku-2",
                "E11": "green",
                "D12": "sku-2-b",
                "E12": "yellow",
            },
        )

        # å…ˆé ­ã‚»ãƒ«ã®åå‰å®šç¾©
        set_defined_names(
            wb,
            {
                "json.orders.1.date": "B2",
                "json.orders.items.1.name": "C5",
                "json.orders.items.details.1.sku": "D9",
                "json.orders.items.details.1.color": "E9",
            },
        )

        # çŸ©å½¢æç”»
        draw_rect_border(ws, 2, 2, 3, 4)
        draw_rect_border(ws, 5, 3, 7, 5)
        draw_rect_border(ws, 9, 4, 12, 5)

        # æ¤œå‡ºå¯¾è±¡ã‚»ãƒ«åé ˜åŸŸã«ã‚¹ã‚­ãƒ£ãƒ³ã‚’é™å®šã—ã¦çŸ©å½¢æ¤œå‡º
        cell_map = xlsx2json.extract_cell_names_from_workbook(wb)
        rects = xlsx2json.detect_rectangular_regions(ws, cell_map)

        # æœŸå¾…çŸ©å½¢ï¼ˆtop,left,bottom,rightï¼‰é›†åˆ
        expected = {(2, 2, 3, 4), (5, 3, 7, 5), (9, 4, 12, 5)}
        found = {(t, l, b, r) for (t, l, b, r, _c) in rects}
        # ã™ã¹ã¦å«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ï¼ˆä¸¦ã³é †ã¯å•ã‚ãªã„ï¼‰
        for exp in expected:
            assert exp in found

    # è‡ªå‹•ã‚³ãƒ³ãƒ†ãƒŠç”Ÿæˆï¼ˆrangeä»˜ä¸ï¼‰ã¯ä»•æ§˜å¤–ã®ãŸã‚ã“ã“ã§ã¯æ¤œè¨¼ã—ãªã„


class TestPositionCorrectionCalculation:
    """ä½ç½®è£œæ­£è¨ˆç®—ã¨é–¢é€£ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®æœ€å°ãƒ†ã‚¹ãƒˆï¼ˆT4.1.3ï¼‰"""

    def test_calculate_target_position_various(self):
        base = (3, 5)  # C5
        # rowæ–¹å‘
        assert xlsx2json.calculate_target_position(base, "row", 1, 0) == (3, 5)
        assert xlsx2json.calculate_target_position(base, "row", 2, 1) == (3, 6)
        assert xlsx2json.calculate_target_position(base, "row", 3, 2) == (3, 9)
        # columnæ–¹å‘
        assert xlsx2json.calculate_target_position(base, "column", 1, 0) == (3, 5)
        assert xlsx2json.calculate_target_position(base, "column", 2, 1) == (4, 5)
        assert xlsx2json.calculate_target_position(base, "column", 3, 3) == (9, 5)

    def test_generate_cell_name_for_element_parent_and_child(self):
        # è¦ª: æœ«å°¾ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä»˜ä¸
        n1 = xlsx2json.generate_cell_name_for_element("json.orders", 2, "date")
        assert n1 == "json.orders.2.date"
        # å­: æœ«å°¾ã®æ•°å€¤ã‚’ç½®æ›
        n2 = xlsx2json.generate_cell_name_for_element("json.orders.1", 2, "date")
        assert n2 == "json.orders.2.date"
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãªã—
        n3 = xlsx2json.generate_cell_name_for_element("json.orders", 3, None)
        assert n3 == "json.orders.3"
        # è¤‡åˆã‚­ãƒ¼
        n4 = xlsx2json.generate_cell_name_for_element("json.orders.items", 4, "name")
        assert n4 == "json.orders.items.4.name"


class TestContainerIncrementValueReading:  # Deprecated minimal increment tests removed (covered by other scenarios)
    pass


class TestErrorHandling:
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def temp_dir(self):
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)

    # === ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ ===

    def test_invalid_file_format_handling(self, temp_dir):
        """ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ

        JSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç„¡åŠ¹ãªJSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«
        invalid_schema_file = temp_dir / "invalid_schema.json"
        with invalid_schema_file.open("w") as f:
            f.write('{"invalid": json}')  # æœ‰åŠ¹ã§ãªã„JSON

        with pytest.raises(json.JSONDecodeError):
            xlsx2json.SchemaLoader.load_schema(invalid_schema_file)

        # æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã®ã‚ã‚‹JSONãƒ•ã‚¡ã‚¤ãƒ«
        broken_json_file = temp_dir / "broken.json"
        with broken_json_file.open("w") as f:
            f.write('{"unclosed": "string}')  # é–‰ã˜æ‹¬å¼§ãªã—

        with pytest.raises(json.JSONDecodeError):
            with broken_json_file.open("r") as f:
                json.load(f)

    def test_missing_file_resources_handling(self, temp_dir):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ

        å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å­˜åœ¨ã—ãªã„ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«
        nonexistent_file = temp_dir / "nonexistent.json"
        with pytest.raises(FileNotFoundError):
            xlsx2json.SchemaLoader.load_schema(nonexistent_file)

        # å­˜åœ¨ã—ãªã„Excelãƒ•ã‚¡ã‚¤ãƒ«
        nonexistent_xlsx = temp_dir / "nonexistent.xlsx"
        with pytest.raises(FileNotFoundError):
            xlsx2json.parse_named_ranges_with_prefix(nonexistent_xlsx, prefix="json")

        # æ¨©é™ä¸è¶³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã®ãƒ•ã‚¡ã‚¤ãƒ«åé›†ï¼ˆãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰

    # collect_xlsx_files å‰Šé™¤ã«ä¼´ã„ã“ã®åˆ†å²ã¯ç„¡åŠ¹åŒ–

    # === ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ ===

    def test_array_transformation_error_scenarios(self):
        """é…åˆ—å¤‰æ›å‡¦ç†ã§ã®ã‚¨ãƒ©ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ

        ç„¡åŠ¹ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚„é–¢æ•°ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç„¡åŠ¹ãªå¤‰æ›é–¢æ•°ã®ãƒ†ã‚¹ãƒˆï¼ˆline 364-370ã‚’ã‚«ãƒãƒ¼ï¼‰
        with pytest.raises(ValueError, match="Failed to load transform function"):
            xlsx2json.ArrayTransformRule(
                "json.test", "function", "non_existent_module:invalid_function"
            )

        # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError, match="Failed to load transform function"):
            xlsx2json.ArrayTransformRule(
                "json.test", "function", "/nonexistent/file.py:some_function"
            )

        # ç„¡åŠ¹ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä»•æ§˜ã®ãƒ†ã‚¹ãƒˆï¼ˆline 370-371ã‚’ã‚«ãƒãƒ¼ï¼‰
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as tmp:
            tmp.write("# Invalid Python syntax [\n")
            tmp.flush()
            try:
                with pytest.raises(
                    ValueError, match="Failed to load transform function"
                ):
                    xlsx2json.ArrayTransformRule(
                        "json.test", "function", f"{tmp.name}:some_function"
                    )
            finally:
                Path(tmp.name).unlink()

        # ç„¡åŠ¹ãªå¤‰æ›ã‚¿ã‚¤ãƒ—ã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError):
            xlsx2json.ArrayTransformRule("json.test", "invalid_type", "spec")

        # é–¢æ•°ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
        try:
            rule = xlsx2json.ArrayTransformRule(
                "json.test", "function", "invalid_python_code"
            )
        except Exception:
            pass  # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’æœŸå¾…

    def test_command_execution_error_handling(self):
        """ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ

        å¤–éƒ¨ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œæ™‚ã®ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®ãƒ†ã‚¹ãƒˆ
        with patch("subprocess.run") as mock_run:
            mock_run.side_effect = subprocess.TimeoutExpired("test_cmd", 1)

            try:
                rule = xlsx2json.ArrayTransformRule("json.test", "command", "sleep 10")
                rule.transform("test_data")
            except Exception:
                pass  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¾‹å¤–ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…

        # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œå¤±æ•—ã®ãƒ†ã‚¹ãƒˆ
        with patch("subprocess.run") as mock_run:
            mock_run.side_effect = subprocess.CalledProcessError(1, "test_cmd")

            try:
                rule = xlsx2json.ArrayTransformRule("json.test", "command", "exit 1")
                rule.transform("test_data")
            except Exception:
                pass  # å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…

    # === ã‚¹ã‚­ãƒ¼ãƒãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ ===

    def test_schema_validation_error_processing(self, temp_dir):
        """ã‚¹ã‚­ãƒ¼ãƒãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ†ã‚¹ãƒˆ

        ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒé•åæ™‚ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç”ŸæˆãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å‹é•åãƒ‡ãƒ¼ã‚¿
        invalid_data = {
            "name": 123,  # æ–‡å­—åˆ—ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒæ•°å€¤
            "age": "not_a_number",  # æ•°å€¤ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒæ–‡å­—åˆ—
            "email": "invalid_email_format",  # ãƒ¡ãƒ¼ãƒ«å½¢å¼ã§ã¯ãªã„
        }

        # å³æ ¼ãªã‚¹ã‚­ãƒ¼ãƒ
        strict_schema = {
            "type": "object",
            "properties": {
                "name": {"type": "string"},
                "age": {"type": "integer", "minimum": 0},
                "email": {"type": "string", "format": "email"},
            },
            "required": ["name", "age", "email"],
        }

        validator = Draft7Validator(strict_schema)
        log_dir = temp_dir / "error_logs"

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç”Ÿæˆ
        xlsx2json.SchemaLoader.validate_and_log(invalid_data, validator, log_dir, "validation_test")

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        error_log = log_dir / "validation_test.error.log"
        assert error_log.exists()

        # ã‚¨ãƒ©ãƒ¼å†…å®¹ã®ç¢ºèª
        with error_log.open("r", encoding="utf-8") as f:
            log_content = f.read()
            assert len(log_content) > 0  # ã‚¨ãƒ©ãƒ¼å†…å®¹ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹

    # === ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ ===

    def test_main_application_error_scenarios(self, temp_dir):
        """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œæ™‚ã®ã‚¨ãƒ©ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ

        ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œæ™‚ã®æ§˜ã€…ãªã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å¼•æ•°ãªã—ã§ã®å®Ÿè¡Œ
        with patch("sys.argv", ["xlsx2json.py"]):
            with patch("xlsx2json.logger") as mock_logger:
                result = xlsx2json.main()
                assert result == 1  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1ã‚’è¿”ã™
                mock_logger.error.assert_called()

        # ç„¡åŠ¹ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã®å®Ÿè¡Œ
        invalid_config = temp_dir / "invalid_config.json"
        with invalid_config.open("w") as f:
            f.write("invalid json content")

        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch(
            "sys.argv",
            ["xlsx2json.py", "--config", str(invalid_config), str(test_xlsx)],
        ):
            with patch("xlsx2json.logger") as mock_logger:
                result = xlsx2json.main()
                assert result == 1  # JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ã§ã¯1ã‚’è¿”ã™

        # è§£æä¾‹å¤–ã§ã®å®Ÿè¡Œ
        with patch("sys.argv", ["xlsx2json.py", str(test_xlsx)]):
            with patch(
                "xlsx2json.parse_named_ranges_with_prefix",
                side_effect=Exception("Test exception"),
            ):
                with patch("xlsx2json.logger") as mock_logger:
                    result = xlsx2json.main()
                    assert result == 0  # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼ã§ã‚‚ãƒ¡ã‚¤ãƒ³é–¢æ•°ã¯0ã‚’è¿”ã™
                    # processing_stats.add_errorãŒå‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

    # === ãƒªã‚½ãƒ¼ã‚¹ãƒ»æ¨©é™ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ ===

    def test_resource_permission_error_handling(self, temp_dir):
        """ãƒªã‚½ãƒ¼ã‚¹ãƒ»æ¨©é™ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ

        ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ æ¨©é™ã‚„ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # èª­ã¿å–ã‚Šå°‚ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã®æ›¸ãè¾¼ã¿è©¦è¡Œ
        readonly_dir = temp_dir / "readonly"
        readonly_dir.mkdir()
        readonly_dir.chmod(0o444)  # èª­ã¿å–ã‚Šå°‚ç”¨

        test_data = {"test": "data"}

        try:
            output_path = readonly_dir / "test.json"
            with pytest.raises(PermissionError):
                xlsx2json.write_data(test_data, output_path)
        finally:
            readonly_dir.chmod(0o755)  # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

    def test_edge_case_error_conditions(self):
        """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ã‚¨ãƒ©ãƒ¼æ¡ä»¶ãƒ†ã‚¹ãƒˆ

        å¢ƒç•Œæ¡ä»¶ã‚„ç‰¹æ®Šãªã‚±ãƒ¼ã‚¹ã§ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # None ãƒ‡ãƒ¼ã‚¿ã§ã®å‡¦ç†
        result = xlsx2json.clean_empty_values(None)
        assert result is None

        # å¾ªç’°å‚ç…§ãƒ‡ãƒ¼ã‚¿ã§ã®JSONå‡ºåŠ›
        circular_data = {}
        circular_data["self"] = circular_data

        with pytest.raises((ValueError, RecursionError)):
            json.dumps(circular_data)

        # ç„¡åŠ¹ãªãƒ‘ã‚¹å½¢å¼ã§ã® JSON ãƒ‘ã‚¹æŒ¿å…¥
        root = {}
        try:
            xlsx2json.insert_json_path(root, ["invalid", "path", ""], "value")
        except Exception:
            pass  # ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…

    def test_comprehensive_error_recovery(self):
        """åŒ…æ‹¬çš„ãªã‚¨ãƒ©ãƒ¼å›å¾©ãƒ†ã‚¹ãƒˆ

        è¤‡æ•°ã®ã‚¨ãƒ©ãƒ¼ãŒé€£ç¶šã—ã¦ç™ºç”Ÿã—ãŸå ´åˆã®å›å¾©å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ãƒ­ã‚°è¨­å®šã‚¨ãƒ©ãƒ¼
        original_logger = xlsx2json.logger
        try:
            # ãƒ­ã‚¬ãƒ¼ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
            xlsx2json.logger = None

            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ãŒç¶™ç¶šã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            try:
                xlsx2json.is_empty_value("")
            except AttributeError:
                pass  # ãƒ­ã‚¬ãƒ¼ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚‹ä¾‹å¤–

        finally:
            xlsx2json.logger = original_logger

        # è¤‡æ•°ã®å¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼
        invalid_rules = [
            "json.test1=invalid_type:spec",
            "json.test2=function:non_existent:func",
            "json.test3=command:invalid_command",
        ]

        with patch("xlsx2json.logger") as mock_logger:
            try:
                xlsx2json.parse_array_transform_rules(invalid_rules, "json")
            except Exception:
                pass
            # è­¦å‘Šãƒ»ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒé©åˆ‡ã«å‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert mock_logger.warning.called or mock_logger.error.called
        with pytest.raises(ValueError, match="Failed to load transform function"):
            xlsx2json.ArrayTransformRule(
                "test.path", "function", "nonexistent_module:nonexistent_function"
            )

    @patch("subprocess.run")
    def test_command_timeout(self, mock_run):
        """ã‚³ãƒãƒ³ãƒ‰ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹
        mock_run.side_effect = subprocess.TimeoutExpired("sleep", 30)

        rule = xlsx2json.ArrayTransformRule("test.path", "command", "sleep 60")
        result = rule.transform("test_value")

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯å…ƒã®å€¤ãŒè¿”ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert result == "test_value"

    def test_array_transform_rule_comprehensive_errors(self):
        """ArrayTransformRuleã®åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆï¼ˆçµ±åˆï¼‰"""
        # ç„¡åŠ¹ãªã‚¿ã‚¤ãƒ—ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError):
            xlsx2json.ArrayTransformRule("path", "invalid_type", "spec")

        # ç„¡åŠ¹ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä»•æ§˜ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError, match="must be.*function"):
            xlsx2json.ArrayTransformRule("test.path", "function", "invalid_spec")

        # å­˜åœ¨ã—ãªã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError, match="Failed to load.*function"):
            xlsx2json.ArrayTransformRule(
                "test.path", "function", "nonexistent_module:func"
            )

        # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError, match="Failed to load.*function"):
            xlsx2json.ArrayTransformRule("test.path", "function", "nonexistent.py:func")

        # é–¢æ•°ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
        try:
            rule = xlsx2json.ArrayTransformRule(
                "path", "function", "lambda: undefined_var"
            )
            rule.transform("test")  # Should trigger function execution error
        except Exception:
            pass  # Expected error

    def test_array_transform_rule_command_execution_error(self):
        """ArrayTransformRuleã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆï¼ˆline 408å¯¾å¿œï¼‰"""
        try:
            rule = xlsx2json.ArrayTransformRule(
                "path", "command", "command_that_does_not_exist_xyz"
            )
            result = rule.transform("input")
        except Exception:
            pass  # Expected for command execution errors

    def test_array_transform_rule_split_processing_errors(self):
        """ArrayTransformRuleã®splitå‡¦ç†ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆï¼ˆlines 414, 418å¯¾å¿œï¼‰"""
        try:
            rule = xlsx2json.ArrayTransformRule("path", "split", "")  # Empty delimiter
            result = rule.transform("test,data")
        except Exception:
            pass  # Expected for split processing errors

    def test_parse_array_split_rules_invalid_format(self):
        """parse_array_split_rulesã®ç„¡åŠ¹ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè­¦å‘Šãƒ†ã‚¹ãƒˆï¼ˆlines 294-295å¯¾å¿œï¼‰"""
        invalid_rules = ["invalid_rule_format", "another=invalid"]

        with patch("xlsx2json.logger") as mock_logger:
            xlsx2json.parse_array_split_rules(invalid_rules, "json")

            # ç„¡åŠ¹ãªé…åˆ—åŒ–è¨­å®šã®è­¦å‘ŠãŒå‡ºåŠ›ã•ã‚Œã‚‹
            mock_logger.warning.assert_called()
            assert "ç„¡åŠ¹ãªé…åˆ—åŒ–è¨­å®š" in str(mock_logger.warning.call_args)

    # collect_xlsx_files ã®åŒ…æ‹¬ãƒ†ã‚¹ãƒˆã¯å‰Šé™¤

    def test_main_function_error_handling(self):
        """mainé–¢æ•°ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        original_argv = sys.argv
        try:
            # å¼•æ•°ãªã—ã§ã®mainå®Ÿè¡Œã‚’ãƒ†ã‚¹ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ãŒã‚«ãƒãƒ¬ãƒƒã‚¸ã¯å‘ä¸Šï¼‰
            sys.argv = ["xlsx2json.py"]

            try:
                xlsx2json.main()
            except SystemExit:
                # å¼•æ•°ä¸è¶³ã«ã‚ˆã‚‹æ­£å¸¸ãªçµ‚äº†
                pass
            except Exception:
                # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã‚‚è¨±å®¹ï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸ŠãŒç›®çš„ï¼‰
                pass

        finally:
            sys.argv = original_argv

    def test_command_execution_scenarios_lines_408_418_from_precision(self):
        """Test command execution scenarios covering lines 408-418 (æ—§TestPrecisionCoverage95Plusçµ±åˆ)"""
        # Test command-based array transformations using proper API
        try:
            rule = xlsx2json.ArrayTransformRule("json.test", "command", "echo 'a b c'")
            result = rule.transform("test_input")
            # Should return array or handle gracefully
        except Exception:
            pass  # Expected for command execution

        try:
            rule = xlsx2json.ArrayTransformRule(
                "json.test", "command", "invalid_command_xyz"
            )
            result = rule.transform("test_input")
        except Exception:
            pass  # Expected for invalid commands

        try:
            rule = xlsx2json.ArrayTransformRule(
                "json.test", "command", "python -c 'print(\"1\\n2\\n3\")'"
            )
            result = rule.transform("input")
        except Exception:
            pass  # Expected for complex commands

    # === æ‹¡å¼µã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ ===

    def test_array_transform_rule_parameter_validation(self):
        """ArrayTransformRuleã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""

        # ç©ºã®path
        with pytest.raises(
            ValueError, match="pathã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.ArrayTransformRule("", "function", "test:func")

        # Noneã®path
        with pytest.raises(
            ValueError, match="pathã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.ArrayTransformRule(None, "function", "test:func")

        # ç©ºã®transform_type
        with pytest.raises(
            ValueError, match="transform_typeã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.ArrayTransformRule("test", "", "test:func")

        # ç©ºã®transform_spec
        with pytest.raises(
            ValueError, match="transform_specã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.ArrayTransformRule("test", "function", "")

    def test_parse_array_split_rules_enhanced_validation(self):
        """parse_array_split_rulesé–¢æ•°ã®æ‹¡å¼µãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""

        # ç©ºã®prefixã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(
            ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.parse_array_split_rules(["test=,"], "")

        # Noneã®prefixã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(
            ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.parse_array_split_rules(["test=,"], None)

    def test_parse_array_transform_rules_enhanced_validation(self):
        """parse_array_transform_rulesé–¢æ•°ã®æ‹¡å¼µãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""

        # ç©ºã®prefixã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(
            ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.parse_array_transform_rules(["test=function:module:func"], "")


if __name__ == "__main__":
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®šï¼ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã®è©³ç´°æƒ…å ±è¡¨ç¤ºç”¨ï¼‰
    logging.basicConfig(level=logging.INFO)


# ==== ä»¥ä¸‹ã€åˆ†æ•£ã—ã¦ã„ãŸ test_*.py ã®çµ±åˆãƒ†ã‚¹ãƒˆç¾¤ ====

class TestArrayUtils:
    """test_array_utils.py ã®çµ±åˆ"""

    def test_ensure_array_and_element_creates_array_and_element(self):
        root = {}
        elem = m.ensure_array_and_element(root, "A", 0)
        assert isinstance(root["A"], list)
        # åˆæœŸè¦ç´ ã¯ Noneï¼ˆè¾æ›¸ã¯å¾Œæ®µãƒ­ã‚¸ãƒƒã‚¯ã§å¿…è¦æ™‚ã«ç”Ÿæˆï¼‰
        assert elem is None
        assert root["A"][0] is None

    def test_ensure_array_and_element_extends_and_returns_element(self):
        root = {"A": [{}]}
        elem = m.ensure_array_and_element(root, "A", 2)
        assert len(root["A"]) == 3
        # 2ç•ªç›®ã¯æ—¢å­˜è¾æ›¸ã‚’ä¿æŒã—ã€3ç•ªç›®ã¯ None ã§ç¢ºä¿
        assert isinstance(root["A"][0], dict)
        assert root["A"][1] is None
        assert root["A"][2] is None
        assert elem is None


class TestShapes:
    """test_shapes.py ã®çµ±åˆ"""

    def test_merge_unique_scalar_and_list(self):
        # None existing + scalar
        assert m.merge_into_list_unique(None, 1) == [1]
        # scalar existing + scalar
        assert m.merge_into_list_unique(1, 2) == [1, 2]
        # list existing + scalar duplicate
        assert m.merge_into_list_unique([1, 2], 2) == [1, 2]
        # list existing + list values
        assert m.merge_into_list_unique([1], [2, 3]) == [1, 2, 3]

    def test_merge_unique_ignores_empty_and_duplicates(self):
        assert m.merge_into_list_unique([], None) == []
        assert m.merge_into_list_unique([], "") == []
        assert m.merge_into_list_unique(["a"], ["", None, "a"]) == ["a"]

    def test_merge_unique_list_of_list_is_unchanged(self):
        existing = [[1, 2], [3, 4]]
        out = m.merge_into_list_unique(existing, [5, 6])
        # list-of-list ã¯ä¸å¤‰ï¼ˆå½¢çŠ¶ä¿è­·ï¼‰
        assert out == existing
        # è¿”ã‚Šå€¤ã¯ã‚³ãƒ”ãƒ¼ã§ã‚ã‚Šã€å…ƒãƒªã‚¹ãƒˆã‚’ç ´å£Šã—ãªã„
        assert out is not existing

    def test_apply_expected_shape_to_value_1d_scalar_to_list(self):
        efs = {("arr", "field"): "1D"}
        # ã‚¹ã‚«ãƒ©â†’1D
        assert m.apply_expected_shape_to_value(1, "field", efs, "arr") == [1]
        # 1Dâ†’1D
        assert m.apply_expected_shape_to_value([1, 2], "field", efs, "arr") == [1, 2]
        # 2Dã¯ãã®ã¾ã¾
        assert m.apply_expected_shape_to_value([[1, 2]], "field", efs, "arr") == [[1, 2]]

    def test_apply_expected_shape_to_value_2d_from_scalar_and_1d_and_empty(self):
        efs = {("arr", "field"): "2D"}
        # ã‚¹ã‚«ãƒ©â†’2D
        assert m.apply_expected_shape_to_value(1, "field", efs, "arr") == [[1]]
        # 1Dâ†’2D
        assert m.apply_expected_shape_to_value([1, 2], "field", efs, "arr") == [[1, 2]]
        # ç©º1Dâ†’2Dï¼ˆç©ºãªã‚‰ [[]]ï¼‰
        assert m.apply_expected_shape_to_value([], "field", efs, "arr") == [[]]


class TestHelpersAndAnchors:
    """test_helpers.py ã®çµ±åˆ"""

    class DummyDefinedName:
        """æœ€å°é™ã® interface ã‚’æŒã¤ãƒ€ãƒŸãƒ¼ DefinedName"""

        def __init__(self, destinations):
            self.destinations = destinations

    def test_find_arrays_with_double_index_basic(self):
        prefix = "json"
        normalized = prefix + "."
        # å®šç¾©åã¨ç”Ÿæˆåã®ä¸¡æ–¹ã«äºŒé‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å«ã‚€ã‚‚ã®ã‚’æ··åœ¨
        all_name_keys = [
            "json.A.1.x",  # 1é‡
            "json.A.1.2.x",  # 2é‡ (æ¤œå‡º: A)
            "json.B.10.1.y.z",  # 2é‡ (æ¤œå‡º: B)
            "json.C.name",  # è©²å½“ã›ãš
        ]
        gen_map = {
            "json.D.3.4.z": 1,  # 2é‡ (æ¤œå‡º: D)
            "json.A.999": 0,  # è©²å½“ã›ãš
        }
        got = m.find_arrays_with_double_index(normalized, all_name_keys, gen_map)
        assert got == {"A", "B", "D"}

    def test_compute_container_parents_with_children(self):
        container_parent_names = {"json.A", "json.B", "json.C"}
        all_name_keys = [
            "json.A.1",  # A ã«å­ï¼ˆå®šç¾©åï¼‰ã‚ã‚Š
            "json.B",  # B ã¯å­ãªã—
            "json.C.name",  # C ã«å­ï¼ˆå®šç¾©åï¼‰ã‚ã‚Š
        ]
        gen_map = {"json.B.1": 0}  # B ã¯ç”Ÿæˆåã§å­ã‚ã‚Š
        got = m.compute_container_parents_with_children(
            container_parent_names, all_name_keys, gen_map
        )
        assert got == {"json.A", "json.B", "json.C"}

    def test_compute_group_to_root_map_from_containers_and_names(self):
        containers = {
            # json.<root>.<group>.1.<child>
            "json.R1.lv1.1.A": {},
            # ã‚‚ã†ä¸€ã¤åˆ¥ root ã«åŒã˜ group ãƒ©ãƒ™ãƒ«ãŒã‚ã‚‹ â†’ æ›–æ˜§åŒ–ã—ã¦é™¤å¤–
            "json.R2.lv1.1.B": {},
            # åˆ¥ã‚°ãƒ«ãƒ¼ãƒ—
            "json.R1.lv2.1.C": {},
        }
        prefix = "json"
        normalized = prefix + "."
        # å®šç¾©åã§ã‚‚ group ã‚’è£œè¶³
        all_names = [
            "json.R3.lv3.1.x",
            "json.R3.lv3.1.y",
            # ä»–ã«ã‚‚é©å½“ãªåå‰
            "json.R4.name",
        ]
        got = m.compute_group_to_root_map(containers, prefix, normalized, all_names)
        # lv1 ã¯ R1/R2 ã§æ›–æ˜§ â†’ é™¤å¤–, lv2 ã¯ R1, lv3 ã¯ R3
        assert got == {"lv2": "R1", "lv3": "R3"}

    def test_precompute_generated_indices_for_array_and_skip_logic(self):
        prefix = "json"
        normalized = prefix + "."
        array = "arr"
        gen_map = {
            "json.arr.1.name": "a1",
            "json.arr.3.name": "a3",
        }
        defined_only_name_keys = set()

        indices = m.precompute_generated_indices_for_array(gen_map, normalized, array)
        assert indices == {1, 3}

        # idx=1 ã¯ç”Ÿæˆåã‚ã‚Š â†’ skip True
        assert (
            m.should_skip_distribution_index(
                1, array, "name", normalized, defined_only_name_keys, gen_map, indices
            )
            is True
        )
        # idx=2 ã¯ç”Ÿæˆåãªã—ï¼å®šç¾©åãªã— â†’ skip Falseï¼ˆåˆ†é…ã•ã‚Œã‚‹ï¼‰
        assert (
            m.should_skip_distribution_index(
                2, array, "name", normalized, defined_only_name_keys, gen_map, indices
            )
            is False
        )

        # å®šç¾©åãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼ˆcand1/cand2ï¼‰
        defined_only_name_keys = {
            "json.arr.2.name",  # cand1
            "json.arr.name.5",  # cand2ï¼ˆç†è«–ä¸Šã®åˆ¥é…ç½®ï¼‰
        }
        # idx=2 ã¯å®šç¾©åãŒã‚ã‚‹ â†’ skip True
        assert (
            m.should_skip_distribution_index(
                2, array, "name", normalized, defined_only_name_keys, gen_map, indices
            )
            is True
        )
        # idx=5 ã¯ cand2 ã¨ä¸€è‡´ â†’ skip True
        assert (
            m.should_skip_distribution_index(
                5, array, "name", normalized, defined_only_name_keys, gen_map, indices
            )
            is True
        )

    @pytest.mark.parametrize("field_token,expected", [(None, False), ("name", True)])
    def test_skip_distribution_without_and_with_field(self, field_token, expected):
        prefix = "json"
        normalized = prefix + "."
        array = "arr"
        gen_map = None
        defined_only_name_keys = {"json.arr.2.name"}
        indices = set()
        got = m.should_skip_distribution_index(
            2, array, field_token, normalized, defined_only_name_keys, gen_map, indices
        )
        assert got is expected

    def test_handle_parent_level_for_double_index_array_basic(self):
        # æœŸå¾…: è¦ªãƒ¬ãƒ™ãƒ« parent.i.field ã‚’ [i][0][field] ã¸æ ¼ç´ï¼ˆç”ŸæˆåãŒç„¡ã„å ´åˆï¼‰

        class DummyWB:
            pass

        wb = DummyWB()
        defined_name = object()
        value = "X"
        array_ref = [None, None, None]
        array_name = "A"
        array_index = 1
        path_keys = [array_name, "2", "field"]
        name = f"json.{array_name}.2.field"
        normalized_prefix = "json."
        gen_map = {}  # ç”Ÿæˆåãªã—
        expected_field_shape = {(array_name, "field"): "1D"}

        # å…ˆã« [i] ã‚¹ãƒ­ãƒƒãƒˆã‚’ç¢ºä¿
        array_ref[array_index] = None

        handled = m.handle_parent_level_for_double_index_array(
            wb=wb,
            defined_name=defined_name,
            value=value,
            array_ref=array_ref,
            array_name=array_name,
            array_index=array_index,
            path_keys=path_keys,
            name=name,
            normalized_prefix=normalized_prefix,
            gen_map=gen_map,
            expected_field_shape=expected_field_shape,
        )
        assert handled is True
        assert isinstance(array_ref[array_index], list)
        assert isinstance(array_ref[array_index][0], dict)
        assert array_ref[array_index][0]["field"] == ["X"]

    def test_handle_parent_level_for_double_index_array_skip_on_generated(self):
        # æœŸå¾…: å½“è©² i ã«ç”ŸæˆåãŒå­˜åœ¨ã™ã‚‹æ™‚ã€è¦ªãƒ¬ãƒ™ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—
        wb = object()
        defined_name = object()
        value = "X"
        array_ref = [None]
        array_name = "A"
        array_index = 0
        path_keys = [array_name, "1", "field"]
        name = f"json.{array_name}.1.field"
        normalized_prefix = "json."
        gen_map = {"json.A.1.1": 123}  # i=1 ã®é…ä¸‹ã«ç”Ÿæˆåã‚ã‚Š
        expected_field_shape = {(array_name, "field"): "1D"}

        array_ref[array_index] = None

        handled = m.handle_parent_level_for_double_index_array(
            wb=wb,
            defined_name=defined_name,
            value=value,
            array_ref=array_ref,
            array_name=array_name,
            array_index=array_index,
            path_keys=path_keys,
            name=name,
            normalized_prefix=normalized_prefix,
            gen_map=gen_map,
            expected_field_shape=expected_field_shape,
        )
        assert handled is True
        # è¦ªãƒ¬ãƒ™ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ â†’ array_ref ã¯å¤‰æ›´ã•ã‚Œãªã„
        assert array_ref[array_index] is None

    def test_suppress_label_terminal_if_applicable_true_and_false(self):
        normalized_prefix = "json."
        group_labels = {"lv1", "lv2"}
        # é…åˆ—è¦ç´ é…ä¸‹ï¼ˆjson.A.1.lv1ï¼‰ã§ã€å¯¾å¿œã‚¢ãƒ³ã‚«ãƒ¼ï¼ˆjson.A.1.1 ç³»ï¼‰ãŒå­˜åœ¨ã™ã‚‹ã‚±ãƒ¼ã‚¹
        original_path_keys = ["A", "1", "lv1"]
        remaining_keys = ["lv1"]
        all_name_keys = [
            "json.A.1.1",  # ã‚¢ãƒ³ã‚«ãƒ¼å­˜åœ¨
            "json.A.1.1.name",  # å­ã‚‚å­˜åœ¨
        ]
        container_parent_names = set()
        assert (
            m.suppress_label_terminal_if_applicable(
                remaining_keys=remaining_keys,
                original_path_keys=original_path_keys,
                group_labels=group_labels,
                normalized_prefix=normalized_prefix,
                all_name_keys=all_name_keys,
                container_parent_names=container_parent_names,
            )
            is True
        )

        # å¯¾å¿œã‚¢ãƒ³ã‚«ãƒ¼ãŒãªã„å ´åˆã¯ False
        all_name_keys = ["json.A.1.name"]
        assert (
            m.suppress_label_terminal_if_applicable(
                remaining_keys=remaining_keys,
                original_path_keys=original_path_keys,
                group_labels=group_labels,
                normalized_prefix=normalized_prefix,
                all_name_keys=all_name_keys,
                container_parent_names=container_parent_names,
            )
            is False
        )

    def test_should_skip_parent_distribution_for_index(self):
        normalized_prefix = "json."
        array_name = "A"
        # i=1 ã«ç”ŸæˆåãŒã‚ã‚‹ â†’ è¦ªãƒ¬ãƒ™ãƒ«åˆ†é…ã¯ã‚¹ã‚­ãƒƒãƒ—
        gen_map = {"json.A.1.1": 0}
        assert (
            m.should_skip_parent_distribution_for_index(
                array_name=array_name,
                array_index=0,
                normalized_prefix=normalized_prefix,
                gen_map=gen_map,
            )
            is True
        )
        # i=2 ã¯ç”Ÿæˆåãªã— â†’ åˆ†é…è¨±å¯
        assert (
            m.should_skip_parent_distribution_for_index(
                array_name=array_name,
                array_index=1,
                normalized_prefix=normalized_prefix,
                gen_map=gen_map,
            )
            is False
        )

    def test_should_skip_distribution_index(self):
        # ç”Ÿæˆæ¸ˆã¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾è±¡ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        assert xlsx2json.should_skip_distribution_index(
            tgt_idx_int=2,
            array_name="items",
            field_token="name",
            normalized_prefix="json.",
            defined_only_name_keys=set(),
            gen_map=None,
            gen_indices={2, 5},
        )

        # å®šç¾©åã«è©²å½“ãƒ‘ã‚¹ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        assert xlsx2json.should_skip_distribution_index(
            tgt_idx_int=3,
            array_name="items",
            field_token="name",
            normalized_prefix="json.",
            defined_only_name_keys={"json.items.3.name"},
            gen_map=None,
            gen_indices=set(),
        )

        # ãã‚Œä»¥å¤–ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ãªã„
        assert not xlsx2json.should_skip_distribution_index(
            tgt_idx_int=1,
            array_name="items",
            field_token="name",
            normalized_prefix="json.",
            defined_only_name_keys=set(),
            gen_map=None,
            gen_indices=set(),
        )

    def test_find_local_anchor_row_with_numeric_tokens(self):
        # æ•°å€¤ãƒˆãƒ¼ã‚¯ãƒ³æ–‡å­—åˆ—ã‚’1åˆ—ã«ä¸¦ã¹ãŸæœ€å°ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ
        wb = openpyxl.Workbook()
        ws = wb.active
        # ãƒˆãƒ¼ã‚¯ãƒ³ã‚’Aåˆ—ã®2ã€œ5è¡Œã«é…ç½®
        ws.cell(row=2, column=1, value="1-1")
        ws.cell(row=3, column=1, value="1-2")
        ws.cell(row=4, column=1, value="2-1")
        ws.cell(row=5, column=1, value="2-2")

        # current_positions ã¯ä»»æ„ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ (åˆ—, è¡Œ) ã«ãƒãƒƒãƒ—ï¼ˆAåˆ—ã‚’å‚ç…§ï¼‰
        current_positions = {"num": (1, 2)}
        # å…ˆé ­ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹['2'] ã‹ã¤é•·ã•2ã«ä¸€è‡´ã™ã‚‹è¡Œã‚’æ¢ç´¢ â†’ æœ€åˆã«ä¸€è‡´ã™ã‚‹ã®ã¯4è¡Œç›®ã®ã¯ãš
        found = xlsx2json.find_local_anchor_row(
            ws=ws,
            current_positions=current_positions,
            probe_fields=["num"],
            numeric_probe_cols=[1],
            local_aligned_row=2,
            eff_pb=10,
            step=1,
            expected_len=2,
            expected_prefix=["2"],
        )
        assert found == 4


class TestFieldAnchorGen:
    """test_field_anchor_gen.py ã®çµ±åˆ"""

    @staticmethod
    def _dollar(a1: str) -> str:
        # A1 -> $A$1 / A1:B1 -> $A$1:$B$1
        if ":" in a1:
            s, e = a1.split(":", 1)
            return TestFieldAnchorGen._dollar(s) + ":" + TestFieldAnchorGen._dollar(e)
        m2 = re.fullmatch(r"([A-Za-z]+)(\d+)", a1)
        if not m2:
            return a1
        col, row = m2.groups()
        return f"${col.upper()}${row}"

    @staticmethod
    def _add_name(wb, name: str, sheet: str, ref: str):
        if "!" not in ref:
            ref = f"{sheet}!{TestFieldAnchorGen._dollar(ref)}"
        wb.defined_names.add(DefinedName(name, attr_text=ref))

    def test_generate_subarray_names_horizontal_then_vertical(self, tmp_path):
        wb = Workbook()
        ws = wb.active
        ws.title = "S"
        # æ¨ª1x4
        for i, col in enumerate(["A", "B", "C", "D"], start=1):
            ws[f"{col}1"] = i
        # ç¸¦3x1
        ws["F1"] = "x1"; ws["F2"] = "x2"; ws["F3"] = "x3"
        # 2D ã¯å¯¾è±¡å¤–
        ws["H1"] = 1; ws["I1"] = 2; ws["H2"] = 3; ws["I2"] = 4

        # å®šç¾©å: json.A.1.field.1 ãŒ 1x4 / json.B.1.col.1 ãŒ 3x1 / json.C.1.z.1 ã¯2D
        self._add_name(wb, "json.A.1.field.1", "S", "$A$1:$D$1")
        self._add_name(wb, "json.B.1.col.1", "S", "$F$1:$F$3")
        self._add_name(wb, "json.C.1.z.1", "S", "$H$1:$I$2")

        # å®Ÿè¡Œå¯¾è±¡ãƒ˜ãƒ«ãƒ‘ãƒ¼
        m.generate_subarray_names_for_field_anchors(wb, normalized_prefix="json.")

        gm = m.get_generated_names_map(wb) or {}
        # A: 1x4 â†’ 2..4 ã‚’ç”Ÿæˆ
        assert "json.A.1.field.2" in gm
        assert "json.A.1.field.3" in gm
        assert "json.A.1.field.4" in gm
        # B: 3x1 â†’ 2..3 ã‚’ç”Ÿæˆ
        assert "json.B.1.col.2" in gm
        assert "json.B.1.col.3" in gm
        # C: 2D â†’ ç”Ÿæˆã—ãªã„
        assert not any(
            k.startswith("json.C.1.z.") and k.endswith(tuple(["2", "3"])) for k in gm.keys()
        )

    def test_generate_subarray_names_respect_existing_definitions(self):
        wb = Workbook()
        ws = wb.active
        ws.title = "S"
        ws["A1"] = 1; ws["B1"] = 2; ws["C1"] = 3
        # 1x3
        self._add_name(wb, "json.A.1.f.1", "S", "$A$1:$C$1")
        # æ—¢å­˜å®šç¾©: .2 ã¯æ—¢ã«ã‚ã‚‹ â†’ ç”Ÿæˆã‚¹ã‚­ãƒƒãƒ—
        self._add_name(wb, "json.A.1.f.2", "S", "$B$1")

        m.generate_subarray_names_for_field_anchors(wb, normalized_prefix="json.")
        gm = m.get_generated_names_map(wb) or {}
        # .3 ã¯ç”Ÿæˆã•ã‚Œã‚‹ãŒ .2 ã¯ç”Ÿæˆã•ã‚Œãªã„
        assert "json.A.1.f.3" in gm
        assert "json.A.1.f.2" not in gm


class TestAnchorSuppress:
    """test_anchor_suppress.py ã®çµ±åˆ"""

    def test_should_skip_array_anchor_insertion(self):
        prefix = "json"
        normalized = prefix + "."
        # ç–‘ä¼¼ç”Ÿæˆåãƒãƒƒãƒ—
        gen_map = {
            # A.1.* é…ä¸‹ã«ç”Ÿæˆåã‚ã‚Š
            "json.A.1.field": "S!$A$1",
            # åˆ¥é…åˆ— B ã«ã¯ç„¡ã—
        }
        # i=1 ã¯ã‚¹ã‚­ãƒƒãƒ—ã€i=2 ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ãªã„
        assert m.should_skip_array_anchor_insertion("A", 0, normalized, gen_map) is True
        assert m.should_skip_array_anchor_insertion("A", 1, normalized, gen_map) is False
        assert m.should_skip_array_anchor_insertion("B", 0, normalized, gen_map) is False


class TestMultiSheetAggregationMinimal:
    """ãƒãƒ«ãƒã‚·ãƒ¼ãƒˆé›†ç´„ã®æœ€å°æ¤œè¨¼ãƒ†ã‚¹ãƒˆ

    - 2ã‚·ãƒ¼ãƒˆé›†ç´„ã®é †åºï¼ˆãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯é †ï¼‰
    - éè¡¨ç¤ºã‚·ãƒ¼ãƒˆã‚‚å«ã‚ã‚‹ï¼æœªå®šç¾©ã‚·ãƒ¼ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
    - ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€å¤§ä»¶æ•°ã®æ‰“ã¡æ­¢ã‚
    """

    def _define_parent_ranges(self, wb, sheet_title: str, top_row: int = 2):
        set_defined_names(
            wb,
            {
                "json.orders.1.date": f"{sheet_title}!$B${top_row}",
                "json.orders.1.customer": f"{sheet_title}!$C${top_row}",
                "json.orders.1.amount": f"{sheet_title}!$D${top_row}",
            },
        )

    def test_multisheet_aggregate_across_two_sheets(self):
        wb = Workbook()
        ws1 = wb.active
        ws1.title = "Sheet1"
        ws2 = wb.create_sheet("Sheet2")

        # Sheet1: 2ä»¶
        ws1["B2"] = "2025-01-01"
        ws1["C2"] = "S1-A"
        ws1["D2"] = "10"
        ws1["B3"] = "2025-01-02"
        ws1["C3"] = "S1-B"
        ws1["D3"] = "20"
        draw_rect_border(ws1, top=2, left=2, bottom=3, right=4)
        self._define_parent_ranges(wb, "Sheet1", top_row=2)

        # Sheet2: 2ä»¶
        set_cells(
            ws2,
            {
                "B2": "2025-02-01",
                "C2": "S2-A",
                "D2": "100",
                "B3": "2025-02-02",
                "C3": "S2-B",
                "D3": "200",
            },
        )
        draw_rect_border(ws2, top=2, left=2, bottom=3, right=4)
        self._define_parent_ranges(wb, "Sheet2", top_row=2)

        containers = {
            "json.orders": {"direction": "row", "increment": 1, "range": "$B$2:$D$3"}
        }
        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)

        assert generated["json.orders.1.date"] == "2025-01-01"
        assert generated["json.orders.2.date"] == "2025-01-02"
        assert generated["json.orders.3.date"] == "2025-02-01"
        assert generated["json.orders.4.date"] == "2025-02-02"

    def test_multisheet_includes_hidden_and_skips_unmatched(self):
        wb = Workbook()
        ws1 = wb.active
        ws1.title = "Visible1"
        ws_hidden = wb.create_sheet("Hidden2")
        ws_hidden.sheet_state = "hidden"
        ws_unmatched = wb.create_sheet("Unmatched")

        set_cells(ws1, {"B2": "2025-03-01", "C2": "V1", "D2": "1"})
        draw_rect_border(ws1, top=2, left=2, bottom=2, right=4)
        self._define_parent_ranges(wb, "Visible1", top_row=2)

        set_cells(ws_hidden, {"B2": "2025-03-02", "C2": "H2", "D2": "2"})
        draw_rect_border(ws_hidden, top=2, left=2, bottom=2, right=4)
        self._define_parent_ranges(wb, "Hidden2", top_row=2)

        # Unmatched ã‚·ãƒ¼ãƒˆã¯å®šç¾©åã‚’ä»˜ã‘ãªã„
        ws_unmatched["B2"] = "SHOULD-NOT-READ"

        containers = {
            "json.orders": {"direction": "row", "increment": 1, "range": "$B$2:$D$2"}
        }
        generated = xlsx2json.generate_cell_names_from_containers(containers, wb)

        assert generated["json.orders.1.date"] == "2025-03-01"
        assert generated["json.orders.2.date"] == "2025-03-02"
        assert "SHOULD-NOT-READ" not in " ".join(str(v) for v in generated.values())

    def test_multisheet_respects_global_max_elements(self):
        wb = Workbook()
        ws1 = wb.active
        ws1.title = "S1"
        ws2 = wb.create_sheet("S2")

        set_cells(
            ws1,
            {
                "B2": "2025-04-01",
                "C2": "A1",
                "D2": "10",
                "B3": "2025-04-02",
                "C3": "A2",
                "D3": "20",
            },
        )
        draw_rect_border(ws1, top=2, left=2, bottom=3, right=4)
        self._define_parent_ranges(wb, "S1", top_row=2)

        set_cells(
            ws2,
            {
                "B2": "2025-04-03",
                "C2": "B1",
                "D2": "30",
                "B3": "2025-04-04",
                "C3": "B2",
                "D3": "40",
            },
        )
        draw_rect_border(ws2, top=2, left=2, bottom=3, right=4)
        self._define_parent_ranges(wb, "S2", top_row=2)

        containers = {
            "json.orders": {"direction": "row", "increment": 1, "range": "$B$2:$D$3"}
        }
        generated = xlsx2json.generate_cell_names_from_containers(
            containers, wb, global_max_elements=3
        )

        assert generated["json.orders.1.date"] == "2025-04-01"
        assert generated["json.orders.2.date"] == "2025-04-02"
        assert generated["json.orders.3.date"] == "2025-04-03"
        assert "json.orders.4.date" not in generated


class TestCommandLineOptions:
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ

    å„ç¨®CLIã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‹•ä½œã‚’åŒ…æ‹¬çš„ã«æ¤œè¨¼:
    - --prefix / -p ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    - --log_level ã®å„ãƒ¬ãƒ™ãƒ«
    - --trim ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    - --container ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    - --config ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
    - çŸ­ç¸®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    - ã‚ªãƒ—ã‚·ãƒ§ãƒ³çµ„ã¿åˆã‚ã›
    """

    @pytest.fixture
    def temp_dir(self):
        """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆãƒ»å‰Šé™¤"""
        temp_path = Path(tempfile.mkdtemp())
        yield temp_path
        shutil.rmtree(temp_path)

    @pytest.fixture
    def sample_xlsx(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆç”¨Excelãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        xlsx_path = temp_dir / "test.xlsx"
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "Sheet1"
        ws["A1"] = "TestData"
        ws["B1"] = "  Trimable  "

        # åå‰ä»˜ãç¯„å›²å®šç¾©
        set_defined_names(wb, {"json_test": "A1", "json_trim_test": "B1"})

        wb.save(xlsx_path)
        wb.close()
        return xlsx_path

    def test_prefix_option_long_form(self, sample_xlsx, temp_dir):
        """--prefix ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--prefix",
                "custom",
                "--output-dir",
                str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data"),
            ):
                mock_parse.return_value = {"test": "data"}

                result = xlsx2json.main()
                assert result == 0

                # prefixãŒæ­£ã—ãæ¸¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_parse.assert_called_with(
                    sample_xlsx,
                    "custom",
                    array_split_rules=None,
                    array_transform_rules=None,
                    containers={},
                    schema=None,
                )

    def test_prefix_option_short_form(self, sample_xlsx, temp_dir):
        """--prefix ã®çŸ­ç¸®å½¢ -p ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "-p",
                "short_prefix",
                "-o",
                str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data"),
            ):
                mock_parse.return_value = {"test": "data"}

                result = xlsx2json.main()
                assert result == 0

                # çŸ­ç¸®å½¢ã§ã‚‚prefixãŒæ­£ã—ãæ¸¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_parse.assert_called_with(
                    sample_xlsx,
                    "short_prefix",
                    array_split_rules=None,
                    array_transform_rules=None,
                    containers={},
                    schema=None,
                )

    def test_log_level_debug(self, sample_xlsx, temp_dir):
        """--log_level DEBUG ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--log-level",
                "DEBUG",
                "--output-dir",
                str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data"),
                patch("logging.basicConfig") as mock_logging,
            ):
                mock_parse.return_value = {"test": "data"}

                result = xlsx2json.main()
                assert result == 0

                # DEBUGãƒ¬ãƒ™ãƒ«ãŒè¨­å®šã•ã‚Œã€æ—¢å®šã®æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨æ—¥æ™‚ä»˜ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæ¸¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_logging.assert_called_with(
                    level=logging.DEBUG,
                    format="%(asctime)s %(levelname)s: %(message)s",
                    datefmt="%Y/%m/%d %H:%M:%S",
                )

    def test_log_level_warning(self, sample_xlsx, temp_dir):
        """--log_level WARNING ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--log-level",
                "WARNING",
                "--output-dir",
                str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data"),
                patch("logging.basicConfig") as mock_logging,
            ):
                mock_parse.return_value = {"test": "data"}

                result = xlsx2json.main()
                assert result == 0

                # WARNINGãƒ¬ãƒ™ãƒ«ãŒè¨­å®šã•ã‚Œã€æ—¢å®šã®æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨æ—¥æ™‚ä»˜ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæ¸¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_logging.assert_called_with(
                    level=logging.WARNING,
                    format="%(asctime)s %(levelname)s: %(message)s",
                    datefmt="%Y/%m/%d %H:%M:%S",
                )

    def test_trim_option(self, sample_xlsx, temp_dir):
        """--trim ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--trim",
                "--output-dir",
                str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 4

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data"),
            ):
                mock_parse.return_value = {"test": "data"}

                result = xlsx2json.main()
                assert result == 0

                # trimã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¯ã‚‚ã†ä½¿ç”¨ã—ãªã„ï¼‰
                # parse_named_ranges_with_prefix ãŒæ­£å¸¸ã«å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_parse.assert_called_once()

    def test_container_option(self, sample_xlsx, temp_dir):
        """--container ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        container_def = '{"sales": {"direction": "row", "items": ["date", "amount"]}}'

        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--container",
                container_def,
                "--output-dir",
                str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data"),
                patch("xlsx2json.validate_cli_containers") as mock_validate,
                patch("xlsx2json.parse_container_args") as mock_parse_containers,
            ):
                mock_parse.return_value = {"test": "data"}
                mock_parse_containers.return_value = {
                    "sales": {
                        "direction": "row",
                        "items": ["date", "amount"],
                    }
                }

                result = xlsx2json.main()
                assert result == 0

                # ã‚³ãƒ³ãƒ†ãƒŠã®æ¤œè¨¼ã¨è§£æãŒå‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_validate.assert_called_once()
                mock_parse_containers.assert_called_once()

    def test_schema_option_short_form(self, sample_xlsx, temp_dir):
        """--schema ã®çŸ­ç¸®å½¢ -s ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        schema_file = temp_dir / "test_schema.json"
        schema_content = {"type": "object", "properties": {"test": {"type": "string"}}}

        with schema_file.open("w", encoding="utf-8") as f:
            json.dump(schema_content, f)

        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "-s",
                str(schema_file),
                "-o",
                str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data"),
            ):
                mock_parse.return_value = {"test": "data"}

                result = xlsx2json.main()
                assert result == 0

                # ã‚¹ã‚­ãƒ¼ãƒã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                # parse_named_ranges_with_prefix ãŒæ­£å¸¸ã«å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_parse.assert_called_once()

    def test_multiple_options_combination(self, sample_xlsx, temp_dir):
        """è¤‡æ•°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--prefix",
                "test_prefix",
                "--trim",
                "--log-level",
                "ERROR",
                "--output-dir",
                str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 8

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data") as mock_write,
                patch("logging.basicConfig") as mock_logging,
            ):
                mock_parse.return_value = {"test": "data"}

                result = xlsx2json.main()
                assert result == 0

                # å„ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæ­£ã—ãé©ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_parse.assert_called_with(
                    sample_xlsx,
                    "test_prefix",
                    array_split_rules=None,
                    array_transform_rules=None,
                    containers={},
                    schema=None,
                )
                # trimã¨log-levelã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã€æ—¢å®šã®æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨æ—¥æ™‚ä»˜ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæ¸¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_logging.assert_called_with(
                    level=logging.ERROR,
                    format="%(asctime)s %(levelname)s: %(message)s",
                    datefmt="%Y/%m/%d %H:%M:%S",
                )

                # è¤‡æ•°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                # è©³ç´°ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼ã¯ä»–ã®ãƒ†ã‚¹ãƒˆã§å®Ÿæ–½

    def test_config_file_option(self, sample_xlsx, temp_dir):
        """--config ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        config_file = temp_dir / "test_config.json"
        config_content = {
            "prefix": "config_prefix",
            "output_dir": str(temp_dir),
            "containers": {
                "test_container": {
                    "direction": "row",
                    "items": ["name", "value"],
                }
            },
        }

        with config_file.open("w", encoding="utf-8") as f:
            json.dump(config_content, f)

        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--config",
                str(config_file),
            ][index]
            mock_argv.__len__ = lambda _: 3

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data") as mock_write,
            ):
                mock_parse.return_value = {"test": "data"}

                result = xlsx2json.main()
                assert result == 0

                # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®å€¤ãŒä½¿ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                # prefixã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã‚‹
                mock_parse.assert_called_with(
                    sample_xlsx,
                    "config_prefix",
                    array_split_rules=None,
                    array_transform_rules=None,
                    containers=config_content["containers"],
                    schema=None,
                )

    def test_config_file_option_yaml_basic(self, sample_xlsx, temp_dir):
        """--config ã« YAML ã‚’æ¸¡ã—ãŸå ´åˆã«æ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã‚‹"""
        config_file = temp_dir / "test_config.yaml"
        yaml_content = (
            "prefix: yaml_prefix\n"
            f"output-dir: {temp_dir}\n"
            "containers:\n"
            "  test_container:\n"
            "    direction: row\n"
            "    items: [name, value]\n"
        )
        config_file.write_text(yaml_content, encoding="utf-8")

        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--config",
                str(config_file),
            ][index]
            mock_argv.__len__ = lambda _: 3

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data") as mock_write,
            ):
                mock_parse.return_value = {"test": "data"}

                result = xlsx2json.main()
                assert result == 0

                expected_containers = {
                    "test_container": {
                        "direction": "row",
                        "items": ["name", "value"],
                    }
                }
                mock_parse.assert_called_with(
                    sample_xlsx,
                    "yaml_prefix",
                    array_split_rules=None,
                    array_transform_rules=None,
                    containers=expected_containers,
                    schema=None,
                )

    def test_config_file_option_yaml_output_yaml_format(self, sample_xlsx, temp_dir):
        """YAMLè¨­å®šã§ output-format: yaml ã‚’æŒ‡å®šã—ãŸå ´åˆã« .yaml å‡ºåŠ›ã«ãªã‚‹"""
        config_file = temp_dir / "test_config.yaml"
        out_dir = temp_dir / "out"
        yaml_content = (
            "prefix: yaml_prefix\n" f"output-dir: {out_dir}\n" "output-format: yaml\n"
        )
        config_file.write_text(yaml_content, encoding="utf-8")

        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--config",
                str(config_file),
            ][index]
            mock_argv.__len__ = lambda _: 3

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch(
                    "xlsx2json.parse_named_ranges_with_prefix",
                    return_value={"ok": True},
                ),
                patch("xlsx2json.write_data") as mock_write,
            ):
                result = xlsx2json.main()
                assert result == 0

                # å‡ºåŠ›å…ˆãƒ‘ã‚¹ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¼•æ•°ã‚’æ¤œè¨¼
                call_args = mock_write.call_args[0]
                output_path = Path(call_args[1])
                output_format = call_args[2]
                assert output_format == "yaml"
                assert output_path.suffix == ".yaml"
                assert output_path.parent == out_dir

    def test_default_output_dir_is_input_dir_output_when_omitted(
        self, sample_xlsx, temp_dir
    ):
        """--output-dir æœªæŒ‡å®šæ™‚ã¯å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé…ä¸‹ã® output/ ã«å‡ºåŠ›ã•ã‚Œã‚‹ã€‚"""
        # ç¢ºå®Ÿã«ã‚¯ãƒªãƒ¼ãƒ³
        default_out = sample_xlsx.parent / "output"
        if default_out.exists():
            shutil.rmtree(default_out)

        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
            ][index]
            mock_argv.__len__ = lambda _: 2

            with (
                patch(
                    "xlsx2json.Xlsx2JsonConverter._collect_xlsx_files",
                    return_value=[sample_xlsx],
                ),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_data") as mock_write,
            ):
                mock_parse.return_value = {"ok": True}

                result = xlsx2json.main()
                assert result == 0

                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‡ºåŠ›å…ˆãŒ input_dir/output/<name>.json ã§ã‚ã‚‹ã“ã¨
                assert default_out.exists() and default_out.is_dir()
                out_path = mock_write.call_args[0][1]
                # out_path ã¯ Path ã‚‚ã—ãã¯æ–‡å­—åˆ—æƒ³å®š
                out_path = Path(out_path)
                assert out_path.parent == default_out
                assert out_path.name == sample_xlsx.stem + ".json"


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    pytest.main([__file__, "-v"])

# =============================================================================
# è¿½åŠ ã‚«ãƒãƒ¬ãƒƒã‚¸å¼·åŒ–ãƒ†ã‚¹ãƒˆ: reconstruct/command/split/leadingç©º
# =============================================================================

def test_reconstruct_skip_when_array_value_not_list():
    from xlsx2json import apply_post_parse_pipeline
    result = {"arr": {"a": 1}}  # listã§ãªã„ã®ã§ã‚¹ã‚­ãƒƒãƒ—
    out = apply_post_parse_pipeline(
        result=result,
        root_first_pos={"arr": (0,0,0)},
        prefix="data",
        user_provided_containers=False,
        containers=None,
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map={"data.arr.1.x": 99},
    )
    assert out["arr"] == {"a": 1}

# =============================================================================
# è¿½åŠ åˆ†å²ãƒ†ã‚¹ãƒˆ batch2
# =============================================================================

def test_reconstruct_leading_empty_trim_after_gen():
    # ç”Ÿæˆåã«ã‚ˆã‚Š base_list[0] ãŒç©º(ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã™ã¹ã¦None/"")ã«ãªã‚Šé™¤å»ã•ã‚Œã‚‹çµŒè·¯
    from xlsx2json import apply_post_parse_pipeline
    result = {"arr": [{"a": None}, {"b": 2}]}
    # idx=1 ã«ç©ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ (None/"") ã®ã¿ã€ idx=2 ã« 'c':3 ã‚’ç”Ÿæˆ â†’ æœ€çµ‚ã§å…ˆé ­ç©ºè¦ç´ é™¤å»
    gen_map = {"data.arr.1.x": None, "data.arr.1.y": "", "data.arr.2.c": 3}
    out = apply_post_parse_pipeline(
        result=result,
        root_first_pos={"arr": (0,0,0)},
        prefix="data",
        user_provided_containers=False,
        containers=None,
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=gen_map,
    )
    # å…ˆé ­ç©º( a:None ã®ã¿ ) ã¯é™¤å»ã•ã‚Œ b=2 ã®è¦ç´ ãŒå…ˆé ­, ç”Ÿæˆ c ã¯2ç•ªç›®
    assert out["arr"][0]["b"] == 2 and out["arr"][1]["c"] == 3


def test_reconstruct_skip_empty_value_generation():
    from xlsx2json import apply_post_parse_pipeline
    # fv in (None,"") ã‚¹ã‚­ãƒƒãƒ—ã§æ—¢å­˜ 'k' ä¸åœ¨ â†’ æŒ¿å…¥ã•ã‚Œãªã„
    result = {"arr": [{}]}
    gen_map = {"data.arr.1.k": ""}  # ç©ºæ–‡å­—ã¯ã‚¹ã‚­ãƒƒãƒ—
    out = apply_post_parse_pipeline(
        result=result,
        root_first_pos={"arr": (0,0,0)},
        prefix="data",
        user_provided_containers=False,
        containers=None,
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=gen_map,
    )
    # æ—©æœŸãƒ•ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ä»•æ§˜: ç©ºè¾æ›¸ã®ã¿ã®é…åˆ—ã¯å‰Šé™¤ â†’ arr ã‚­ãƒ¼æ¶ˆæ»…
    assert "arr" not in out


def test_replicate_excludes_lv_label():
    from xlsx2json import apply_post_parse_pipeline
    # prefix=data ä¸‹ã« lv2 ã¨é€šå¸¸ã‚­ãƒ¼ val ãŒã‚ã‚‹ã€‚ lv2 ã¯ lv\d+ ãªã®ã§è¤‡è£½å¯¾è±¡å¤–ã€‚
    result = {"data": {"lv2": 1, "val": 2}}
    out = apply_post_parse_pipeline(
        result=result,
        root_first_pos={"data": (0,0,0), "lv2": (0,1,0), "val": (0,2,0)},
        prefix="data",
        user_provided_containers=True,
        containers={},
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels={"lv2"},
        group_to_root={},
        gen_map=None,
    )
    keys = set(out.keys())
    assert "val" in keys and "lv2" not in keys  # lv2 ã¯è¤‡è£½ã•ã‚Œãªã„


def test_command_json_success_roundtrip():
    from xlsx2json import ArrayTransformRule, apply_post_parse_pipeline
    # ãƒã‚¹ãƒˆ list ã‚’ JSON æ–‡å­—åˆ—ã§æ¸¡ã— python -c ãŒ JSON åŠ å·¥ã— JSON å‡ºåŠ›
    script = "import sys,json;data=json.loads(sys.stdin.read());print(json.dumps({'ok':len(data)}))"
    cmd_spec = f"python -c \"{script}\""
    rule = ArrayTransformRule(path="tbl.colA", transform_type="command", transform_spec=cmd_spec)
    result = {"data": {"tbl": {"colA": [[1,2],[3]], "colB": [10,20]}}}
    out = apply_post_parse_pipeline(
        result=result,
        root_first_pos={"data": (0,0,0)},
        prefix="data",
        user_provided_containers=True,
        containers={"data.tbl": {}},
        array_transform_rules={"tbl.colA": [rule]},
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=None,
    )
    # colA ã¯ JSON decode çµæœã® dict ã«ç½®æ›ã•ã‚Œ reshape ã§ colB ã¨åŒé•· max=2 ã®è¡Œã«è¤‡è£½ã•ã‚Œãªã„ï¼ˆlist-of-dicts per indexã§ colA é list -> ãã®ã¾ã¾?ï¼‰
    # å®Ÿè£…ä¸Š: commandçµæœãŒ dict ã®å ´åˆ ãã® dict ã‚’å€¤ã¨ã—ã¦ä¿æŒã—ã€reshape ã§ colA ã¯ listæ¤œå‡ºã•ã‚Œãšåˆ—é™¤å¤–â†’ dictåˆ—ä¸å‡è¡¡é˜²æ­¢ ã“ã“ã§ã¯ colA dict é list -> reshapeå¾Œ å„è¡Œã« colA ã¯å­˜åœ¨ã—ãªã„æƒ³å®šã€‚
    # ã—ãŸãŒã£ã¦ tbl ã¯ list[ {colB:10}, {colB:20} ] ã¨ãªã‚‹ã€‚
    rows = out["data"]["tbl"]
    assert rows[0]["colB"] == 10 and "colA" not in rows[0]


def test_transform_rules_wildcard_parent_priority():
    from xlsx2json import parse_array_transform_rules, ArrayTransformRule
    # ãƒ«ãƒ¼ãƒ«å„ªå…ˆé †: å®Œå…¨ä¸€è‡´ > è¦ªã‚­ãƒ¼ > ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰
    raw = [
        "data.arr.*.name=split:,",           # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰
        "data.arr.1=command:cat",            # è¦ªã‚­ãƒ¼ï¼ˆarr.1ï¼‰
        "data.arr.1.name=function:builtins:len",  # å®Œå…¨ä¸€è‡´
    ]
    rules = parse_array_transform_rules(raw, prefix="data")
    # æ­£å¸¸ã«3ã‚­ãƒ¼ãŒæ ¼ç´ã•ã‚Œã€å¾Œå‹ã¡çµ±åˆï¼ˆwildcard ã¯æœ€å¾Œ update ã•ã‚Œã‚‹ä»•æ§˜ï¼‰
    assert "arr.*.name" in rules and "arr.1" in rules and "arr.1.name" in rules
    # å„ãƒªã‚¹ãƒˆå‹ï¼ˆArrayTransformRuleã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰
    from xlsx2json import ArrayTransformRule as ATR
    assert all(isinstance(r, ATR) for v in rules.values() for r in v)


def test_reconstruct_skip_when_list_contains_non_dict():
    from xlsx2json import apply_post_parse_pipeline
    # 2ç•ªç›®è¦ç´ ãŒédict -> any((it is not None) and not dict) True â†’ ã‚¹ã‚­ãƒƒãƒ—
    result = {"arr": [{"a": 1}, 5]}
    gen_map = {"data.arr.2.b": 10}
    out = apply_post_parse_pipeline(
        result=result,
        root_first_pos={"arr": (0,0,0)},
        prefix="data",
        user_provided_containers=False,
        containers=None,
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=gen_map,
    )
    assert out["arr"][0]["a"] == 1 and len(out["arr"]) == 2 and out["arr"][1] == 5


def test_reconstruct_field_overwrite_block_for_existing_non_empty_container():
    from xlsx2json import apply_post_parse_pipeline
    # æ—¢å­˜ elem[0]['k'] ãŒ list ã‹ã¤ç©ºã§ãªã„ â†’ åŒåç”Ÿæˆå€¤ã§ä¸Šæ›¸ãã•ã‚Œãªã„
    result = {"arr": [{"k": [1,2]}, {}]}
    gen_map = {"data.arr.1.k": 999, "data.arr.2.k": 5}
    out = apply_post_parse_pipeline(
        result=result,
        root_first_pos={"arr": (0,0,0)},
        prefix="data",
        user_provided_containers=False,
        containers=None,
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=gen_map,
    )
    # k ã¯ä¸Šæ›¸ãã•ã‚Œãªã„ï¼ˆ1,2 ã®ã¾ã¾ï¼‰ã€ç¬¬2è¦ç´ ã«ã¯ k=5 ãŒæŒ¿å…¥
    assert out["arr"][0]["k"] == [1,2]
    assert out["arr"][1]["k"] == 5


def test_command_timeout(monkeypatch):
    from xlsx2json import ArrayTransformRule, apply_post_parse_pipeline
    # sleep 2 ã‚’ timeout 1 ã«ã—ãŸã„ â†’ monkeypatch ã§ã¯ _transform_with_command å†… timeout=30 å›ºå®šã®ãŸã‚
    # ç–‘ä¼¼çš„ã« TimeoutExpired ã‚’ç™ºç”Ÿã•ã›ã‚‹ãŸã‚ subprocess.run ã‚’å·®ã—æ›¿ãˆã‚‹
    import subprocess, types
    def fake_run(*a, **kw):
        raise subprocess.TimeoutExpired(cmd="sleep", timeout=0.01)
    monkeypatch.setattr("subprocess.run", fake_run)
    rule = ArrayTransformRule(path="tbl.colA", transform_type="command", transform_spec="sleep 1")
    result = {"data": {"tbl": {"colA": ["1", "2"]}}}
    out = apply_post_parse_pipeline(
        result=result,
        root_first_pos={"data": (0,0,0)},
        prefix="data",
        user_provided_containers=True,
        containers={"data.tbl": {}},
        array_transform_rules={"tbl.colA": [rule]},
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=None,
    )
    # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§å¤‰æ›å¤±æ•— â†’ å…ƒã®æ–‡å­—åˆ—è¦ç´ ãŒãã®ã¾ã¾ reshape å¾Œã‚‚ä¿æŒ
    assert out["data"]["tbl"][0]["colA"] == "1"


def test_command_nonzero_and_multiline_list():
    from xlsx2json import ArrayTransformRule, apply_post_parse_pipeline
    # 1: returncode !=0 ã®ã‚±ãƒ¼ã‚¹ï¼ˆpython -c exit 5ï¼‰
    bad = ArrayTransformRule(path="tbl.colA", transform_type="command", transform_spec="python -c 'import sys;sys.exit(5)'")
    # 2: ãƒ•ãƒ©ãƒƒãƒˆé…åˆ—å…¥åŠ› -> æ”¹è¡Œ -> ã‚³ãƒãƒ³ãƒ‰ã¯ cat ã§ãã®ã¾ã¾è¤‡æ•°è¡Œå‡ºåŠ› => liståŒ–
    cat = ArrayTransformRule(path="tbl.colB", transform_type="command", transform_spec="cat")
    result = {"data": {"tbl": {"colA": ["7", "8"], "colB": ["a", "b", "c"]}}}
    out = apply_post_parse_pipeline(
        result=result,
        root_first_pos={"data": (0,0,0)},
        prefix="data",
        user_provided_containers=True,
        containers={"data.tbl": {}},
        array_transform_rules={"tbl.colA": [bad], "tbl.colB": [cat]},
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=None,
    )
    rows = out["data"]["tbl"]
    # reshapeå¾Œ: dict of lists â†’ list of dicts ãªã®ã§ colB ã®å„è¦ç´ ã¯è¡Œã”ã¨ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹
    # colA: 2è¦ç´  â†’ 3è¡Œç›®ã¯ colA æ¬„æ¬ è½, colB: 3è¦ç´  â†’ 3è¡Œ
    assert rows[0]["colA"] == "7" and rows[1]["colA"] == "8"
    assert rows[0]["colB"] == "a" and rows[1]["colB"] == "b" and rows[2]["colB"] == "c"


def test_split_escaped_pipe_restores_delimiter():
    from xlsx2json import ArrayTransformRule
    # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãŒ '|' ã«å¾©å…ƒã•ã‚Œã‚‹ã“ã¨ã‚’é‡ç‚¹ç¢ºèªï¼ˆè¤‡é›‘å¤šæ®µã¯åˆ¥ãƒ†ã‚¹ãƒˆã§æ—¢å­˜ï¼‰
    rule = ArrayTransformRule(path="root.val", transform_type="split", transform_spec=",|\\|")
    # delimiters: [",", "|"] ã¸å¾©å…ƒ
    value = "A,B|C"
    out = rule.transform(value)
    # å°‘ãªãã¨ã‚‚ A,B,C ãŒéšå±¤ã©ã“ã‹ã«å«ã¾ã‚Œã‚‹
    flat = []
    def _f(x):
        if isinstance(x, list):
            for e in x: _f(e)
        else: flat.append(x)
    _f(out)
    assert set(["A","B","C"]).issubset(set(flat))


def test_remove_leading_empty_elements_multiple():
    from xlsx2json import apply_post_parse_pipeline
    # ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ« list å…ˆé ­ã®ç©ºdict ãŒ2ã¤é™¤å»ã•ã‚Œã‚‹ã‚±ãƒ¼ã‚¹
    result = {"arr": [{}, {}, {"x": 1}]}
    out = apply_post_parse_pipeline(
        result=result,
        root_first_pos={"arr": (0,0,0)},
        prefix="data",
        user_provided_containers=False,
        containers=None,
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=None,
    )
    assert out["arr"][0]["x"] == 1 and len(out["arr"]) == 1


def test_wildcard_transform_applied_in_listed_order(tmp_path: Path):
    """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰å¤‰æ›ãŒè¨˜è¼‰é †ã«é€æ¬¡é©ç”¨ã•ã‚Œã‚‹ã“ã¨ã®å¥å…¨æ€§ãƒ†ã‚¹ãƒˆã€‚"""
    wb = Workbook()
    ws = wb.active
    ws.title = "S1"
    set_cells(ws, {"A1": "v1", "A2": "v2"})
    set_defined_names(
        wb,
        {
            "json.root.alpha.item": "A1",
            "json.root.beta.item": "A2",
        },
        default_sheet=ws.title,
    )
    xlsx_path = tmp_path / "order.xlsx"
    wb.save(xlsx_path)

    tf_module = tmp_path / "order_transform.py"
    tf_module.write_text(
        (
            "def add_item2(node):\n"
            "    assert isinstance(node, dict)\n"
            "    d = dict(node)\n"
            "    d['item2'] = str(node['item']) + '_x'\n"
            "    return d\n"
            "def upper_item2(node):\n"
            "    assert isinstance(node, dict)\n"
            "    if 'item2' in node:\n"
            "        d = dict(node)\n"
            "        d['item2'] = str(node['item2']).upper()\n"
            "        return d\n"
            "    return node\n"
        )
    )
    transforms = [
        f"json.root.*=function:{tf_module}:add_item2",
        f"json.root.*=function:{tf_module}:upper_item2",
    ]
    result = xlsx2json.parse_named_ranges_with_prefix(
        xlsx_path,
        prefix="json",
        array_transform_rules=xlsx2json.parse_array_transform_rules(
            transforms, prefix="json", trim_enabled=False
        ),
    )
    root = result.get("root")
    assert isinstance(root, dict)
    assert root["alpha"]["item2"] == "V1_X"
    assert root["beta"]["item2"] == "V2_X"


def test_wildcard_mid_layer_adds_derived_field(tmp_path: Path):
    """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ä¸­é–“éšå±¤ (json.root.*.child) ã«å¯¾ã™ã‚‹å¤‰æ›ã§ã€
    å­è¦ç´  (itemA, itemB) ã‹ã‚‰æ´¾ç”Ÿã—ãŸæ–°è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ derived ã‚’è¿½åŠ ã—å‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã€‚

    - å„ child ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯ itemA, itemB ãŒå­˜åœ¨
    - å¤‰æ›é–¢æ•°ã¯ node['derived'] = f"{itemA}-{itemB}" ã‚’è¿½åŠ 
    - ãã®å¾Œ itemA / itemB ã‚’å¤§æ–‡å­—åŒ– (é †åºä¾å­˜) ã‚’åˆ¥ãƒ«ãƒ¼ãƒ«ã§é©ç”¨ã—ã€derived ã¯å…ƒã®å€¤ (å…ƒã®å¤§å°) ã‚’ä¿æŒ
      â†’ è¨˜è¼‰é †é©ç”¨ã‚’åˆ©ç”¨ã— derived ç”Ÿæˆæ™‚ã®ã‚ªãƒªã‚¸ãƒŠãƒ«å€¤ãŒä½¿ã‚ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    """
    wb = Workbook()
    ws = wb.active
    ws.title = "S1"
    # alpha child
    ws["A1"] = "a1"
    ws["B1"] = "b1"
    # beta child
    ws["A2"] = "a2"
    ws["B2"] = "b2"
    set_defined_names(
        wb,
        {
            "json.root.alpha.child.itemA": "A1",
            "json.root.alpha.child.itemB": "B1",
            "json.root.beta.child.itemA": "A2",
            "json.root.beta.child.itemB": "B2",
        },
        default_sheet=ws.title,
    )
    xlsx_path = tmp_path / "midlayer.xlsx"
    wb.save(xlsx_path)

    tf_module = tmp_path / "mid_layer_tf.py"
    tf_module.write_text(
        (
            "def add_derived(node):\n"
            "    # ä¸­é–“éšå±¤ child ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã« derived è¿½åŠ \n"
            "    assert isinstance(node, dict)\n"
            "    if 'itemA' in node and 'itemB' in node:\n"
            "        d = dict(node)\n"
            "        # f-string ã‚’é¿ã‘æ–‡å­—åˆ—çµåˆã§è¡¨ç¾ (ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ã‚¯ã‚©ãƒ¼ãƒˆè¡çªå›é¿)\n"
            "        d['derived'] = str(node['itemA']) + '-' + str(node['itemB'])\n"
            "        return d\n"
            "    return node\n"
            "def upper_items(node):\n"
            "    assert isinstance(node, dict)\n"
            "    d = dict(node)\n"
            "    if 'itemA' in d: d['itemA'] = str(d['itemA']).upper()\n"
            "    if 'itemB' in d: d['itemB'] = str(d['itemB']).upper()\n"
            "    return d\n"
        )
    )

    transforms = [
        f"json.root.*.child=function:{tf_module}:add_derived",
        f"json.root.*.child=function:{tf_module}:upper_items",
    ]
    result = xlsx2json.parse_named_ranges_with_prefix(
        xlsx_path,
        prefix="json",
        array_transform_rules=xlsx2json.parse_array_transform_rules(
            transforms, prefix="json", trim_enabled=False
        ),
    )
    root = result.get("root")
    assert isinstance(root, dict)
    for key, expect_a, expect_b in [("alpha", "A1", "B1"), ("beta", "A2", "B2")]:
        child = root[key]["child"]
        # æ´¾ç”Ÿãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å…ƒã®å°æ–‡å­—å€¤ã‚’çµåˆã—ãŸå½¢ (é †åºé©ç”¨ã§å¤§æ–‡å­—åŒ–å‰ã®å€¤)
        assert child["derived"] == expect_a.lower() + "-" + expect_b.lower()
        # itemA/B ã¯2ç•ªç›®ã®ãƒ«ãƒ¼ãƒ«ã§å¤§æ–‡å­—åŒ–
        assert child["itemA"] == expect_a
        assert child["itemB"] == expect_b


def test_non_wildcard_transform_applied(tmp_path: Path):
    """RED: ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãªã—ãƒ‘ã‚¿ãƒ¼ãƒ³ (json.customer) ã® function å¤‰æ›ã‚‚é©ç”¨ã•ã‚Œã‚‹ã¹ãã€‚ç¾çŠ¶æœªå¯¾å¿œãªã‚‰å¤±æ•—ã€‚"""
    # ç°¡æ˜“ Excel (customer.name ã¨ address ã®ã¿)
    wb = Workbook(); ws = wb.active; ws.title = "S1"
    ws["A1"] = "å±±ç”° å¤ªéƒ"
    ws["B1"] = "ã¨ã†ãã‚‡ã†"  # address
    # æ—¢å­˜ãƒ†ã‚¹ãƒˆç¾¤ã® set_defined_names ã‚’å†åˆ©ç”¨
    set_defined_names(wb, {
        "json.customer.name": "A1",
        "json.customer.address": "B1",
    }, default_sheet=ws.title)
    xlsx_path = tmp_path / "customer.xlsx"
    wb.save(xlsx_path)

    # å‹•çš„ transform ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (split & drop name)
    tf_py = tmp_path / "cust_tf.py"
    tf_py.write_text(
        (
            "def split_customer_name(node):\n"
            "    if not isinstance(node, dict): return node\n"
            "    n = node.get('name')\n"
            "    if isinstance(n, str) and ' ' in n:\n"
            "        parts = [p for p in n.split(' ') if p]\n"
            "        if len(parts) >= 2:\n"
            "            d = dict(node); d['last_name']=parts[0]; d['first_name']=parts[1]; d.pop('name', None); return d\n"
            "    return node\n"
        )
    )
    transforms = [f"json.customer=function:{tf_py}:split_customer_name"]
    result = xlsx2json.parse_named_ranges_with_prefix(
        xlsx_path,
        prefix="json",
        array_transform_rules=xlsx2json.parse_array_transform_rules(
            transforms, prefix="json", trim_enabled=False
        ),
    )
    cust = result.get("customer")
    assert isinstance(cust, dict)
    # æœŸå¾…: name ã¯å‰Šé™¤ã•ã‚Œ last_name / first_name ãŒç”Ÿæˆã•ã‚Œã‚‹
    assert "name" not in cust, "éãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰å¤‰æ›ãŒé©ç”¨ã•ã‚Œãš name ãŒæ®‹ã£ã¦ã„ã‚‹"
    assert cust.get("last_name") == "å±±ç”°"
    assert cust.get("first_name") == "å¤ªéƒ"


    # ä»¥é™ã®ãƒ†ã‚¹ãƒˆç¾¤ãŒèª¤ã£ã¦ã“ã®é–¢æ•°ã‚¹ã‚³ãƒ¼ãƒ—ã«å…¥ã£ã¦ã„ãŸãŸã‚ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã¸å¾©å…ƒ


@pytest.fixture
def temp_dir():
    """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆãƒ»å‰Šé™¤"""
    temp_path = Path(tempfile.mkdtemp())
    yield temp_path
    shutil.rmtree(temp_path)


def test_load_schema_with_none_path():
    result = xlsx2json.SchemaLoader.load_schema(None)
    assert result is None


def test_validate_and_log_no_errors(temp_dir):
    data = {"user": {"name": "test", "email": "test@example.com"}}
    schema = {
        "type": "object",
        "properties": {
            "user": {
                "type": "object",
                "properties": {
                    "name": {"type": "string"},
                    "email": {"type": "string"},
                },
            }
        },
    }
    validator = Draft7Validator(schema)
    log_dir = temp_dir / "logs"
    xlsx2json.SchemaLoader.validate_and_log(data, validator, log_dir, "test_file")
    error_log = log_dir / "test_file.error.log"
    assert not error_log.exists()


def test_reorder_json_with_schema():
    data = {"z_field": "last", "a_field": "first", "m_field": "middle"}
    schema = {
        "type": "object",
        "properties": {
            "a_field": {"type": "string"},
            "m_field": {"type": "string"},
            "z_field": {"type": "string"},
        },
    }
    result = xlsx2json.reorder_json(data, schema)
    keys = list(result.keys())
    assert keys == ["a_field", "m_field", "z_field"]


def test_reorder_json_with_list_items():
    data = [{"z": 3, "a": 1, "m": 2}, {"z": 6, "a": 4, "m": 5}]
    schema = {
        "type": "array",
        "items": {
            "type": "object",
            "properties": {
                "a": {"type": "integer"},
                "m": {"type": "integer"},
                "z": {"type": "integer"},
            },
        },
    }
    result = xlsx2json.reorder_json(data, schema)
    for item in result:
        keys = list(item.keys())
        assert keys == ["a", "m", "z"]


def test_reorder_json_non_dict_or_list():
    data = "simple_string"
    schema = {"type": "string"}
    result = xlsx2json.reorder_json(data, schema)
    assert result == "simple_string"


def test_is_completely_empty_string():
    assert xlsx2json.is_completely_empty("   ") is True
    assert xlsx2json.is_completely_empty("") is True
    assert xlsx2json.is_completely_empty("not empty") is False


def test_write_data_with_none_data(temp_dir):
    output_path = temp_dir / "test.json"
    data = {"empty1": None, "empty2": "", "empty3": []}
    with patch("xlsx2json.clean_empty_values", return_value=None):
        xlsx2json.write_data(data, output_path)
    assert output_path.exists()
    with output_path.open("r", encoding="utf-8") as f:
        content = json.load(f)
        # æ–°ä»•æ§˜: write_data æœ«å°¾ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å»ƒæ­¢ã«ã‚ˆã‚Š suppress_empty=True ã§ã‚‚
        # ç©ºå€¤ (None/""/[]) ã¯ãã®ã¾ã¾ä¿æŒã•ã‚Œã‚‹ã€‚
        assert content == {"empty1": None, "empty2": "", "empty3": []}


def test_write_data_with_schema_validation(temp_dir):
    output_path = temp_dir / "test.json"
    data = {"name": "test", "age": 25}
    schema = {
        "type": "object",
        "properties": {"name": {"type": "string"}, "age": {"type": "integer"}},
    }
    validator = Draft7Validator(schema)
    xlsx2json.write_data(data, output_path, schema=schema, validator=validator)
    assert output_path.exists()
    with output_path.open("r", encoding="utf-8") as f:
        result = json.load(f)
        assert list(result.keys()) == ["name", "age"]


def test_main_no_input_files():
    with patch("sys.argv", ["xlsx2json.py"]):
        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.main()
            # å¼•æ•°ä¸è¶³ã¯ã‚¨ãƒ©ãƒ¼çµ‚äº†ã‚³ãƒ¼ãƒ‰ (1) ã‚’è¿”ã™å®Ÿè£…ã«å¤‰æ›´ã•ã‚ŒãŸ
            assert result == 1
            mock_logger.error.assert_called()


def test_main_no_xlsx_files_found():
    with patch("sys.argv", ["xlsx2json.py", "/empty/directory"]):
        # ä»¥å‰ã¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç›´ä¸‹ã® collect_xlsx_files ã‚’ãƒ‘ãƒƒãƒã—ã¦ã„ãŸãŒ
        # å®Ÿè£…ãŒ Xlsx2JsonConverter._collect_xlsx_files ã«ç§»è¡Œã—ãŸãŸã‚ã“ã¡ã‚‰ã‚’ãƒ‘ãƒƒãƒ
        with patch("xlsx2json.Xlsx2JsonConverter._collect_xlsx_files", return_value=[]):
            with patch("xlsx2json.logger") as mock_logger:
                result = xlsx2json.main()
                # ç¾è¡Œå®Ÿè£…: ãƒ•ã‚¡ã‚¤ãƒ«åé›†çµæœãŒç©ºã§ã‚‚ã‚¨ãƒ©ãƒ¼æ‰±ã„ã«ã›ãšæ­£å¸¸çµ‚äº† (0)
                assert result == 0
                # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã¯å‡ºåŠ›ã•ã‚Œãªã„ä»•æ§˜
                mock_logger.error.assert_not_called()


def test_main_with_config_file_error(temp_dir):
    config_file = temp_dir / "invalid_config.json"
    with config_file.open("w") as f:
        f.write("invalid json content")
    test_xlsx = temp_dir / "test.xlsx"
    wb = Workbook()
    wb.save(test_xlsx)
    with patch(
        "sys.argv", ["xlsx2json.py", "--config", str(config_file), str(test_xlsx)]
    ):
        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.main()
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã¯ 1 ã‚’è¿”ã™
            assert result == 1
            mock_logger.error.assert_called()

def test_main_parse_exception(temp_dir):
    """parse_named_ranges_with_prefix ã§ã®ä¾‹å¤–å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
    test_xlsx = temp_dir / "test.xlsx"
    wb = Workbook(); wb.save(test_xlsx)
    with patch("sys.argv", ["xlsx2json.py", str(test_xlsx)]):
        with patch(
            "xlsx2json.parse_named_ranges_with_prefix",
            side_effect=Exception("Test exception"),
        ):
            with patch("xlsx2json.logger") as mock_logger:
                result = xlsx2json.main()
                # ç¾è¡Œå®Ÿè£…: å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¾‹å¤–ã¯é›†è¨ˆã—ã¦ç¶™ç¶š -> æœ€çµ‚æˆ»ã‚Šå€¤ 0
                assert result == 0
                mock_logger.exception.assert_called()

def test_main_data_is_none(temp_dir):
    """ãƒ‡ãƒ¼ã‚¿ãŒNoneã®å ´åˆã®å‡¦ç†ãƒ†ã‚¹ãƒˆ (å‡ºåŠ›ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹æƒ³å®š)"""
    test_xlsx = temp_dir / "test.xlsx"
    wb = Workbook(); wb.save(test_xlsx)
    with patch("sys.argv", ["xlsx2json.py", str(test_xlsx)]):
        # parse_named_ranges_with_prefix ãŒ None ã‚’è¿”ã™ã‚±ãƒ¼ã‚¹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        with patch("xlsx2json.parse_named_ranges_with_prefix", return_value=None):
            with patch("xlsx2json.logger") as mock_logger:
                result = xlsx2json.main()
                # å¤‰æ›ã¯æˆåŠŸæ‰±ã„ã§ 0 ã‚’è¿”ã™è¨­è¨ˆãªã‚‰ 0, ã‚¨ãƒ©ãƒ¼æ‰±ã„ãªã‚‰ 1 (ã“ã“ã§ã¯ 0 ã‚’æœŸå¾…ã—å¾Œã§å¿…è¦ãªã‚‰èª¿æ•´)
                # ç¾è¡Œå®Ÿè£…ã§ã¯ converter.process_files ãŒå¸¸ã« 0 ã‚’è¿”ã™ãŸã‚ 0
                assert result == 0
                # ç‰¹åˆ¥ãªã‚¨ãƒ©ãƒ¼ã¯ç™ºç”Ÿã—ãªã„æƒ³å®š

    def test_main_parse_exception(self, temp_dir):
        """parse_named_ranges_with_prefix ã§ã®ä¾‹å¤–å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # æœ‰åŠ¹ãªExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch("sys.argv", ["xlsx2json.py", str(test_xlsx)]):
            with patch(
                "xlsx2json.parse_named_ranges_with_prefix",
                side_effect=Exception("Test exception"),
            ):
                with patch("xlsx2json.logger") as mock_logger:
                    xlsx2json.main()
                    # ä¾‹å¤–ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                    mock_logger.exception.assert_called()

    def test_main_data_is_none(self, temp_dir):
        """ãƒ‡ãƒ¼ã‚¿ãŒNoneã®å ´åˆã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch("sys.argv", ["xlsx2json.py", str(test_xlsx)]):
            with patch("xlsx2json.parse_named_ranges_with_prefix", return_value=None):
                with patch("xlsx2json.logger") as mock_logger:
                    xlsx2json.main()
                    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                    mock_logger.error.assert_called()

    def test_main_empty_data_warning(self, temp_dir):
        """ç©ºãƒ‡ãƒ¼ã‚¿ã®è­¦å‘Šãƒ†ã‚¹ãƒˆ"""
        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch("sys.argv", ["xlsx2json.py", str(test_xlsx)]):
            with patch("xlsx2json.parse_named_ranges_with_prefix", return_value={}):
                with patch("xlsx2json.logger") as mock_logger:
                    xlsx2json.main()
                    # è­¦å‘Šãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                    mock_logger.warning.assert_called()

    def test_main_config_from_file(self, temp_dir):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®å¼•æ•°èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        # ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        schema_file = temp_dir / "schema.json"
        schema_data = {"type": "object", "properties": {"test": {"type": "string"}}}
        with schema_file.open("w", encoding="utf-8") as f:
            json.dump(schema_data, f)

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        config_file = temp_dir / "config.json"
        config_data = {
            "inputs": "test_input.xlsx",
            "output_dir": str(temp_dir / "output"),
            "schema": str(schema_file),
            "transform": ["json.test=split:,"],
        }
        with config_file.open("w", encoding="utf-8") as f:
            json.dump(config_data, f)

        # ãƒ†ã‚¹ãƒˆç”¨Excelãƒ•ã‚¡ã‚¤ãƒ«
        test_xlsx = temp_dir / "test_input.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch("sys.argv", ["xlsx2json.py", "--config", str(config_file)]):
            with patch("xlsx2json.collect_xlsx_files", return_value=[test_xlsx]):
                with patch(
                    "xlsx2json.parse_named_ranges_with_prefix",
                    return_value={"test": "data"},
                ):
                    with patch("xlsx2json.write_data") as mock_write:
                        xlsx2json.main()
                        # write_dataãŒå‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                        mock_write.assert_called()

    def test_main_string_output_dir_conversion(self, temp_dir):
        """output_dirãŒæ–‡å­—åˆ—ã®å ´åˆã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch(
            "sys.argv", ["xlsx2json.py", str(test_xlsx), "--output-dir", str(temp_dir)]
        ):
            with patch(
                "xlsx2json.parse_named_ranges_with_prefix",
                return_value={"test": "data"},
            ):
                with patch("xlsx2json.write_data") as mock_write:
                    xlsx2json.main()
                    # write_dataãŒå‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                    mock_write.assert_called()

    def test_parse_array_transform_rules_conflict_function_over_split(self):
        """functionå‹ãŒsplitå‹ã‚’ä¸Šæ›¸ãã™ã‚‹ãƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=split:,", "json.test=function:builtins:str"]

        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.parse_array_transform_rules(rules, "json")

            # functionå‹ãŒå„ªå…ˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert "test" in result  # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒé™¤å»ã•ã‚Œã‚‹
            assert result["test"].transform_type == "function"

            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            mock_logger.debug.assert_called()

    def test_parse_array_transform_rules_no_overwrite_function_by_split(self):
        """splitå‹ãŒfunctionå‹ã‚’ä¸Šæ›¸ãã—ãªã„ãƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=function:builtins:str", "json.test=split:,"]

        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.parse_array_transform_rules(rules, "json")

            # functionå‹ãŒä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert "test" in result  # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒé™¤å»ã•ã‚Œã‚‹
            assert result["test"].transform_type == "function"

            # ã‚¹ã‚­ãƒƒãƒ—ã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            mock_logger.debug.assert_called()

    def test_parse_array_transform_rules_same_type_conflict(self):
        """åŒã˜å‹ã®ãƒ«ãƒ¼ãƒ«é‡è¤‡ãƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=split:,", "json.test=split:;"]

        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.parse_array_transform_rules(rules, "json")

            # æœ€åˆã®ãƒ«ãƒ¼ãƒ«ãŒä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert "test" in result  # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒé™¤å»ã•ã‚Œã‚‹
            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            mock_logger.debug.assert_called()

    def test_parse_array_transform_rules_other_type_conflict(self):
        """ãã®ä»–ã®å‹ã®çµ„ã¿åˆã‚ã›ã§ã®ä¸Šæ›¸ããƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=command:echo", "json.test=split:,"]

        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.parse_array_transform_rules(rules, "json")

            # å¾Œã‹ã‚‰æ¥ãŸãƒ«ãƒ¼ãƒ«ã§ä¸Šæ›¸ãã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert "test" in result  # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒé™¤å»ã•ã‚Œã‚‹
            assert result["test"].transform_type == "split"

            # ä¸Šæ›¸ãã®ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            mock_logger.info.assert_called()

    def test_parse_array_transform_rules_with_schema_resolution_conflict(self):
        """ã‚¹ã‚­ãƒ¼ãƒè§£æ±ºå¾Œã®ãƒ«ãƒ¼ãƒ«ç«¶åˆãƒ†ã‚¹ãƒˆ"""
        schema = {
            "type": "object",
            "properties": {
                "user_name": {"type": "string"},
                "user_group": {"type": "string"},
            },
        }

        rules = ["json.user/*=command:echo", "json.user/*=split:,"]

        with patch("xlsx2json.logger") as mock_logger:
            xlsx2json.parse_array_transform_rules(rules, "json", schema)

            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆãƒ«ãƒ¼ãƒ«ç«¶åˆå‡¦ç†ï¼‰
            mock_logger.debug.assert_called()

    def test_transform_rule_unknown_type_warning(self):
        """ä¸æ˜ãªå¤‰æ›ã‚¿ã‚¤ãƒ—ã®è­¦å‘Šãƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=unknown_type:some_spec"]

        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.parse_array_transform_rules(rules, "json")

            # ä¸æ˜ãªã‚¿ã‚¤ãƒ—ã®è­¦å‘ŠãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            mock_logger.warning.assert_called()
            # ãƒ«ãƒ¼ãƒ«ãŒç™»éŒ²ã•ã‚Œãªã„ã“ã¨ã‚’ç¢ºèª
            assert "json.test" not in result

    # å®Ÿç”¨çš„ãªãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãƒ†ã‚¹ãƒˆï¼ˆcollect_xlsx_filesä¾å­˜ï¼‰ã¯å‰Šé™¤

    def test_array_transform_rules_with_samples(self):
        """samplesãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨ã—ãŸtransformé–¢æ•°ãƒ†ã‚¹ãƒˆ"""
        # samplesãƒ•ã‚©ãƒ«ãƒ€ã®æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        samples_dir = Path(__file__).parent / "samples"
        if samples_dir.exists():
            transform_file = samples_dir / "transform.py"
            if transform_file.exists():
                # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆ
                rules = [f"json.test=function:{transform_file}:uppercase_transform"]

                # functionæŒ‡å®šã§ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ãƒ†ã‚¹ãƒˆ
                try:
                    transform_rules = xlsx2json.parse_array_transform_rules(
                        rules, "json", None
                    )
                    if "test" in transform_rules:
                        rule = transform_rules["test"]
                        # å¤‰æ›ã‚’ãƒ†ã‚¹ãƒˆ
                        result = rule.transform("hello")
                        assert isinstance(result, str)
                except Exception:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã‚„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
                    pass

    def test_array_transform_command_error_handling(self):
        """commandå¤‰æ›ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=command:echo"]

        transform_rules = xlsx2json.parse_array_transform_rules(rules, "json", None)

        if "test" in transform_rules:
            rule = transform_rules["test"]

            with patch("xlsx2json.logger") as mock_logger:
                # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                with patch("subprocess.run", side_effect=Exception("Command error")):
                    result = rule.transform("test_value")

                    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã€å…ƒã®å€¤ãŒè¿”ã•ã‚Œã‚‹
                    assert result == "test_value"

    def test_logging_and_debug_paths_from_coverage_boost(self):
        """ãƒ­ã‚°ã¨ãƒ‡ãƒãƒƒã‚°ãƒ‘ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

        logger = logging.getLogger("xlsx2json")
        original_level = logger.level
        try:
            for level in [logging.DEBUG, logging.INFO, logging.WARNING]:
                logger.setLevel(level)
                try:
                    xlsx2json.parse_array_transform_rules(
                        ["json.test=split:,"], "json", None
                    )
                    with patch("xlsx2json.logger.debug") as mock_debug:
                        mock_debug("Test debug message")
                    with patch("xlsx2json.logger.info") as mock_info:
                        mock_info("Test info message")
                    with patch("xlsx2json.logger.warning") as mock_warning:
                        mock_warning("Test warning message")
                except Exception:
                    pass
        finally:
            logger.setLevel(original_level)

    def test_debugging_and_logging_branches_lines_821_822_928_936_from_precision(self):
        """Test debugging and logging branches"""
        # Test with debug mode and various logging scenarios
        original_args = sys.argv
        try:
            # Simulate debug mode
            sys.argv = ["xlsx2json.py", "--debug", "test.xlsx"]

            # Test main function with debug
            with patch("xlsx2json.collect_xlsx_files") as mock_collect:
                mock_collect.return_value = []
                try:
                    xlsx2json.main()
                except SystemExit:
                    pass
        finally:
            sys.argv = original_args


class TestProcessingStats:
    """ProcessingStatsã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

    def test_processing_stats_warnings(self):
        """è­¦å‘Šæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        stats = xlsx2json.ProcessingStats()

        # è­¦å‘Šã‚’è¿½åŠ 
        stats.add_warning("ãƒ†ã‚¹ãƒˆè­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")

        assert len(stats.warnings) == 1
        assert "ãƒ†ã‚¹ãƒˆè­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸" in stats.warnings

    def test_processing_stats_duration(self):
        """å‡¦ç†æ™‚é–“è¨ˆæ¸¬ã®ãƒ†ã‚¹ãƒˆ"""
        stats = xlsx2json.ProcessingStats()

        # æ™‚é–“è¨ˆæ¸¬ãªã—ã®å ´åˆ
        assert stats.get_duration() == 0

        # æ™‚é–“è¨ˆæ¸¬ã‚ã‚Šã®å ´åˆ
        stats.start_processing()
        time.sleep(0.01)  # çŸ­ã„å¾…æ©Ÿ
        stats.end_processing()

        duration = stats.get_duration()
        assert duration > 0

    def test_processing_stats_log_summary(self, caplog):
        """ãƒ­ã‚°ã‚µãƒãƒªãƒ¼å‡ºåŠ›ã®ãƒ†ã‚¹ãƒˆ"""
        # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’INFOã«è¨­å®š
        caplog.set_level(logging.INFO)

        stats = xlsx2json.ProcessingStats()
        stats.containers_processed = 5
        stats.cells_generated = 100
        stats.cells_read = 150
        stats.empty_cells_skipped = 20

        # ã‚¨ãƒ©ãƒ¼ã¨è­¦å‘Šã‚’è¿½åŠ 
        stats.add_error("ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼")
        stats.add_warning("ãƒ†ã‚¹ãƒˆè­¦å‘Š")

        # æ™‚é–“ã‚’è¨­å®š
        stats.start_processing()
        stats.end_processing()

        # ãƒ­ã‚°ã‚µãƒãƒªãƒ¼ã‚’å®Ÿè¡Œ
        stats.log_summary()

        # ãƒ­ã‚°å†…å®¹ã‚’ç¢ºèªï¼ˆINFOãƒ¬ãƒ™ãƒ«ã®ãƒ­ã‚°ãŒå–å¾—ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼‰
        assert "å‡¦ç†çµ±è¨ˆã‚µãƒãƒª" in caplog.text or "å‡¦ç†çµ±è¨ˆã‚µãƒãƒªãƒ¼" in caplog.text
        assert "å‡¦ç†ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒŠæ•°: 5" in caplog.text
        assert "ã‚¨ãƒ©ãƒ¼æ•°: 1" in caplog.text
        assert "è­¦å‘Šæ•°: 1" in caplog.text


class TestSchemaErrorHandling:
    """ã‚¹ã‚­ãƒ¼ãƒé–¢é€£ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸æ”¹å–„ï¼‰"""

    def test_load_schema_missing_file(self, tmp_path):
        """å­˜åœ¨ã—ãªã„ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        missing_schema = tmp_path / "missing_schema.json"

        # load_schemaé–¢æ•°ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if hasattr(xlsx2json, "load_schema"):
            try:
                result = xlsx2json.SchemaLoader.load_schema(missing_schema)
                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã®å‡¦ç†ã‚’ç¢ºèª
            except (FileNotFoundError, IOError):
                # æœŸå¾…ã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯OK
                pass
        else:
            # é–¢æ•°ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass

    def test_load_schema_invalid_json(self, tmp_path):
        """ç„¡åŠ¹ãªJSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        invalid_schema = tmp_path / "invalid_schema.json"
        invalid_schema.write_text("not valid json")

        if hasattr(xlsx2json, "load_schema"):
            try:
                result = xlsx2json.SchemaLoader.load_schema(invalid_schema)
                # ç„¡åŠ¹ãªJSONã®å ´åˆã®å‡¦ç†ã‚’ç¢ºèª
            except Exception:
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯OK
                pass
        else:
            # é–¢æ•°ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass


class TestContainers:
    """ã‚³ãƒ³ãƒ†ãƒŠæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""

    def test_load_container_config_missing_file(self, tmp_path):
        """å­˜åœ¨ã—ãªã„ã‚³ãƒ³ãƒ†ãƒŠè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        missing_config = tmp_path / "missing_config.json"

        result = xlsx2json.load_container_config(missing_config)
        assert result == {}

    def test_load_container_config_invalid_json(self, tmp_path):
        """ç„¡åŠ¹ãªJSONã‚³ãƒ³ãƒ†ãƒŠè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        invalid_config = tmp_path / "invalid_config.json"
        invalid_config.write_text("invalid json")

        result = xlsx2json.load_container_config(invalid_config)
        assert result == {}

    def test_resolve_container_range_direct_range(self):
        """ç›´æ¥ç¯„å›²æŒ‡å®šã®è§£æ±ºãƒ†ã‚¹ãƒˆ"""
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ãªã—ã§ãƒ†ã‚¹ãƒˆå¯èƒ½ãªé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
        try:
            # parse_rangeãŒå­˜åœ¨ã™ã‚‹å ´åˆ
            start_coord, end_coord = xlsx2json.parse_range("B2:D4")
            assert start_coord == (2, 2)
            assert end_coord == (4, 4)
        except Exception:
            # é–¢æ•°ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass

    def test_process_containers_edge_cases(self, tmp_path):
        """ã‚³ãƒ³ãƒ†ãƒŠå‡¦ç†ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        # ç©ºã®è¨­å®šã§ã®ãƒ†ã‚¹ãƒˆ
        result = {}
        config_path = tmp_path / "nonexistent_config.json"

        # é–¢æ•°ãŒå­˜åœ¨ã™ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèª
        if hasattr(xlsx2json, "process_all_containers"):
            # å­˜åœ¨ã—ãªã„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚‚æ­£å¸¸ã«å‡¦ç†ã•ã‚Œã‚‹
            try:
                xlsx2json.process_all_containers(None, config_path, result)
            except Exception:
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ãƒ†ã‚¹ãƒˆã‚’ãƒ‘ã‚¹
                pass
        else:
            # é–¢æ•°ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass


class TestJSONPath:
    """JSON pathé–¢é€£æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""

    def test_insert_json_path_empty_keys(self):
        """ç©ºã®ã‚­ãƒ¼ã§ã®JSON pathæŒ¿å…¥ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        root = {}

        with pytest.raises(ValueError, match="JSON.*ãƒ‘ã‚¹.*ç©º"):
            xlsx2json.insert_json_path(root, [], "value")

    def test_insert_json_path_array_conversion(self):
        """é…åˆ—ã¸ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        root = {"key": {}}

        # ç©ºè¾æ›¸ã‚’é…åˆ—ã«å¤‰æ›
        xlsx2json.insert_json_path(root, ["key", "1"], "value1")
        assert isinstance(root["key"], list)
        assert root["key"][0] == "value1"

    def test_insert_json_path_dict_conversion(self):
        """è¾æ›¸ã¸ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        root = {"key": []}

        # ç©ºé…åˆ—ã‚’è¾æ›¸ã«å¤‰æ›
        xlsx2json.insert_json_path(root, ["key", "subkey"], "value1")
        assert isinstance(root["key"], dict)
        assert root["key"]["subkey"] == "value1"


class TestArrayTransformRule:
    """é…åˆ—å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""

    def test_array_transform_rule_unknown_fallback(self):
        """ä¸æ˜ãªtransform_typeã®å ´åˆã¯å€¤ã‚’ãã®ã¾ã¾è¿”ã™ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        rule = xlsx2json.ArrayTransformRule("test.path", "split", ",")
        rule.transform_type = "unknown"
        assert rule.transform("value") == "value"

class TestCommandTransformNewSpec:
    @patch("subprocess.run")
    def test_nested_list_serialized_as_json(self, mock_run):
        nested = [["a", "b"], ["c", ["d"]]]
        rule = xlsx2json.ArrayTransformRule("x", "command", "cat", trim_enabled=False)
        # subprocess.run ãŒå‘¼ã°ã‚ŒãŸã¨ã stdin(input=) ã« JSON æ–‡å­—åˆ—ãŒæ¥ã‚‹ã‹ã‚’æ¤œè¨¼
        def _side_effect(args, input, stdout, stderr, text, timeout):  # noqa: D401
            return SimpleNamespace(returncode=0, stdout=input, stderr="")
        mock_run.side_effect = _side_effect
        out = rule.transform(nested)
        # JSON decode å¯èƒ½ã§ã‚ã‚‹ã¹ã
        decoded = json.loads(out) if isinstance(out, str) else out
        assert decoded == nested

    @patch("subprocess.run")
    def test_dict_serialized_as_json(self, mock_run):
        data = {"k": [1, 2, {"x": 3}]}
        rule = xlsx2json.ArrayTransformRule("x", "command", "cat", trim_enabled=False)
        def _side_effect(args, input, stdout, stderr, text, timeout):
            return SimpleNamespace(returncode=0, stdout=input, stderr="")
        mock_run.side_effect = _side_effect
        out = rule.transform(data)
        decoded = json.loads(out) if isinstance(out, str) else out
        assert decoded == data

    @patch("subprocess.run")
    def test_flat_scalar_list_is_newline_joined_not_json(self, mock_run):
        values = ["A", "B", "A"]
        rule = xlsx2json.ArrayTransformRule("x", "command", "cat", trim_enabled=False)
        def _side_effect(args, input, stdout, stderr, text, timeout):
            return SimpleNamespace(returncode=0, stdout=input, stderr="")
        mock_run.side_effect = _side_effect
        out = rule.transform(values)
        # ãƒ•ãƒ©ãƒƒãƒˆã‚¹ã‚«ãƒ©é…åˆ—å…¥åŠ› â†’ æ”¹è¡Œçµåˆå¾Œã« treat_multiline_as_list ã§è¡Œé…åˆ—ã¸å¾©å…ƒ
        assert isinstance(out, list)
        assert out == ["A", "B", "A"]  # é‡è¤‡ã¯ä¿æŒï¼ˆcatãªã®ã§ã‚½ãƒ¼ãƒˆ/ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ãªã—ï¼‰


class TestParseArraySplitRules:
    """é…åˆ—åˆ†å‰²ãƒ«ãƒ¼ãƒ«è§£æã®ãƒ†ã‚¹ãƒˆ"""

    def test_parse_array_split_rules_invalid_rule_format(self):
        """ç„¡åŠ¹ãªãƒ«ãƒ¼ãƒ«å½¢å¼ã§ã®è­¦å‘Šãƒ†ã‚¹ãƒˆ"""
        result = xlsx2json.parse_array_split_rules(["invalid_rule"], "json.")
        assert result == {}

    def test_parse_array_split_rules_empty_rule(self):
        """ç©ºã®ãƒ«ãƒ¼ãƒ«ã§ã®è­¦å‘Šãƒ†ã‚¹ãƒˆ"""
        result = xlsx2json.parse_array_split_rules(["", None], "json.")
        assert result == {}


class TestUtilityExtensions:
    """ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®æ‹¡å¼µãƒ†ã‚¹ãƒˆ"""

    def test_parse_range_error_cases(self):
        """ç¯„å›²ãƒ‘ãƒ¼ã‚¹æ™‚ã®ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        # ç„¡åŠ¹ãªç¯„å›²æ–‡å­—åˆ—
        with pytest.raises(ValueError):
            xlsx2json.parse_range("invalid_range")

        # ç©ºæ–‡å­—åˆ—
        with pytest.raises(ValueError):
            xlsx2json.parse_range("")


class TestDataIntegrity:
    """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ãƒ†ã‚¹ãƒˆ"""

    def test_hierarchical_json_structure_integrity(self):
        """éšå±¤JSONãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ•´åˆæ€§ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šãƒã‚¹ãƒˆæ§‹é€ ç ´ç¶»é˜²æ­¢ï¼‰"""
        root = {}

        # æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã§ã®æ•´åˆæ€§ç¢ºèª
        test_paths = [
            ["level1", "level2", "level3", "data1"],
            ["level1", "level2", "level4", "data2"],
            ["level1", "other_branch", "data3"],
            ["level1", "level2", "level3", "data4"],  # åŒã˜ãƒ‘ã‚¹ã¸ã®ä¸Šæ›¸ã
        ]

        values = ["å€¤1", "å€¤2", "å€¤3", "å€¤4_ä¸Šæ›¸ã"]

        for path, value in zip(test_paths, values):
            xlsx2json.insert_json_path(root, path, value)

        # æ§‹é€ ã®æ•´åˆæ€§ç¢ºèª
        assert root["level1"]["level2"]["level3"]["data1"] == "å€¤1"
        assert root["level1"]["level2"]["level3"]["data4"] == "å€¤4_ä¸Šæ›¸ã"
        assert root["level1"]["level2"]["level4"]["data2"] == "å€¤2"
        assert root["level1"]["other_branch"]["data3"] == "å€¤3"

        # ãƒã‚¹ãƒˆæ§‹é€ ãŒå£Šã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
        assert isinstance(root["level1"]["level2"], dict)
        assert isinstance(root["level1"], dict)

    def test_excel_to_json_conversion_workflow_validation(self):
        """Excelâ†’JSONå¤‰æ›ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“ã®æ¤œè¨¼ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šå¤‰æ›ãƒ—ãƒ­ã‚»ã‚¹ä¿è¨¼ï¼‰"""
        # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®æŠ€è¡“çš„ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
        conversion_workflow_steps = [
            # Step 1: Excelç¯„å›²å®šç¾©
            {
                "range": "B2:D4",
                "direction": "row",
                "items": ["field1", "field2", "field3"],
            },
            # Step 2: ãƒ‡ãƒ¼ã‚¿ç¯„å›²è§£æ
            None,  # parse_rangeçµæœ
            # Step 3: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°æ¤œå‡º
            None,  # detect_instance_countçµæœ
            # Step 4: ã‚»ãƒ«åç”Ÿæˆ
            None,  # generate_cell_namesçµæœ
            # Step 5: JSONæ§‹é€ æ§‹ç¯‰
            {},  # æœ€çµ‚JSONçµæœ
        ]

        # Step 2: ç¯„å›²è§£æ
        start_coord, end_coord = xlsx2json.parse_range(
            conversion_workflow_steps[0]["range"]
        )
        conversion_workflow_steps[1] = (start_coord, end_coord)
        assert start_coord == (2, 2) and end_coord == (4, 4)

        # Step 3: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°æ¤œå‡º
        instance_count = xlsx2json.detect_instance_count(
            start_coord, end_coord, conversion_workflow_steps[0]["direction"]
        )
        conversion_workflow_steps[2] = instance_count
        assert instance_count == 3  # B2:D4ã§rowæ–¹å‘ãªã®ã§3ãƒ¬ã‚³ãƒ¼ãƒ‰

        # Step 4: ã‚»ãƒ«åç”Ÿæˆ
        cell_names = xlsx2json.generate_cell_names(
            "dataset",
            start_coord,
            end_coord,
            conversion_workflow_steps[0]["direction"],
            conversion_workflow_steps[0]["items"],
        )
        conversion_workflow_steps[3] = cell_names
        assert len(cell_names) == 9  # 3ãƒ¬ã‚³ãƒ¼ãƒ‰ Ã— 3é …ç›®

        # Step 5: JSONæ§‹é€ æ§‹ç¯‰
        result = conversion_workflow_steps[4]
        test_data = {
            "dataset_1_field1": "2024-01-15",
            "dataset_1_field2": "itemA",
            "dataset_1_field3": 100000,
            "dataset_2_field1": "2024-01-16",
            "dataset_2_field2": "itemB",
            "dataset_2_field3": 150000,
            "dataset_3_field1": "2024-01-17",
            "dataset_3_field2": "itemC",
            "dataset_3_field3": 120000,
        }

        for cell_name in cell_names:
            if cell_name in test_data:
                xlsx2json.insert_json_path(result, [cell_name], test_data[cell_name])

        # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®å®Œå…¨æ€§ç¢ºèª
        assert result["dataset_1_field1"] == "2024-01-15"
        assert result["dataset_2_field3"] == 150000
        assert result["dataset_3_field2"] == "itemC"

        # æ•°å€¤åˆè¨ˆã®è¨ˆç®—ç¢ºèªï¼ˆæŠ€è¡“çš„æ¤œè¨¼ï¼‰
        total_values = sum(
            [
                result["dataset_1_field3"],
                result["dataset_2_field3"],
                result["dataset_3_field3"],
            ]
        )
        assert total_values == 370000  # 100000 + 150000 + 120000


class TestErrorRecovery:
    """ã‚¨ãƒ©ãƒ¼å›å¾©ã®ãƒ†ã‚¹ãƒˆ"""

    def test_memory_exhaustion_protection(self):
        """ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ä¿è­·ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡é˜²æ­¢ï¼‰"""
        # éå¸¸ã«å¤§ããªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å‡¦ç†
        range_str = "A1:Z1000"  # 26åˆ— Ã— 1000è¡Œ = 26000ã‚»ãƒ«
        huge_data_config = {
            "direction": "row",
            "items": [f"ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰{chr(65+i)}" for i in range(26)],  # A-Z
        }

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒåˆ¶å¾¡å¯èƒ½ãªç¯„å›²å†…ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        start_coord, end_coord = xlsx2json.parse_range(range_str)
        assert start_coord == (1, 1) and end_coord == (26, 1000)

        instance_count = xlsx2json.detect_instance_count(
            start_coord, end_coord, huge_data_config["direction"]
        )
        assert instance_count == 1000

        # ã‚»ãƒ«åç”Ÿæˆã‚’å°ã•ãªãƒãƒƒãƒã§å®Ÿè¡Œï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç¢ºèªï¼‰
        small_batch = xlsx2json.generate_cell_names(
            "å·¨å¤§ãƒ†ãƒ¼ãƒ–ãƒ«",
            (1, 1),
            (5, 10),  # 5åˆ— Ã— 10è¡Œã«ç¸®å°
            huge_data_config["direction"],
            huge_data_config["items"][:5],
        )

        # ãƒãƒƒãƒå‡¦ç†ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(small_batch) == 50  # 5é …ç›® Ã— 10è¡Œ

    def test_infinite_recursion_prevention(self):
        """ç„¡é™å†å¸°é˜²æ­¢ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šã‚¹ã‚¿ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢ï¼‰"""
        # æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã§ã®ã‚¹ã‚¿ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢
        deep_root = {}

        # éå¸¸ã«æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã‚’ä½œæˆï¼ˆ1000éšå±¤ï¼‰
        current_level = deep_root
        for level in range(100):  # ã‚¹ã‚¿ãƒƒã‚¯åˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚100éšå±¤ã«èª¿æ•´
            level_key = f"level_{level}"
            current_level[level_key] = {}
            current_level = current_level[level_key]

        # æœ€æ·±éƒ¨ã«å€¤ã‚’è¨­å®š
        current_level["deep_value"] = "æœ€æ·±éƒ¨ã®å€¤"

        # æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        try:
            # clean_empty_valuesãŒæ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã‚’å‡¦ç†ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª
            cleaned = xlsx2json.clean_empty_values(deep_root)

            # å€¤ãŒä¿æŒã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            current_check = cleaned
            for level in range(100):
                level_key = f"level_{level}"
                assert level_key in current_check
                current_check = current_check[level_key]

            assert current_check["deep_value"] == "æœ€æ·±éƒ¨ã®å€¤"

        except RecursionError:
            # ã‚¹ã‚¿ãƒƒã‚¯åˆ¶é™ã«é”ã—ãŸå ´åˆã‚‚é©åˆ‡ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            pass  # æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ


class TestTransformationRules:
    """å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""

    def test_custom_function_integration_reliability(self):
        """ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°çµ±åˆã®ä¿¡é ¼æ€§ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šå¤–éƒ¨é–¢æ•°ã®å®‰å…¨å®Ÿè¡Œï¼‰"""
        # ã‚«ã‚¹ã‚¿ãƒ å¤‰æ›é–¢æ•°ã‚’å®šç¾©
        custom_function_code = '''
def numeric_calculator(amount_str):
    """æ•°å€¤è¨ˆç®—å‡¦ç†é–¢æ•°"""
    try:
        amount = float(amount_str)
        multiplier = 1.10  # 10%å¢—åŠ 
        return int(amount * multiplier)
    except (ValueError, TypeError):
        return 0

def format_identifier(id_str):
    """è­˜åˆ¥å­ã‚’æ¨™æº–å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if not isinstance(id_str, str):
        return ""
    
    # ãƒã‚¤ãƒ•ãƒ³ã¨ç©ºç™½ã‚’é™¤å»
    cleaned = id_str.replace("-", "").replace(" ", "")
    
    # 11æ¡ã®å ´åˆã¯ XXX-XXXX-XXXX å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    if len(cleaned) == 11 and cleaned.isdigit():
        return f"{cleaned[:3]}-{cleaned[3:7]}-{cleaned[7:]}"
    
    return id_str

def safe_division(input_str):
    """å®‰å…¨ãªé™¤ç®—ï¼ˆã‚¼ãƒ­é™¤ç®—ã‚¨ãƒ©ãƒ¼å›é¿ï¼‰"""
    try:
        parts = input_str.split(",")
        if len(parts) != 2:
            return "ERROR: Invalid format"
        
        num = float(parts[0])
        den = float(parts[1])
        if den == 0:
            return "ERROR: Division by zero"
        return round(num / den, 2)
    except (ValueError, TypeError):
        return "ERROR: Invalid input"
'''

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢æ•°ã‚’ä¿å­˜
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".py", delete=False, encoding="utf-8"
        ) as f:
            f.write(custom_function_code)
            temp_function_file = f.name

        try:
            # æ•°å€¤è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ
            rule_calc = xlsx2json.ArrayTransformRule(
                "value", "function", f"{temp_function_file}:numeric_calculator"
            )

            test_amounts = ["1000", "2500.50", "0", "invalid"]
            expected_results = [
                1100,
                2750,
                0,
                0,
            ]  # 10%åŠ ç®— + ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆæµ®å‹•å°æ•°ç‚¹èª¤å·®è€ƒæ…®ï¼‰

            for amount, expected in zip(test_amounts, expected_results):
                result = rule_calc.transform(amount)
                assert (
                    result == expected
                ), f"æ•°å€¤è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {amount} -> {result} (æœŸå¾…å€¤: {expected})"  # è­˜åˆ¥å­ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆ
            rule_format = xlsx2json.ArrayTransformRule(
                "identifier", "function", f"{temp_function_file}:format_identifier"
            )

            format_tests = [
                ("09012345678", "090-1234-5678"),
                ("090-1234-5678", "090-1234-5678"),  # æ—¢ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿
                ("123", "123"),  # çŸ­ã™ãã‚‹å ´åˆã¯ãã®ã¾ã¾
                (None, ""),  # Nullå€¤ã®å‡¦ç†
            ]

            for format_input, expected in format_tests:
                result = rule_format.transform(format_input)
                assert (
                    result == expected
                ), f"è­˜åˆ¥å­ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {format_input} -> {result}"

            # å®‰å…¨é™¤ç®—ã®ãƒ†ã‚¹ãƒˆ
            rule_division = xlsx2json.ArrayTransformRule(
                "ratio", "function", f"{temp_function_file}:safe_division"
            )

            # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ•°å€¤ãƒšã‚¢ã§é™¤ç®—ã‚’ãƒ†ã‚¹ãƒˆ
            division_tests = [
                ("10,2", 5.0),
                ("7,3", 2.33),
                ("5,0", "ERROR: Division by zero"),  # ã‚¼ãƒ­é™¤ç®—
                ("abc,def", "ERROR: Invalid input"),  # ç„¡åŠ¹å…¥åŠ›
            ]

            for input_pair, expected in division_tests:
                result = rule_division.transform(input_pair)
                assert result == expected, f"é™¤ç®—ã‚¨ãƒ©ãƒ¼: {input_pair} -> {result}"

        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            os.unlink(temp_function_file)

    def test_array_transformation_complex_scenarios(self):
        """é…åˆ—å¤‰æ›ã®è¤‡é›‘ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®æŸ”è»Ÿæ€§ï¼‰"""
        # è¤‡é›‘ãªåŒºåˆ‡ã‚Šæ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³
        complex_split_patterns = [
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: è¤‡æ•°åŒºåˆ‡ã‚Šæ–‡å­—
            ("apple,banana;orange|grape", [","]),
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ç©ºç™½ã¨ã‚¿ãƒ–æ··åˆ
            ("item1\titem2 item3\t\titem4", ["\t"]),
            # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ã‚«ã‚¹ã‚¿ãƒ åŒºåˆ‡ã‚Šæ–‡å­—
            ("data::part1::part2::part3", ["::"]),
            # ãƒ‘ã‚¿ãƒ¼ãƒ³4: æ”¹è¡ŒåŒºåˆ‡ã‚Š
            ("line1\nline2\nline3\r\nline4", ["\n"]),
        ]

        for input_data, delimiters in complex_split_patterns:
            for delimiter in delimiters:
                try:
                    rule = xlsx2json.ArrayTransformRule("test_path", "split", delimiter)
                    result = rule.transform(input_data)

                    # åˆ†å‰²çµæœãŒé…åˆ—ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                    assert isinstance(
                        result, list
                    ), f"åˆ†å‰²çµæœãŒé…åˆ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {result}"

                    # åˆ†å‰²ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªï¼ˆç©ºè¦ç´ ã¯é™¤å¤–ï¼‰
                    non_empty_result = [item for item in result if item.strip()]
                    assert (
                        len(non_empty_result) > 0
                    ), f"æœ‰åŠ¹ãªåˆ†å‰²çµæœãŒã‚ã‚Šã¾ã›ã‚“: {result}"

                except Exception as e:
                    # ArrayTransformRuleã®åˆæœŸåŒ–ã‚„å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã¯æƒ³å®šå†…
                    assert "callable" in str(e) or "transform" in str(
                        e
                    ), f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}"

    def test_json_schema_validation_data_rules(self):
        """JSONã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼ï¼‰"""
        # ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒ«ç”¨ã®JSONã‚¹ã‚­ãƒ¼ãƒ
        data_schema = {
            "type": "object",
            "properties": {
                "customer": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string", "minLength": 1},
                        "age": {"type": "integer", "minimum": 0, "maximum": 150},
                        "email": {"type": "string", "pattern": r"^[^@]+@[^@]+\.[^@]+$"},
                    },
                    "required": ["name", "age"],
                },
                "orders": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "amount": {"type": "number", "minimum": 0},
                            "date": {"type": "string"},
                        },
                        "required": ["amount", "date"],
                    },
                    "minItems": 1,
                },
            },
            "required": ["customer", "orders"],
        }

        # ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".json", delete=False, encoding="utf-8"
        ) as f:
            json.dump(data_schema, f, ensure_ascii=False)
            schema_file = f.name

        try:
            # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚¹ãƒˆ
            valid_business_data = {
                "customer": {
                    "name": "ç”°ä¸­å¤ªéƒ",
                    "age": 35,
                    "email": "tanaka@example.com",
                },
                "orders": [
                    {"amount": 1500.0, "date": "2024-01-15"},
                    {"amount": 2800.0, "date": "2024-01-20"},
                ],
            }

            # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚¹ãƒˆ
            invalid_business_data_samples = [
                # é¡§å®¢åãªã—
                {
                    "customer": {"age": 35},
                    "orders": [{"amount": 1000, "date": "2024-01-01"}],
                },
                # å¹´é½¢ãŒç¯„å›²å¤–
                {
                    "customer": {"name": "å±±ç”°èŠ±å­", "age": 200},
                    "orders": [{"amount": 1000, "date": "2024-01-01"}],
                },
                # ã‚¨ãƒ³ãƒˆãƒªé‡‘é¡ãŒãƒã‚¤ãƒŠã‚¹
                {
                    "customer": {"name": "ä½è—¤æ¬¡éƒ", "age": 40},
                    "orders": [{"amount": -500, "date": "2024-01-01"}],
                },
                # å¿…é ˆé …ç›®ä¸è¶³
                {
                    "customer": {"name": "éˆ´æœ¨ä¸‰éƒ", "age": 25}
                    # orders ãªã—
                },
            ]

            # JSONSchemaæ¤œè¨¼ã¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¾å­˜ãªã®ã§ã€åŸºæœ¬çš„ãªæ§‹é€ ãƒã‚§ãƒƒã‚¯ã®ã¿å®Ÿè¡Œ
            def validate_data_rules(data):
                """ç°¡æ˜“ç‰ˆã®ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒ«æ¤œè¨¼"""
                errors = []

                # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æƒ…å ±ãƒã‚§ãƒƒã‚¯
                if "customer" not in data:
                    errors.append("customer missing")
                else:
                    customer = data["customer"]
                    if "name" not in customer or not customer["name"]:
                        errors.append("customer name missing")
                    if "age" not in customer:
                        errors.append("customer age missing")
                    elif (
                        not isinstance(customer["age"], int)
                        or customer["age"] < 0
                        or customer["age"] > 150
                    ):
                        errors.append("customer age invalid")

                # ã‚¨ãƒ³ãƒˆãƒªæƒ…å ±ãƒã‚§ãƒƒã‚¯
                if "orders" not in data:
                    errors.append("orders missing")
                else:
                    orders = data["orders"]
                    if not isinstance(orders, list) or len(orders) == 0:
                        errors.append("orders empty")
                    else:
                        for i, order in enumerate(orders):
                            if "amount" not in order:
                                errors.append(f"order {i} amount missing")
                            elif (
                                not isinstance(order["amount"], (int, float))
                                or order["amount"] < 0
                            ):
                                errors.append(f"order {i} amount invalid")

                return errors

            # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
            valid_errors = validate_data_rules(valid_business_data)
            assert len(valid_errors) == 0, f"æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {valid_errors}"

            # ç„¡åŠ¹ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
            for i, invalid_data in enumerate(invalid_business_data_samples):
                invalid_errors = validate_data_rules(invalid_data)
                assert (
                    len(invalid_errors) > 0
                ), f"ç„¡åŠ¹ãƒ‡ãƒ¼ã‚¿{i}ãŒæ¤œè¨¼ã‚’ãƒ‘ã‚¹: {invalid_data}"

        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            os.unlink(schema_file)


class TestUtilityFunctions:
    """ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ

    ã‚³ã‚¢ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®å‹•ä½œã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’æ¤œè¨¼
    """

    @pytest.fixture
    def temp_dir(self):
        """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆãƒ»å‰Šé™¤"""
        temp_path = Path(tempfile.mkdtemp())
        yield temp_path
        shutil.rmtree(temp_path)

    @pytest.fixture
    def sample_workbook(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ä½œæˆ"""
        xlsx_path = temp_dir / "coverage_test.xlsx"
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "TestSheet"

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è¨­å®š
        ws["A1"] = "Name"
        ws["B1"] = "Value"
        ws["A2"] = "Test1"
        ws["B2"] = "100"
        ws["A3"] = "Test2"
        ws["B3"] = "200"

        # åå‰ä»˜ãç¯„å›²å®šç¾©
        set_defined_names(
            wb,
            {
                "test_range": "TestSheet!$A$1:$B$3",
                "single_cell": "TestSheet!$A$1",
            },
        )

        wb.save(xlsx_path)
        wb.close()
        return xlsx_path

    def test_load_container_config_file_not_found(self, temp_dir):
        """load_container_config: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        non_existent_path = temp_dir / "non_existent_config.json"
        result = xlsx2json.load_container_config(non_existent_path)
        assert result == {}

    def test_load_container_config_invalid_json(self, temp_dir):
        """load_container_config: ç„¡åŠ¹ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        invalid_json_path = temp_dir / "invalid_config.json"
        with invalid_json_path.open("w", encoding="utf-8") as f:
            f.write("{ invalid json }")

        result = xlsx2json.load_container_config(invalid_json_path)
        assert result == {}

    def test_load_container_config_no_containers_key(self, temp_dir):
        """load_container_config: containersã‚­ãƒ¼ãŒãªã„å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        config_path = temp_dir / "no_containers_config.json"
        config_content = {"other_key": "value"}

        with config_path.open("w", encoding="utf-8") as f:
            json.dump(config_content, f)

        result = xlsx2json.load_container_config(config_path)
        assert result == {}

    def test_load_container_config_valid_file(self, temp_dir):
        """load_container_config: æ­£å¸¸ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        config_path = temp_dir / "valid_config.json"
        config_content = {
            "containers": {
                "test_container": {
                    "direction": "row",
                    "items": ["name", "value"],
                }
            }
        }

        with config_path.open("w", encoding="utf-8") as f:
            json.dump(config_content, f)

        result = xlsx2json.load_container_config(config_path)
        expected = config_content["containers"]
        assert result == expected

    def test_resolve_container_range_named_range(self, sample_workbook):
        """resolve_container_range: åå‰ä»˜ãç¯„å›²ã®è§£æ±ºãƒ†ã‚¹ãƒˆ"""
        wb = openpyxl.load_workbook(sample_workbook)

        # åå‰ä»˜ãç¯„å›²ã®è§£æ±º
        result = xlsx2json.resolve_container_range(wb, "test_range")
        expected = ((1, 1), (2, 3))  # A1:B3
        assert result == expected

        wb.close()

    def test_resolve_container_range_cell_reference(self, sample_workbook):
        """resolve_container_range: ã‚»ãƒ«å‚ç…§æ–‡å­—åˆ—ã®è§£æ±ºãƒ†ã‚¹ãƒˆ"""
        wb = openpyxl.load_workbook(sample_workbook)

        # ç›´æ¥ç¯„å›²æŒ‡å®š
        result = xlsx2json.resolve_container_range(wb, "A1:C5")
        expected = ((1, 1), (3, 5))
        assert result == expected

        wb.close()

    def test_resolve_container_range_invalid_range(self, sample_workbook):
        """resolve_container_range: ç„¡åŠ¹ãªç¯„å›²æŒ‡å®šã®ãƒ†ã‚¹ãƒˆ"""
        wb = openpyxl.load_workbook(sample_workbook)

        with pytest.raises(ValueError):
            xlsx2json.resolve_container_range(wb, "INVALID_RANGE")

        wb.close()

    def test_convert_string_to_array_various_types(self):
        """convert_string_to_array: æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        # æ–‡å­—åˆ—ã®åˆ†å‰²
        assert xlsx2json.convert_string_to_array("a,b,c", ",") == ["a", "b", "c"]
        # æ•°å€¤ï¼ˆéæ–‡å­—åˆ—ï¼‰
        assert xlsx2json.convert_string_to_array(123, ",") == 123
        # None
        assert xlsx2json.convert_string_to_array(None, ",") == None
        # ç©ºæ–‡å­—åˆ—
        assert xlsx2json.convert_string_to_array("", ",") == []

    def test_convert_string_to_multidimensional_array_edge_cases(self):
        """convert_string_to_multidimensional_array: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # è¤‡æ•°ãƒ‡ãƒªãƒŸã‚¿ã§ã®åˆ†å‰²
        result = xlsx2json.convert_string_to_multidimensional_array(
            "a,b|c,d", ["|", ","]
        )
        expected = [["a", "b"], ["c", "d"]]
        assert result == expected
        # ç©ºæ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array("", [","])
        assert result == []
        # éæ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array(123, [","])
        assert result == 123

    def test_is_empty_value_edge_cases(self):
        """is_empty_value: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # ç©ºã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_empty_value("") == True
        assert xlsx2json.is_empty_value(None) == True
        assert xlsx2json.is_empty_value([]) == True
        assert xlsx2json.is_empty_value({}) == True
        assert xlsx2json.is_empty_value("   ") == True  # ç©ºç™½ã®ã¿
        # ç©ºã§ã¯ãªã„ã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_empty_value("0") == False
        assert xlsx2json.is_empty_value(0) == False  # 0ã¯ç©ºå€¤ã§ã¯ãªã„
        assert xlsx2json.is_empty_value(False) == False  # Falseã¯ç©ºå€¤ã§ã¯ãªã„
        assert xlsx2json.is_empty_value([0]) == False
        assert xlsx2json.is_empty_value({"key": "value"}) == False

    def test_is_completely_empty_edge_cases(self):
        """is_completely_empty: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # å®Œå…¨ã«ç©ºã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        assert xlsx2json.is_completely_empty({}) == True
        assert xlsx2json.is_completely_empty([]) == True
        assert xlsx2json.is_completely_empty({"empty": {}, "null": None}) == True
        # ç©ºã§ã¯ãªã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        assert xlsx2json.is_completely_empty({"value": "test"}) == False
        assert xlsx2json.is_completely_empty([1, 2, 3]) == False
        assert xlsx2json.is_completely_empty("string") == False

    def test_clean_empty_values(self):
        """clean_empty_arrays_contextually: é…åˆ—ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        # suppress_empty=True ã®å ´åˆ
        data_with_empty = {
            "valid_array": [1, 2, 3],
            "empty_array": [],
            "mixed_array": [1, "", None, 2],
            "nested": {"empty_nested_array": [], "valid_nested": [4, 5]},
        }
        result = xlsx2json.clean_empty_values(data_with_empty)
        assert "empty_array" not in result
        assert result["valid_array"] == [1, 2, 3]
        assert "empty_nested_array" not in result["nested"]
        assert result["nested"]["valid_nested"] == [4, 5]

    def test_insert_json_path_complex(self):
        """insert_json_path: è¤‡é›‘ãªJSONãƒ‘ã‚¹æŒ¿å…¥ãƒ†ã‚¹ãƒˆ"""
        result = {}

        # åŸºæœ¬çš„ãªãƒ‘ã‚¹
        xlsx2json.insert_json_path(result, ["level1", "level2", "field"], "value")
        expected = {"level1": {"level2": {"field": "value"}}}
        assert result == expected
        # é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ1-basedï¼‰
        result = {}
        xlsx2json.insert_json_path(result, ["array", "1"], "first")
        xlsx2json.insert_json_path(result, ["array", "2"], "second")
        assert result["array"][0] == "first"
        assert result["array"][1] == "second"

    def test_parse_range_single_cell_edge_cases(self):
        """parse_range: å˜ä¸€ã‚»ãƒ«ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # parse_rangeã¯ç¯„å›²å½¢å¼ï¼ˆA1:B2ï¼‰ã‚’æœŸå¾…ã™ã‚‹ã®ã§ã€å˜ä¸€ã‚»ãƒ«ã®å ´åˆã¯åˆ¥ã®é–¢æ•°ã‚’ä½¿ã†
        # ä»£ã‚ã‚Šã«ã€ç¯„å›²æ–‡å­—åˆ—ã§ã®ãƒ†ã‚¹ãƒˆã‚’è¡Œã†
        result = xlsx2json.parse_range("A1:A1")
        assert result == ((1, 1), (1, 1))
        # å¤§ããªç¯„å›²
        result = xlsx2json.parse_range("AA100:AB101")
        assert result == ((27, 100), (28, 101))  # AA=27, AB=28
        # ç„¡åŠ¹ãªå½¢å¼
        with pytest.raises(ValueError):
            xlsx2json.parse_range("INVALID")
        with pytest.raises(ValueError):
            xlsx2json.parse_range("A1:INVALID")

    def test_ArrayTransformRule_safe_operations(self):
        """ArrayTransformRule: å®‰å…¨ãªæ“ä½œã®ãƒ†ã‚¹ãƒˆ"""
        # æ­£å¸¸ãªsplitå¤‰æ›
        rule = xlsx2json.ArrayTransformRule("test", "split", ",")
        rule._transform_func = lambda x: x.split(",") if isinstance(x, str) else x
        # æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
        result = rule.transform("a,b,c")
        assert result == ["a", "b", "c"]
        # éæ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        result = rule.transform(123)
        assert result == 123
        result = rule.transform(None)
        assert result == None
        # ãƒªã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
        result = rule.transform(["a,b", "c,d"])
        assert result == [["a", "b"], ["c", "d"]]

    def test_insert_json_path_basic_dict_and_list(self):
        root: dict[str, object] = {}
        # è¾æ›¸ãƒ‘ã‚¹ã¸ã®æŒ¿å…¥
        xlsx2json.insert_json_path(root, ["a", "b"], 123)
        assert root == {"a": {"b": 123}}

        # æ•°å€¤ãƒ‘ã‚¹ã¯ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã—ã€1å§‹ã¾ã‚Šã®2ç•ªç›®ã®ä½ç½®ã«å€¤ã‚’é…ç½®ã™ã‚‹
        xlsx2json.insert_json_path(root, ["a2", "1", "2"], "x")
        assert isinstance(root["a2"], list)
        assert len(root["a2"]) >= 1
        assert isinstance(root["a2"][0], list)
        assert len(root["a2"][0]) >= 2
        assert root["a2"][0][1] == "x"
    """ã‚³ã‚¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚«ãƒãƒ¬ãƒƒã‚¸æ”¹å–„ãƒ†ã‚¹ãƒˆ

    ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®é‡è¦ãªéƒ¨åˆ†ã‚’ãƒ†ã‚¹ãƒˆ
    """

    @pytest.fixture
    def complex_workbook(self, temp_dir):
        """è¤‡é›‘ãªãƒ†ã‚¹ãƒˆç”¨ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ä½œæˆ"""
        xlsx_path = temp_dir / "advanced_test.xlsx"
        wb = openpyxl.Workbook()

        # ãƒ¡ã‚¤ãƒ³ã‚·ãƒ¼ãƒˆ
        ws = wb.active
        ws.title = "MainSheet"

        # è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ 
        ws["A1"] = "ID"
        ws["B1"] = "Name"
        ws["C1"] = "Data"
        ws["A2"] = "1"
        ws["B2"] = "Test1"
        ws["C2"] = "a,b,c"
        ws["A3"] = "2"
        ws["B3"] = "Test2"
        ws["C3"] = "x,y,z"

        # åˆ¥ã‚·ãƒ¼ãƒˆè¿½åŠ 
        ws2 = wb.create_sheet("SecondSheet")
        ws2["A1"] = "SecondData"
        ws2["B1"] = "Value"

        # åå‰ä»˜ãç¯„å›²å®šç¾©
        set_defined_names(
            wb,
            {
                "json_main_data": "MainSheet!$A$1:$C$3",
                "json_second_data": "SecondSheet!$A$1:$B$1",
                "json_transform_test": "MainSheet!$C$2",
            },
        )

        wb.save(xlsx_path)
        wb.close()
        return xlsx_path

    def test_load_schema_error_handling(self, temp_dir):
        """load_schema: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
        # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«
        non_existent = temp_dir / "non_existent.json"
        with pytest.raises(FileNotFoundError):
            xlsx2json.SchemaLoader.load_schema(non_existent)

        # ç„¡åŠ¹ãªJSON
        invalid_json = temp_dir / "invalid.json"
        with invalid_json.open("w") as f:
            f.write("{ invalid json }")

        with pytest.raises(json.JSONDecodeError):
            xlsx2json.SchemaLoader.load_schema(invalid_json)

    def test_write_data_scenarios(self, temp_dir):
        """write_data: æ§˜ã€…ãªã‚·ãƒŠãƒªã‚ªã®ãƒ†ã‚¹ãƒˆ"""
        # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿
        output_path = temp_dir / "output.json"
        test_data = {"name": "test", "value": 123}
        xlsx2json.write_data(test_data, output_path)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert output_path.exists()

        # å†…å®¹ã®ç¢ºèª
        with output_path.open("r", encoding="utf-8") as f:
            loaded_data = json.load(f)
        assert loaded_data == test_data

    def test_parse_named_ranges_with_transform_rules(self, complex_workbook, temp_dir):
        """parse_named_ranges_with_prefix: å¤‰æ›ãƒ«ãƒ¼ãƒ«ä»˜ããƒ†ã‚¹ãƒˆ"""
        # å¤‰æ›ãƒ«ãƒ¼ãƒ«é©ç”¨ã§ã®è§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(
            complex_workbook, "json", containers={}
        )

        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªï¼ˆãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã«å®šç¾©ã•ã‚ŒãŸåå‰ä»˜ãç¯„å›²ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼‰
        # å®Ÿéš›ã®çµæœã«åŸºã¥ã„ã¦æœŸå¾…å€¤ã‚’èª¿æ•´
        assert isinstance(result, dict)

    def test_validate_cli_containers_error_cases(self):
        """validate_cli_containers: ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # ç„¡åŠ¹ãªJSON
        with pytest.raises(ValueError, match="ç„¡åŠ¹ãªJSONå½¢å¼"):
            xlsx2json.validate_cli_containers(["{ invalid json }"])

        # æ–‡å­—åˆ—ã§ã¯ãªã„å ´åˆ
        with pytest.raises(TypeError):
            xlsx2json.validate_cli_containers([123])

    def test_parse_container_args_complex(self):
        """parse_container_args: è¤‡é›‘ãªå¼•æ•°è§£æãƒ†ã‚¹ãƒˆ"""
        container_args = [
            '{"table1": {"direction": "row", "items": ["id", "name"]}}',
            '{"table2": {"direction": "column", "items": ["col1", "col2"]}}',
        ]
        result = xlsx2json.parse_container_args(container_args)

        expected = {
            "table1": {"direction": "row", "items": ["id", "name"]},
            "table2": {
                "direction": "column",
                "items": ["col1", "col2"],
            },
        }
        assert result == expected


class TestCoverageEnhancement:
    """ã‚«ãƒãƒ¬ãƒƒã‚¸å¼·åŒ–ã®ãŸã‚ã®è¿½åŠ ãƒ†ã‚¹ãƒˆ

    æœªã‚«ãƒãƒ¼é ˜åŸŸã®ç¶²ç¾…çš„ãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹90%ã‚«ãƒãƒ¬ãƒƒã‚¸é”æˆã‚’ç›®æŒ‡ã™
    """

    @pytest.fixture
    def temp_dir(self):
        """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
        temp_path = Path(tempfile.mkdtemp())
        yield temp_path
        shutil.rmtree(temp_path)

    @pytest.fixture
    def mock_workbook(self, temp_dir):
        """ãƒ¢ãƒƒã‚¯ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ä½œæˆ"""
        xlsx_path = temp_dir / "test.xlsx"
        wb = openpyxl.Workbook()
        ws = wb.active

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
        set_cells(
            ws,
            {
                "A1": "Header1",
                "B1": "Header2",
                "A2": "Data1",
                "B2": "Data2",
                "A3": "Data3",
                "B3": "Data4",
            },
        )

        wb.save(xlsx_path)
        wb.close()
        return xlsx_path

    def test_main_function_coverage(self, mock_workbook, temp_dir):
        """mainé–¢æ•°ã®å®Ÿè¡Œãƒ‘ã‚¹ã‚’ãƒ†ã‚¹ãƒˆ"""
        output_dir = temp_dir / "output"

        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(mock_workbook),
                "--output-dir",
                str(output_dir),
            ][index]
            mock_argv.__len__ = lambda _: 4

            result = xlsx2json.main()
            assert result == 0

    def test_container_processing_workflow(self, mock_workbook, temp_dir):
        """ã‚³ãƒ³ãƒ†ãƒŠå‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
        wb = openpyxl.load_workbook(mock_workbook)

        # ãƒ‘ãƒ–ãƒªãƒƒã‚¯é–¢æ•°çµŒç”±ã§ã‚³ãƒ³ãƒ†ãƒŠå‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        config = {
            "containers": {
                "test_container": {
                    "range": "A1:B3",
                    "direction": "row",
                    "items": ["col1", "col2"],
                }
            }
        }
        config_path = temp_dir / "config.json"
        with config_path.open("w", encoding="utf-8") as f:
            json.dump(config, f)

        # parse_named_ranges_with_prefixçµŒç”±ã§ã‚³ãƒ³ãƒ†ãƒŠå‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.parse_named_ranges_with_prefix(
            mock_workbook, "json", containers=config["containers"]
        )

        assert isinstance(result, dict)
        wb.close()

    def test_json_path_container_functionality(self):
        """JSONãƒ‘ã‚¹ã‚³ãƒ³ãƒ†ãƒŠæ©Ÿèƒ½ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
        # ã‚ˆã‚Šç›´æ¥çš„ãªãƒ†ã‚¹ãƒˆï¼šåŸºæœ¬çš„ãªãƒ‘ã‚¹æŒ¿å…¥ã®ãƒ†ã‚¹ãƒˆ
        root = {}

        # é€šå¸¸ã®JSONãƒ‘ã‚¹æŒ¿å…¥ã§åŸºæœ¬å‹•ä½œã‚’ãƒ†ã‚¹ãƒˆ
        xlsx2json.insert_json_path(root, ["data", "items", "1"], "first")
        xlsx2json.insert_json_path(root, ["data", "items", "2"], "second")

        assert isinstance(root["data"]["items"], list)
        assert root["data"]["items"][0] == "first"
        assert root["data"]["items"][1] == "second"

    def test_json_path_complex_nesting(self):
        """JSONãƒ‘ã‚¹ã®è¤‡é›‘ãªãƒã‚¹ãƒˆæ§‹é€ ãƒ†ã‚¹ãƒˆ"""
        root = {}

        # æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã®æ§‹ç¯‰
        xlsx2json.insert_json_path(
            root, ["level1", "level2", "level3", "data"], "deep_value"
        )

        # é…åˆ—ã¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ··åœ¨
        xlsx2json.insert_json_path(root, ["items", "1", "id"], 1)
        xlsx2json.insert_json_path(root, ["items", "1", "name"], "item1")
        xlsx2json.insert_json_path(root, ["items", "2", "id"], 2)
        xlsx2json.insert_json_path(root, ["items", "2", "name"], "item2")

        assert root["level1"]["level2"]["level3"]["data"] == "deep_value"
        assert isinstance(root["items"], list)
        assert len(root["items"]) == 2
        assert root["items"][0]["id"] == 1
        assert root["items"][1]["name"] == "item2"

    def test_array_transformation_edge_cases(self):
        """é…åˆ—å¤‰æ›ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹"""
        # ArrayTransformRuleã®ãƒ†ã‚¹ãƒˆ
        rule = xlsx2json.ArrayTransformRule("test", "split", "split:,")
        rule._transform_func = lambda x: x.split(",") if isinstance(x, str) else x

        # æ§˜ã€…ãªå…¥åŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³
        test_cases = [
            ("", [""]),
            ("single", ["single"]),
            ("a,b,c", ["a", "b", "c"]),
            ("a,,c", ["a", "", "c"]),  # ç©ºè¦ç´ ã‚’å«ã‚€
            (",a,", ["", "a", ""]),  # å‰å¾Œã«ç©ºè¦ç´ 
        ]

        for input_val, expected in test_cases:
            result = rule.transform(input_val)
            assert (
                result == expected
            ), f"Input: {input_val}, Expected: {expected}, Got: {result}"

    def test_unicode_and_special_characters(self):
        """Unicodeæ–‡å­—ã¨ç‰¹æ®Šæ–‡å­—ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        root = {}

        # Unicodeæ–‡å­—ã‚’å«ã‚€ãƒ‘ã‚¹
        xlsx2json.insert_json_path(root, ["æ—¥æœ¬èª", "ãƒ‡ãƒ¼ã‚¿"], "å€¤")
        xlsx2json.insert_json_path(root, ["emoji", "ğŸ˜€"], "smile")
        xlsx2json.insert_json_path(root, ["special", "key with spaces"], "spaced")

        assert root["æ—¥æœ¬èª"]["ãƒ‡ãƒ¼ã‚¿"] == "å€¤"
        assert root["emoji"]["ğŸ˜€"] == "smile"
        assert root["special"]["key with spaces"] == "spaced"

    def test_data_cleaning_comprehensive(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
        # è¤‡é›‘ãªãƒã‚¹ãƒˆæ§‹é€ ã§ã®ç©ºé…åˆ—ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        test_data = {
            "level1": {
                "empty_array": [],
                "mixed_array": ["", None, "data"],
                "nested": {"completely_empty": ["", [None, []]], "has_data": ["value"]},
            },
            "root_empty": [],
        }

        cleaned = xlsx2json.clean_empty_values(test_data)

        # å®Œå…¨ã«ç©ºã®é…åˆ—ã¯å‰Šé™¤ã•ã‚Œã‚‹
        assert "empty_array" not in cleaned["level1"]
        assert "completely_empty" not in cleaned["level1"]["nested"]
        assert "root_empty" not in cleaned

        # ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹é…åˆ—ã¯ä¿æŒã•ã‚Œã‚‹
        assert "mixed_array" in cleaned["level1"]
        assert "has_data" in cleaned["level1"]["nested"]

    def test_main_function_error_scenarios(self, temp_dir):
        """mainé–¢æ•°ã®ã‚¨ãƒ©ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(temp_dir / "nonexistent.xlsx"),
            ][index]
            mock_argv.__len__ = lambda _: 2

            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®å‡¦ç†ã‚’ç¢ºèª
            try:
                result = xlsx2json.main()
                # ã‚¨ãƒ©ãƒ¼å‡¦ç†ã«ã‚ˆã‚Šæ­£å¸¸ã«å‡¦ç†ãŒç¶™ç¶šã•ã‚Œã‚‹å ´åˆã¯0ã‚’è¿”ã™
                assert result in [0, 1], f"äºˆæœŸã—ãªã„æˆ»ã‚Šå€¤: {result}"
            except SystemExit as e:
                # argparseã®ã‚¨ãƒ©ãƒ¼ã§SystemExitãŒç™ºç”Ÿã™ã‚‹å ´åˆ
                assert e.code in [0, 1, 2], f"äºˆæœŸã—ãªã„exit code: {e.code}"

    def test_container_validation_comprehensive(self):
        """ã‚³ãƒ³ãƒ†ãƒŠè¨­å®šã®åŒ…æ‹¬çš„æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        # æ­£å¸¸ãªã‚³ãƒ³ãƒ†ãƒŠè¨­å®š
        valid_containers = {
            "json.table": {
                "direction": "row",
                "items": ["id", "name", "value"],
            }
        }

        # validate_container_configé–¢æ•°ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
        if hasattr(xlsx2json, "validate_container_config"):
            errors = xlsx2json.validate_container_config(valid_containers)
            assert len(errors) == 0

    def test_processing_stats_functionality(self):
        """å‡¦ç†çµ±è¨ˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        stats = xlsx2json.processing_stats

        # ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½
        stats.reset()

        # ã‚¨ãƒ©ãƒ¼è¿½åŠ æ©Ÿèƒ½
        stats.add_error("Test error 1")
        stats.add_error("Test error 2")

        assert len(stats.errors) == 2
        assert "Test error 1" in stats.errors
        assert "Test error 2" in stats.errors

    def test_load_schema_with_broken_json_file(self, temp_dir):
        """load_schemaé–¢æ•°ã§ç ´æã—ãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¸¡ã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        broken_json = temp_dir / "broken.json"
        with broken_json.open("w") as f:
            f.write("{ broken json")

        with pytest.raises(json.JSONDecodeError):
            xlsx2json.SchemaLoader.load_schema(broken_json)

    def test_array_split_and_transform_integration(self):
        """é…åˆ—åˆ†å‰²ã¨å¤‰æ›ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # splitè¦å‰‡ã®ãƒ†ã‚¹ãƒˆ
        split_rules = ["json.data=split:,", "json.items=split:;"]
        parsed_split = xlsx2json.parse_array_split_rules(split_rules, "json.")

        assert "data" in parsed_split
        assert "items" in parsed_split

        # transformè¦å‰‡ã®ãƒ†ã‚¹ãƒˆ
        transform_rules = ["json.data=function:json:loads", "json.items=command:echo"]
        parsed_transform = xlsx2json.parse_array_transform_rules(
            transform_rules, "json."
        )

        assert "data" in parsed_transform
        assert "items" in parsed_transform

    def test_error_boundary_conditions(self):
        """ã‚¨ãƒ©ãƒ¼å¢ƒç•Œæ¡ä»¶ã®ãƒ†ã‚¹ãƒˆ"""
        # ç©ºã‚­ãƒ¼ã§ã®JSONãƒ‘ã‚¹æŒ¿å…¥
        with pytest.raises(ValueError):
            xlsx2json.insert_json_path({}, [], "value")

        # ç„¡åŠ¹ãªã‚¿ã‚¤ãƒ—ã§ã®insert_json_pathï¼ˆé€šå¸¸ã®insert_json_pathã§ãƒ†ã‚¹ãƒˆï¼‰
        with pytest.raises(TypeError, match="insert_json_path: root must be dict"):
            root = "not_dict"
            xlsx2json.insert_json_path(root, ["key"], "value")

    def test_schema_validation_comprehensive(self, temp_dir):
        """ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ã®åŒ…æ‹¬ãƒ†ã‚¹ãƒˆ"""
        # ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        schema_data = {
            "type": "object",
            "properties": {
                "name": {"type": "string"},
                "age": {"type": "number"},
                "items": {"type": "array", "items": {"type": "string"}},
            },
            "required": ["name"],
        }

        schema_file = temp_dir / "test_schema.json"
        with schema_file.open("w") as f:
            json.dump(schema_data, f)

        # ã‚¹ã‚­ãƒ¼ãƒãƒ­ãƒ¼ãƒ‰
        schema = xlsx2json.SchemaLoader.load_schema(schema_file)
        assert schema is not None
        assert schema["type"] == "object"

    def test_workbook_operations_coverage(self, mock_workbook):
        """ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯æ“ä½œã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ†ã‚¹ãƒˆ"""
        wb = openpyxl.load_workbook(mock_workbook)
        position = xlsx2json.get_cell_position_from_name("json.test.1.name", wb)
        assert position is None or isinstance(position, tuple)

        ws = wb.active
        value = xlsx2json.read_cell_value((1, 1), ws)
        assert value is not None or value is None

    def test_parse_container_args_invalid_json(self):
        """ç„¡åŠ¹ãªJSONå¼•æ•°ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        invalid_containers = [
            "invalid_json",
            '{"incomplete": {"range":}',
            '{"valid": {"range": "A1:B2", "items": ["a", "b"]}}',
        ]
        with pytest.raises(ValueError):
            xlsx2json.parse_container_args(invalid_containers)

    def test_samples_list1_expected_grouping(self, tmp_path: Path):
        """
        å¤–éƒ¨samplesã«ä¾å­˜ã›ãšã€ãƒªã‚¹ãƒˆ1ãŒæœŸå¾…ã™ã‚‹ãƒã‚¹ãƒˆé…åˆ—æ§‹é€ ã§ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼ã€‚

        æœŸå¾…:
            ãƒªã‚¹ãƒˆ1 = [
                [
                    {aaaã‚³ãƒ¼ãƒ‰: ['aaa11-1','aaa11-2','aaa11-3'], aaaåç§°: 'aaaåç§°11'},
                    {aaaã‚³ãƒ¼ãƒ‰: ['aaa12-1'], aaaåç§°: 'aaaåç§°12'},
                    {aaaã‚³ãƒ¼ãƒ‰: ['aaa13-1'], aaaåç§°: 'aaaåç§°13'},
                ],
                [
                    {aaaã‚³ãƒ¼ãƒ‰: ['aaa21-1'], aaaåç§°: 'aaaåç§°21'},
                    {aaaã‚³ãƒ¼ãƒ‰: ['aaa22-1'], aaaåç§°: 'aaaåç§°22'},
                ],
                [
                    {aaaã‚³ãƒ¼ãƒ‰: ['aaa31-1'], aaaåç§°: 'aaaåç§°31'},
                ]
            ]
        """
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "Sheet1"

        # è¦ªã‚°ãƒ«ãƒ¼ãƒ— i ã®çŸ©å½¢ï¼ˆB2:F4, B5:F6, B7:F7ï¼‰
        draw_rect_border(ws, top=2, left=2, bottom=4, right=6)
        draw_rect_border(ws, top=5, left=2, bottom=6, right=6)
        draw_rect_border(ws, top=7, left=2, bottom=7, right=6)

        # å€¤é…ç½®ï¼ˆBåˆ—=åç§°, D..F=ã‚³ãƒ¼ãƒ‰, Cåˆ—=ãƒ©ãƒ™ãƒ«ï¼‰
        set_cells(ws, {
            # i=1, j=1..3
            "B2": "aaaåç§°11",
            "D2": "aaa11-1",
            "E2": "aaa11-2",
            "F2": "aaa11-3",
            "B3": "aaaåç§°12",
            "D3": "aaa12-1",
            "B4": "aaaåç§°13",
            "D4": "aaa13-1",
            # i=2, j=1..2
            "B5": "aaaåç§°21",
            "D5": "aaa21-1",
            "B6": "aaaåç§°22",
            "D6": "aaa22-1",
            # i=3, j=1
            "B7": "aaaåç§°31",
            "D7": "aaa31-1",
        })
        for r in [2, 3, 4, 5, 6, 7]:
            ws[f"C{r}"] = "aaaãƒ©ãƒ™ãƒ«"

        # åå‰ä»˜ãç¯„å›²ã®å®šç¾©ï¼ˆè¦ª i ã¨å­ j ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼‰
        set_defined_names(wb, {
            # è¦ª i ã®ç¯„å›²ï¼ˆé€£ç¶šã‚¹ã‚­ãƒ£ãƒ³ã«ã‚ˆã‚Š3ã‚°ãƒ«ãƒ¼ãƒ—ï¼‰
            "json.ãƒªã‚¹ãƒˆ1.1": "Sheet1!$B$2:$F$7",
            # å­ j ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¡Œï¼ˆB2:F2ï¼‰
            "json.ãƒªã‚¹ãƒˆ1.1.1": "Sheet1!$B$2:$F$2",
            # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            "json.ãƒªã‚¹ãƒˆ1.1.1.aaaãƒ©ãƒ™ãƒ«": "Sheet1!$C$2",
            "json.ãƒªã‚¹ãƒˆ1.1.1.aaaåç§°": "Sheet1!$B$2",
            "json.ãƒªã‚¹ãƒˆ1.1.1.aaaã‚³ãƒ¼ãƒ‰": "Sheet1!$D$2:$F$2",
        })

        xlsx_path = tmp_path / "list1_local.xlsx"
        wb.save(xlsx_path)

        # å­ j ã¯ labels ã§åœæ­¢ï¼ˆå„è¡Œã« "aaaãƒ©ãƒ™ãƒ«" ãŒã‚ã‚‹ï¼‰
        containers = {
            "json.ãƒªã‚¹ãƒˆ1.1": {},
            "json.ãƒªã‚¹ãƒˆ1.1.1": {"labels": ["aaaãƒ©ãƒ™ãƒ«"]},
        }

        result = xlsx2json.parse_named_ranges_with_prefix(
            xlsx_path, prefix="json", containers=containers
        )
        lst = result.get("json", {}).get("ãƒªã‚¹ãƒˆ1")
        assert isinstance(lst, list), f"ãƒªã‚¹ãƒˆ1ã¯é…åˆ—: got {type(lst)}"
        assert len(lst) == 3, f"å¤–å´ã¯3ã‚°ãƒ«ãƒ¼ãƒ—: got {len(lst)}"
        # outer[0]
        g0 = lst[0]
        assert isinstance(g0, list) and len(g0) == 3
        assert g0[0]["aaaã‚³ãƒ¼ãƒ‰"] == ["aaa11-1", "aaa11-2", "aaa11-3"]
        assert g0[0]["aaaåç§°"] == "aaaåç§°11"
        assert g0[1]["aaaã‚³ãƒ¼ãƒ‰"] == ["aaa12-1"]
        assert g0[1]["aaaåç§°"] == "aaaåç§°12"
        assert g0[2]["aaaã‚³ãƒ¼ãƒ‰"] == ["aaa13-1"]
        assert g0[2]["aaaåç§°"] == "aaaåç§°13"
        # outer[1]
        g1 = lst[1]
        assert isinstance(g1, list) and len(g1) == 2
        assert g1[0]["aaaã‚³ãƒ¼ãƒ‰"] == ["aaa21-1"]
        assert g1[0]["aaaåç§°"] == "aaaåç§°21"
        assert g1[1]["aaaã‚³ãƒ¼ãƒ‰"] == ["aaa22-1"]
        assert g1[1]["aaaåç§°"] == "aaaåç§°22"
        # outer[2]
        g2 = lst[2]
        assert isinstance(g2, list) and len(g2) == 1
        assert g2[0]["aaaã‚³ãƒ¼ãƒ‰"] == ["aaa31-1"]
        assert g2[0]["aaaåç§°"] == "aaaåç§°31"


class TestContainerShapePreservation:
    def test_preserve_empty_container_shapes_based_on_sibling_nonempty(self, tmp_path: Path):
        """
        åŒéšå±¤ã«æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒç©ºã§ã‚ã£ã¦ã‚‚ã‚­ãƒ¼ã‚’æ®‹ã—ã€
        - é…åˆ— -> []ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ -> {}ã€ãã®ä»– -> null ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
        åŒéšå±¤ãŒå…¨ã¦ç©ºã®å ´åˆã¯ã€ãã®ç©ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚­ãƒ¼ã¯ç”Ÿæˆã—ãªã„ï¼ˆè¦ªã®è¦ç´ ã¯ç©ºè¾æ›¸ç­‰ã«ãªã‚Šå¾—ã‚‹ï¼‰ã€‚
        ã‚¹ã‚­ãƒ¼ãƒã¯å‚ç…§ã—ãªã„ï¼ˆãƒ‡ãƒ¼ã‚¿å®Ÿä½“ã®ç›´ä¸‹å‹ã®ã¿ã§åˆ¤å®šï¼‰ã€‚
        ã¾ãŸã€1æ®µæ·±ã„ãƒã‚¹ãƒˆã®ç©º/æœ‰åŠ¹ã‚±ãƒ¼ã‚¹ã‚‚ã‚«ãƒãƒ¼ã™ã‚‹ã€‚
        """
        # ã‚±ãƒ¼ã‚¹1: åŒéšå±¤ã«æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã¨ãã€ç©ºã‚³ãƒ³ãƒ†ãƒŠ/ç©ºã‚¹ã‚«ãƒ©ã‚’å½¢çŠ¶ç¶­æŒã§æ®‹ã™
        data1 = {
            "outer_list": [
                {
                    "dummy_array_empty": ["", None, "  "],
                    "dummy_object_empty": {"a": None, "b": ""},
                    "dummy_scalar_empty": " ",
                    # æ·±ã„ãƒã‚¹ãƒˆï¼ˆç©ºï¼‰
                    "dummy_object_deep_empty": {"nested": {"x": None, "y": ""}},
                    "dummy_array_deep_empty": [[None, ""], []],
                    # æ·±ã„ãƒã‚¹ãƒˆï¼ˆæœ‰åŠ¹ï¼‰
                    "dummy_object_deep_valid": {"nested": {"x": "ok"}},
                    "dummy_array_deep_valid": [["ok"], []],
                    # åŒéšå±¤ã«æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿
                    "sibling_valid": "OK",
                },
                {
                    "dummy_array_empty": [None, ""],
                    "sibling_valid": "YES",
                },
                {
                    "dummy_object_empty": {},
                    "sibling_valid": "YES",
                },
            ]
        }

        out1 = tmp_path / "out_shapes1.json"
        xlsx2json.write_data(data1, out1, schema=None)
        with out1.open("r", encoding="utf-8") as f:
            obj = json.load(f)
        assert "outer_list" in obj and isinstance(obj["outer_list"], list)
        e0, e1, e2 = obj["outer_list"]

        # æ–°ä»•æ§˜: æ—©æœŸã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã§ç©ºå€¤è¦ç´ ã¯å‰Šé™¤ã•ã‚Œã€è©²å½“ã‚­ãƒ¼è‡ªä½“ãŒå‰Šé™¤ã•ã‚Œã‚‹ã‹
        # ã‚‚ã—ãã¯å€¤ãŒç¸®é€€ï¼ˆ[] ã‚„ {} ã§ã¯ãªãæ—¢å­˜ã®ç©ºå€¤ç¾¤ãŒé™¤å»ã•ã‚ŒãŸå¾Œã®å½¢ï¼‰ã«ãªã‚‹ã€‚
        # ãã®ãŸã‚å­˜åœ¨ã—ãŸå ´åˆã®ã¿ç·©ã„æ¤œè¨¼ã‚’è¡Œã†ã€‚
        if "dummy_array_empty" in e0:
            assert isinstance(e0["dummy_array_empty"], list)
        if "dummy_object_empty" in e0:
            assert isinstance(e0["dummy_object_empty"], dict)
        if "dummy_scalar_empty" in e0:
            # ç©ºç™½ã‚¹ã‚«ãƒ©ã¯é™¤å»å¯¾è±¡ã ã£ãŸãŸã‚æ®‹ã£ã¦ã„ã‚‹ãªã‚‰ç©ºæ–‡å­—/ç©ºç™½é¡ã®ã¿ã‚’è¨±å®¹
            assert isinstance(e0["dummy_scalar_empty"], str)
        # æ·±ã„ç©ºã‚³ãƒ³ãƒ†ãƒŠã¯å…¨å‰Šé™¤ã•ã‚Œå¾—ã‚‹
        if "dummy_object_deep_empty" in e0:
            assert isinstance(e0["dummy_object_deep_empty"], dict)


    def test_missing_sibling_field_emitted_as_null_without_schema(self, tmp_path: Path):
        """
        ã‚¹ã‚­ãƒ¼ãƒéä¾å­˜: åŒéšå±¤ã«æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹è¾æ›¸ã§ã€
        æ¬ è½ï¼ˆå®Ÿä½“ã¯ç©ºå€¤ï¼‰ã®å…„å¼Ÿãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ null ã¨ã—ã¦å‡ºåŠ›ã•ã‚Œã‚‹ã€‚
        ç›´ä¸‹ã®ãƒ‡ãƒ¼ã‚¿å‹ã®ã¿ã§åˆ¤å®šã—ã€ã‚­ãƒ¼ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ã¦ã„ã‚‹ãŒå€¤ãŒç©ºã§ã‚ã‚‹ã“ã¨ã‚’å‰æã¨ã™ã‚‹ã€‚
        """
        data = {
            "dummy_parent": {
                "present_field": "VAL123",
                # æ¬ è½ç›¸å½“ï¼ˆç©ºå€¤ï¼‰
                "missing_field": ""
            }
        }

        out = tmp_path / "out_missing_sibling.json"
        xlsx2json.write_data(data, out, schema=None)

        with out.open("r", encoding="utf-8") as f:
            obj = json.load(f)

        assert "dummy_parent" in obj
        parent = obj["dummy_parent"]
        # æ—¢å­˜ã¯ç¶­æŒ
        assert parent.get("present_field") == "VAL123"
        # æ–°ä»•æ§˜: å…„å¼Ÿ null è£œå®Œã‚’è¡Œã‚ãšç©ºå€¤ã¯ãã®ã¾ã¾ã€ã¾ãŸã¯å‰Šé™¤ã•ã‚Œå¾—ã‚‹
        if "missing_field" in parent:
            assert parent["missing_field"] in ("", None)

        
    def test_preserve_empty_container_shape_without_schema(self, tmp_path: Path):
        """
        æ–°ä»•æ§˜: ã‚¹ã‚­ãƒ¼ãƒç„¡ã— ã‹ã¤ åŒéšå±¤ã«æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã§ã‚‚ã€
        ãƒ«ãƒ¼ãƒˆã§ç©ºæ§‹é€ å…¨æ¶ˆå»ã‚’å¼·åˆ¶ã›ãšã€å…ƒã‚­ãƒ¼ (outer_list) ãŒæ®‹ã‚‹ã“ã¨ã‚’è¨±å®¹ã™ã‚‹ã€‚
        é…ä¸‹ã®å®Œå…¨ç©ºå€¤è¦ç´ ã¯ prune ã«ã‚ˆã‚Šé™¤å»/ç¸®å°ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
        """
        data = {
            "outer_list": [
                {
                    "dummy_array": ["", None, "  "],
                    "dummy_object": {"a": None, "b": ""},
                    "dummy_scalar": " ",
                    "deep_obj": {"n": {"x": None}},
                    "deep_arr": [[], [None, ""]],
                },
                {
                    "dummy_array": [],
                    "dummy_object": {},
                    "dummy_scalar": "",
                },
            ]
        }

        out = tmp_path / "out_no_schema.json"
        xlsx2json.write_data(data, out, schema=None)

        with out.open("r", encoding="utf-8") as f:
            result = json.load(f)
        # æ–°ä»•æ§˜: outer_list ãŒæ®‹ã‚‹ / list å‹ ã§ã‚ã‚‹ã“ã¨ã®ã¿ç¢ºèª
        assert "outer_list" in result and isinstance(result["outer_list"], list)
        # å„è¦ç´ ã¯ pruning å¾Œã®æ®‹å­˜æ§‹é€ ã€‚è¦ç´ æ•°ã¯ >=1 ã‚’æœŸå¾…ï¼ˆå®Œå…¨ç©ºã§ãªã‘ã‚Œã°ï¼‰
        assert len(result["outer_list"]) >= 1
        # å…ˆé ­è¦ç´ ã«ã¤ã„ã¦ç©ºå€¤ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å‰Šé™¤ã¾ãŸã¯ç©ºãƒªã‚¹ãƒˆ/ç©ºæ–‡å­—ã®ã¾ã¾æ®‹å­˜ã‚’è¨±å®¹
        first = result["outer_list"][0]
        assert isinstance(first, dict)
        # å…ƒã€… dummy_array ã¯ç©ºå€¤ã®ã¿ -> å…¨é™¤å»ã•ã‚Œå¾—ã‚‹
        if "dummy_array" in first:
            v = first["dummy_array"]
            assert isinstance(v, list)
            # å…¨ã¦ç©ºå€¤ã ã£ãŸå ´åˆã¯ [] ã«ãªã£ã¦ã„ã‚‹ã‹ã€ç©ºå€¤ãŒæ®‹ã£ã¦ã„ã¦ã‚‚è¨±å®¹
            assert all((x in ("", None) or (isinstance(x, str) and not x.strip())) for x in v) or v == []
        # dummy_object ã‚‚åŒæ§˜ã«ç©ºå€¤æ§‹é€ ãªã®ã§æ®‹ã£ã¦ã„ã‚‹ãªã‚‰å€¤ã¯ç©ºå€¤ã®ã¿
        if "dummy_object" in first:
            dv = first["dummy_object"]
            assert isinstance(dv, dict)
            assert all((vv in (None, "") or (isinstance(vv, str) and not vv.strip())) for vv in dv.values())



def test_command_json_adds_fields_consumed_by_following_command():
    """å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®commandã«ã¤ã„ã¦ã€JSONæ–‡å­—åˆ—â†’è‡ªå‹•ãƒ‘ãƒ¼ã‚¹â†’å¾Œç¶šcommandã¸ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¼æ’­ãŒæ©Ÿèƒ½ã™ã‚‹ã“ã¨ã€‚"""
    # åˆ©ç”¨ã™ã‚‹ Python å®Ÿè¡Œå¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«
    py = sys.executable  # ä¾‹: /usr/bin/python3

    # 1æ®µç›®: stdin ã§å—ã‘å–ã£ãŸã‚¹ã‚«ãƒ©æ–‡å­—åˆ— base ã‚’ JSON {original: base, numbers:[1,2,3]} ã«ã—ã¦å‡ºåŠ›
    code1 = (
        "import sys,json; d=sys.stdin.read().strip(); "
        "print(json.dumps({'original': d, 'numbers':[1,2,3]}, ensure_ascii=False))"
    )
    # 2æ®µç›®: stdin ã§å—ã‘å–ã£ãŸ dict JSON ã‚’ãƒ‘ãƒ¼ã‚¹ã— length ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ ã—ã¦å†å‡ºåŠ›
    code2 = (
        "import sys,json; s=sys.stdin.read(); obj=json.loads(s); "
        "obj['length']=len(obj.get('numbers', [])); print(json.dumps(obj, ensure_ascii=False))"
    )

    rule1 = xlsx2json.ArrayTransformRule(
        "dummy", "command", f"{py} -c \"{code1}\"", trim_enabled=False
    )
    rule2 = xlsx2json.ArrayTransformRule(
        "dummy", "command", f"{py} -c \"{code2}\"", trim_enabled=False
    )

    mid = rule1.transform("base")
    assert mid == {"original": "base", "numbers": [1, 2, 3]}

    final = rule2.transform(mid)
    assert final["original"] == "base"
    assert final["numbers"] == [1, 2, 3]
    assert final["length"] == 3

def test_reorder_json_additional_paths():
    schema = {
        "type": "object",
        "properties": {
            "a": {"type": "string"},
            "b": {"type": "object", "properties": {"x": {"type": "number"}, "y": {"type": "string"}}},
            "c": {"type": "array", "items": {"type": "object", "properties": {"k": {"type": "string"}}}},
        },
    }
    obj = {"c": [{"k": "v"}, {"k": "v2"}], "b": {"y": "str", "x": 10}, "a": "aaa", "z": 123}
    reordered = xlsx2json.reorder_json(obj, schema)
    assert list(reordered.keys())[:3] == ["a", "b", "c"]
    assert reordered["b"]["x"] == 10 and reordered["b"]["y"] == "str"
    assert reordered["c"][1]["k"] == "v2"
    assert reordered["z"] == 123


def test_array_transform_rule_split_multi_delimiters():
    rule = xlsx2json.ArrayTransformRule("json.path", "split", "-|,|;", trim_enabled=False)
    data = "aa-bb,cc;dd"
    res = rule.transform(data)
    assert isinstance(res, list)
    def flatten(xs):
        for x in xs:
            if isinstance(x, list):
                yield from flatten(x)
            else:
                yield x
    flat = list(flatten(res))
    assert {"aa", "bb", "cc", "dd"}.issubset(set(flat))


def test_array_transform_command_non_json_and_multiline():
    py = sys.executable
    code = "import sys; print('L1\\nL2\\nL3')"
    rule = xlsx2json.ArrayTransformRule("dummy", "command", f"{py} -c \"{code}\"", trim_enabled=False)
    out = rule.transform(["A", "B", "C"])
    assert out == ["L1", "L2", "L3"]


def test_array_transform_command_timeout(monkeypatch):
    from subprocess import TimeoutExpired
    import subprocess
    def fake_run(*args, **kwargs):
        raise TimeoutExpired(cmd="fake", timeout=0.01)
    monkeypatch.setattr(subprocess, "run", fake_run)
    rule = xlsx2json.ArrayTransformRule("dummy", "command", "echo", trim_enabled=False)
    result = rule.transform({"k": 1})
    assert result == {"k": 1}


def test_array_transform_command_error(monkeypatch):
    import subprocess
    calls = {"n": 0}
    def fake_run(*args, **kwargs):
        calls["n"] += 1
        if calls["n"] == 1:
            class CP:
                returncode = 0
                stdout = "ok"
                stderr = ""
            return CP()
        raise RuntimeError("boom")
    monkeypatch.setattr(subprocess, "run", fake_run)
    rule = xlsx2json.ArrayTransformRule("dummy", "command", "echo", trim_enabled=False)
    out = rule.transform("x")
    assert out == "x"


def test_insert_json_path_numeric_and_object_merging():
    root = {}
    xlsx2json.insert_json_path(root, ["parent", "items", "1", "name"], "n1")
    xlsx2json.insert_json_path(root, ["parent", "items", "2", "name"], "n2")
    xlsx2json.insert_json_path(root, ["parent", "meta", "info"], "x")
    xlsx2json.insert_json_path(root, ["parent", "meta", "extra"], "y")
    assert root["parent"]["items"][0]["name"] == "n1"
    assert root["parent"]["items"][1]["name"] == "n2"
    assert set(root["parent"]["meta"].keys()) == {"info", "extra"}


def test_clean_empty_values_schema_array_preservation():
    data = {"root": {"arr": ["", None], "obj": {"a": None}}}
    schema = {
        "type": "object",
        "properties": {
            "root": {
                "type": "object",
                "properties": {
                    "arr": {"type": "array", "items": {"type": "string"}},
                    "obj": {"type": "object", "properties": {"a": {"type": "string"}}},
                },
            }
        },
    }
    cleaned = xlsx2json.clean_empty_values(data, schema=schema)
    assert cleaned["root"]["arr"] == []
    if "obj" in cleaned["root"]:
        assert cleaned["root"]["obj"] in ({}, {"a": None})


def test_to_iso_for_validation_datetime():
    import datetime as dt
    d = {"ts": dt.datetime(2024,1,2,3,4,5), "day": dt.date(2024,1,2), "t": dt.time(3,4,5)}
    out = xlsx2json.to_iso_for_validation(d)
    assert out["ts"].startswith("2024-01-02T03:04:05")
    assert out["day"] == "2024-01-02"
    assert out["t"].startswith("03:04:05")


def test_normalize_array_field_shapes_various():
    lst = [
        {"a": 1, "b": [1,2]},
        {"a": 2, "b": [[3,4],[5,6]]},
        {"a": 3, "b": [7,8]}
    ]
    out = xlsx2json.normalize_array_field_shapes(lst)
    assert isinstance(out, list)
    assert all(isinstance(e["b"], list) for e in out)
    assert any(isinstance(e["b"][0], list) for e in out)


def test_write_data_yaml(tmp_path):
    data = {"a":1}
    path = tmp_path / "out.yaml"
    xlsx2json.write_data(data, path, output_format="yaml", schema=None, validator=None)
    assert path.exists() and path.read_text().strip().startswith("a:")


def test_schema_loader_error_cases(tmp_path):
    with pytest.raises(FileNotFoundError):
        xlsx2json.SchemaLoader.load_schema(tmp_path / "missing.json")
    d = tmp_path / "dir"; d.mkdir()
    with pytest.raises(ValueError):
        xlsx2json.SchemaLoader.load_schema(d)


def test_reorder_json_list_items_schema():
    schema = {"type":"array", "items":{"type":"object", "properties":{"x": {"type":"number"}, "y":{"type":"number"}}}}
    obj = [{"y":2,"x":1},{"x":3,"y":4}]
    out = xlsx2json.reorder_json(obj, schema)
    assert out[0]["x"] == 1 and list(out[0].keys())[0] == "x"


# ---------------------------------------------------------------------------
# è¿½åŠ : ã‚·ãƒ¼ã‚±ãƒ³ã‚¹/ç”Ÿæˆå/command JSON set ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã®æœªã‚«ãƒãƒ¼è£œå®Œãƒ†ã‚¹ãƒˆ
# ---------------------------------------------------------------------------


def test_parse_seq_tokens_and_seqindexspec_matches():
    from xlsx2json import parse_seq_tokens, SeqIndexSpec
    # æ•°å€¤ã®ã¿æŠ½å‡ºã•ã‚Œã‚‹
    assert parse_seq_tokens("1-2-abc-003") == ["1", "2", "003"]
    assert parse_seq_tokens(123) == []  # éæ–‡å­—åˆ—
    assert parse_seq_tokens("abc") == []

    # SeqIndexSpec.matches ãƒ‘ã‚¿ãƒ¼ãƒ³
    spec = SeqIndexSpec(ancestor_prefix=("1",), parent_local=2, expected_length=3)
    assert spec.matches("1-2-5") is True           # prefix 1-2, é•·ã•3
    assert spec.matches("1-2") is False            # é•·ã•ä¸è¶³
    assert spec.matches("1-3-5") is False          # prefix ä¸ä¸€è‡´
    assert spec.matches("x-2-5") is False          # æ•°å€¤ãƒˆãƒ¼ã‚¯ãƒ³ã§ãªã„


def test_generate_subarray_names_for_field_anchors(tmp_path):
    import openpyxl
    import xlsx2json

    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "Sheet1"
    ws["B2"] = "v1"; ws["C2"] = "v2"; ws["D2"] = "v3"; ws["E2"] = "v4"
    # openpyxl ã®å†…éƒ¨ API å·®ç•°ã‚’é¿ã‘ã‚‹ãŸã‚ã€generate_subarray_names_for_field_anchors ãŒ
    # åˆ©ç”¨ã™ã‚‹ .defined_names.items() äº’æ›ã ã‘ã‚’æº€ãŸã™ç°¡æ˜“è¾æ›¸ã‚’ç›´æ¥å·®ã—æ›¿ãˆã‚‹ã€‚
    # ï¼ˆä»–ãƒ†ã‚¹ãƒˆã¸å‰¯ä½œç”¨ã‚’ä¸ãˆãªã„ã‚ˆã†ã€ã“ã®ãƒ†ã‚¹ãƒˆå†…ã§ã®ã¿ä½¿ç”¨ï¼‰
    class _FakeDN:
        destinations = [("Sheet1", "$B$2:$E$2")]
    wb.defined_names = {"json.Arr.1.field.1": _FakeDN()}
    xlsx2json.generate_subarray_names_for_field_anchors(wb, "json.")
    gen = xlsx2json.get_generated_names_map(wb)
    assert all(k in gen for k in ("json.Arr.1.field.2", "json.Arr.1.field.3", "json.Arr.1.field.4"))


def test_generate_subarray_names_for_field_anchors_vertical_and_existing_skip():
    """ç¸¦æ–¹å‘(Nx1) ç¯„å›²ã§ã®ç”Ÿæˆã€é€”ä¸­ index ãŒæ—¢å­˜å®šç¾©åãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ã“ã¨ã€‚"""
    import openpyxl
    import xlsx2json
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "S"
    # ç¸¦: B2..B5
    for i, v in enumerate(["a","b","c","d"], start=2):
        ws[f"B{i}"] = v
    class _DN:
        destinations=[("S","$B$2:$B$5")]
    # æ—¢å­˜ã§ .3 ã‚’å®šç¾© -> ç”Ÿæˆã‚¹ã‚­ãƒƒãƒ—æœŸå¾…
    class _DN3:
        destinations=[("S","$B$4")]
    wb.defined_names = {
        "json.Vert.1.col.1": _DN(),
        "json.Vert.1.col.3": _DN3(),
    }
    xlsx2json.generate_subarray_names_for_field_anchors(wb, "json.")
    gen = xlsx2json.get_generated_names_map(wb)
    # .2, .4 ã¯ç”Ÿæˆã€.3 ã¯æ—¢å­˜å®šç¾©ã§ç”Ÿæˆã•ã‚Œãªã„
    assert "json.Vert.1.col.2" in gen
    assert "json.Vert.1.col.4" in gen
    assert "json.Vert.1.col.3" not in gen  # ç”Ÿæˆã•ã‚Œãšï¼ˆæ—¢å­˜å®šç¾©åã¯ _generated_names ã«å…¥ã‚‰ãªã„ï¼‰


def test_check_seq_accept_and_dedup_paths():
    from xlsx2json import check_seq_accept_and_dedup, NumericTokenPolicy
    # has_numeric_series_field = True ãƒ‘ã‚¹
    seen = {}
    pol = NumericTokenPolicy(strict_spec_match=True)
    # æœŸå¾…é•·3, prefix=[1], parent=2 -> "1-2-5" OK
    ok1 = check_seq_accept_and_dedup(policy=pol, expected_len=3, has_numeric_series_field=True,
        seq_like_val="1-2-5", group_indexes=[1], parent_local_index=2, group_key_for_dedup=(1,2), seen_tokens=seen)
    assert ok1 is True and "1-2-5" in seen[(1,2)]
    # é‡è¤‡ -> False
    dup = check_seq_accept_and_dedup(policy=pol, expected_len=3, has_numeric_series_field=True,
        seq_like_val="1-2-5", group_indexes=[1], parent_local_index=2, group_key_for_dedup=(1,2), seen_tokens=seen)
    assert dup is False
    # strict_spec_match True ã§ prefix ä¸ä¸€è‡´ -> False
    bad = check_seq_accept_and_dedup(policy=pol, expected_len=3, has_numeric_series_field=True,
        seq_like_val="9-9-9", group_indexes=[1], parent_local_index=2, group_key_for_dedup=(1,2), seen_tokens=seen)
    assert bad is False
    # has_numeric_series_field False ã§ seq_like_val None -> True (é€šé)
    seen2={}
    ok2 = check_seq_accept_and_dedup(policy=pol, expected_len=3, has_numeric_series_field=False,
        seq_like_val=None, group_indexes=[1], parent_local_index=2, group_key_for_dedup=(1,), seen_tokens=seen2)
    assert ok2 is True and (1,) not in seen2  # None ã¯ dedup ç™»éŒ²ã•ã‚Œãªã„
    # has_numeric_series_field False ã§å€¤ã‚ã‚Š + strict mismatch -> False
    bad2 = check_seq_accept_and_dedup(policy=pol, expected_len=3, has_numeric_series_field=False,
        seq_like_val="9-9", group_indexes=[1], parent_local_index=2, group_key_for_dedup=(1,), seen_tokens=seen2)
    assert bad2 is False


def test_should_skip_by_row_ownership():
    from xlsx2json import should_skip_by_row_ownership, NestedScanPolicy
    pol = NestedScanPolicy(ancestors_first_bounds=True, row_ownership_without_tokens=True)
    used_positions = {"f1": (5, 10), "f2": (6, 10)}  # row=10
    claims = {}
    # åˆå›: non_empty=True ã§ç™»éŒ²ã— False (ã‚¹ã‚­ãƒƒãƒ—ã—ãªã„)
    r1 = should_skip_by_row_ownership(policy=pol, expected_len=2, numeric_token_fields=[], used_positions=used_positions,
        non_empty=True, group_key=(1,), claims_by_group=claims)
    assert r1 is False and 10 in claims[(1,)]
    # 2å›ç›®: åŒ row -> True (ã‚¹ã‚­ãƒƒãƒ—)
    r2 = should_skip_by_row_ownership(policy=pol, expected_len=2, numeric_token_fields=[], used_positions=used_positions,
        non_empty=True, group_key=(1,), claims_by_group=claims)
    assert r2 is True
    # numeric_token_fields ãŒå­˜åœ¨ã™ã‚‹ã¨æŠ‘æ­¢æ¡ä»¶ä¸æˆç«‹ -> False
    r3 = should_skip_by_row_ownership(policy=pol, expected_len=2, numeric_token_fields=["seq"], used_positions=used_positions,
        non_empty=True, group_key=(1,), claims_by_group=claims)
    assert r3 is False


def test_command_transform_serializes_set_and_preserves_structure():
    import sys
    import xlsx2json
    py = sys.executable
    # echo çš„ Python ã‚³ãƒãƒ³ãƒ‰ (stdin ã‚’ãã®ã¾ã¾å‡ºåŠ›)
    code = "import sys; data=sys.stdin.read(); print(data)"
    rule = xlsx2json.ArrayTransformRule("dummy", "command", f"{py} -c \"{code}\"", trim_enabled=False)
    # set ã‚’å«ã‚€ dict ï¼ˆé †åºéæ±ºå®šï¼‰
    data = {"numbers": {5, 1, 3}}
    out = rule.transform(data)
    # JSON ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºæ™‚ã« set -> ã‚½ãƒ¼ãƒˆæ¸ˆã¿ãƒªã‚¹ãƒˆåŒ–ã•ã‚Œã€ãã®å¾Œãƒ‘ãƒ¼ã‚¹å¾©å…ƒ
    assert isinstance(out["numbers"], list)
    assert out["numbers"] == sorted(out["numbers"])  # æ˜‡é †
    assert set(out["numbers"]) == {1,3,5}


def test_compute_excluded_indexed_field_names_cases():
    import types
    import xlsx2json
    # æ§‹æˆ: base ã¨ base.1 ãŒã‚ã‚Š base.1 ãŒå˜ä¸€ã‚»ãƒ« -> é™¤å¤–å¯¾è±¡
    #       range ã¨ range.1 ãŒã‚ã‚Š range.1 ãŒè¤‡æ•°ã‚»ãƒ« -> é™¤å¤–ã•ã‚Œãªã„
    #       broken.1 ã¯ destinations è§£æå¤±æ•—ã§å®‰å…¨å´é™¤å¤–
    class DN1:  # å˜ä¸€ã‚»ãƒ«
        destinations = [("S", "$B$2")]
    class DNRange:  # è¤‡æ•°ã‚»ãƒ«ç¸¦ 2
        destinations = [("S", "$C$2:$C$3")]
    class DNBroken:  # destinations ã«ä¸æ­£å€¤
        destinations = [("S", None)]
    all_names = {
        "json.base": DN1(),
        "json.base.1": DN1(),
        "json.range": DNRange(),
        "json.range.1": DNRange(),
        # broken: base ã‚‚å­˜åœ¨ã•ã›ã¦ç«¶åˆæ¡ä»¶ã‚’æº€ãŸã™ãŒ destinations ãŒè§£æä¸èƒ½/å˜ä¸€ã‚»ãƒ«æ‰±ã„
        "json.broken": DNBroken(),
        "json.broken.1": DNBroken(),
    }
    keys = list(all_names.keys())
    excluded = xlsx2json.compute_excluded_indexed_field_names("json.", keys, all_names)
    assert "json.base.1" in excluded  # å˜ä¸€ã‚»ãƒ« -> é™¤å¤–
    assert "json.range.1" not in excluded  # è¤‡æ•°ã‚»ãƒ« -> æ®‹ã™
    assert "json.broken.1" in excluded  # è§£æå¤±æ•— -> å®‰å…¨å´é™¤å¤–


def test_should_skip_array_anchor_insertion_variants():
    import xlsx2json
    # ç”ŸæˆåãŒç„¡ã„ -> False
    assert xlsx2json.should_skip_array_anchor_insertion("Arr", 0, "json.", None) is False
    # ç”ŸæˆåãŒã‚ã‚‹ãŒ index é•ã„ -> False
    gen_map = {"json.Arr.2.field": "Sheet1!$B$2"}
    assert xlsx2json.should_skip_array_anchor_insertion("Arr", 0, "json.", gen_map) is False
    # ç”ŸæˆåãŒ index=1 (0-based 0) ã®å­ã‚’æŒã¤ -> True
    gen_map2 = {"json.Arr.1.field": "Sheet1!$B$2"}
    assert xlsx2json.should_skip_array_anchor_insertion("Arr", 0, "json.", gen_map2) is True


def test_normalize_array_field_shapes_mixed_2d_and_scalar():
    import xlsx2json
    # list-of-dicts å†…ã§ 'a' ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒ scalar / 1D / 2D æ··åœ¨ â†’ 2Dã¸æ˜‡æ ¼
    data = [
        {"a": 1, "b": [1,2]},                # a: scalar
        {"a": [3,4], "b": [3]},              # a: 1D
        {"a": [[5],[6]], "b": 5},           # a: 2D
    ]
    out = xlsx2json.normalize_array_field_shapes(data)
    assert all(isinstance(row["a"], list) for row in out)
    # a ã¯ 2D ã«çµ±ä¸€ã•ã‚Œæœ€åˆã®è¡Œã‚‚ [[1]] ã®å½¢ã«ãªã‚‹
    assert out[0]["a"] == [[1]] and out[2]["a"] == [[5],[6]]
    # b ã¯ 1D å„ªå…ˆï¼ˆ2D ç„¡ã„ï¼‰â†’ scalar ã¯ [scalar] ã«æ˜‡æ ¼
    assert out[0]["b"] == [1,2]
    assert out[2]["b"] == [5]


def test_reorder_json_preserves_schema_order_and_appends_unknown():
    import xlsx2json
    obj = {"z": 0, "a": 1, "b": {"y": 2, "x": 3}, "c": [{"k": 1, "m": 2}]}
    schema = {
        "properties": {
            "a": {"type": "number"},
            "b": {"type": "object", "properties": {"x": {}, "y": {}}},
            "c": {"type": "array", "items": {"properties": {"m": {}, "k": {}}}},
        }
    }
    re = xlsx2json.reorder_json(obj, schema)
    # ãƒ«ãƒ¼ãƒˆé †: a,b,c (schema) ã®å¾Œã«æœªçŸ¥ã‚­ãƒ¼ z ãŒç¶­æŒ
    assert list(re.keys()) == ["a","b","c","z"]
    # b ã®ä¸­ã‚‚ x,y é †ã€ãã®å¾ŒæœªçŸ¥ã‚­ãƒ¼ç„¡ã—
    assert list(re["b"].keys()) == ["x","y"]
    # c é…åˆ—è¦ç´ ã®ã‚­ãƒ¼é †: m,k (schema é †) â†’ æœªçŸ¥ãªã—
    assert list(re["c"][0].keys()) == ["m","k"]

# =============================================================================
# apply_post_parse_pipeline ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ S1-S4
# =============================================================================

def _mini_pipeline_call(**kwargs):  # helper
    from xlsx2json import apply_post_parse_pipeline  # type: ignore
    return apply_post_parse_pipeline(**kwargs)


def test_apply_post_parse_pipeline_s1_no_containers_fallback_normalize():
    """S1: ã‚³ãƒ³ãƒ†ãƒŠæœªæŒ‡å®š / groupå¸å + å…ˆé ­ç©ºè¦ç´ é™¤å»ã€‚
    group_to_root: lv1->rootA, lv2->rootB
    lv2 å…ˆé ­è¦ç´  {} ã¯é™¤å»ã•ã‚Œã‚‹ã€‚
    """
    result = {"lv1": [{"a": 1}, {"a": 2}], "lv2": [{}, {"x": 10}], "other": 5}
    out = _mini_pipeline_call(
        result=result,
        root_first_pos={"lv1": (0,0,0), "other": (0,1,0), "lv2": (0,2,0)},
        prefix="data",
        user_provided_containers=False,
        containers=None,
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels={"lv1", "lv2"},
        group_to_root={"lv1": "rootA", "lv2": "rootB"},
        gen_map=None,
    )
    assert "lv1" not in out and "lv2" not in out  # å¸åæ¸ˆã¿
    assert out["rootA"]["lv1"][0]["a"] == 1
    # æ—©æœŸãƒ•ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ä»•æ§˜: å…ˆé ­ç©ºè¦ç´  {} ã¯é™¤å»ã•ã‚Œã€æœ€åˆã®è¦ç´ ã¯ {'x':10}
    assert out["rootB"]["lv2"][0] == {"x": 10}
    assert out["other"] == 5


def test_apply_post_parse_pipeline_s2_containers_with_transform():
    """S2: ã‚³ãƒ³ãƒ†ãƒŠ + commandå¤‰æ› + reshapeã€‚
    tbl.colA ã‚’ +100 å¤‰æ›ã€‚ reshape å¾Œ list-of-dictsã€‚
    """
    from xlsx2json import ArrayTransformRule  # type: ignore
    # å…¥åŠ›ã¯ãƒ•ãƒ©ãƒƒãƒˆé…åˆ—ãªã®ã§æ”¹è¡ŒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã§å±Šãä»•æ§˜
    script = "import sys,json;data=[int(x)+100 for x in sys.stdin.read().splitlines() if x.strip()];print(json.dumps(data))"
    cmd_spec = f"python -c \"{script}\""
    rules = {"tbl.colA": [ArrayTransformRule(path="tbl.colA", transform_type="command", transform_spec=cmd_spec)]}
    result = {"data": {"tbl": {"colA": ["1", "2"], "colB": ["3", "4"]}}}
    out = _mini_pipeline_call(
        result=result,
        root_first_pos={"data": (0,0,0)},
        prefix="data",
        user_provided_containers=True,
        containers={"data.tbl": {}},
        array_transform_rules=rules,
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=None,
    )
    tbl = out["data"]["tbl"]
    assert isinstance(tbl, list) and len(tbl) == 2
    assert tbl[0]["colA"] == 101 and tbl[1]["colA"] == 102
    assert tbl[0]["colB"] == "3"  # æœªå¤‰æ›


def test_apply_post_parse_pipeline_s3_prefix_children_replicate_and_order():
    """S3: ã‚³ãƒ³ãƒ†ãƒŠæŒ‡å®šæ™‚ prefix å­è¤‡è£½ + ãƒ«ãƒ¼ãƒˆé †åºå®‰å®šåŒ–ã€‚"""
    result = {"data": {"tbl": 1, "val": 2}, "X": 9, "Y": 10}
    out = _mini_pipeline_call(
        result=result,
        root_first_pos={"data": (0,0,0), "tbl": (0,1,0), "val": (0,2,0), "X": (0,3,0), "Y": (0,4,0)},
        prefix="data",
        user_provided_containers=True,
        containers={},
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels={"lv1"},  # lvå½¢å¼ã®ã¿è¤‡è£½é™¤å¤–å¯¾è±¡
        group_to_root={},
        gen_map=None,
    )
    keys = list(out.keys())
    assert keys[:5] == ["data", "tbl", "val", "X", "Y"]
    assert out["tbl"] == 1 and out["val"] == 2


def test_apply_post_parse_pipeline_s4_generated_names_reconstruct():
    """S4: gen_map ã«ã‚ˆã‚‹å†æ§‹ç¯‰ã§ç¬¬2è¦ç´ ã«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è£œå®Œã€‚"""
    result = {"arr": [{"a": 1}, {}]}
    gen_map = {"data.arr.2.b": 22}
    out = _mini_pipeline_call(
        result=result,
        root_first_pos={"arr": (0,0,0)},
        prefix="data",
        user_provided_containers=False,
        containers=None,
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=gen_map,
    )
    assert out["arr"][1]["b"] == 22
    assert out["arr"][0]["a"] == 1

# =============================================================================
# è¿½åŠ åˆ†å²ãƒ†ã‚¹ãƒˆ batch3
# =============================================================================

def test_get_applicable_transform_rules_parent_vs_wildcard_precedence():
    from xlsx2json import parse_array_transform_rules, get_applicable_transform_rules, ArrayTransformRule
    raw = [
        "data.arr.*.name=split:,",
        "data.arr.1=command:cat",
    ]
    rules = parse_array_transform_rules(raw, prefix="data")
    r = get_applicable_transform_rules(rules, ["arr","1","name"], ["arr","1","name"])
    assert r and r[0].transform_type == "command"


def test_non_wildcard_rule_does_not_apply_to_children():
    """éãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã®å¤‰æ›ãƒ«ãƒ¼ãƒ«ã¯å®Œå…¨ä¸€è‡´ã®ã¿é©ç”¨ã•ã‚Œã€è¦ªã‚­ãƒ¼ä¸€è‡´ã§å­ãƒ‘ã‚¹ã«é©ç”¨ã•ã‚Œãªã„ã“ã¨ã€‚

    READMEã®å¥‘ç´„: ã€Œéãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã¯å®Œå…¨ä¸€è‡´ã€ã€‚æœ¬ãƒ†ã‚¹ãƒˆã¯ get_applicable_transform_rules ã®é¸æŠçµæœãŒ
    è¦ªã‚­ãƒ¼ä¸€è‡´ã§ãƒ’ãƒƒãƒˆã—ãªã„ã“ã¨ã‚’æ¤œè¨¼ã™ã‚‹ã€‚
    """
    import xlsx2json
    # æº–å‚™: è¦ªã‚­ãƒ¼ 'json.root' ã«ã ã‘ãƒ«ãƒ¼ãƒ«ã‚’å®šç¾©ï¼ˆéãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ï¼‰
    rules_map = xlsx2json.parse_array_transform_rules(
        ["json.root=function:builtins:str"], prefix="json", schema=None, trim_enabled=False
    )
    # å¯¾è±¡ãƒ‘ã‚¹ã¯å­ 'root.child'ï¼ˆnormalized/original ã„ãšã‚Œã‚‚åŒã˜ã§OKï¼‰
    normalized = ["root", "child"]
    original = ["root", "child"]
    selected = xlsx2json.get_applicable_transform_rules(rules_map, normalized, original)
    # è¦ªã‚­ãƒ¼ä¸€è‡´ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯ç„¡åŠ¹ã§ã‚ã‚‹ã¹ãï¼ˆNoneã‚’æœŸå¾…ï¼‰
    assert (
        selected is None
    ), "Non-wildcard parent rule must NOT apply to child paths (exact match only)."


def test_command_multiline_raw_no_list_when_not_flat():
    from xlsx2json import ArrayTransformRule, apply_post_parse_pipeline
    script = "import sys;print('L1');print('L2')"
    cmd_spec = f"python -c \"{script}\""
    rule = ArrayTransformRule(path="tbl.colA", transform_type="command", transform_spec=cmd_spec)
    result = {"data": {"tbl": {"colA": [[1,2],[3,4]], "colB": [1,2]}}}
    out = _mini_pipeline_call(
        result=result,
        root_first_pos={"data": (0,0,0)},
        prefix="data",
        user_provided_containers=True,
        containers={"data.tbl": {}},
        array_transform_rules={"tbl.colA": [rule]},
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=None,
    )
    rows = out["data"]["tbl"]
    assert len(rows) == 2 and all("colA" not in r for r in rows)


def test_function_transform_dict_no_expand(monkeypatch):
    from xlsx2json import ArrayTransformRule, apply_post_parse_pipeline
    import types, sys
    mod = types.ModuleType("_tmpmod_funcdict2")
    def f(value):
        return {"gen": 123, "orig_len": len(value)}
    mod.f = f
    sys.modules[mod.__name__] = mod
    rule = ArrayTransformRule(path="tbl.colA", transform_type="function", transform_spec=f"_tmpmod_funcdict2:f")
    result = {"data": {"tbl": {"colA": [10,20], "colB": [1,2]}}}
    out = _mini_pipeline_call(
        result=result,
        root_first_pos={"data": (0,0,0)},
        prefix="data",
        user_provided_containers=True,
        containers={"data.tbl": {}},
        array_transform_rules={"tbl.colA": [rule]},
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=None,
    )
    rows = out["data"]["tbl"]
    assert len(rows) == 2 and all("colA" not in r for r in rows)


def test_reconstruct_non_empty_dict_overwrite_skip():
    from xlsx2json import apply_post_parse_pipeline
    result = {"arr": [{"k": {"inner": 1}}, {}]}
    gen_map = {"data.arr.1.k": 999, "data.arr.2.k": {"x": 2}}
    out = _mini_pipeline_call(
        result=result,
        root_first_pos={"arr": (0,0,0)},
        prefix="data",
        user_provided_containers=False,
        containers=None,
        array_transform_rules=None,
        normalized_prefix="data.",
        group_labels=set(),
        group_to_root={},
        gen_map=gen_map,
    )
    assert out["arr"][0]["k"] == {"inner":1} and out["arr"][1]["k"] == {"x":2}


def test_split_single_delimiter_depth():
    from xlsx2json import ArrayTransformRule
    rule = ArrayTransformRule(path="root.val", transform_type="split", transform_spec=",")
    out = rule.transform("A,B,C")
    assert out == ["A","B","C"]


def test_wildcard_applies_to_scalar_array_elements(tmp_path: Path):
    """ã‚¹ã‚«ãƒ©ãƒ¼è¦ç´ é…åˆ—ã«ã‚‚ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãŒè¦ç´ å˜ä½ã§é©ç”¨ã•ã‚Œã‚‹ã“ã¨ã€‚
    json.root.items.*=function:upper ã§ ["a","b"] -> ["A","B"]
    """
    wb = Workbook(); ws = wb.active; ws.title = "S"
    ws["A1"] = "a"; ws["A2"] = "b"
    set_defined_names(wb, {
        "json.root.items.1": "A1",
        "json.root.items.2": "A2",
    }, default_sheet=ws.title)
    xlsx_path = tmp_path / "scalars.xlsx"; wb.save(xlsx_path)

    rules = xlsx2json.parse_array_transform_rules(
        ["json.root.items.*=function:samples/transform.py:upper"], prefix="json", trim_enabled=False
    )
    result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json", array_transform_rules=rules)
    assert result["root"]["items"] == ["A", "B"]


def test_top_level_completely_empty_returns_empty_object(tmp_path: Path):
    """ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ãŒå®Œå…¨ç©ºã®å ´åˆã€None ã§ã¯ãªã {} ã‚’è¿”ã™ã€‚"""
    wb = Workbook(); ws = wb.active; ws.title = "S"
    # ã™ã¹ã¦ç©ºå€¤
    ws["A1"] = None; ws["A2"] = ""; ws["A3"] = "  "
    set_defined_names(wb, {
        "json.empty.1": "A1",
        "json.empty.2": "A2",
        "json.empty.3": "A3",
    }, default_sheet=ws.title)
    xlsx_path = tmp_path / "empty.xlsx"; wb.save(xlsx_path)

    result = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")
    assert isinstance(result, dict) and result == {}


def test_find_matching_paths_list_element_dicts_are_indexed(tmp_path: Path):
    """find_matching_paths ã¯é…åˆ—ãƒãƒ¼ãƒ‰è‡ªä½“ã‚’è¿”ã•ãšã€
    è¦ç´ ãŒè¾æ›¸ã®å ´åˆã®ã¿ 1 å§‹ã¾ã‚Šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä»˜ãã§è¿”ã™ã€‚"""
    wb = Workbook(); ws = wb.active; ws.title = "S"
    ws["A1"] = "x1"; ws["A2"] = "x2"; ws["B1"] = "y1"
    set_defined_names(wb, {
        "json.root.alphaitems.1.value": "A1",
        "json.root.alphaitems.2.value": "A2",
        "json.root.betaitems.1.value": "B1",
    }, default_sheet=ws.title)
    xlsx_path = tmp_path / "wild.xlsx"; wb.save(xlsx_path)
    data = xlsx2json.parse_named_ranges_with_prefix(xlsx_path, prefix="json")

    paths = xlsx2json.find_matching_paths(data, "root.*items.*")
    # è¦ç´ è¾æ›¸ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä»˜ããƒ‘ã‚¹ã®ã¿
    assert set(paths) == {"root.alphaitems.1", "root.alphaitems.2", "root.betaitems.1"}


def test_find_matching_paths_nested_arrays_with_partial_wildcards():
    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: ãƒã‚¹ãƒˆã—ãŸé…åˆ—æ§‹é€ ï¼ˆdictè¦ç´ ã¨ã‚¹ã‚«ãƒ©ãƒ¼è¦ç´ ã®æ··åœ¨ã‚’å«ã‚€ï¼‰
    data = {
        "root": {
            "lists": [
                {"items": [
                    {"name": "alpha"},
                    {"name": "beta"},
                    {"note": "skip"},
                ]},
                {"items": [
                    {"name": "gamma"},
                    "delta",  # ã‚¹ã‚«ãƒ©ãƒ¼è¦ç´ 
                ]},
            ]
        }
    }

    # ãƒ‘ã‚¿ãƒ¼ãƒ³: éƒ¨åˆ†ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã‚’å«ã‚€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆ"na*"ï¼‰ã§ name ã«ä¸€è‡´ã™ã‚‹è¦ç´ ã®è¾æ›¸ã‚’å¯¾è±¡ã«ã™ã‚‹
    # æœŸå¾…: 1-basedã®ä»®æƒ³ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å«ã‚€ãƒ‘ã‚¹åˆ—æŒ™ã€‚
    # - root.lists.1.items.1.name -> "alpha"
    # - root.lists.1.items.2.name -> "beta"
    # - root.lists.2.items.1.name -> "gamma"
    from xlsx2json import find_matching_paths, get_nested_value

    pattern = "root.lists.*.items.*.na*"
    matches = find_matching_paths(data, pattern)

    assert sorted(matches) == [
        "root.lists.1.items.1.name",
        "root.lists.1.items.2.name",
        "root.lists.2.items.1.name",
    ]

    # ãƒãƒƒãƒã—ãŸå„ãƒ‘ã‚¹ã®æœ«ç«¯å€¤ã‚’æ¤œè¨¼
    values = [get_nested_value(data, p) for p in matches]
    assert sorted(values) == ["alpha", "beta", "gamma"]

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    pytest.main([__file__, "-v"])

