#!/usr/bin/env python3
"""
xlsx2json.py ã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

ã“ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã®ä¸»è¦æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ï¼š
- åŸºæœ¬çš„ãªåå‰ä»˜ãç¯„å›²ã®è§£æ
- ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã®æ§‹ç¯‰
- é…åˆ—ãƒ»å¤šæ¬¡å…ƒé…åˆ—ã®å¤‰æ›
- å¤‰æ›ãƒ«ãƒ¼ãƒ«ï¼ˆsplit, function, commandï¼‰
- JSON Schema ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
- è¨˜å·ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†

READMEã¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‚è€ƒã«ã€å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å³ã—ãŸãƒ†ã‚¹ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚
"""

import pytest
import json
import tempfile
import shutil
from pathlib import Path
from unittest.mock import patch, MagicMock
import argparse
import logging
import subprocess
import sys
import os
from datetime import datetime, date

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆsys.argvã‚’ãƒ¢ãƒƒã‚¯ã—ã¦å®‰å…¨ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
import unittest.mock

sys.path.insert(0, str(Path(__file__).parent))
with unittest.mock.patch.object(sys, "argv", ["test"]):
    import xlsx2json

# openpyxlã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ï¼‰
import openpyxl
from openpyxl import Workbook, load_workbook
from openpyxl.workbook.defined_name import DefinedName

# jsonschemaã¯å¸¸ã«åˆ©ç”¨å¯èƒ½ã¨æƒ³å®š
from jsonschema import Draft7Validator


class DataCreator:
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""

    def __init__(self, temp_dir: Path):
        self.temp_dir = temp_dir
        self.workbook = None
        self.worksheet = None

    def create_basic_workbook(self) -> Path:
        """åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
        self.workbook = Workbook()
        self.worksheet = self.workbook.active
        self.worksheet.title = "Sheet1"

        # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å‹ã®ãƒ†ã‚¹ãƒˆ
        self.worksheet["A1"] = "å±±ç”°å¤ªéƒ"
        self.worksheet["A2"] = "æ±äº¬éƒ½æ¸‹è°·åŒº"
        self.worksheet["A3"] = 123
        self.worksheet["A4"] = 45.67
        self.worksheet["A5"] = datetime(2025, 1, 15, 10, 30, 0)
        self.worksheet["A6"] = date(2025, 1, 19)  # å›ºå®šæ—¥ä»˜ã«å¤‰æ›´
        self.worksheet["A7"] = True
        self.worksheet["A8"] = False
        self.worksheet["A9"] = ""  # ç©ºã‚»ãƒ«
        self.worksheet["A10"] = None  # Noneã‚»ãƒ«

        # é…åˆ—åŒ–ç”¨ã®ãƒ‡ãƒ¼ã‚¿
        self.worksheet["B1"] = "apple,banana,orange"
        self.worksheet["B2"] = "1,2,3,4,5"
        self.worksheet["B3"] = "ã‚¿ã‚°1,ã‚¿ã‚°2,ã‚¿ã‚°3"

        # å¤šæ¬¡å…ƒé…åˆ—ç”¨ã®ãƒ‡ãƒ¼ã‚¿
        self.worksheet["C1"] = "A,B;C,D"  # 2æ¬¡å…ƒ
        self.worksheet["C2"] = "a1,a2\nb1,b2\nc1,c2"  # æ”¹è¡Œã¨ã‚«ãƒ³ãƒ
        self.worksheet["C3"] = "x1,x2|y1,y2;z1,z2|w1,w2"  # 3æ¬¡å…ƒ

        # æ—¥æœ¬èªãƒ»è¨˜å·ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿
        self.worksheet["D1"] = "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ"
        self.worksheet["D2"] = "è¨˜å·ãƒ†ã‚¹ãƒˆï¼ï¼ ï¼ƒï¼„ï¼…"
        self.worksheet["D3"] = "æ”¹è¡Œ\nãƒ†ã‚¹ãƒˆ\nãƒ‡ãƒ¼ã‚¿"

        # ãƒã‚¹ãƒˆæ§‹é€ ç”¨ã®ãƒ‡ãƒ¼ã‚¿
        self.worksheet["E1"] = "æ·±ã„éšå±¤ã®ãƒ†ã‚¹ãƒˆ"
        self.worksheet["E2"] = "ã•ã‚‰ã«æ·±ã„å€¤"

        # åå‰ä»˜ãç¯„å›²ã‚’å®šç¾©
        self._define_basic_names()

        # ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        file_path = self.temp_dir / "basic_test.xlsx"
        self.workbook.save(file_path)
        return file_path

    def _define_basic_names(self):
        """åŸºæœ¬çš„ãªåå‰ä»˜ãç¯„å›²ã‚’å®šç¾©"""
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹
        self._add_named_range("json.customer.name", "Sheet1!$A$1")
        self._add_named_range("json.customer.address", "Sheet1!$A$2")
        self._add_named_range("json.numbers.integer", "Sheet1!$A$3")
        self._add_named_range("json.numbers.float", "Sheet1!$A$4")
        self._add_named_range("json.datetime", "Sheet1!$A$5")
        self._add_named_range("json.date", "Sheet1!$A$6")
        self._add_named_range("json.flags.enabled", "Sheet1!$A$7")
        self._add_named_range("json.flags.disabled", "Sheet1!$A$8")
        self._add_named_range("json.empty_cell", "Sheet1!$A$9")
        self._add_named_range("json.null_cell", "Sheet1!$A$10")

        # é…åˆ—åŒ–å¯¾è±¡
        self._add_named_range("json.tags", "Sheet1!$B$1")
        self._add_named_range("json.numbers.array", "Sheet1!$B$2")
        self._add_named_range("json.japanese_tags", "Sheet1!$B$3")

        # å¤šæ¬¡å…ƒé…åˆ—
        self._add_named_range("json.matrix", "Sheet1!$C$1")
        self._add_named_range("json.grid", "Sheet1!$C$2")
        self._add_named_range("json.cube", "Sheet1!$C$3")

        # æ—¥æœ¬èªãƒ»è¨˜å·
        self._add_named_range("json.japanese.greeting", "Sheet1!$D$1")
        self._add_named_range("json.japanese.symbols", "Sheet1!$D$2")
        self._add_named_range("json.multiline", "Sheet1!$D$3")

        # ãƒã‚¹ãƒˆæ§‹é€ 
        self._add_named_range("json.deep.level1.level2.level3.value", "Sheet1!$E$1")
        self._add_named_range("json.deep.level1.level2.level4.value", "Sheet1!$E$2")

        # é…åˆ—ã®ãƒã‚¹ãƒˆ
        self._add_named_range("json.items.1.name", "Sheet1!$A$1")
        self._add_named_range("json.items.1.price", "Sheet1!$A$3")
        self._add_named_range("json.items.2.name", "Sheet1!$A$2")
        self._add_named_range("json.items.2.price", "Sheet1!$A$4")

    def create_wildcard_workbook(self) -> Path:
        """è¨˜å·ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
        self.workbook = Workbook()
        self.worksheet = self.workbook.active
        self.worksheet.title = "Sheet1"  # æ˜ç¤ºçš„ã«ã‚·ãƒ¼ãƒˆåã‚’è¨­å®š

        # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ç”¨ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        self.worksheet["A1"] = "ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼‘"
        self.worksheet["A2"] = "ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼’"
        self.worksheet["A3"] = "ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼“"

        # è¨˜å·ã‚’å«ã‚€åå‰ï¼ˆã‚¹ã‚­ãƒ¼ãƒã§è§£æ±ºã•ã‚Œã‚‹äºˆå®šï¼‰
        self._add_named_range("json.user_name", "Sheet1!$A$1")  # ãã®ã¾ã¾ä¸€è‡´
        self._add_named_range("json.user_group", "Sheet1!$A$2")  # userï¼group ã«ãƒãƒƒãƒ
        self._add_named_range("json.user_", "Sheet1!$A$3")  # è¤‡æ•°ãƒãƒƒãƒã®ã‚±ãƒ¼ã‚¹

        file_path = self.temp_dir / "wildcard_test.xlsx"
        self.workbook.save(file_path)
        return file_path

    def create_transform_workbook(self) -> Path:
        """å¤‰æ›ãƒ«ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
        self.workbook = Workbook()
        self.worksheet = self.workbook.active
        self.worksheet.title = "Sheet1"  # æ˜ç¤ºçš„ã«ã‚·ãƒ¼ãƒˆåã‚’è¨­å®š

        # å¤‰æ›ç”¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        self.worksheet["A1"] = "apple,banana,orange"
        self.worksheet["A2"] = "1;2;3|4;5;6"
        self.worksheet["A3"] = "line1\nline2\nline3"
        self.worksheet["A4"] = "  trim_test  "
        self.worksheet["A5"] = "command_test_data"

        # åå‰ä»˜ãç¯„å›²å®šç¾©
        self._add_named_range("json.split_comma", "Sheet1!$A$1")
        self._add_named_range("json.split_multi", "Sheet1!$A$2")
        self._add_named_range("json.split_newline", "Sheet1!$A$3")
        self._add_named_range("json.function_test", "Sheet1!$A$4")
        self._add_named_range("json.command_test", "Sheet1!$A$5")

        file_path = self.temp_dir / "transform_test.xlsx"
        self.workbook.save(file_path)
        return file_path

    def create_complex_workbook(self) -> Path:
        """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
        self.workbook = Workbook()
        self.worksheet = self.workbook.active
        self.worksheet.title = "Sheet1"  # æ˜ç¤ºçš„ã«ã‚·ãƒ¼ãƒˆåã‚’è¨­å®š

        # è¤‡é›‘ãªæ§‹é€ ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ãï¼‰
        data_values = {
            "A1": "ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ",
            "A2": "é–‹ç™ºéƒ¨",
            "A3": "ç”°ä¸­èŠ±å­",
            "A4": "tanaka@example.com",
            "A5": "03-1234-5678",
            "B1": "ãƒ†ã‚¹ãƒˆéƒ¨",
            "B2": "ä½è—¤æ¬¡éƒ",
            "B3": "sato@example.com",
            "B4": "03-5678-9012",
            "C1": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆÎ±",
            "C2": "2025-01-01",
            "C3": "2025-12-31",
            "C4": "é€²è¡Œä¸­",
            "D1": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆÎ²",
            "D2": "2025-03-01",
            "D3": "2025-06-30",
            "D4": "å®Œäº†",
            "E1": "ã‚¿ã‚¹ã‚¯1,ã‚¿ã‚¹ã‚¯2,ã‚¿ã‚¹ã‚¯3",
            "E2": "é«˜,ä¸­,ä½",
            "E3": "2025-02-01,2025-02-15,2025-03-01",
            # è¦ªé…åˆ—ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆsamplesã«åŸºã¥ãï¼‰
            "F1": "G2",
            "F2": "H2a1,H2b1\nH2a2,H2b2",
            "G1": "G3a1,G3b1\nG3a2",
            "G2": "H3a1\nH3a2",
            "H1": "H5",
        }

        for cell, value in data_values.items():
            self.worksheet[cell] = value

        # è¤‡é›‘ãªåå‰ä»˜ãç¯„å›²ã‚’å®šç¾©
        self._define_complex_names()

        file_path = self.temp_dir / "complex_test.xlsx"
        self.workbook.save(file_path)
        return file_path

    def _define_complex_names(self):
        """è¤‡é›‘ãªæ§‹é€ ã®åå‰ä»˜ãç¯„å›²ã‚’å®šç¾©"""
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        self._add_named_range("json.system.name", "Sheet1!$A$1")

        # éƒ¨ç½²æƒ…å ±ï¼ˆé…åˆ—ï¼‰
        self._add_named_range("json.departments.1.name", "Sheet1!$A$2")
        self._add_named_range("json.departments.1.manager.name", "Sheet1!$A$3")
        self._add_named_range("json.departments.1.manager.email", "Sheet1!$A$4")
        self._add_named_range("json.departments.1.manager.phone", "Sheet1!$A$5")

        self._add_named_range("json.departments.2.name", "Sheet1!$B$1")
        self._add_named_range("json.departments.2.manager.name", "Sheet1!$B$2")
        self._add_named_range("json.departments.2.manager.email", "Sheet1!$B$3")
        self._add_named_range("json.departments.2.manager.phone", "Sheet1!$B$4")

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ï¼ˆé…åˆ—ï¼‰
        self._add_named_range("json.projects.1.name", "Sheet1!$C$1")
        self._add_named_range("json.projects.1.start_date", "Sheet1!$C$2")
        self._add_named_range("json.projects.1.end_date", "Sheet1!$C$3")
        self._add_named_range("json.projects.1.status", "Sheet1!$C$4")

        self._add_named_range("json.projects.2.name", "Sheet1!$D$1")
        self._add_named_range("json.projects.2.start_date", "Sheet1!$D$2")
        self._add_named_range("json.projects.2.end_date", "Sheet1!$D$3")
        self._add_named_range("json.projects.2.status", "Sheet1!$D$4")

        # é…åˆ—åŒ–å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿
        self._add_named_range("json.tasks", "Sheet1!$E$1")
        self._add_named_range("json.priorities", "Sheet1!$E$2")
        self._add_named_range("json.deadlines", "Sheet1!$E$3")

        # å¤šæ¬¡å…ƒé…åˆ—ã®ãƒ†ã‚¹ãƒˆï¼ˆsamplesã®parentã«åŸºã¥ãï¼‰
        self._add_named_range("json.parent.1.1", "Sheet1!$F$1")
        self._add_named_range("json.parent.1.2", "Sheet1!$F$2")
        self._add_named_range("json.parent.2.1", "Sheet1!$G$1")
        self._add_named_range("json.parent.2.2", "Sheet1!$G$2")
        self._add_named_range("json.parent.3.1", "Sheet1!$H$1")

    def _add_named_range(self, name: str, range_ref: str):
        """åå‰ä»˜ãç¯„å›²ã‚’è¿½åŠ """
        # Excelå½¢å¼ã®ã‚»ãƒ«å‚ç…§ã«ä¿®æ­£ï¼ˆ$è¨˜å·ã¯ä¸è¦ï¼‰
        defined_name = DefinedName(name, attr_text=range_ref)
        self.workbook.defined_names.add(defined_name)

    def create_schema_file(self) -> Path:
        """ãƒ†ã‚¹ãƒˆç”¨ã®JSON Schemaãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        schema = {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "title": "Test Schema",
            "type": "object",
            "properties": {
                "customer": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "address": {"type": "string"},
                    },
                    "required": ["name"],
                },
                "numbers": {
                    "type": "object",
                    "properties": {
                        "integer": {"type": "number"},
                        "float": {"type": "number"},
                        "array": {"type": "array", "items": {"type": "string"}},
                    },
                },
                "tags": {"type": "array", "items": {"type": "string"}},
                "matrix": {
                    "type": "array",
                    "items": {"type": "array", "items": {"type": "string"}},
                },
                "user_name": {"type": "string"},
                "userï¼group": {"type": "string"},
                "userï¼": {"type": "string"},
                "userï¼Ÿ": {"type": "string"},
                "items": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string"},
                            "price": {"type": "number"},
                        },
                    },
                },
                "parent": {
                    "type": "array",
                    "description": "4æ¬¡å…ƒé…åˆ—(ç¸¦Ã—æ¨ªÃ—ã‚»ãƒ«å†…ç¸¦Ã—æ¨ª)",
                    "items": {
                        "type": "array",
                        "description": "3æ¬¡å…ƒé…åˆ—(æ¨ªÃ—ã‚»ãƒ«å†…ç¸¦Ã—æ¨ª)",
                        "items": {
                            "type": "array",
                            "description": "2æ¬¡å…ƒé…åˆ—(ã‚»ãƒ«å†…ç¸¦Ã—æ¨ª)",
                            "items": {
                                "type": "array",
                                "description": "1æ¬¡å…ƒé…åˆ—(ã‚»ãƒ«å†…æ¨ª)",
                                "items": {"type": "string", "description": "æ–‡å­—åˆ—"},
                            },
                        },
                    },
                },
            },
        }

        schema_file = self.temp_dir / "test_schema.json"
        with schema_file.open("w", encoding="utf-8") as f:
            json.dump(schema, f, ensure_ascii=False, indent=2)

        return schema_file

    def create_wildcard_schema_file(self) -> Path:
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ã®JSON Schemaãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        schema = {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "title": "Wildcard Test Schema",
            "type": "object",
            "properties": {
                "user_name": {"type": "string"},
                "userï¼group": {"type": "string"},
                "userï¼": {"type": "string"},
                "userï¼Ÿ": {"type": "string"},
            },
        }

        schema_file = self.temp_dir / "wildcard_schema.json"
        with schema_file.open("w", encoding="utf-8") as f:
            json.dump(schema, f, ensure_ascii=False, indent=2)

        return schema_file


def create_temp_excel(workbook):
    """ãƒ†ã‚¹ãƒˆç”¨ã®ä¸€æ™‚çš„ãªExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    temp_file = tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False)
    workbook.save(temp_file.name)
    temp_file.close()
    return temp_file.name


class TestNamedRanges:
    """åå‰ä»˜ãç¯„å›²ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture(scope="class")
    def temp_dir(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)

    @pytest.fixture(scope="class")
    def creator(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’æä¾›"""
        return DataCreator(temp_dir)

    @pytest.fixture(scope="class")
    def basic_xlsx(self, creator):
        """åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_basic_workbook()

    @pytest.fixture(scope="class")
    def wildcard_xlsx(self, creator):
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_wildcard_workbook()

    @pytest.fixture(scope="class")
    def transform_xlsx(self, creator):
        """å¤‰æ›ãƒ«ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_transform_workbook()

    @pytest.fixture(scope="class")
    def complex_xlsx(self, creator):
        """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_complex_workbook()

    @pytest.fixture(scope="class")
    def schema_file(self, creator):
        """JSON Schemaãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_schema_file()

    @pytest.fixture(scope="class")
    def wildcard_schema_file(self, creator):
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_wildcard_schema_file()

    @pytest.fixture(scope="class")
    def transform_file(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆç”¨ã®å¤‰æ›é–¢æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        transform_content = '''
def trim_and_upper(value):
    """æ–‡å­—åˆ—ã‚’ãƒˆãƒªãƒ ã—ã¦å¤§æ–‡å­—åŒ–"""
    if isinstance(value, str):
        return value.strip().upper()
    return value

def multiply_by_two(value):
    """æ•°å€¤ã‚’2å€ã«ã™ã‚‹"""
    try:
        return float(value) * 2
    except (ValueError, TypeError):
        return value

def csv_split(value):
    """CSVå½¢å¼ã§åˆ†å‰²"""
    if not isinstance(value, str):
        return value
    import csv
    from io import StringIO
    reader = csv.reader(StringIO(value))
    return [row for row in reader if any(cell.strip() for cell in row)]
'''

        transform_file = temp_dir / "test_transforms.py"
        with transform_file.open("w", encoding="utf-8") as f:
            f.write(transform_content)

        return transform_file

    # === åå‰ä»˜ãç¯„å›²ã®æ ¸å¿ƒå‡¦ç†ãƒ†ã‚¹ãƒˆ ===

    def test_extract_basic_data_types(self, basic_xlsx):
        """åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹ã®æŠ½å‡ºã¨å¤‰æ›ç¢ºèª

        Excelåå‰ä»˜ãç¯„å›²ã‹ã‚‰æ–‡å­—åˆ—ã€æ•°å€¤ã€çœŸå½å€¤ã€æ—¥æ™‚ã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã€
        é©åˆ‡ãªPythonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        # æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿å‹ã®æ¤œè¨¼
        assert result["customer"]["name"] == "å±±ç”°å¤ªéƒ"
        assert result["customer"]["address"] == "æ±äº¬éƒ½æ¸‹è°·åŒº"

        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿å‹ã®æ¤œè¨¼
        assert result["numbers"]["integer"] == 123
        assert result["numbers"]["float"] == 45.67

        # çœŸå½å€¤ãƒ‡ãƒ¼ã‚¿å‹ã®æ¤œè¨¼
        assert result["flags"]["enabled"] is True
        assert result["flags"]["disabled"] is False

        # æ—¥æ™‚å‹ã®æ¤œè¨¼ï¼ˆdatetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å–å¾—ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
        assert isinstance(result["datetime"], datetime)
        assert isinstance(result["date"], date)

    def test_build_nested_json_structure(self, basic_xlsx):
        """ãƒã‚¹ãƒˆã—ãŸJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®æ§‹ç¯‰

        ãƒ‰ãƒƒãƒˆè¨˜æ³•ã®åå‰ä»˜ãç¯„å›²ã‹ã‚‰éšå±¤çš„ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒ
        æ­£ã—ãæ§‹ç¯‰ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æƒ…å ±ã®ãƒã‚¹ãƒˆæ§‹é€ 
        assert "customer" in result
        assert isinstance(result["customer"], dict)
        assert result["customer"]["name"] == "å±±ç”°å¤ªéƒ"

        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¹ãƒˆæ§‹é€ 
        assert "numbers" in result
        assert isinstance(result["numbers"], dict)
        assert result["numbers"]["integer"] == 123

        # æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã®ç¢ºèª
        deep_value = result["deep"]["level1"]["level2"]["level3"]["value"]
        assert deep_value == "æ·±ã„éšå±¤ã®ãƒ†ã‚¹ãƒˆ"

        deep_value2 = result["deep"]["level1"]["level2"]["level4"]["value"]
        assert deep_value2 == "ã•ã‚‰ã«æ·±ã„å€¤"

    def test_construct_array_structures(self, basic_xlsx):
        """é…åˆ—æ§‹é€ ã®è‡ªå‹•æ§‹ç¯‰

        æ•°å€¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æŒã¤åå‰ä»˜ãç¯„å›²ã‹ã‚‰é…åˆ—ãŒæ­£ã—ãæ§‹ç¯‰ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        # é…åˆ—æ§‹é€ ã®ç¢ºèª
        items = result["items"]
        assert isinstance(items, list)
        assert len(items) == 2

        # 1ç•ªç›®ã®ã‚¢ã‚¤ãƒ†ãƒ 
        assert items[0]["name"] == "å±±ç”°å¤ªéƒ"
        assert items[0]["price"] == 123

        # 2ç•ªç›®ã®ã‚¢ã‚¤ãƒ†ãƒ 
        assert items[1]["name"] == "æ±äº¬éƒ½æ¸‹è°·åŒº"
        assert items[1]["price"] == 45.67

    def test_handle_empty_and_null_values(self, basic_xlsx):
        """ç©ºå€¤ã¨NULLå€¤ã®é©åˆ‡ãªå‡¦ç†

        Excelã®ç©ºã‚»ãƒ«ã€NULLå€¤ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        # åŸºæœ¬çš„ãªçµæœã®å­˜åœ¨ã‚’ãƒ†ã‚¹ãƒˆ
        assert isinstance(result, dict)
        assert len(result) > 0

    def test_custom_prefix_support(self, temp_dir):
        """ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

        æŒ‡å®šã—ãŸãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»¥å¤–ã®åå‰ä»˜ãç¯„å›²ãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ç”¨ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        workbook = Workbook()
        worksheet = workbook.active
        worksheet.title = "Sheet1"
        worksheet["A1"] = "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ"

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§åå‰ä»˜ãç¯„å›²ã‚’å®šç¾©
        defined_name = DefinedName("custom.test.value", attr_text="Sheet1!$A$1")
        workbook.defined_names.add(defined_name)

        custom_file = temp_dir / "custom_prefix.xlsx"
        workbook.save(custom_file)

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§è§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(custom_file, prefix="custom")

        assert result["test"]["value"] == "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ"

    def test_single_cell_vs_range_extraction(self, temp_dir):
        """å˜ä¸€ã‚»ãƒ«ã¨ç¯„å›²ã®å€¤æŠ½å‡ºã®åŒºåˆ¥

        åå‰ä»˜ãç¯„å›²ãŒå˜ä¸€ã‚»ãƒ«ã‹ç¯„å›²ã‹ã«ã‚ˆã£ã¦é©åˆ‡ãªå½¢å¼ã§å€¤ãŒè¿”ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        workbook = Workbook()
        worksheet = workbook.active
        worksheet.title = "Sheet1"

        # å˜ä¸€ã‚»ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿
        worksheet["A1"] = "single_value"
        # ç¯„å›²ç”¨ã®ãƒ‡ãƒ¼ã‚¿
        worksheet["B1"] = "range_value1"
        worksheet["B2"] = "range_value2"

        # å˜ä¸€ã‚»ãƒ«ã®åå‰ä»˜ãç¯„å›²
        single_name = DefinedName("single_cell", attr_text="Sheet1!$A$1")
        workbook.defined_names.add(single_name)

        # ç¯„å›²ã®åå‰ä»˜ãç¯„å›²
        range_name = DefinedName("cell_range", attr_text="Sheet1!$B$1:$B$2")
        workbook.defined_names.add(range_name)

        test_file = temp_dir / "range_test.xlsx"
        workbook.save(test_file)

        # ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿
        wb = xlsx2json.load_workbook(test_file, data_only=True)

        # å˜ä¸€ã‚»ãƒ«ã¯å€¤ã®ã¿è¿”ã™ã“ã¨ã‚’ç¢ºèª
        single_name_def = wb.defined_names["single_cell"]
        single_result = xlsx2json.get_named_range_values(wb, single_name_def)
        assert single_result == "single_value"
        assert not isinstance(single_result, list)

        # ç¯„å›²ã¯ãƒªã‚¹ãƒˆã§è¿”ã™ã“ã¨ã‚’ç¢ºèª
        range_name_def = wb.defined_names["cell_range"]
        range_result = xlsx2json.get_named_range_values(wb, range_name_def)
        assert isinstance(range_result, list)
        assert range_result == ["range_value1", "range_value2"]

    def test_multidimensional_array_construction(self, complex_xlsx):
        """å¤šæ¬¡å…ƒé…åˆ—ã®æ§‹ç¯‰ï¼ˆsamplesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä»•æ§˜æº–æ‹ ï¼‰

        ãƒ‰ãƒƒãƒˆè¨˜æ³•ã«ã‚ˆã‚‹å¤šæ¬¡å…ƒé…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰é©åˆ‡ãªæ§‹é€ ãŒæ§‹ç¯‰ã•ã‚Œã‚‹ã“ã¨ã‚’æ¤œè¨¼
        """
        result = xlsx2json.parse_named_ranges_with_prefix(complex_xlsx, prefix="json")

        # å¤šæ¬¡å…ƒé…åˆ—ã®ç¢ºèª
        parent = result["parent"]
        assert isinstance(parent, list)
        assert len(parent) == 3

        # å„æ¬¡å…ƒã®ç¢ºèª
        assert isinstance(parent[0], list)
        assert len(parent[0]) == 2

        # å…·ä½“çš„ãªå€¤ã®ç¢ºèªï¼ˆå®Ÿéš›ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãï¼‰
        assert parent[0][0] == "G2"  # F1ã‚»ãƒ«ã®å€¤
        # F2ã‚»ãƒ«ã¯è¤‡æ•°è¡Œãƒ‡ãƒ¼ã‚¿ãªã®ã§æ–‡å­—åˆ—ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹
        assert isinstance(parent[0][1], str)
        assert parent[1][0] == "G3a1,G3b1\nG3a2"  # G1ã‚»ãƒ«ã®å€¤

    def test_parse_named_ranges_enhanced_validation(self):
        """parse_named_ranges_with_prefixé–¢æ•°ã®æ‹¡å¼µãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ
            nonexistent_file = temp_path / "nonexistent.xlsx"
            with pytest.raises(
                FileNotFoundError, match="Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            ):
                xlsx2json.parse_named_ranges_with_prefix(nonexistent_file, "json")

            # æ–‡å­—åˆ—ãƒ‘ã‚¹ã§ã‚‚å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            test_file = temp_path / "test.xlsx"
            wb = Workbook()
            wb.save(test_file)

            # æ–‡å­—åˆ—ãƒ‘ã‚¹ã§å‘¼ã³å‡ºã—
            result = xlsx2json.parse_named_ranges_with_prefix(str(test_file), "json")
            assert isinstance(result, dict)

            # ç©ºã®prefixã®ãƒ†ã‚¹ãƒˆ
            with pytest.raises(
                ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            ):
                xlsx2json.parse_named_ranges_with_prefix(test_file, "")

    def test_error_handling_integration(self):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # æ­£å¸¸ãªExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            test_file = temp_path / "test.xlsx"
            wb = Workbook()
            ws = wb.active
            ws["A1"] = "test_value"

            # åå‰ä»˜ãç¯„å›²ã‚’è¿½åŠ 
            defined_name = DefinedName("json.test", attr_text="Sheet!$A$1")
            wb.defined_names.add(defined_name)
            wb.save(test_file)

            # æ­£å¸¸ãªã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ
            result = xlsx2json.parse_named_ranges_with_prefix(test_file, "json")
            assert "test" in result
            assert result["test"] == "test_value"

            # ç„¡åŠ¹ãªprefixã§ã‚¨ãƒ©ãƒ¼
            with pytest.raises(
                ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            ):
                xlsx2json.parse_named_ranges_with_prefix(test_file, None)

    # === Containeræ©Ÿèƒ½ï¼šExcelç¯„å›²è§£æãƒ»åº§æ¨™è¨ˆç®—ãƒ†ã‚¹ãƒˆ ===

    def test_excel_range_parsing_basic(self):
        """åŸºæœ¬çš„ãªExcelç¯„å›²æ–‡å­—åˆ—ã®è§£æãƒ†ã‚¹ãƒˆ"""
        start_coord, end_coord = xlsx2json.parse_range("B2:D4")
        assert start_coord == (2, 2)  # Båˆ—=2, 2è¡Œç›®
        assert end_coord == (4, 4)    # Dåˆ—=4, 4è¡Œç›®

    def test_excel_range_parsing_single_cell(self):
        """å˜ä¸€ã‚»ãƒ«æŒ‡å®šã®æ­£å¸¸å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        start_coord, end_coord = xlsx2json.parse_range("A1:A1")
        assert start_coord == (1, 1)
        assert end_coord == (1, 1)

    def test_excel_range_parsing_large_range(self):
        """å¤§ããªç¯„å›²æŒ‡å®šã§ã®åº§æ¨™å¤‰æ›ç²¾åº¦ãƒ†ã‚¹ãƒˆ"""
        start_coord, end_coord = xlsx2json.parse_range("A1:Z100")
        assert start_coord == (1, 1)
        assert end_coord == (26, 100)  # Zåˆ—=26

    def test_excel_range_parsing_error_handling(self):
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã§èµ·ã“ã‚Šã†ã‚‹ä¸æ­£ãªç¯„å›²æŒ‡å®šã®ã‚¨ãƒ©ãƒ¼å‡¦ç†"""
        with pytest.raises(ValueError, match="ç„¡åŠ¹ãªç¯„å›²å½¢å¼"):
            xlsx2json.parse_range("INVALID")
        
        with pytest.raises(ValueError, match="ç„¡åŠ¹ãªç¯„å›²å½¢å¼"):
            xlsx2json.parse_range("A1-B2")  # ã‚³ãƒ­ãƒ³ãŒå¿…è¦


class TestComplexData:
    """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ãƒ†ã‚¹ãƒˆ"""

    def test_complex_transform_rule_conflicts(self):
        """è¤‡é›‘ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ç«¶åˆã¨å„ªå…ˆåº¦ãƒ†ã‚¹ãƒˆ"""
        # è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’ä½œæˆ
        wb = Workbook()
        ws = wb.active
        ws.title = "TestData"

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è¨­å®š
        ws["A1"] = "data1,data2,data3"  # splitå¯¾è±¡
        ws["B1"] = "100"  # intå¤‰æ›å¯¾è±¡
        ws["C1"] = "true"  # boolå¤‰æ›å¯¾è±¡
        ws["D1"] = "2023-12-01"  # dateå¤‰æ›å¯¾è±¡

        # åå‰ä»˜ãç¯„å›²ã®è¨­å®šï¼ˆæ–°ã—ã„APIä½¿ç”¨ï¼‰
        defined_name = DefinedName("json.test_data", attr_text="TestData!$A$1:$D$1")
        wb.defined_names.add(defined_name)

        temp_file = create_temp_excel(wb)
        try:
            # çµæœã‚’å–å¾—ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ãªãç›´æ¥è§£æï¼‰
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # çµæœã®æ¤œè¨¼ï¼ˆåŸºæœ¬çš„ãªå¤‰æ›ãŒè¡Œã‚ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
            assert "test_data" in result
            test_data = result["test_data"]
            # parse_named_ranges_with_prefixã¯ç¯„å›²ã®å€¤ã‚’å¹³å¦åŒ–ã—ã¦è¿”ã™
            assert len(test_data) == 4  # A1:D1ã®4ã¤ã®ã‚»ãƒ«
            assert test_data[0] == "data1,data2,data3"
            assert test_data[1] == "100"
            assert test_data[2] == "true"
            assert test_data[3] == "2023-12-01"

        finally:
            os.unlink(temp_file)

    def test_deeply_nested_json_paths(self):
        """æ·±ã„ãƒã‚¹ãƒˆã®JSONãƒ‘ã‚¹ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        ws["A1"] = "level1_data"
        ws["B1"] = "level2_data"
        ws["C1"] = "level3_data"
        ws["D1"] = "level4_data"

        # åå‰ä»˜ãç¯„å›²ã®è¨­å®šï¼ˆæ–°ã—ã„APIä½¿ç”¨ï¼‰
        defined_name = DefinedName("json.nested_data", attr_text="Sheet!$A$1:$D$1")
        wb.defined_names.add(defined_name)

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç¢ºèª
            assert "nested_data" in result
            nested_data = result["nested_data"]
            # ç¯„å›²A1:D1ã®4ã¤ã®ã‚»ãƒ«ã®å€¤ãŒå¹³å¦åŒ–ã•ã‚Œã‚‹
            assert len(nested_data) == 4
            assert nested_data[0] == "level1_data"
            assert nested_data[1] == "level2_data"
            assert nested_data[2] == "level3_data"
            assert nested_data[3] == "level4_data"

        finally:
            os.unlink(temp_file)

    def test_multidimensional_arrays_with_complex_transforms(self):
        """å¤šæ¬¡å…ƒé…åˆ—ã¨è¤‡é›‘ãªå¤‰æ›ã®çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # 2æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®è¨­å®š
        data = [
            ["1,2,3", "a,b,c", "true,false,true"],
            ["4,5,6", "d,e,f", "false,true,false"],
            ["7,8,9", "g,h,i", "true,true,false"],
        ]

        for i, row in enumerate(data, 1):
            for j, cell in enumerate(row, 1):
                ws.cell(row=i, column=j, value=cell)

        # åå‰ä»˜ãç¯„å›²ã®è¨­å®šï¼ˆæ–°ã—ã„APIä½¿ç”¨ï¼‰
        defined_name = DefinedName("json.matrix_data", attr_text="Sheet!$A$1:$C$3")
        wb.defined_names.add(defined_name)

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # çµæœã®æ¤œè¨¼
            assert "matrix_data" in result
            matrix_data = result["matrix_data"]
            # 3x3ã®ç¯„å›²ãªã®ã§9å€‹ã®ã‚»ãƒ«å€¤ãŒå¹³å¦åŒ–ã•ã‚Œã‚‹
            assert len(matrix_data) == 9

            # ãƒ‡ãƒ¼ã‚¿ã®é †åºç¢ºèªï¼ˆè¡Œå„ªå…ˆã§å¹³å¦åŒ–ã•ã‚Œã‚‹ï¼‰
            expected_values = [
                "1,2,3",
                "a,b,c",
                "true,false,true",
                "4,5,6",
                "d,e,f",
                "false,true,false",
                "7,8,9",
                "g,h,i",
                "true,true,false",
            ]

            for i, expected in enumerate(expected_values):
                assert (
                    matrix_data[i] == expected
                ), f"ä½ç½®{i}ã®ãƒ‡ãƒ¼ã‚¿ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™"

        finally:
            os.unlink(temp_file)

    def test_schema_validation_with_wildcard_resolution(self):
        """ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ã¨ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰è§£æ±ºã®è¤‡é›‘ãªçµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ 
        ws["A1"] = "user1"
        ws["B1"] = "25"
        ws["C1"] = "user1@example.com"
        ws["A2"] = "user2"
        ws["B2"] = "30"
        ws["C2"] = "user2@example.com"

        # åå‰ä»˜ãç¯„å›²ã®è¨­å®šï¼ˆæ–°ã—ã„APIä½¿ç”¨ï¼‰
        defined_name = DefinedName("json.users", attr_text="Sheet!$A$1:$C$2")
        wb.defined_names.add(defined_name)

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç¢ºèª
            assert "users" in result
            users = result["users"]
            # 2x3ã®ç¯„å›²ãªã®ã§6å€‹ã®ã‚»ãƒ«å€¤ãŒå¹³å¦åŒ–ã•ã‚Œã‚‹
            assert len(users) == 6

            # ãƒ‡ãƒ¼ã‚¿ã®é †åºç¢ºèªï¼ˆè¡Œå„ªå…ˆã§å¹³å¦åŒ–ã•ã‚Œã‚‹ï¼‰
            expected_values = [
                "user1",
                "25",
                "user1@example.com",
                "user2",
                "30",
                "user2@example.com",
            ]
            for i, expected in enumerate(expected_values):
                assert users[i] == expected, f"ä½ç½®{i}ã®ãƒ‡ãƒ¼ã‚¿ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™"

        finally:
            os.unlink(temp_file)

    def test_error_recovery_scenarios(self):
        """ã‚¨ãƒ©ãƒ¼å›å¾©ã‚·ãƒŠãƒªã‚ªã®ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # ä¸€éƒ¨ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        ws["A1"] = "valid_data"
        ws["B1"] = "not_a_number"  # æ•°å€¤å¤‰æ›ã§å¤±æ•—ã™ã‚‹
        ws["C1"] = "2023-13-40"  # ç„¡åŠ¹ãªæ—¥ä»˜
        ws["A2"] = "valid_data2"
        ws["B2"] = "123"  # æœ‰åŠ¹ãªæ•°å€¤
        ws["C2"] = "2023-12-01"  # æœ‰åŠ¹ãªæ—¥ä»˜

        # åå‰ä»˜ãç¯„å›²ã®è¨­å®šï¼ˆæ–°ã—ã„APIä½¿ç”¨ï¼‰
        defined_name = DefinedName("json.mixed_data", attr_text="Sheet!$A$1:$C$2")
        wb.defined_names.add(defined_name)

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å›å¾©ã®ç¢ºèª
            assert "mixed_data" in result
            mixed_data = result["mixed_data"]
            # 2x3ã®ç¯„å›²ãªã®ã§6å€‹ã®ã‚»ãƒ«å€¤ãŒå¹³å¦åŒ–ã•ã‚Œã‚‹
            assert len(mixed_data) == 6

            # ãƒ‡ãƒ¼ã‚¿ã®é †åºç¢ºèªï¼ˆè¡Œå„ªå…ˆã§å¹³å¦åŒ–ã•ã‚Œã‚‹ï¼‰
            expected_values = [
                "valid_data",
                "not_a_number",
                "2023-13-40",
                "valid_data2",
                "123",
                "2023-12-01",
            ]
            for i, expected in enumerate(expected_values):
                assert mixed_data[i] == expected, f"ä½ç½®{i}ã®ãƒ‡ãƒ¼ã‚¿ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™"

        finally:
            os.unlink(temp_file)

    def test_complex_wildcard_patterns(self):
        """è¤‡é›‘ãªãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # è¤‡é›‘ãªãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
        ws["A1"] = "item_001"
        ws["B1"] = "item_002"
        ws["C1"] = "special_item"
        ws["A2"] = "item_003"
        ws["B2"] = "item_004"
        ws["C2"] = "another_special"

        # è¤‡æ•°ã®åå‰ä»˜ãç¯„å›²ã§ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ†ã‚¹ãƒˆ
        defined_name1 = DefinedName("json.prefix.item.1", attr_text="Sheet!$A$1")
        defined_name2 = DefinedName("json.prefix.item.2", attr_text="Sheet!$B$1")
        defined_name3 = DefinedName("json.prefix.special.main", attr_text="Sheet!$C$1")
        defined_name4 = DefinedName("json.other.item.3", attr_text="Sheet!$A$2")
        wb.defined_names.add(defined_name1)
        wb.defined_names.add(defined_name2)
        wb.defined_names.add(defined_name3)
        wb.defined_names.add(defined_name4)

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å±•é–‹ç¢ºèª
            assert "prefix" in result
            assert "other" in result

            # prefixé…ä¸‹ã®æ§‹é€ ç¢ºèª
            prefix = result["prefix"]
            assert "item" in prefix
            assert "special" in prefix

            # itemé…ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª
            items = prefix["item"]
            assert "1" in items or len(items) >= 1
            assert "2" in items or len(items) >= 2

        finally:
            os.unlink(temp_file)

    def test_unicode_and_special_characters(self):
        """Unicodeæ–‡å­—ã¨ç‰¹æ®Šæ–‡å­—ã®ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # æ§˜ã€…ãªUnicodeæ–‡å­—ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        unicode_data = [
            "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ",  # æ—¥æœ¬èª
            "ğŸŒğŸŒğŸŒ",  # çµµæ–‡å­—
            "HÃ¤llo WÃ¶rld",  # ã‚¦ãƒ ãƒ©ã‚¦ãƒˆ
            "Ğ—Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹ Ğ¼Ğ¸Ñ€",  # ã‚­ãƒªãƒ«æ–‡å­—
            "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…",  # ã‚¢ãƒ©ãƒ“ã‚¢æ–‡å­—
            "ğ“—ğ“®ğ“µğ“µğ“¸ ğ“¦ğ“¸ğ“»ğ“µğ“­",  # æ•°å­¦æ–‡å­—
            '"quotes"',  # ã‚¯ã‚©ãƒ¼ãƒˆ
            "line\nbreak",  # æ”¹è¡Œ
            "tab\there",  # ã‚¿ãƒ–
        ]

        for i, data in enumerate(unicode_data, 1):
            ws.cell(row=i, column=1, value=data)

        # åå‰ä»˜ãç¯„å›²ã®è¨­å®š
        defined_name = DefinedName(
            "json.unicode_test", attr_text=f"Sheet!$A$1:$A${len(unicode_data)}"
        )
        wb.defined_names.add(defined_name)

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, prefix="json")

            # Unicodeæ–‡å­—ã®æ­£ã—ã„å‡¦ç†ç¢ºèª
            assert "unicode_test" in result
            unicode_result = result["unicode_test"]
            # 9è¡Œx1åˆ—ã®ç¯„å›²ãªã®ã§9å€‹ã®å€¤ãŒè¿”ã•ã‚Œã‚‹
            assert len(unicode_result) == len(unicode_data)

            # å„æ–‡å­—ã®æ­£ç¢ºæ€§ç¢ºèªï¼ˆå¹³å¦åŒ–ã•ã‚Œã¦ã„ã‚‹ã®ã§ç›´æ¥æ¯”è¼ƒï¼‰
            for i, expected in enumerate(unicode_data):
                assert (
                    unicode_result[i] == expected
                ), f"Unicodeæ–‡å­—ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œã¦ã„ã¾ã›ã‚“: {expected}"

        finally:
            os.unlink(temp_file)

    def test_edge_case_cell_values(self):
        """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãªã‚»ãƒ«å€¤ã®ãƒ†ã‚¹ãƒˆ"""
        wb = Workbook()
        ws = wb.active

        # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãªãƒ‡ãƒ¼ã‚¿
        edge_cases = [
            None,  # Noneã‚»ãƒ«
            "",  # ç©ºæ–‡å­—åˆ—
            " ",  # ã‚¹ãƒšãƒ¼ã‚¹ã®ã¿
            0,  # ã‚¼ãƒ­
            False,  # False
            True,  # True
            float("inf"),  # ç„¡é™å¤§
            -float("inf"),  # è² ã®ç„¡é™å¤§
            1e-10,  # éå¸¸ã«å°ã•ãªæ•°
            1e10,  # éå¸¸ã«å¤§ããªæ•°
            "0",  # æ–‡å­—åˆ—ã®ã‚¼ãƒ­
            "False",  # æ–‡å­—åˆ—ã®False
            " \t\n ",  # ç©ºç™½æ–‡å­—ã®ã¿
        ]

        for i, value in enumerate(edge_cases, 1):
            try:
                ws.cell(row=i, column=1, value=value)
            except (ValueError, TypeError):
                # è¨­å®šã§ããªã„å€¤ã¯æ–‡å­—åˆ—ã¨ã—ã¦è¨­å®š
                ws.cell(row=i, column=1, value=str(value))

        # åå‰ä»˜ãç¯„å›²ã®è¨­å®š
        defined_name = DefinedName(
            "json.edge_cases", attr_text=f"Sheet!$A$1:$A${len(edge_cases)}"
        )
        wb.defined_names.add(defined_name)

        temp_file = create_temp_excel(wb)
        try:
            result = xlsx2json.parse_named_ranges_with_prefix(temp_file, "json")
            assert "edge_cases" in result
            
            # çµæœã®æ¤œè¨¼ï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèªï¼‰
            assert len(result["edge_cases"]) == len(edge_cases)
            
        finally:
            os.unlink(temp_file)

    # === Containeræ©Ÿèƒ½ï¼šæ§‹é€ è§£æãƒ»ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ¤œå‡ºãƒ†ã‚¹ãƒˆ ===

    def test_container_structure_vertical_analysis(self):
        """ç¸¦æ–¹å‘ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        start_coord = (2, 2)  # B2
        end_coord = (4, 4)    # D4
        
        # vertical direction: è¡Œæ•°ã‚’æ•°ãˆã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰è¡Œæ•°ï¼‰
        count = xlsx2json.detect_instance_count(start_coord, end_coord, "vertical")
        assert count == 3  # 2,3,4è¡Œç›® = 3ãƒ¬ã‚³ãƒ¼ãƒ‰

    def test_container_structure_horizontal_analysis(self):
        """æ¨ªæ–¹å‘ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        start_coord = (2, 2)  # B2
        end_coord = (4, 4)    # D4
        
        # horizontal direction: åˆ—æ•°ã‚’æ•°ãˆã‚‹ï¼ˆæœŸé–“æ•°ï¼‰
        count = xlsx2json.detect_instance_count(start_coord, end_coord, "horizontal")
        assert count == 3  # B,C,Dåˆ— = 3æœŸé–“

    def test_container_structure_single_record(self):
        """å˜ä¸€ãƒ¬ã‚³ãƒ¼ãƒ‰æ§‹é€ ã®æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        count = xlsx2json.detect_instance_count((1, 1), (1, 1), "vertical")
        assert count == 1

    def test_container_structure_invalid_direction(self):
        """ç„¡åŠ¹ãªé…ç½®æ–¹å‘ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        with pytest.raises(ValueError, match="ç„¡åŠ¹ãªdirection"):
            xlsx2json.detect_instance_count((1, 1), (2, 2), "invalid")

    def test_container_structure_column_analysis(self):
        """åˆ—æ–¹å‘ï¼ˆcolumnï¼‰æ§‹é€ ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        start_coord = (2, 2)  # B2
        end_coord = (4, 4)    # D4
        
        # column direction: åˆ—æ•°ã‚’æ•°ãˆã‚‹ï¼ˆhorizontal ã¨åŒã˜å‹•ä½œï¼‰
        count = xlsx2json.detect_instance_count(start_coord, end_coord, "column")
        assert count == 3  # B,C,Dåˆ— = 3åˆ—

    # === Containeræ©Ÿèƒ½ï¼šãƒ‡ãƒ¼ã‚¿å‡¦ç†çµ±åˆãƒ†ã‚¹ãƒˆ ===

    def test_dataset_processing_complete_workflow(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†ã®å…¨ä½“ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # CONTAINER_SPEC.mdã®ãƒ‡ãƒ¼ã‚¿ä¾‹ã«åŸºã¥ãè¨­å®š
        container_config = {
            "range": "B2:D4",
            "direction": "vertical", 
            "items": ["æ—¥ä»˜", "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£", "å€¤"],
            "labels": True
        }
        
        # Step 1: Excelç¯„å›²è§£æ
        start_coord, end_coord = xlsx2json.parse_range(container_config["range"])
        assert start_coord == (2, 2)
        assert end_coord == (4, 4)
        
        # Step 2: ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°æ¤œå‡º
        record_count = xlsx2json.detect_instance_count(start_coord, end_coord, container_config["direction"])
        assert record_count == 3
        
        # Step 3: ãƒ‡ãƒ¼ã‚¿ç”¨ã‚»ãƒ«åç”Ÿæˆ
        cell_names = xlsx2json.generate_cell_names(
            "dataset", start_coord, end_coord,
            container_config["direction"], container_config["items"]
        )
        assert len(cell_names) == 9  # 3ãƒ¬ã‚³ãƒ¼ãƒ‰ x 3é …ç›®
        
        # Step 4: ãƒ‡ãƒ¼ã‚¿JSONæ§‹é€ æ§‹ç¯‰
        result = {}
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        xlsx2json.insert_json_path(result, ["ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«", "ã‚¿ã‚¤ãƒˆãƒ«"], "æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿å®Ÿç¸¾")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰
        test_data = {
            "dataset_1_æ—¥ä»˜": "2024-01-15", "dataset_1_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£": "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£A", "dataset_1_å€¤": 150000,
            "dataset_2_æ—¥ä»˜": "2024-01-20", "dataset_2_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£": "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£B", "dataset_2_å€¤": 200000,
            "dataset_3_æ—¥ä»˜": "2024-01-25", "dataset_3_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£": "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£C", "dataset_3_å€¤": 180000
        }
        
        for cell_name in cell_names:
            if cell_name in test_data:
                xlsx2json.insert_json_path(result, [cell_name], test_data[cell_name])
        
        # æŠ€è¡“è¦ä»¶æ¤œè¨¼
        assert "ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«" in result
        assert result["ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"]["ã‚¿ã‚¤ãƒˆãƒ«"] == "æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿å®Ÿç¸¾"
        assert result["dataset_1_æ—¥ä»˜"] == "2024-01-15"
        assert result["dataset_2_å€¤"] == 200000

    def test_multi_table_data_integration(self):
        """è¤‡æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»ãƒªã‚¹ãƒˆï¼‰ã®çµ±åˆãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        tables = {
            "dataset": {"range": "A1:B2", "direction": "vertical", "items": ["æœˆ", "å€¤"]},
            "list": {"range": "D1:E2", "direction": "vertical", "items": ["é …ç›®", "æ•°é‡"]}
        }
        
        result = {}
        
        for table_name, config in tables.items():
            start_coord, end_coord = xlsx2json.parse_range(config["range"])
            cell_names = xlsx2json.generate_cell_names(
                table_name, start_coord, end_coord,
                config["direction"], config["items"]
            )
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
            for i, cell_name in enumerate(cell_names):
                xlsx2json.insert_json_path(result, [cell_name], f"{table_name}ãƒ‡ãƒ¼ã‚¿{i+1}")
        
        # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãçµ±åˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert "dataset_1_æœˆ" in result
        assert "dataset_2_å€¤" in result
        assert "list_1_é …ç›®" in result
        assert "list_2_æ•°é‡" in result
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç‹¬ç«‹æ€§ç¢ºèª
        assert result["dataset_1_æœˆ"] == "datasetãƒ‡ãƒ¼ã‚¿1"
        assert result["list_1_é …ç›®"] == "listãƒ‡ãƒ¼ã‚¿1"

    def test_data_card_layout_workflow(self):
        """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚«ãƒ¼ãƒ‰å‹ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
        # ã‚«ãƒ¼ãƒ‰å‹ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
        card_config = {
            "range": "A1:A3",
            "direction": "vertical",
            "increment": 5,  # ã‚«ãƒ¼ãƒ‰é–“éš”
            "items": ["ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å", "è­˜åˆ¥å­", "ä½æ‰€"],
            "labels": True
        }
        
        start_coord, end_coord = xlsx2json.parse_range(card_config["range"])
        entity_count = xlsx2json.detect_instance_count(start_coord, end_coord, card_config["direction"])
        
        cell_names = xlsx2json.generate_cell_names(
            "entity", start_coord, end_coord,
            card_config["direction"], card_config["items"]
        )
        
        result = {}
        
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
        entity_data = {
            "entity_1_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å": "å±±ç”°å¤ªéƒ", "entity_1_è­˜åˆ¥å­": "03-1234-5678", "entity_1_ä½æ‰€": "æ±äº¬éƒ½",
            "entity_2_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å": "ä½è—¤èŠ±å­", "entity_2_è­˜åˆ¥å­": "06-9876-5432", "entity_2_ä½æ‰€": "å¤§é˜ªåºœ",
            "entity_3_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å": "ç”°ä¸­æ¬¡éƒ", "entity_3_è­˜åˆ¥å­": "052-1111-2222", "entity_3_ä½æ‰€": "æ„›çŸ¥çœŒ"
        }
        
        for cell_name in cell_names:
            if cell_name in entity_data:
                xlsx2json.insert_json_path(result, [cell_name], entity_data[cell_name])
        
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§ç¢ºèª
        assert result["entity_1_ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å"] == "å±±ç”°å¤ªéƒ"
        assert result["entity_2_è­˜åˆ¥å­"] == "06-9876-5432"
        assert result["entity_3_ä½æ‰€"] == "æ„›çŸ¥çœŒ"

    # === Containeræ©Ÿèƒ½ï¼šã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ ===

    def test_container_system_integration_comprehensive(self):
        """Excelç¯„å›²å‡¦ç†ã‹ã‚‰JSONçµ±åˆã¾ã§å…¨æ©Ÿèƒ½é€£æºãƒ†ã‚¹ãƒˆ"""
        # è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’åŒæ™‚å‡¦ç†
        test_configs = [
            {
                "name": "å£²ä¸Š",
                "range": "B2:D4", 
                "direction": "vertical",
                "items": ["æ—¥ä»˜", "é¡§å®¢", "é‡‘é¡"]
            },
            {
                "name": "inventory",
                "range": "F1:H2",
                "direction": "vertical", 
                "items": ["ã‚¢ã‚¤ãƒ†ãƒ ã‚³ãƒ¼ãƒ‰", "ã‚¢ã‚¤ãƒ†ãƒ å", "æ•°é‡"]
            }
        ]
        
        consolidated_result = {}
        
        for config in test_configs:
            # å„æ©Ÿèƒ½ã®é€£æºå‹•ä½œç¢ºèª
            start_coord, end_coord = xlsx2json.parse_range(config["range"])
            instance_count = xlsx2json.detect_instance_count(start_coord, end_coord, config["direction"])
            cell_names = xlsx2json.generate_cell_names(
                config["name"], start_coord, end_coord, 
                config["direction"], config["items"]
            )
            
            # ã‚·ã‚¹ãƒ†ãƒ çµ±åˆã§ã®æ­£å¸¸æ€§ç¢ºèª
            assert len(cell_names) == instance_count * len(config["items"])
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŠ•å…¥
            for i, cell_name in enumerate(cell_names):
                xlsx2json.insert_json_path(consolidated_result, [cell_name], f"çµ±åˆãƒ‡ãƒ¼ã‚¿{i+1}")
        
        # çµ±åˆçµæœã®å¥å…¨æ€§ç¢ºèª
        assert "å£²ä¸Š_1_æ—¥ä»˜" in consolidated_result
        assert "inventory_1_ã‚¢ã‚¤ãƒ†ãƒ ã‚³ãƒ¼ãƒ‰" in consolidated_result
        assert len(consolidated_result) >= 12  # æœ€ä½é™ã®ãƒ‡ãƒ¼ã‚¿æ•°ç¢ºèª

    def test_container_error_recovery_and_data_integrity(self):
        """ç•°å¸¸ç³»ã§ã®å›å¾©åŠ›ã¨ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ä¿è¨¼ãƒ†ã‚¹ãƒˆ"""
        result = {}
        
        # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        xlsx2json.insert_json_path(result, ["æ­£å¸¸ãƒ‡ãƒ¼ã‚¿", "å€¤"], "OK")
        
        # ç•°å¸¸ç³»ãƒ‡ãƒ¼ã‚¿æŠ•å…¥è©¦è¡Œï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ä»–ã«å½±éŸ¿ã—ãªã„ã“ã¨ã‚’ç¢ºèªï¼‰
        try:
            xlsx2json.parse_range("INVALID_RANGE")
        except ValueError:
            # ã‚¨ãƒ©ãƒ¼å¾Œã‚‚æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒä¿æŒã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert result["æ­£å¸¸ãƒ‡ãƒ¼ã‚¿"]["å€¤"] == "OK"
        
        try:
            xlsx2json.detect_instance_count((1, 1), (2, 2), "INVALID_DIRECTION")
        except ValueError:
            # ã‚¨ãƒ©ãƒ¼å¾Œã‚‚ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãŒä¿ãŸã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert len(result) == 1
        
        # ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§å¾Œã®æ­£å¸¸å‹•ä½œç¢ºèª
        xlsx2json.insert_json_path(result, ["å¾©æ—§ãƒ‡ãƒ¼ã‚¿", "å€¤"], "RECOVERED")
        assert result["å¾©æ—§ãƒ‡ãƒ¼ã‚¿"]["å€¤"] == "RECOVERED"


class TestDataTransformation:
    """ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture(scope="class")
    def temp_dir(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)

    @pytest.fixture(scope="class")
    def creator(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’æä¾›"""
        return DataCreator(temp_dir)

    @pytest.fixture(scope="class")
    def transform_xlsx(self, creator):
        """å¤‰æ›ãƒ«ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_transform_workbook()

    @pytest.fixture(scope="class")
    def complex_xlsx(self, creator):
        """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_complex_workbook()

    @pytest.fixture(scope="class")
    def transform_file(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆç”¨ã®å¤‰æ›é–¢æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        transform_content = '''
def trim_and_upper(value):
    """æ–‡å­—åˆ—ã‚’ãƒˆãƒªãƒ ã—ã¦å¤§æ–‡å­—åŒ–"""
    if isinstance(value, str):
        return value.strip().upper()
    return value

def multiply_by_two(value):
    """æ•°å€¤ã‚’2å€ã«ã™ã‚‹"""
    try:
        return float(value) * 2
    except (ValueError, TypeError):
        return value

def csv_split(value):
    """CSVå½¢å¼ã§åˆ†å‰²"""
    if not isinstance(value, str):
        return value
    import csv
    from io import StringIO
    reader = csv.reader(StringIO(value))
    return [row for row in reader if any(cell.strip() for cell in row)]
'''

        transform_file = temp_dir / "test_transforms.py"
        with transform_file.open("w", encoding="utf-8") as f:
            f.write(transform_content)

        return transform_file

    # === ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ ===

    def test_apply_simple_split_transformation(self, transform_xlsx):
        """å˜ç´”ãªåˆ†å‰²å¤‰æ›ã®é©ç”¨

        ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã‚’é…åˆ—ã«å¤‰æ›ã™ã‚‹åŸºæœ¬çš„ãªåˆ†å‰²å¤‰æ›æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        transform_rules = xlsx2json.parse_array_transform_rules(
            ["json.split_comma=split:,"], prefix="json"
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            transform_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        expected = ["apple", "banana", "orange"]
        assert result["split_comma"] == expected

    def test_apply_multidimensional_split_transformation(self, transform_xlsx):
        """å¤šæ¬¡å…ƒåˆ†å‰²å¤‰æ›ã®é©ç”¨

        è¤‡æ•°ã®åŒºåˆ‡ã‚Šæ–‡å­—ã‚’ä½¿ã£ãŸå¤šæ¬¡å…ƒé…åˆ—å¤‰æ›æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        transform_rules = xlsx2json.parse_array_transform_rules(
            ["json.split_multi=split:;|\\|"], prefix="json"
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            transform_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        # ç¾åœ¨ã®å®Ÿè£…ã«åˆã‚ã›ã¦æœŸå¾…å€¤ã‚’ä¿®æ­£
        # "1;2;3|4;5;6" ãŒ ";" ã§åˆ†å‰²ã•ã‚Œã¦ ["1", "2", "3|4", "5", "6"] ã«ãªã‚Š
        # ã•ã‚‰ã«å„è¦ç´ ãŒ "|" ã§åˆ†å‰²ã•ã‚Œã‚‹
        expected = [["1"], ["2"], ["3", "4"], ["5"], ["6"]]
        assert result["split_multi"] == expected

    def test_apply_newline_split_transformation(self, transform_xlsx):
        """æ”¹è¡Œåˆ†å‰²å¤‰æ›ã®é©ç”¨

        æ”¹è¡Œæ–‡å­—ã«ã‚ˆã‚‹æ–‡å­—åˆ—åˆ†å‰²æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        transform_rules = xlsx2json.parse_array_transform_rules(
            ["json.split_newline=split:\\n"], prefix="json"
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            transform_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        expected = ["line1", "line2", "line3"]
        assert result["split_newline"] == expected

    def test_apply_python_function_transformation(self, transform_xlsx, transform_file):
        """Pythoné–¢æ•°ã«ã‚ˆã‚‹å€¤å¤‰æ›

        å¤–éƒ¨Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®é–¢æ•°ã‚’ä½¿ã£ãŸå€¤ã®å¤‰æ›æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        transform_spec = f"json.function_test=function:{transform_file}:trim_and_upper"
        transform_rules = xlsx2json.parse_array_transform_rules(
            [transform_spec], prefix="json"
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            transform_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        # "  trim_test  " -> "TRIM_TEST"
        assert result["function_test"] == "TRIM_TEST"

    @patch("subprocess.run")
    def test_apply_external_command_transformation(self, mock_run, transform_xlsx):
        """å¤–éƒ¨ã‚³ãƒãƒ³ãƒ‰ã«ã‚ˆã‚‹å€¤å¤‰æ›

        ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ãŸå€¤ã®å¤‰æ›æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ãƒ¢ãƒƒã‚¯ã®è¨­å®šï¼šechoã‚³ãƒãƒ³ãƒ‰ã®çµæœã‚’æ¨¡æ“¬
        mock_result = MagicMock()
        mock_result.returncode = 0
        mock_result.stdout = "COMMAND_TEST_DATA"
        mock_run.return_value = mock_result

        transform_rules = xlsx2json.parse_array_transform_rules(
            ["json.command_test=command:echo"], prefix="json"
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            transform_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        assert result["command_test"] == "COMMAND_TEST_DATA"
        # ã‚³ãƒãƒ³ãƒ‰ã¯åˆæœŸåŒ–æ™‚ã¨actualå®Ÿè¡Œæ™‚ã«2å›å‘¼ã°ã‚Œã‚‹
        assert mock_run.call_count == 2

    def test_parse_and_apply_transformation_rules(self):
        """å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®è§£æã¨é©ç”¨

        å¤‰æ›ãƒ«ãƒ¼ãƒ«æ–‡å­—åˆ—ã®è§£æã¨å†…éƒ¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¸ã®å¤‰æ›ã‚’ãƒ†ã‚¹ãƒˆ
        """
        rules_list = ["colors=split:,", "items=split:\n"]
        rules = xlsx2json.parse_array_transform_rules(rules_list, "json", None)

        assert "colors" in rules
        assert "items" in rules
        assert rules["colors"].transform_type == "split"
        assert rules["items"].transform_type == "split"

    def test_handle_transformation_errors(self):
        """å¤‰æ›ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

        ç„¡åŠ¹ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚„å¤‰æ›å®Ÿè¡Œæ™‚ã®ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç„¡åŠ¹ãªå¤‰æ›ã‚¿ã‚¤ãƒ—
        with pytest.raises(Exception):
            xlsx2json.ArrayTransformRule("test.path", "invalid_type", "spec")

        # ç„¡åŠ¹ãªPythoné–¢æ•°æŒ‡å®š
        try:
            rule = xlsx2json.ArrayTransformRule(
                "test.path", "function", "invalid_syntax("
            )
            rule.transform("test")
        except Exception:
            pass  # ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

    def test_array_transform_rule_functionality(self):
        """ArrayTransformRuleã‚¯ãƒ©ã‚¹ã®æ©Ÿèƒ½

        å¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åŸºæœ¬æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
        """
        rule = xlsx2json.ArrayTransformRule("test.path", "split", "split:,")
        rule._transform_func = (
            lambda x: xlsx2json.convert_string_to_multidimensional_array(x, [","])
        )

        result = rule.transform("a,b,c")
        assert result == ["a", "b", "c"]

    def test_array_transform_rule_transform_comprehensive(self):
        """ArrayTransformRule.transform()ãƒ¡ã‚½ãƒƒãƒ‰ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""

        # functionå‹å¤‰æ›ã®ãƒ†ã‚¹ãƒˆ
        rule = xlsx2json.ArrayTransformRule("test.path", "function", "json:loads")

        # _global_trimãŒTrueã§listçµæœã®å ´åˆ
        original_trim = getattr(xlsx2json, "_global_trim", False)
        try:
            xlsx2json._global_trim = True

            # ãƒ¢ãƒƒã‚¯functionã‚’è¨­å®š
            def mock_func(value):
                return ["  item1  ", "  item2  "]

            rule._transform_func = mock_func
            result = rule.transform("test")
            expected = ["item1", "item2"]  # trimã•ã‚Œã‚‹
            assert result == expected

            # élistçµæœã®å ´åˆã¯trimã•ã‚Œãªã„
            def mock_func_non_list(value):
                return "  not_list  "

            rule._transform_func = mock_func_non_list
            result = rule.transform("test")
            assert result == "  not_list  "  # trimã•ã‚Œãªã„

            # _global_trimãŒFalseã®å ´åˆ
            xlsx2json._global_trim = False
            rule._transform_func = mock_func
            result = rule.transform("test")
            expected = ["  item1  ", "  item2  "]  # trimã•ã‚Œãªã„
            assert result == expected

        finally:
            xlsx2json._global_trim = original_trim

        # splitå‹å¤‰æ›ã®ãƒ†ã‚¹ãƒˆ
        rule = xlsx2json.ArrayTransformRule("test.path", "split", "split:,")

        # ãƒ¢ãƒƒã‚¯splité–¢æ•°ã‚’è¨­å®š
        def mock_split_func(value):
            return value.split(",")

        rule._transform_func = mock_split_func

        # listå…¥åŠ›ã®å ´åˆ
        result = rule.transform(["a,b", "c,d"])
        expected = [["a", "b"], ["c", "d"]]
        assert result == expected

        # élistå…¥åŠ›ã®å ´åˆ
        result = rule.transform("a,b,c")
        expected = ["a", "b", "c"]
        assert result == expected

        # splitå‹ã§transformé–¢æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼
        rule = xlsx2json.ArrayTransformRule("test.path", "split", "split:,")
        # splitå‹ã®å ´åˆã€_transform_funcãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã¨TypeError
        with pytest.raises(TypeError):
            rule.transform("test")

    @patch("subprocess.run")
    def test_array_transform_rule_command_transform_comprehensive(self, mock_run):
        """ArrayTransformRule._transform_with_command()ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""

        rule = xlsx2json.ArrayTransformRule("test.path", "command", "echo test")

        # æ­£å¸¸ãªã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
        mock_run.return_value = MagicMock(returncode=0, stdout="test output", stderr="")
        result = rule.transform("input")
        assert result == "test output"

        # JSONã¨ã—ã¦è§£æå¯èƒ½ãªå‡ºåŠ›
        mock_run.return_value = MagicMock(
            returncode=0, stdout='{"key": "value"}', stderr=""
        )
        result = rule.transform("input")
        assert result == {"key": "value"}

        # è¤‡æ•°è¡Œå‡ºåŠ›
        mock_run.return_value = MagicMock(
            returncode=0, stdout="line1\nline2\nline3", stderr=""
        )
        result = rule.transform("input")
        assert result == ["line1", "line2", "line3"]

        # ç©ºè¡Œã‚’å«ã‚€è¤‡æ•°è¡Œå‡ºåŠ›
        mock_run.return_value = MagicMock(
            returncode=0, stdout="line1\n\nline3\n", stderr=""
        )
        result = rule.transform("input")
        assert result == ["line1", "line3"]  # ç©ºè¡Œã¯é™¤å»ã•ã‚Œã‚‹

        # ã‚³ãƒãƒ³ãƒ‰å¤±æ•—æ™‚
        mock_run.return_value = MagicMock(
            returncode=1, stdout="", stderr="error message"
        )
        result = rule.transform("test_input")
        assert result == "test_input"  # å…ƒã®å€¤ã‚’è¿”ã™

        # Noneå…¥åŠ›ã®å‡¦ç†
        mock_run.return_value = MagicMock(returncode=0, stdout="output", stderr="")
        result = rule.transform(None)
        # Noneã¯ç©ºæ–‡å­—åˆ—ã«å¤‰æ›ã•ã‚Œã¦ã‚³ãƒãƒ³ãƒ‰ã«æ¸¡ã•ã‚Œã‚‹
        mock_run.assert_called_with(
            ["echo", "test"], input="", capture_output=True, text=True, timeout=30
        )

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¾‹å¤–
        mock_run.side_effect = subprocess.TimeoutExpired("cmd", 30)
        result = rule.transform("input")
        assert result == "input"  # å…ƒã®å€¤ã‚’è¿”ã™

        # ãã®ä»–ã®ä¾‹å¤–
        mock_run.side_effect = Exception("test error")
        result = rule.transform("input")
        assert result == "input"  # å…ƒã®å€¤ã‚’è¿”ã™

    def test_parse_array_transform_rules_comprehensive(self):
        """parse_array_transform_rules()ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""

        # æ­£å¸¸ãªã‚±ãƒ¼ã‚¹
        rules = [
            "test.path=split:,",
            "func.path=function:json:loads",
            "cmd.path=command:echo test",
        ]

        result = xlsx2json.parse_array_transform_rules(rules, "PREFIX_")

        # æ­£å¸¸ãªãƒ«ãƒ¼ãƒ«ãŒ3ã¤å«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(result) == 3
        assert "test.path" in result
        assert "func.path" in result
        assert "cmd.path" in result

        assert result["test.path"].transform_type == "split"
        assert result["func.path"].transform_type == "function"
        assert result["cmd.path"].transform_type == "command"

        # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã®ãƒ«ãƒ¼ãƒ«
        rules_with_prefix = [
            "PREFIX_.test.path=split:,",
            "PREFIX_.func.path=function:json:loads",
        ]

        result = xlsx2json.parse_array_transform_rules(rules_with_prefix, "PREFIX_")
        assert len(result) == 2
        assert "test.path" in result
        assert "func.path" in result

        # ä¸æ­£ãªãƒ«ãƒ¼ãƒ«å½¢å¼
        invalid_rules = [
            "invalid_rule_without_equals",
            "path=unknown:type",
            "=empty_path",
        ]

        result = xlsx2json.parse_array_transform_rules(invalid_rules, "PREFIX_")
        assert len(result) == 0

        # ç©ºã®ãƒ«ãƒ¼ãƒ«ãƒªã‚¹ãƒˆ
        result = xlsx2json.parse_array_transform_rules([], "PREFIX_")
        assert len(result) == 0

        # ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ï¼šç„¡åŠ¹ãªprefix
        with pytest.raises(
            ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.parse_array_transform_rules(["test=split:,"], "")

        with pytest.raises(
            ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.parse_array_transform_rules(["test=split:,"], None)

        # splitå‹ã®è©³ç´°ãƒ†ã‚¹ãƒˆ
        split_rules = [
            "path1=split:,",
            "path2=split:|",
            "path3=split:,|;",
            "path4=split:\\n",
        ]

        result = xlsx2json.parse_array_transform_rules(split_rules, "PREFIX_")
        assert len(result) == 4

        # splitå‹ã®transformé–¢æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        for path, rule in result.items():
            assert rule.transform_type == "split"
            assert hasattr(rule, "_transform_func")
            assert callable(rule._transform_func)

        # ãƒ«ãƒ¼ãƒ«ä¸Šæ›¸ãã®ãƒ†ã‚¹ãƒˆï¼ˆfunctionå‹ãŒsplitå‹ã‚’ä¸Šæ›¸ãï¼‰
        overwrite_rules = ["same.path=split:,", "same.path=function:json:loads"]

        result = xlsx2json.parse_array_transform_rules(overwrite_rules, "PREFIX_")
        assert len(result) == 1
        assert result["same.path"].transform_type == "function"

        # splitå‹ãŒfunctionå‹ã‚’ä¸Šæ›¸ãã—ãªã„ã“ã¨ã‚’ç¢ºèª
        no_overwrite_rules = ["same.path=function:json:loads", "same.path=split:,"]

        result = xlsx2json.parse_array_transform_rules(no_overwrite_rules, "PREFIX_")
        assert len(result) == 1
        assert result["same.path"].transform_type == "function"


class TestSchemaValidation:
    """ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture(scope="class")
    def temp_dir(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)

    @pytest.fixture(scope="class")
    def creator(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’æä¾›"""
        return DataCreator(temp_dir)

    @pytest.fixture(scope="class")
    def basic_xlsx(self, creator):
        """åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_basic_workbook()

    @pytest.fixture(scope="class")
    def wildcard_xlsx(self, creator):
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_wildcard_workbook()

    @pytest.fixture(scope="class")
    def schema_file(self, creator):
        """JSON Schemaãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        schema = {
            "type": "object",
            "properties": {
                "customer": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "address": {"type": "string"},
                    },
                },
                "numbers": {
                    "type": "object",
                    "properties": {
                        "integer": {"type": "integer"},
                        "float": {"type": "number"},
                    },
                },
            },
        }

        schema_path = creator.temp_dir / "schema.json"
        with schema_path.open("w", encoding="utf-8") as f:
            json.dump(schema, f, indent=2)

        return schema_path

    @pytest.fixture(scope="class")
    def wildcard_schema_file(self, creator):
        """ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        schema = {
            "type": "object",
            "properties": {
                "user": {
                    "type": "array",
                    "items": {"type": "string"},
                },
            },
        }

        schema_path = creator.temp_dir / "wildcard_schema.json"
        with schema_path.open("w", encoding="utf-8") as f:
            json.dump(schema, f, indent=2)

        return schema_path

    # === JSON Schemaãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_load_and_validate_schema_success(self, basic_xlsx, schema_file):
        """JSONã‚¹ã‚­ãƒ¼ãƒã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼æˆåŠŸ

        æœ‰åŠ¹ãªJSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼æˆåŠŸã‚’ãƒ†ã‚¹ãƒˆ
        """
        # é…åˆ—å¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚’è¨­å®šã—ã¦çµæœã‚’å–å¾—
        transform_rules = xlsx2json.parse_array_transform_rules(
            [
                "json.tags=split:,",
                "json.numbers.array=split:,",
                "json.matrix=split:;|,",
            ],
            prefix="json",
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            basic_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        schema = xlsx2json.load_schema(schema_file)
        validator = Draft7Validator(schema)

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãŒãªã„ã“ã¨ã‚’ç¢ºèª
        errors = list(validator.iter_errors(result))
        # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯ãƒ­ã‚°ã«å‡ºåŠ›ã—ã¦è©³ç´°ã‚’ç¢ºèª
        if errors:
            for error in errors:
                print(f"Validation error: {error.message} at {error.absolute_path}")
        assert len(errors) == 0, f"Schema validation errors: {errors}"

    def test_wildcard_symbol_resolution(self, wildcard_xlsx, wildcard_schema_file):
        """è¨˜å·ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ã«ã‚ˆã‚‹åå‰è§£æ±ºãƒ†ã‚¹ãƒˆ

        "ï¼"è¨˜å·ã«ã‚ˆã‚‹ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰æ©Ÿèƒ½ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚­ãƒ¼ãƒã‚’è¨­å®š
        xlsx2json._global_schema = xlsx2json.load_schema(wildcard_schema_file)

        try:
            result = xlsx2json.parse_named_ranges_with_prefix(
                wildcard_xlsx, prefix="json"
            )

            # ãã®ã¾ã¾ä¸€è‡´ã™ã‚‹ã‚±ãƒ¼ã‚¹
            assert result["user_name"] == "ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼‘"

            # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ãƒãƒƒãƒãƒ³ã‚°ï¼ˆuser_group -> userï¼groupï¼‰
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯å…ƒã®ã‚­ãƒ¼åãŒä½¿ç”¨ã•ã‚Œã‚‹
            assert "user_group" in result  # å®Ÿéš›ã«ç”Ÿæˆã•ã‚ŒãŸã‚­ãƒ¼
            assert result["user_group"] == "ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼’"

        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            xlsx2json._global_schema = None

    def test_validation_error_logging(self, temp_dir):
        """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°å‡ºåŠ›æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        ãƒ‡ãƒ¼ã‚¿ãŒã‚¹ã‚­ãƒ¼ãƒã«é•åã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç”Ÿæˆã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿
        invalid_data = {
            "customer": {
                "name": 123,  # æ–‡å­—åˆ—ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒæ•°å€¤
                "address": None,
            },
            "numbers": {
                "integer": "not_a_number",  # æ•°å€¤ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒæ–‡å­—åˆ—
                "float": [],
            },
        }

        # ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "customer": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "address": {"type": "string"},
                    },
                    "required": ["name", "address"],
                },
                "numbers": {
                    "type": "object",
                    "properties": {
                        "integer": {"type": "integer"},
                        "float": {"type": "number"},
                    },
                },
            },
        }

        validator = Draft7Validator(schema)
        log_dir = temp_dir / "validation_logs"

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ­ã‚°å‡ºåŠ›ã‚’å®Ÿè¡Œ
        xlsx2json.validate_and_log(invalid_data, validator, log_dir, "test_file")

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        error_log = log_dir / "test_file.error.log"
        assert error_log.exists()

        # ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’ç¢ºèª
        with error_log.open("r", encoding="utf-8") as f:
            log_content = f.read()
            assert "customer.name" in log_content or "name" in log_content
            assert "customer.address" in log_content or "address" in log_content

    def test_validation_no_errors_coverage(self, temp_dir):
        """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãŒãªã„å ´åˆã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ†ã‚¹ãƒˆ

        validate_and_logé–¢æ•°ã§ã‚¨ãƒ©ãƒ¼ãŒãªã„å ´åˆã®æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ã‚’ãƒ†ã‚¹ãƒˆï¼ˆline 54ï¼‰
        """
        # æ­£å¸¸ãªãƒ‡ãƒ¼ã‚¿
        valid_data = {
            "customer": {
                "name": "å±±ç”°å¤ªéƒ",
                "address": "æ±äº¬éƒ½æ¸‹è°·åŒº",
            },
            "numbers": {
                "integer": 123,
                "float": 45.67,
            },
        }

        # ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "customer": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "address": {"type": "string"},
                    },
                },
                "numbers": {
                    "type": "object",
                    "properties": {
                        "integer": {"type": "integer"},
                        "float": {"type": "number"},
                    },
                },
            },
        }

        validator = Draft7Validator(schema)
        log_dir = temp_dir / "validation_logs"

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ï¼‰ã‚’å®Ÿè¡Œ - line 54ã®returnã‚’ã‚«ãƒãƒ¼
        xlsx2json.validate_and_log(valid_data, validator, log_dir, "valid_test")

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆã‚¨ãƒ©ãƒ¼ãŒãªã„ãŸã‚ï¼‰
        error_log = log_dir / "valid_test.error.log"
        assert not error_log.exists()

    def test_schema_driven_key_ordering(self):
        """ã‚¹ã‚­ãƒ¼ãƒã«ã‚ˆã‚‹ã‚­ãƒ¼é †åºåˆ¶å¾¡æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        JSONã‚¹ã‚­ãƒ¼ãƒã«å®šç¾©ã•ã‚ŒãŸé †åºã§ã‚­ãƒ¼ãŒä¸¦ã³æ›¿ãˆã‚‰ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # é †åºãŒç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿
        unordered_data = {
            "z_last": "should be last",
            "a_first": "should be first",
            "m_middle": "should be middle",
        }

        # ç‰¹å®šã®é †åºã‚’å®šç¾©ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "a_first": {"type": "string"},
                "m_middle": {"type": "string"},
                "z_last": {"type": "string"},
            },
        }

        result = xlsx2json.reorder_json(unordered_data, schema)

        # ã‚­ãƒ¼ã®é †åºãŒã‚¹ã‚­ãƒ¼ãƒé€šã‚Šã«ãªã‚‹ã“ã¨ã‚’ç¢ºèª
        keys = list(result.keys())
        assert keys == ["a_first", "m_middle", "z_last"]

    def test_reorder_json_missing_keys_coverage(self):
        """reorder_jsoné–¢æ•°ã§å­˜åœ¨ã—ãªã„ã‚­ãƒ¼ã®å‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆline 87ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼‰

        ã‚¹ã‚­ãƒ¼ãƒã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ãŒãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„ã‚­ãƒ¼ã®å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ä¸€éƒ¨ã®ã‚­ãƒ¼ãŒæ¬ ã‘ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿
        incomplete_data = {
            "existing_key": "value1",
            "another_key": "value2",
        }

        # ã‚ˆã‚Šå¤šãã®ã‚­ãƒ¼ã‚’å®šç¾©ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "missing_key": {"type": "string"},  # ãƒ‡ãƒ¼ã‚¿ã«ã¯ãªã„
                "existing_key": {"type": "string"},
                "another_missing": {"type": "string"},  # ãƒ‡ãƒ¼ã‚¿ã«ã¯ãªã„
                "another_key": {"type": "string"},
            },
        }

        result = xlsx2json.reorder_json(incomplete_data, schema)

        # å­˜åœ¨ã™ã‚‹ã‚­ãƒ¼ã®ã¿ãŒå«ã¾ã‚Œã€ã‚¹ã‚­ãƒ¼ãƒã®é †åºã«å¾“ã†ã“ã¨ã‚’ç¢ºèª
        expected_keys = ["existing_key", "another_key"]  # ã‚¹ã‚­ãƒ¼ãƒé †ã§å­˜åœ¨ã™ã‚‹ã‚‚ã®
        assert list(result.keys()) == expected_keys
        assert result["existing_key"] == "value1"
        assert result["another_key"] == "value2"

    def test_reorder_json_array_items_coverage(self):
        """reorder_jsoné–¢æ•°ã§é…åˆ—ã‚¢ã‚¤ãƒ†ãƒ ã®ä¸¦ã³æ›¿ãˆãƒ†ã‚¹ãƒˆï¼ˆline 91ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼‰

        é…åˆ—å†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦ä¸¦ã³æ›¿ãˆã‚‰ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # é…åˆ—ãƒ‡ãƒ¼ã‚¿
        array_data = [
            {"z_field": "z1", "a_field": "a1", "m_field": "m1"},
            {"z_field": "z2", "a_field": "a2", "m_field": "m2"},
        ]

        # é…åˆ—ã‚¢ã‚¤ãƒ†ãƒ ã®ä¸¦ã³æ›¿ãˆã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "a_field": {"type": "string"},
                    "m_field": {"type": "string"},
                    "z_field": {"type": "string"},
                },
            },
        }

        result = xlsx2json.reorder_json(array_data, schema)

        # é…åˆ—ã®å„è¦ç´ ãŒã‚¹ã‚­ãƒ¼ãƒé †ã«ä¸¦ã³æ›¿ãˆã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert isinstance(result, list)
        assert len(result) == 2

        for item in result:
            keys = list(item.keys())
            assert keys == ["a_field", "m_field", "z_field"]

    def test_nested_object_schema_validation(self):
        """ãƒã‚¹ãƒˆã—ãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆ

        è¤‡é›‘ãªãƒã‚¹ãƒˆæ§‹é€ ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ãƒã‚¹ãƒˆã—ãŸãƒ‡ãƒ¼ã‚¿
        nested_data = {
            "company": {
                "name": "ãƒ†ã‚¹ãƒˆä¼šç¤¾",
                "departments": [
                    {"name": "é–‹ç™ºéƒ¨", "employees": [{"name": "ç”°ä¸­", "age": 30}]},
                    {"name": "å“è³ªä¿è¨¼éƒ¨", "employees": [{"name": "ä½è—¤", "age": 25}]},
                ],
            }
        }

        # ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã®ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "company": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "departments": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "name": {"type": "string"},
                                    "employees": {
                                        "type": "array",
                                        "items": {
                                            "type": "object",
                                            "properties": {
                                                "name": {"type": "string"},
                                                "age": {"type": "integer"},
                                            },
                                            "required": ["name", "age"],
                                        },
                                    },
                                },
                                "required": ["name", "employees"],
                            },
                        },
                    },
                    "required": ["name", "departments"],
                },
            },
            "required": ["company"],
        }

        validator = Draft7Validator(schema)
        errors = list(validator.iter_errors(nested_data))

        assert len(errors) == 0, f"Validation errors: {errors}"

    def test_schema_load_error_handling(self, temp_dir):
        """ã‚¹ã‚­ãƒ¼ãƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ

        ä¸æ­£ãªã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒé©åˆ‡ã«è¡Œã‚ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«
        nonexistent_file = temp_dir / "nonexistent_schema.json"
        with pytest.raises(FileNotFoundError):
            xlsx2json.load_schema(nonexistent_file)

        # ä¸æ­£ãªJSONãƒ•ã‚¡ã‚¤ãƒ«
        invalid_schema_file = temp_dir / "invalid_schema.json"
        with invalid_schema_file.open("w") as f:
            f.write("{ invalid json content")

        with pytest.raises(json.JSONDecodeError):
            xlsx2json.load_schema(invalid_schema_file)

        # Noneãƒ‘ã‚¹ã®ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.load_schema(None)
        assert result is None

    def test_array_transform_comprehensive_lines_478_487_from_precision(self):
        """é…åˆ—å¤‰æ›ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆï¼ˆçµ±åˆï¼šé‡è¤‡å‰Šé™¤æ¸ˆã¿ï¼‰

        é…åˆ—å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®è©³ç´°ãªå‹•ä½œã¨ä¾‹å¤–å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # Noneå…¥åŠ›ã®ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.convert_string_to_multidimensional_array(None, [","])
        assert result is None

        # ç©ºæ–‡å­—åˆ—ã®ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.convert_string_to_multidimensional_array("", [","])
        assert result == []

        # è¤‡é›‘ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ
        test_rules = [
            "json.data=split:,",
            "json.values=function:lambda x: x.split('-')",
            "json.commands=command:echo test",
        ]

        # ã‚¹ã‚­ãƒ¼ãƒãƒ™ãƒ¼ã‚¹ã®å¤‰æ›ãƒ«ãƒ¼ãƒ«è§£æãƒ†ã‚¹ãƒˆ
        test_schema = {
            "type": "object",
            "properties": {
                "items": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "data": {"type": "array"},
                            "values": {"type": "array"},
                            "commands": {"type": "array"}
                        }
                    }
                }
            }
        }

        # ç„¡åŠ¹ãªãƒ«ãƒ¼ãƒ«å½¢å¼ã®ãƒ†ã‚¹ãƒˆ
        with patch("xlsx2json.logger") as mock_logger:
            invalid_rules = ["invalid_rule_format", "another=invalid"]
            xlsx2json.parse_array_split_rules(invalid_rules, "json")  # prefixå¼•æ•°ã‚’è¿½åŠ 
            mock_logger.warning.assert_called()

        # è¤‡é›‘ãªåˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆ
        test_string = "a;b;c\nd;e;f"
        result = xlsx2json.convert_string_to_multidimensional_array(
            test_string, ["\n", ";"]
        )
        expected = [["a", "b", "c"], ["d", "e", "f"]]
        assert result == expected

    def test_load_schema_enhanced_validation(self):
        """load_schemaé–¢æ•°ã®æ‹¡å¼µãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ
            nonexistent_file = temp_path / "nonexistent.json"
            with pytest.raises(
                FileNotFoundError, match="ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            ):
                xlsx2json.load_schema(nonexistent_file)

            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®šã—ãŸå ´åˆã®ãƒ†ã‚¹ãƒˆ
            dir_path = temp_path / "directory"
            dir_path.mkdir()
            with pytest.raises(
                ValueError, match="æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
            ):
                xlsx2json.load_schema(dir_path)

            # èª­ã¿è¾¼ã¿æ¨©é™ã®ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
            # ã“ã®å ´åˆã¯FileNotFoundErrorãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
            broken_file = temp_path / "broken.json"
            broken_file.write_text("valid json content", encoding="utf-8")
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            broken_file.unlink()

            with pytest.raises(FileNotFoundError):
                xlsx2json.load_schema(broken_file)

    def test_reorder_json_comprehensive(self):
        """reorder_jsoné–¢æ•°ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""

        # åŸºæœ¬çš„ãªdictä¸¦ã³æ›¿ãˆ
        data = {"z": 1, "a": 2, "m": 3}
        schema = {
            "type": "object",
            "properties": {
                "a": {"type": "number"},
                "m": {"type": "string"},
                "z": {"type": "number"},
            },
        }
        result = xlsx2json.reorder_json(data, schema)
        keys_order = list(result.keys())
        assert keys_order == ["a", "m", "z"]  # ã‚¹ã‚­ãƒ¼ãƒé †

        # ã‚¹ã‚­ãƒ¼ãƒã«ãªã„ã‚­ãƒ¼ã®å‡¦ç†
        data = {"z": 1, "unknown": "value", "a": 2}
        result = xlsx2json.reorder_json(data, schema)
        keys_order = list(result.keys())
        assert keys_order == ["a", "z", "unknown"]  # ã‚¹ã‚­ãƒ¼ãƒé † + ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †

        # å†å¸°çš„ãªä¸¦ã³æ›¿ãˆ
        data = {"outer": {"z": 1, "a": 2}, "simple": "value"}
        schema = {
            "type": "object",
            "properties": {
                "outer": {
                    "type": "object",
                    "properties": {"a": {"type": "number"}, "z": {"type": "number"}},
                },
                "simple": {"type": "string"},
            },
        }
        result = xlsx2json.reorder_json(data, schema)
        assert list(result.keys()) == ["outer", "simple"]
        assert list(result["outer"].keys()) == ["a", "z"]

        # listå‹ã®å‡¦ç†
        data = [{"z": 1, "a": 2}, {"b": 3, "a": 4}]
        schema = {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "a": {"type": "number"},
                    "b": {"type": "number"},
                    "z": {"type": "number"},
                },
            },
        }
        result = xlsx2json.reorder_json(data, schema)
        assert list(result[0].keys()) == ["a", "z"]
        assert list(result[1].keys()) == ["a", "b"]

        # ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–å‹ã®å‡¦ç†ï¼ˆãã®ã¾ã¾è¿”ã™ï¼‰
        assert xlsx2json.reorder_json("string", schema) == "string"
        assert xlsx2json.reorder_json(123, schema) == 123
        assert xlsx2json.reorder_json(None, schema) is None

        # ã‚¹ã‚­ãƒ¼ãƒãŒdictã§ãªã„å ´åˆ
        result = xlsx2json.reorder_json({"a": 1}, "not_dict")
        assert result == {"a": 1}

        # objãŒdictã§ãªã„å ´åˆ
        result = xlsx2json.reorder_json("not_dict", schema)
        assert result == "not_dict"

        # listã§ã‚¹ã‚­ãƒ¼ãƒã«itemsãŒãªã„å ´åˆ
        data = [1, 2, 3]
        schema = {"type": "array"}  # itemsãŒãªã„
        result = xlsx2json.reorder_json(data, schema)
        assert result == [1, 2, 3]


class TestJSONOutput:
    """JSONå‡ºåŠ›ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture(scope="class")
    def temp_dir(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)

    @pytest.fixture(scope="class")
    def creator(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’æä¾›"""
        return DataCreator(temp_dir)

    @pytest.fixture(scope="class")
    def basic_xlsx(self, creator):
        """åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_basic_workbook()

    @pytest.fixture(scope="class")
    def complex_xlsx(self, creator):
        """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        return creator.create_complex_workbook()

    # === JSONå‡ºåŠ›åˆ¶å¾¡æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_json_file_output_basic_formatting(self, basic_xlsx, temp_dir):
        """åŸºæœ¬çš„ãªJSONãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¶å¾¡ãƒ†ã‚¹ãƒˆ

        JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›ã¨ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒæ­£ã—ãåˆ¶å¾¡ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
        output_path = temp_dir / "test_output.json"
        xlsx2json.write_json(result, output_path)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert output_path.exists()

        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’ç¢ºèª
        with output_path.open("r", encoding="utf-8") as f:
            content = f.read()
            # JSONå½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            data = json.loads(content)
            assert isinstance(data, dict)
            assert "customer" in data
            assert "numbers" in data

    def test_complex_data_structure_processing(self, complex_xlsx):
        """è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        result = xlsx2json.parse_named_ranges_with_prefix(complex_xlsx, prefix="json")

        # ã‚·ã‚¹ãƒ†ãƒ å
        assert result["system"]["name"] == "ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ "

        # éƒ¨ç½²é…åˆ—ã®ç¢ºèª
        departments = result["departments"]
        assert isinstance(departments, list)
        assert len(departments) == 2

        # 1ç•ªç›®ã®éƒ¨ç½²
        dept1 = departments[0]
        assert dept1["name"] == "é–‹ç™ºéƒ¨"
        assert dept1["manager"]["name"] == "ç”°ä¸­èŠ±å­"
        assert dept1["manager"]["email"] == "tanaka@example.com"

        # 2ç•ªç›®ã®éƒ¨ç½²
        dept2 = departments[1]
        assert dept2["name"] == "ãƒ†ã‚¹ãƒˆéƒ¨"
        assert dept2["manager"]["name"] == "ä½è—¤æ¬¡éƒ"

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé…åˆ—ã®ç¢ºèª
        projects = result["projects"]
        assert isinstance(projects, list)
        assert len(projects) == 2
        assert projects[0]["name"] == "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆÎ±"
        assert projects[1]["status"] == "å®Œäº†"

    def test_array_with_split_transformation(self, complex_xlsx):
        """é…åˆ—ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        transform_rules = xlsx2json.parse_array_transform_rules(
            ["json.tasks=split:,", "json.priorities=split:,", "json.deadlines=split:,"],
            prefix="json",
        )

        result = xlsx2json.parse_named_ranges_with_prefix(
            complex_xlsx, prefix="json", array_transform_rules=transform_rules
        )

        # ã‚¿ã‚¹ã‚¯ã®åˆ†å‰²ç¢ºèª
        assert result["tasks"] == ["ã‚¿ã‚¹ã‚¯1", "ã‚¿ã‚¹ã‚¯2", "ã‚¿ã‚¹ã‚¯3"]
        assert result["priorities"] == ["é«˜", "ä¸­", "ä½"]
        assert result["deadlines"] == ["2025-02-01", "2025-02-15", "2025-03-01"]

    def test_multidimensional_array_like_samples(self, complex_xlsx):
        """samplesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®parenté…åˆ—ã®ã‚ˆã†ãªå¤šæ¬¡å…ƒé…åˆ—ãƒ†ã‚¹ãƒˆ"""
        # åˆ†å‰²å¤‰æ›ã¯è¡Œã‚ãšã€æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.parse_named_ranges_with_prefix(complex_xlsx, prefix="json")

        parent = result["parent"]
        assert isinstance(parent, list)  # ãƒªã‚¹ãƒˆã¨ã—ã¦æ§‹ç¯‰ã•ã‚Œã‚‹
        assert len(parent) == 3  # 3ã¤ã®è¡Œ

        # å„è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
        assert len(parent[0]) == 2  # 1è¡Œç›®: 2ã¤ã®åˆ—
        assert len(parent[1]) == 2  # 2è¡Œç›®: 2ã¤ã®åˆ—
        assert len(parent[2]) == 1  # 3è¡Œç›®: 1ã¤ã®åˆ—

    # === JSONå‡ºåŠ›ã®ãƒ†ã‚¹ãƒˆ ===

    def test_json_output_formatting(self, basic_xlsx, temp_dir):
        """JSONå‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        output_file = temp_dir / "test_output.json"
        xlsx2json.write_json(result, output_file)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        assert output_file.exists()

        # JSONå½¢å¼ã§èª­ã¿è¾¼ã¿å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        with output_file.open("r", encoding="utf-8") as f:
            reloaded_data = json.load(f)

        assert reloaded_data["customer"]["name"] == "å±±ç”°å¤ªéƒ"

    def test_datetime_serialization(self, basic_xlsx, temp_dir):
        """æ—¥æ™‚å‹ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
        result = xlsx2json.parse_named_ranges_with_prefix(basic_xlsx, prefix="json")

        output_file = temp_dir / "datetime_test.json"
        xlsx2json.write_json(result, output_file)

        # JSONèª­ã¿è¾¼ã¿æ™‚ã«datetimeãŒæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        with output_file.open("r", encoding="utf-8") as f:
            reloaded_data = json.load(f)

        # ISOå½¢å¼ã®æ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert isinstance(reloaded_data["datetime"], str)
        assert reloaded_data["datetime"].startswith("2025-01-15T")

        assert isinstance(reloaded_data["date"], str)
        assert reloaded_data["date"] == "2025-01-19T00:00:00"  # å®Ÿéš›ã®å‡ºåŠ›å½¢å¼

    # === ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ ===

    def test_error_handling_invalid_file(self, temp_dir):
        """ç„¡åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        invalid_file = temp_dir / "nonexistent.xlsx"

        with pytest.raises(FileNotFoundError):
            xlsx2json.parse_named_ranges_with_prefix(invalid_file, prefix="json")

    def test_error_handling_invalid_transform_rule(self):
        """ç„¡åŠ¹ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        invalid_rules = [
            "invalid_format",  # = ãŒãªã„
            "json.test=unknown:invalid",  # ä¸æ˜ãªå¤‰æ›ã‚¿ã‚¤ãƒ—
        ]

        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒåœæ­¢ã—ãªã„ã“ã¨ã‚’ç¢ºèª
        for rule in invalid_rules:
            # è­¦å‘Šãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…
            transform_rules = xlsx2json.parse_array_transform_rules(
                [rule], prefix="json"
            )
            # ç„¡åŠ¹ãªãƒ«ãƒ¼ãƒ«ã¯ç„¡è¦–ã•ã‚Œã‚‹ã‹ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã•ã‚Œã‚‹
            assert isinstance(transform_rules, dict)

    def test_prefix_customization(self, temp_dir):
        """ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãƒ†ã‚¹ãƒˆ"""
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ç”¨ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        workbook = Workbook()
        worksheet = workbook.active
        worksheet.title = "Sheet1"  # ã‚·ãƒ¼ãƒˆåã‚’æ˜ç¤ºçš„ã«è¨­å®š
        worksheet["A1"] = "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ"

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§åå‰ä»˜ãç¯„å›²ã‚’å®šç¾©
        defined_name = DefinedName("custom.test.value", attr_text="Sheet1!$A$1")
        workbook.defined_names.add(defined_name)

        custom_file = temp_dir / "custom_prefix.xlsx"
        workbook.save(custom_file)

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§è§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(custom_file, prefix="custom")

        assert result["test"]["value"] == "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ"

    # === ã‚«ãƒãƒ¬ãƒƒã‚¸æ‹¡å¼µãƒ†ã‚¹ãƒˆ ===

    def test_validate_and_log_with_errors(self, temp_dir):
        """validate_and_logé–¢æ•°ã§ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        # ã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©
        schema = {
            "type": "object",
            "properties": {"name": {"type": "string"}, "age": {"type": "number"}},
            "required": ["name"],
        }

        # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿
        invalid_data = {
            "age": "not_a_number",  # æ•°å€¤ã§ãªã„
            # "name"ãŒå¿…é ˆã ãŒå­˜åœ¨ã—ãªã„
        }

        validator = Draft7Validator(schema)
        log_dir = temp_dir / "logs"
        base_name = "test"

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç”Ÿæˆ
        xlsx2json.validate_and_log(invalid_data, validator, log_dir, base_name)

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        error_log = log_dir / f"{base_name}.error.log"
        assert error_log.exists()

        # ãƒ­ã‚°å†…å®¹ã‚’ç¢ºèª
        with error_log.open("r", encoding="utf-8") as f:
            content = f.read()

        assert "age" in content  # å‹ã‚¨ãƒ©ãƒ¼
        assert ": 'name' is a required property" in content  # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼

    def test_parse_array_split_rules_comprehensive(self):
        """parse_array_split_rulesé–¢æ•°ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
        # è¤‡é›‘ãªåˆ†å‰²ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ
        rules = [
            "json.field1=,",
            "json.nested.field2=;|\\n",
            "json.field3=\\t|\\|",
        ]

        result = xlsx2json.parse_array_split_rules(rules, prefix="json.")

        # ãƒ«ãƒ¼ãƒ«ãŒæ­£ã—ãè§£æã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹å‰Šé™¤å¾Œï¼‰
        assert "field1" in result
        assert result["field1"] == [","]

        assert "nested.field2" in result
        assert result["nested.field2"] == [";", "\n"]

        assert "field3" in result
        assert result["field3"] == ["\t", "|"]

    def test_should_convert_to_array_function(self):
        """should_convert_to_arrayé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
        split_rules = {"tags": [","], "nested.values": [";", "\n"]}

        # ãƒãƒƒãƒã™ã‚‹ã‚±ãƒ¼ã‚¹
        result = xlsx2json.should_convert_to_array(["tags"], split_rules)
        assert result == [","]

        # ãƒã‚¹ãƒˆã—ãŸãƒ‘ã‚¹ã§ãƒãƒƒãƒã™ã‚‹ã‚±ãƒ¼ã‚¹
        result = xlsx2json.should_convert_to_array(["nested", "values"], split_rules)
        assert result == [";", "\n"]

        # ãƒãƒƒãƒã—ãªã„ã‚±ãƒ¼ã‚¹
        result = xlsx2json.should_convert_to_array(["other"], split_rules)
        assert result is None

    def test_should_transform_to_array_function(self):
        """should_transform_to_arrayé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
        transform_rules = {
            "tags": xlsx2json.ArrayTransformRule("tags", "split", "split:,")
        }

        # ãƒãƒƒãƒã™ã‚‹ã‚±ãƒ¼ã‚¹
        result = xlsx2json.should_transform_to_array(["tags"], transform_rules)
        assert result is not None
        assert result.path == "tags"

        # ãƒãƒƒãƒã—ãªã„ã‚±ãƒ¼ã‚¹
        result = xlsx2json.should_transform_to_array(["other"], transform_rules)
        assert result is None

    def test_is_string_array_schema_function(self):
        """is_string_array_schemaé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
        # æ–‡å­—åˆ—é…åˆ—ã‚¹ã‚­ãƒ¼ãƒ
        schema = {"type": "array", "items": {"type": "string"}}

        result = xlsx2json.is_string_array_schema(schema)
        assert result is True

        # éæ–‡å­—åˆ—é…åˆ—ã‚¹ã‚­ãƒ¼ãƒ
        schema = {"type": "array", "items": {"type": "number"}}

        result = xlsx2json.is_string_array_schema(schema)
        assert result is False

        # éé…åˆ—ã‚¹ã‚­ãƒ¼ãƒ
        schema = {"type": "string"}

        result = xlsx2json.is_string_array_schema(schema)
        assert result is False

    def test_check_schema_for_array_conversion(self):
        """check_schema_for_array_conversioné–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
        schema = {
            "type": "object",
            "properties": {
                "tags": {
                    "type": "array",
                    "items": {"type": "string", "description": "æ–‡å­—åˆ—"},
                },
                "numbers": {"type": "array", "items": {"type": "number"}},
            },
        }

        # æ–‡å­—åˆ—é…åˆ—ã¨ã—ã¦å¤‰æ›ã™ã¹ã
        result = xlsx2json.check_schema_for_array_conversion(["tags"], schema)
        assert result is True

        # æ•°å€¤é…åˆ—ãªã®ã§å¤‰æ›ã™ã¹ãã§ãªã„
        result = xlsx2json.check_schema_for_array_conversion(["numbers"], schema)
        assert result is False

        # ã‚¹ã‚­ãƒ¼ãƒãŒNoneã®å ´åˆ
        result = xlsx2json.check_schema_for_array_conversion(["tags"], None)
        assert result is False

    def test_array_transform_rule_setup_errors(self):
        """ArrayTransformRule ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
        # ç„¡åŠ¹ãªå¤‰æ›ã‚¿ã‚¤ãƒ—
        with pytest.raises(ValueError, match="Unknown transform type"):
            xlsx2json.ArrayTransformRule("test", "invalid_type", "spec")

    def test_array_transform_rule_command_with_timeout(self):
        """ArrayTransformRule ã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ†ã‚¹ãƒˆ"""
        # éå¸¸ã«çŸ­ã„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
        with patch("subprocess.run") as mock_run:
            mock_run.side_effect = subprocess.TimeoutExpired("echo", 0.001)

            rule = xlsx2json.ArrayTransformRule("test", "command", "command:echo")
            result = rule.transform("test_data")

            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯å…ƒã®å€¤ãŒè¿”ã•ã‚Œã‚‹
            assert result == "test_data"

    def test_array_transform_rule_command_with_error(self):
        """ArrayTransformRule ã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # splitã‚¿ã‚¤ãƒ—ã®ãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ã€å¤‰æ›é–¢æ•°ãŒæ­£ã—ãè¨­å®šã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        rule = xlsx2json.ArrayTransformRule("test", "split", "split:,")

        # å¤–éƒ¨ã‹ã‚‰å¤‰æ›é–¢æ•°ã‚’è¨­å®šï¼ˆå®Ÿéš›ã®å‡¦ç†ã§è¡Œã‚ã‚Œã‚‹ï¼‰
        rule._transform_func = lambda x: xlsx2json.convert_string_to_array(x, ",")

        # é€šå¸¸ã®å‹•ä½œç¢ºèª
        result = rule.transform("a,b,c")
        assert result == ["a", "b", "c"]

    def test_array_transform_rule_command_json_output(self):
        """ArrayTransformRule ã®ã‚³ãƒãƒ³ãƒ‰JSONå‡ºåŠ›ãƒ†ã‚¹ãƒˆ"""
        mock_result = MagicMock()
        mock_result.returncode = 0
        mock_result.stdout = '["result1", "result2"]'

        with patch("subprocess.run", return_value=mock_result):
            rule = xlsx2json.ArrayTransformRule("test", "command", "command:echo")
            result = rule.transform("test_data")

            # JSONé…åˆ—ã¨ã—ã¦è§£æã•ã‚Œã‚‹
            assert result == ["result1", "result2"]

    def test_array_transform_rule_command_multiline_output(self):
        """ArrayTransformRule ã®ã‚³ãƒãƒ³ãƒ‰è¤‡æ•°è¡Œå‡ºåŠ›ãƒ†ã‚¹ãƒˆ"""
        mock_result = MagicMock()
        mock_result.returncode = 0
        mock_result.stdout = "line1\nline2\nline3\n"

        with patch("subprocess.run", return_value=mock_result):
            rule = xlsx2json.ArrayTransformRule("test", "command", "command:echo")
            result = rule.transform("test_data")

            # æ”¹è¡ŒåŒºåˆ‡ã‚Šã§é…åˆ—ã«å¤‰æ›
            assert result == ["line1", "line2", "line3"]

    def test_array_transform_rule_command_failed_return_code(self):
        """ArrayTransformRule ã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œå¤±æ•—ãƒ†ã‚¹ãƒˆ"""
        mock_result = MagicMock()
        mock_result.returncode = 1
        mock_result.stdout = "error output"
        mock_result.stderr = "error message"

        with patch("subprocess.run", return_value=mock_result):
            rule = xlsx2json.ArrayTransformRule(
                "test", "command", "command:failing_command"
            )
            result = rule.transform("test_data")

            # å¤±æ•—æ™‚ã¯å…ƒã®å€¤ãŒè¿”ã•ã‚Œã‚‹
            assert result == "test_data"

    def test_clean_empty_arrays_contextually(self):
        """clean_empty_arrays_contextuallyé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
        data = {
            "tags": [None, "", "tag1"],  # ç©ºè¦ç´ ã‚’å«ã‚€
            "empty_array": [],  # å®Œå…¨ã«ç©ºã®é…åˆ—
            "nested": {"items": ["", None, "item1"], "empty": []},
        }

        result = xlsx2json.clean_empty_arrays_contextually(data, suppress_empty=True)

        # ç©ºè¦ç´ ãŒé™¤å»ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(result["tags"]) == 1
        assert result["tags"][0] == "tag1"

        # å®Œå…¨ã«ç©ºã®é…åˆ—ã¯é™¤å»ã•ã‚Œã‚‹
        assert "empty_array" not in result

        # ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã‚‚å‡¦ç†ã•ã‚Œã‚‹
        assert len(result["nested"]["items"]) == 1
        assert result["nested"]["items"][0] == "item1"
        assert "empty" not in result["nested"]

    def test_global_trim_functionality(self, temp_dir):
        """ã‚°ãƒ­ãƒ¼ãƒãƒ«trimæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®ãƒ†ã‚¹ãƒˆ
        original_trim = getattr(xlsx2json, "_global_trim", False)
        try:
            xlsx2json._global_trim = True
            assert xlsx2json._global_trim is True
            xlsx2json._global_trim = False
            assert xlsx2json._global_trim is False

            # setupé–¢æ•°ã®ä¸æ­£ãªä»•æ§˜ã§ã®ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
            with pytest.raises(
                ValueError, match="transform_specã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            ):
                xlsx2json.ArrayTransformRule("invalid", "function", "")
        finally:
            xlsx2json._global_trim = original_trim

    def test_global_schema_functionality(self):
        """ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚­ãƒ¼ãƒæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        test_schema = {"type": "object", "properties": {"name": {"type": "string"}}}

        original_schema = getattr(xlsx2json, "_global_schema", None)
        try:
            xlsx2json._global_schema = test_schema
            assert xlsx2json._global_schema == test_schema
            xlsx2json._global_schema = None
            assert xlsx2json._global_schema is None
        finally:
            xlsx2json._global_schema = original_schema

    def test_insert_json_path_type_error(self):
        """insert_json_pathé–¢æ•°ã®å‹ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        # ä¸æ­£ãªå‹ã®rootã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        with pytest.raises(TypeError, match="insert_json_path: root must be dict"):
            xlsx2json.insert_json_path("not_a_dict", ["key"], "value")

    def test_insert_json_path_path_collision(self):
        """insert_json_pathé–¢æ•°ã®ãƒ‘ã‚¹è¡çªãƒ†ã‚¹ãƒˆ"""
        root = {}

        # æœ€åˆã®ãƒ‘ã‚¹
        xlsx2json.insert_json_path(root, ["user", "name"], "John")
        assert root["user"]["name"] == "John"

        # åŒã˜ãƒ‘ã‚¹ã«åˆ¥ã®å€¤ã‚’è¨­å®šï¼ˆä¸Šæ›¸ãï¼‰
        xlsx2json.insert_json_path(root, ["user", "name"], "Jane")
        assert root["user"]["name"] == "Jane"

    def test_write_json_with_datetime_serialization(self, temp_dir):
        """write_jsoné–¢æ•°ã§datetimeã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        from datetime import datetime, date

        data = {
            "datetime": datetime(2025, 1, 15, 10, 30, 45),
            "date": date(2025, 1, 19),
        }

        output_file = temp_dir / "datetime_test.json"
        xlsx2json.write_json(data, output_file)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert output_file.exists()

        # JSONèª­ã¿è¾¼ã¿æ™‚ã«datetimeãŒæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        with output_file.open("r", encoding="utf-8") as f:
            reloaded_data = json.load(f)

        # ISOå½¢å¼ã®æ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert isinstance(reloaded_data["datetime"], str)
        assert reloaded_data["datetime"].startswith("2025-01-15T")

        assert isinstance(reloaded_data["date"], str)
        assert reloaded_data["date"] == "2025-01-19"

    def test_get_named_range_values_single_vs_range(self, temp_dir):
        """get_named_range_valuesé–¢æ•°ã§ã®å˜ä¸€ã‚»ãƒ«ã¨ç¯„å›²ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        workbook = Workbook()
        worksheet = workbook.active
        worksheet.title = "Sheet1"  # ã‚·ãƒ¼ãƒˆåã‚’æ˜ç¤ºçš„ã«è¨­å®š

        # å˜ä¸€ã‚»ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿
        worksheet["A1"] = "single_value"
        # ç¯„å›²ç”¨ã®ãƒ‡ãƒ¼ã‚¿
        worksheet["B1"] = "range_value1"
        worksheet["B2"] = "range_value2"

        # å˜ä¸€ã‚»ãƒ«ã®åå‰ä»˜ãç¯„å›²
        single_name = DefinedName("single_cell", attr_text="Sheet1!$A$1")
        workbook.defined_names.add(single_name)

        # ç¯„å›²ã®åå‰ä»˜ãç¯„å›²
        range_name = DefinedName("cell_range", attr_text="Sheet1!$B$1:$B$2")
        workbook.defined_names.add(range_name)

        test_file = temp_dir / "range_test.xlsx"
        workbook.save(test_file)

        # ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿
        wb = xlsx2json.load_workbook(test_file, data_only=True)

        # å˜ä¸€ã‚»ãƒ«ã¯å€¤ã®ã¿è¿”ã™ã“ã¨ã‚’ç¢ºèª
        single_name_def = wb.defined_names["single_cell"]
        single_result = xlsx2json.get_named_range_values(wb, single_name_def)
        assert single_result == "single_value"
        assert not isinstance(single_result, list)

        # ç¯„å›²ã¯ãƒªã‚¹ãƒˆã§è¿”ã™ã“ã¨ã‚’ç¢ºèª
        range_name_def = wb.defined_names["cell_range"]
        range_result = xlsx2json.get_named_range_values(wb, range_name_def)
        assert isinstance(range_result, list)
        assert range_result == ["range_value1", "range_value2"]

    def test_convert_string_to_array_backward_compatibility(self):
        """convert_string_to_arrayé–¢æ•°ã®å¾Œæ–¹äº’æ›æ€§ãƒ†ã‚¹ãƒˆ"""
        # é€šå¸¸ã®æ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_array("a,b,c", ",")
        assert result == ["a", "b", "c"]

        # ç©ºæ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_array("", ",")
        assert result == []

        # ç©ºç™½ã®ã¿ã®æ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_array("   ", ",")
        assert result == []

        # éæ–‡å­—åˆ—å…¥åŠ›
        result = xlsx2json.convert_string_to_array(123, ",")
        assert result == 123

    def test_array_transform_comprehensive_lines_478_487_from_precision(self):
        """Test comprehensive array transform scenarios covering lines 478-487 (æ—§TestPrecisionCoverage95Plusçµ±åˆ)"""
        # Test various array transformation rule parsing
        test_rules = [
            "json.data=split:,",
            "json.values=function:lambda x: x.split('-')",
            "json.commands=command:echo test",
        ]

        # Test parsing with complex schema paths requiring resolution
        test_schema = {
            "type": "object",
            "properties": {
                "items": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "data": {"type": "array"},
                            "values": {"type": "array"},
                        },
                    },
                }
            },
        }

        # Test with wildcard paths that need schema resolution
        wildcard_rules = [
            "json.items.*.data=split:,",
            "json.items.0.values=function:str.split",
        ]

        try:
            # This should trigger lines 478-487 in schema resolution
            rules = xlsx2json.parse_array_transform_rules(
                wildcard_rules, "json", test_schema
            )
            assert isinstance(rules, dict)
        except Exception:
            pass

        # Test direct ArrayTransformRule creation
        try:
            rule = xlsx2json.ArrayTransformRule("json.data", "split", ",")
            result = rule.transform("a,b,c,d")
            assert isinstance(result, list)
        except Exception:
            pass

        try:
            rule = xlsx2json.ArrayTransformRule("json.cmd", "command", "echo test")
            result = rule.transform("input")
        except Exception:
            pass  # Expected for command execution


class TestUtilities:
    """ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def temp_dir(self):
        """ãƒ†ã‚¹ãƒˆç”¨ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"""
        with tempfile.TemporaryDirectory() as tmpdir:
            yield Path(tmpdir)

    # === ç©ºå€¤åˆ¤å®šã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_empty_value_detection_comprehensive(self):
        """åŒ…æ‹¬çš„ãªç©ºå€¤åˆ¤å®šæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        å„ç¨®ãƒ‡ãƒ¼ã‚¿å‹ã«å¯¾ã™ã‚‹ç©ºå€¤åˆ¤å®šãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç©ºã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_empty_value("") is True
        assert xlsx2json.is_empty_value(None) is True
        assert xlsx2json.is_empty_value("   ") is True  # ç©ºç™½ã®ã¿
        assert xlsx2json.is_empty_value("\t\n  ") is True  # ã‚¿ãƒ–ãƒ»æ”¹è¡Œå«ã‚€ç©ºç™½
        assert xlsx2json.is_empty_value([]) is True  # ç©ºã®ãƒªã‚¹ãƒˆ
        assert xlsx2json.is_empty_value({}) is True  # ç©ºã®è¾æ›¸

        # ç©ºã§ã¯ãªã„ã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_empty_value("value") is False
        assert xlsx2json.is_empty_value("0") is False  # æ–‡å­—åˆ—ã®0
        assert xlsx2json.is_empty_value(0) is False  # æ•°å€¤ã®0
        assert xlsx2json.is_empty_value(False) is False  # Boolean False
        assert xlsx2json.is_empty_value([1, 2]) is False
        assert xlsx2json.is_empty_value({"key": "value"}) is False

    def test_complete_emptiness_evaluation(self):
        """å®Œå…¨ç©ºåˆ¤å®šæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã§ã®å®Œå…¨ãªç©ºçŠ¶æ…‹åˆ¤å®šãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å®Œå…¨ã«ç©ºã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_completely_empty({}) is True
        assert xlsx2json.is_completely_empty([]) is True
        assert xlsx2json.is_completely_empty({"empty": {}}) is True
        assert xlsx2json.is_completely_empty([[], {}]) is True
        assert xlsx2json.is_completely_empty({"a": None, "b": "", "c": []}) is True

        # ãƒã‚¹ãƒˆã—ãŸç©ºæ§‹é€ 
        nested_empty = {
            "level1": {
                "level2": {
                    "empty_list": [],
                    "empty_dict": {},
                    "null_value": None,
                    "empty_string": "",
                }
            }
        }
        assert xlsx2json.is_completely_empty(nested_empty) is True

        # ç©ºã§ã¯ãªã„ã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_completely_empty({"key": "value"}) is False
        assert xlsx2json.is_completely_empty(["value"]) is False
        assert xlsx2json.is_completely_empty({"nested": {"key": "value"}}) is False
        assert xlsx2json.is_completely_empty({"a": None, "b": "valid"}) is False

    def test_multidimensional_array_string_conversion(self):
        """å¤šæ¬¡å…ƒé…åˆ—æ–‡å­—åˆ—å¤‰æ›æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        æ–‡å­—åˆ—ã‹ã‚‰å¤šæ¬¡å…ƒé…åˆ—ã¸ã®å¤‰æ›ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # 1æ¬¡å…ƒé…åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array("a,b,c", [","])
        assert result == ["a", "b", "c"]

        # 2æ¬¡å…ƒé…åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array(
            "a,b;c,d", [";", ","]
        )
        assert result == [["a", "b"], ["c", "d"]]

        # 3æ¬¡å…ƒé…åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array(
            "a,b;c,d|e,f;g,h", ["|", ";", ","]
        )
        expected = [[["a", "b"], ["c", "d"]], [["e", "f"], ["g", "h"]]]
        assert result == expected

        # ç©ºæ–‡å­—åˆ—å‡¦ç†
        result = xlsx2json.convert_string_to_multidimensional_array("", [","])
        assert result == []

        # Noneå…¥åŠ›å‡¦ç†
        result = xlsx2json.convert_string_to_multidimensional_array(None, [","])
        assert result is None

        # éæ–‡å­—åˆ—å…¥åŠ›å‡¦ç†
        result = xlsx2json.convert_string_to_multidimensional_array(123, [","])
        assert result == 123

    # === JSONãƒ‘ã‚¹æ“ä½œæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_json_path_insertion_comprehensive(self):
        """åŒ…æ‹¬çš„ãªJSONãƒ‘ã‚¹æŒ¿å…¥æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

        æ§˜ã€…ãªãƒ‘ã‚¹å½¢å¼ã§ã®ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å˜ç´”ãªãƒ‘ã‚¹
        root = {}
        xlsx2json.insert_json_path(root, ["name"], "John")
        assert root["name"] == "John"

        # ãƒã‚¹ãƒˆã—ãŸãƒ‘ã‚¹
        root = {}
        xlsx2json.insert_json_path(root, ["user", "profile", "name"], "Jane")
        assert root["user"]["profile"]["name"] == "Jane"

        # é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆinsert_json_pathã¯1ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼‰
        root = {}
        # insert_json_pathã¯å†…éƒ¨ã§é…åˆ—ã‚’é©åˆ‡ã«æ‹¡å¼µã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        xlsx2json.insert_json_path(root, ["items", "1"], "first")
        xlsx2json.insert_json_path(root, ["items", "2"], "second")
        xlsx2json.insert_json_path(root, ["items", "3"], "third")

        if "items" in root and isinstance(root["items"], list):
            assert root["items"][0] == "first"
            assert root["items"][1] == "second"
            assert root["items"][2] == "third"
        else:
            # é…åˆ—å½¢å¼ã§ãªã„å ´åˆã¯è¾æ›¸å½¢å¼ã§ç¢ºèª
            assert root["items"]["1"] == "first"
            assert root["items"]["2"] == "second"
            assert root["items"]["3"] == "third"

        # è¤‡é›‘ãªæ··åˆãƒ‘ã‚¹
        root = {}
        xlsx2json.insert_json_path(root, ["data", "1", "user", "name"], "Alice")
        xlsx2json.insert_json_path(root, ["data", "1", "user", "age"], 30)
        xlsx2json.insert_json_path(root, ["data", "2", "user", "name"], "Bob")

        if "data" in root and isinstance(root["data"], list) and len(root["data"]) >= 2:
            assert root["data"][0]["user"]["name"] == "Alice"
            assert root["data"][0]["user"]["age"] == 30
            assert root["data"][1]["user"]["name"] == "Bob"
        else:
            # è¾æ›¸å½¢å¼ã®å ´åˆ
            assert root["data"]["1"]["user"]["name"] == "Alice"
            assert root["data"]["1"]["user"]["age"] == 30
            assert root["data"]["2"]["user"]["name"] == "Bob"

    def test_json_path_edge_cases(self):
        """JSONãƒ‘ã‚¹æŒ¿å…¥ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ

        å¢ƒç•Œæ¡ä»¶ã‚„ç‰¹æ®Šã‚±ãƒ¼ã‚¹ã§ã®å‹•ä½œã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç©ºã®ãƒ‘ã‚¹ï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
        root = {"existing": "data"}
        # ç©ºãƒ‘ã‚¹ã§ã¯é©åˆ‡ãªValueErrorãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        with pytest.raises(ValueError, match="JSONãƒ‘ã‚¹ãŒç©ºã§ã™"):
            xlsx2json.insert_json_path(root, [], "new_value")

        # é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆ1ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
        root = {}
        xlsx2json.insert_json_path(root, ["items", "01"], "padded_one")
        if (
            "items" in root
            and isinstance(root["items"], list)
            and len(root["items"]) > 0
        ):
            assert root["items"][0] == "padded_one"
        else:
            # è¾æ›¸å½¢å¼ã®å ´åˆ
            assert root["items"]["01"] == "padded_one"

        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ä¸Šæ›¸ã
        root = {"user": {"name": "old_name"}}
        xlsx2json.insert_json_path(root, ["user", "name"], "new_name")
        assert root["user"]["name"] == "new_name"

    # === ãƒ•ã‚¡ã‚¤ãƒ«åé›†ã¨ãƒ‘ã‚¹è§£æ±ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_excel_file_collection_operations(self, temp_dir):
        """Excelãƒ•ã‚¡ã‚¤ãƒ«åé›†æ“ä½œãƒ†ã‚¹ãƒˆ

        ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®Excelãƒ•ã‚¡ã‚¤ãƒ«åé›†ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ãƒ†ã‚¹ãƒˆç”¨Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        xlsx_files = []
        for i in range(3):
            xlsx_file = temp_dir / f"test_{i}.xlsx"
            wb = Workbook()
            wb.save(xlsx_file)
            xlsx_files.append(xlsx_file)

        # éExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä½œæˆ
        txt_file = temp_dir / "readme.txt"
        txt_file.write_text("This is not an Excel file")

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæŒ‡å®šã§ã®ãƒ•ã‚¡ã‚¤ãƒ«åé›†
        collected_files = xlsx2json.collect_xlsx_files([str(temp_dir)])
        assert len(collected_files) == 3
        for xlsx_file in xlsx_files:
            assert xlsx_file in collected_files
        assert txt_file not in collected_files

        # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®šã§ã®åé›†
        single_file_result = xlsx2json.collect_xlsx_files([str(xlsx_files[0])])
        assert len(single_file_result) == 1
        assert xlsx_files[0] in single_file_result

        # å­˜åœ¨ã—ãªã„ãƒ‘ã‚¹ã§ã®åé›†
        nonexistent_result = xlsx2json.collect_xlsx_files(["/nonexistent/path"])
        assert len(nonexistent_result) == 0

    # === ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ ===

    def test_data_cleaning_operations_comprehensive(self):
        """åŒ…æ‹¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ“ä½œãƒ†ã‚¹ãƒˆ

        æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã§ã®ç©ºå€¤ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # è¤‡é›‘ãªãƒã‚¹ãƒˆæ§‹é€ ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        test_data = {
            "name": "æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿",
            "empty_string": "",
            "null_value": None,
            "empty_list": [],
            "empty_dict": {},
            "valid_list": [1, 2, 3],
            "mixed_list": [1, "", None, 2, [], {}],
            "nested": {
                "valid": "ãƒ‡ãƒ¼ã‚¿",
                "empty": "",
                "null": None,
                "deep_nested": {"empty_array": [], "valid_value": "ä¿æŒã•ã‚Œã‚‹"},
            },
        }

        # suppress_empty=True ã§ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        cleaned_data = xlsx2json.clean_empty_values(test_data, suppress_empty=True)

        # ç©ºå€¤ãŒå‰Šé™¤ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert "empty_string" not in cleaned_data
        assert "null_value" not in cleaned_data
        assert "empty_list" not in cleaned_data
        assert "empty_dict" not in cleaned_data

        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert cleaned_data["name"] == "æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿"
        assert cleaned_data["valid_list"] == [1, 2, 3]
        assert cleaned_data["nested"]["valid"] == "ãƒ‡ãƒ¼ã‚¿"
        assert cleaned_data["nested"]["deep_nested"]["valid_value"] == "ä¿æŒã•ã‚Œã‚‹"

        # é…åˆ—ã‹ã‚‰ç©ºå€¤ãŒå‰Šé™¤ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert cleaned_data["mixed_list"] == [1, 2]

        # suppress_empty=False ã§ã®å‹•ä½œç¢ºèª
        uncleaned_data = xlsx2json.clean_empty_values(test_data, suppress_empty=False)
        assert uncleaned_data == test_data  # å¤‰æ›´ã•ã‚Œãªã„
        result = xlsx2json.convert_string_to_multidimensional_array(
            "a,b|c,d;e,f|g,h", [";", "|", ","]
        )
        expected = [[["a", "b"], ["c", "d"]], [["e", "f"], ["g", "h"]]]
        assert result == expected

        # ç©ºæ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array("", [","])
        assert result == []

        # éæ–‡å­—åˆ—å…¥åŠ›
        result = xlsx2json.convert_string_to_multidimensional_array(123, [","])
        assert result == 123

    def test_insert_json_path(self):
        """JSONãƒ‘ã‚¹æŒ¿å…¥é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
        root = {}

        # å˜ç´”ãªãƒ‘ã‚¹
        xlsx2json.insert_json_path(root, ["key"], "value")
        assert root == {"key": "value"}

        # ãƒã‚¹ãƒˆã—ãŸãƒ‘ã‚¹
        xlsx2json.insert_json_path(root, ["nested", "key"], "nested_value")
        assert root["nested"]["key"] == "nested_value"

        # é…åˆ—ã®ãƒ‘ã‚¹
        root = {}
        xlsx2json.insert_json_path(root, ["array", "1"], "first")
        xlsx2json.insert_json_path(root, ["array", "2"], "second")
        assert isinstance(root["array"], list)
        assert root["array"][0] == "first"
        assert root["array"][1] == "second"

    # === Containeræ©Ÿèƒ½ï¼šã‚»ãƒ«åç”Ÿæˆãƒ»å‘½åè¦å‰‡ãƒ†ã‚¹ãƒˆ ===


class TestErrorHandling:
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def temp_dir(self):
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)

    # === ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ ===

    def test_invalid_file_format_handling(self, temp_dir):
        """ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ

        JSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç„¡åŠ¹ãªJSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«
        invalid_schema_file = temp_dir / "invalid_schema.json"
        with invalid_schema_file.open("w") as f:
            f.write('{"invalid": json}')  # æœ‰åŠ¹ã§ãªã„JSON

        with pytest.raises(json.JSONDecodeError):
            xlsx2json.load_schema(invalid_schema_file)

        # æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã®ã‚ã‚‹JSONãƒ•ã‚¡ã‚¤ãƒ«
        broken_json_file = temp_dir / "broken.json"
        with broken_json_file.open("w") as f:
            f.write('{"unclosed": "string}')  # é–‰ã˜æ‹¬å¼§ãªã—

        with pytest.raises(json.JSONDecodeError):
            with broken_json_file.open("r") as f:
                json.load(f)

    def test_missing_file_resources_handling(self, temp_dir):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ

        å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å­˜åœ¨ã—ãªã„ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«
        nonexistent_file = temp_dir / "nonexistent.json"
        with pytest.raises(FileNotFoundError):
            xlsx2json.load_schema(nonexistent_file)

        # å­˜åœ¨ã—ãªã„Excelãƒ•ã‚¡ã‚¤ãƒ«
        nonexistent_xlsx = temp_dir / "nonexistent.xlsx"
        with pytest.raises(FileNotFoundError):
            xlsx2json.parse_named_ranges_with_prefix(nonexistent_xlsx, prefix="json")

        # æ¨©é™ä¸è¶³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã®ãƒ•ã‚¡ã‚¤ãƒ«åé›†ï¼ˆãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
        with patch("xlsx2json.logger") as mock_logger:
            with patch("os.listdir", side_effect=PermissionError("Permission denied")):
                result = xlsx2json.collect_xlsx_files(["/nonexistent/restricted"])
                assert result == []
                # è­¦å‘Šãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_logger.warning.assert_called()

    # === ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ ===

    def test_array_transformation_error_scenarios(self):
        """é…åˆ—å¤‰æ›å‡¦ç†ã§ã®ã‚¨ãƒ©ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ

        ç„¡åŠ¹ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚„é–¢æ•°ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ç„¡åŠ¹ãªå¤‰æ›é–¢æ•°ã®ãƒ†ã‚¹ãƒˆï¼ˆline 364-370ã‚’ã‚«ãƒãƒ¼ï¼‰
        with pytest.raises(ValueError, match="Failed to load transform function"):
            xlsx2json.ArrayTransformRule(
                "json.test", "function", "non_existent_module:invalid_function"
            )

        # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError, match="Failed to load transform function"):
            xlsx2json.ArrayTransformRule(
                "json.test", "function", "/nonexistent/file.py:some_function"
            )

        # ç„¡åŠ¹ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä»•æ§˜ã®ãƒ†ã‚¹ãƒˆï¼ˆline 370-371ã‚’ã‚«ãƒãƒ¼ï¼‰
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as tmp:
            tmp.write("# Invalid Python syntax [\n")
            tmp.flush()
            try:
                with pytest.raises(
                    ValueError, match="Failed to load transform function"
                ):
                    xlsx2json.ArrayTransformRule(
                        "json.test", "function", f"{tmp.name}:some_function"
                    )
            finally:
                Path(tmp.name).unlink()

        # ç„¡åŠ¹ãªå¤‰æ›ã‚¿ã‚¤ãƒ—ã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError):
            xlsx2json.ArrayTransformRule("json.test", "invalid_type", "spec")

        # é–¢æ•°ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
        try:
            rule = xlsx2json.ArrayTransformRule(
                "json.test", "function", "invalid_python_code"
            )
        except Exception:
            pass  # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’æœŸå¾…

    def test_command_execution_error_handling(self):
        """ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ

        å¤–éƒ¨ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œæ™‚ã®ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®ãƒ†ã‚¹ãƒˆ
        with patch("subprocess.run") as mock_run:
            mock_run.side_effect = subprocess.TimeoutExpired("test_cmd", 1)

            try:
                rule = xlsx2json.ArrayTransformRule("json.test", "command", "sleep 10")
                rule.transform("test_data")
            except Exception:
                pass  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¾‹å¤–ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…

        # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œå¤±æ•—ã®ãƒ†ã‚¹ãƒˆ
        with patch("subprocess.run") as mock_run:
            mock_run.side_effect = subprocess.CalledProcessError(1, "test_cmd")

            try:
                rule = xlsx2json.ArrayTransformRule("json.test", "command", "exit 1")
                rule.transform("test_data")
            except Exception:
                pass  # å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…

    # === ã‚¹ã‚­ãƒ¼ãƒãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ ===

    def test_schema_validation_error_processing(self, temp_dir):
        """ã‚¹ã‚­ãƒ¼ãƒãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ†ã‚¹ãƒˆ

        ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒé•åæ™‚ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç”ŸæˆãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å‹é•åãƒ‡ãƒ¼ã‚¿
        invalid_data = {
            "name": 123,  # æ–‡å­—åˆ—ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒæ•°å€¤
            "age": "not_a_number",  # æ•°å€¤ãŒæœŸå¾…ã•ã‚Œã‚‹ãŒæ–‡å­—åˆ—
            "email": "invalid_email_format",  # ãƒ¡ãƒ¼ãƒ«å½¢å¼ã§ã¯ãªã„
        }

        # å³æ ¼ãªã‚¹ã‚­ãƒ¼ãƒ
        strict_schema = {
            "type": "object",
            "properties": {
                "name": {"type": "string"},
                "age": {"type": "integer", "minimum": 0},
                "email": {"type": "string", "format": "email"},
            },
            "required": ["name", "age", "email"],
        }

        validator = Draft7Validator(strict_schema)
        log_dir = temp_dir / "error_logs"

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç”Ÿæˆ
        xlsx2json.validate_and_log(invalid_data, validator, log_dir, "validation_test")

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        error_log = log_dir / "validation_test.error.log"
        assert error_log.exists()

        # ã‚¨ãƒ©ãƒ¼å†…å®¹ã®ç¢ºèª
        with error_log.open("r", encoding="utf-8") as f:
            log_content = f.read()
            assert len(log_content) > 0  # ã‚¨ãƒ©ãƒ¼å†…å®¹ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹

    # === ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ ===

    def test_main_application_error_scenarios(self, temp_dir):
        """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œæ™‚ã®ã‚¨ãƒ©ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ

        ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œæ™‚ã®æ§˜ã€…ãªã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # å¼•æ•°ãªã—ã§ã®å®Ÿè¡Œ
        with patch("sys.argv", ["xlsx2json.py"]):
            with patch("xlsx2json.logger") as mock_logger:
                result = xlsx2json.main()
                assert result == 1  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1ã‚’è¿”ã™
                mock_logger.error.assert_called()

        # ç„¡åŠ¹ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã®å®Ÿè¡Œ
        invalid_config = temp_dir / "invalid_config.json"
        with invalid_config.open("w") as f:
            f.write("invalid json content")

        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch(
            "sys.argv",
            ["xlsx2json.py", "--config", str(invalid_config), str(test_xlsx)],
        ):
            with patch("xlsx2json.logger") as mock_logger:
                result = xlsx2json.main()
                assert result == 1  # JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ã§ã¯1ã‚’è¿”ã™

        # è§£æä¾‹å¤–ã§ã®å®Ÿè¡Œ
        with patch("sys.argv", ["xlsx2json.py", str(test_xlsx)]):
            with patch(
                "xlsx2json.parse_named_ranges_with_prefix",
                side_effect=Exception("Test exception"),
            ):
                with patch("xlsx2json.logger") as mock_logger:
                    result = xlsx2json.main()
                    assert result == 0  # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼ã§ã‚‚ãƒ¡ã‚¤ãƒ³é–¢æ•°ã¯0ã‚’è¿”ã™
                    # processing_stats.add_errorãŒå‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

    # === ãƒªã‚½ãƒ¼ã‚¹ãƒ»æ¨©é™ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ ===

    def test_resource_permission_error_handling(self, temp_dir):
        """ãƒªã‚½ãƒ¼ã‚¹ãƒ»æ¨©é™ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ

        ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ æ¨©é™ã‚„ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # èª­ã¿å–ã‚Šå°‚ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã®æ›¸ãè¾¼ã¿è©¦è¡Œ
        readonly_dir = temp_dir / "readonly"
        readonly_dir.mkdir()
        readonly_dir.chmod(0o444)  # èª­ã¿å–ã‚Šå°‚ç”¨

        test_data = {"test": "data"}

        try:
            output_path = readonly_dir / "test.json"
            with pytest.raises(PermissionError):
                xlsx2json.write_json(test_data, output_path)
        finally:
            readonly_dir.chmod(0o755)  # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

    def test_edge_case_error_conditions(self):
        """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ã‚¨ãƒ©ãƒ¼æ¡ä»¶ãƒ†ã‚¹ãƒˆ

        å¢ƒç•Œæ¡ä»¶ã‚„ç‰¹æ®Šãªã‚±ãƒ¼ã‚¹ã§ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # None ãƒ‡ãƒ¼ã‚¿ã§ã®å‡¦ç†
        result = xlsx2json.clean_empty_values(None, suppress_empty=True)
        assert result is None

        # å¾ªç’°å‚ç…§ãƒ‡ãƒ¼ã‚¿ã§ã®JSONå‡ºåŠ›
        circular_data = {}
        circular_data["self"] = circular_data

        with pytest.raises((ValueError, RecursionError)):
            json.dumps(circular_data)

        # ç„¡åŠ¹ãªãƒ‘ã‚¹å½¢å¼ã§ã® JSON ãƒ‘ã‚¹æŒ¿å…¥
        root = {}
        try:
            xlsx2json.insert_json_path(root, ["invalid", "path", ""], "value")
        except Exception:
            pass  # ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…

    def test_comprehensive_error_recovery(self):
        """åŒ…æ‹¬çš„ãªã‚¨ãƒ©ãƒ¼å›å¾©ãƒ†ã‚¹ãƒˆ

        è¤‡æ•°ã®ã‚¨ãƒ©ãƒ¼ãŒé€£ç¶šã—ã¦ç™ºç”Ÿã—ãŸå ´åˆã®å›å¾©å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        """
        # ãƒ­ã‚°è¨­å®šã‚¨ãƒ©ãƒ¼
        original_logger = xlsx2json.logger
        try:
            # ãƒ­ã‚¬ãƒ¼ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
            xlsx2json.logger = None

            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ãŒç¶™ç¶šã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            try:
                xlsx2json.is_empty_value("")
            except AttributeError:
                pass  # ãƒ­ã‚¬ãƒ¼ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚‹ä¾‹å¤–

        finally:
            xlsx2json.logger = original_logger

        # è¤‡æ•°ã®å¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼
        invalid_rules = [
            "json.test1=invalid_type:spec",
            "json.test2=function:non_existent:func",
            "json.test3=command:invalid_command",
        ]

        with patch("xlsx2json.logger") as mock_logger:
            try:
                xlsx2json.parse_array_transform_rules(invalid_rules, "json")
            except Exception:
                pass
            # è­¦å‘Šãƒ»ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒé©åˆ‡ã«å‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert mock_logger.warning.called or mock_logger.error.called
        with pytest.raises(ValueError, match="Failed to load transform function"):
            xlsx2json.ArrayTransformRule(
                "test.path", "function", "nonexistent_module:nonexistent_function"
            )

    @patch("subprocess.run")
    def test_command_timeout(self, mock_run):
        """ã‚³ãƒãƒ³ãƒ‰ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹
        mock_run.side_effect = subprocess.TimeoutExpired("sleep", 30)

        rule = xlsx2json.ArrayTransformRule("test.path", "command", "sleep 60")
        result = rule.transform("test_value")

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯å…ƒã®å€¤ãŒè¿”ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert result == "test_value"

    def test_array_transform_rule_comprehensive_errors(self):
        """ArrayTransformRuleã®åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆï¼ˆçµ±åˆï¼‰"""
        # ç„¡åŠ¹ãªã‚¿ã‚¤ãƒ—ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError):
            xlsx2json.ArrayTransformRule("path", "invalid_type", "spec")

        # ç„¡åŠ¹ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä»•æ§˜ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError, match="must be.*function"):
            xlsx2json.ArrayTransformRule("test.path", "function", "invalid_spec")

        # å­˜åœ¨ã—ãªã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError, match="Failed to load.*function"):
            xlsx2json.ArrayTransformRule("test.path", "function", "nonexistent_module:func")

        # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError, match="Failed to load.*function"):
            xlsx2json.ArrayTransformRule("test.path", "function", "nonexistent.py:func")

        # é–¢æ•°ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
        try:
            rule = xlsx2json.ArrayTransformRule(
                "path", "function", "lambda: undefined_var"
            )
            rule.transform("test")  # Should trigger function execution error
        except Exception:
            pass  # Expected error

    def test_array_transform_rule_command_execution_error(self):
        """ArrayTransformRuleã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆï¼ˆline 408å¯¾å¿œï¼‰"""
        try:
            rule = xlsx2json.ArrayTransformRule(
                "path", "command", "command_that_does_not_exist_xyz"
            )
            result = rule.transform("input")
        except Exception:
            pass  # Expected for command execution errors

    def test_array_transform_rule_split_processing_errors(self):
        """ArrayTransformRuleã®splitå‡¦ç†ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆï¼ˆlines 414, 418å¯¾å¿œï¼‰"""
        try:
            rule = xlsx2json.ArrayTransformRule("path", "split", "")  # Empty delimiter
            result = rule.transform("test,data")
        except Exception:
            pass  # Expected for split processing errors

    def test_parse_array_split_rules_invalid_format(self):
        """parse_array_split_rulesã®ç„¡åŠ¹ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè­¦å‘Šãƒ†ã‚¹ãƒˆï¼ˆlines 294-295å¯¾å¿œï¼‰"""
        invalid_rules = ["invalid_rule_format", "another=invalid"]

        with patch("xlsx2json.logger") as mock_logger:
            xlsx2json.parse_array_split_rules(invalid_rules, "json")

            # ç„¡åŠ¹ãªé…åˆ—åŒ–è¨­å®šã®è­¦å‘ŠãŒå‡ºåŠ›ã•ã‚Œã‚‹
            mock_logger.warning.assert_called()
            assert "ç„¡åŠ¹ãªé…åˆ—åŒ–è¨­å®š" in str(mock_logger.warning.call_args)

    def test_collect_xlsx_files_comprehensive(self):
        """collect_xlsx_filesçµ±åˆãƒ†ã‚¹ãƒˆï¼ˆé‡è¤‡å‰Šé™¤ï¼‰"""
        # ç„¡åŠ¹ãªãƒ‘ã‚¹å‡¦ç†ãƒ†ã‚¹ãƒˆ
        invalid_paths = ["/nonexistent/path", "/another/invalid/path"]
        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.collect_xlsx_files(invalid_paths)
            assert result == []

        # ç©ºã®ãƒªã‚¹ãƒˆã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(ValueError, match="å…¥åŠ›ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆãŒç©ºã§ã™"):
            xlsx2json.collect_xlsx_files([])

        # ç„¡åŠ¹ãªãƒ‘ã‚¹å½¢å¼ã®ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.collect_xlsx_files([None, "", "valid_path.xlsx"])
        assert isinstance(result, list)

        # å­˜åœ¨ã—ãªã„ãƒ‘ã‚¹ã§ã®è­¦å‘Šãƒ­ã‚°ãƒ†ã‚¹ãƒˆ
        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.collect_xlsx_files(["/non/existent/path"])
            assert result == []
            mock_logger.warning.assert_called()

    def test_main_function_error_handling(self):
        """mainé–¢æ•°ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        original_argv = sys.argv
        try:
            # å¼•æ•°ãªã—ã§ã®mainå®Ÿè¡Œã‚’ãƒ†ã‚¹ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ãŒã‚«ãƒãƒ¬ãƒƒã‚¸ã¯å‘ä¸Šï¼‰
            sys.argv = ["xlsx2json.py"]

            try:
                xlsx2json.main()
            except SystemExit:
                # å¼•æ•°ä¸è¶³ã«ã‚ˆã‚‹æ­£å¸¸ãªçµ‚äº†
                pass
            except Exception:
                # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã‚‚è¨±å®¹ï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸ŠãŒç›®çš„ï¼‰
                pass

        finally:
            sys.argv = original_argv

    def test_command_execution_scenarios_lines_408_418_from_precision(self):
        """Test command execution scenarios covering lines 408-418 (æ—§TestPrecisionCoverage95Plusçµ±åˆ)"""
        # Test command-based array transformations using proper API
        try:
            rule = xlsx2json.ArrayTransformRule("json.test", "command", "echo 'a b c'")
            result = rule.transform("test_input")
            # Should return array or handle gracefully
        except Exception:
            pass  # Expected for command execution

        try:
            rule = xlsx2json.ArrayTransformRule(
                "json.test", "command", "invalid_command_xyz"
            )
            result = rule.transform("test_input")
        except Exception:
            pass  # Expected for invalid commands

        try:
            rule = xlsx2json.ArrayTransformRule(
                "json.test", "command", "python -c 'print(\"1\\n2\\n3\")'"
            )
            result = rule.transform("input")
        except Exception:
            pass  # Expected for complex commands

    # === æ‹¡å¼µã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ ===

    def test_array_transform_rule_parameter_validation(self):
        """ArrayTransformRuleã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""

        # ç©ºã®path
        with pytest.raises(
            ValueError, match="pathã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.ArrayTransformRule("", "function", "test:func")

        # Noneã®path
        with pytest.raises(
            ValueError, match="pathã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.ArrayTransformRule(None, "function", "test:func")

        # ç©ºã®transform_type
        with pytest.raises(
            ValueError, match="transform_typeã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.ArrayTransformRule("test", "", "test:func")

        # ç©ºã®transform_spec
        with pytest.raises(
            ValueError, match="transform_specã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.ArrayTransformRule("test", "function", "")

    def test_parse_array_split_rules_enhanced_validation(self):
        """parse_array_split_rulesé–¢æ•°ã®æ‹¡å¼µãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""

        # ç©ºã®prefixã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(
            ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.parse_array_split_rules(["test=,"], "")

        # Noneã®prefixã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(
            ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.parse_array_split_rules(["test=,"], None)

    def test_parse_array_transform_rules_enhanced_validation(self):
        """parse_array_transform_rulesé–¢æ•°ã®æ‹¡å¼µãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""

        # ç©ºã®prefixã®ãƒ†ã‚¹ãƒˆ
        with pytest.raises(
            ValueError, match="prefixã¯ç©ºã§ã¯ãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        ):
            xlsx2json.parse_array_transform_rules(["test=function:module:func"], "")


if __name__ == "__main__":
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®šï¼ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã®è©³ç´°æƒ…å ±è¡¨ç¤ºç”¨ï¼‰
    logging.basicConfig(level=logging.INFO)

    # pytestå®Ÿè¡Œ
    pytest.main([__file__, "-v"])

    def test_load_schema_valid(self, sample_schema):
        """Test loading a valid schema"""
        schema = xlsx2json.load_schema(sample_schema)
        assert schema is not None
        assert "properties" in schema
        assert "name" in schema["properties"]

    def test_load_schema_none(self):
        """Test loading schema with None path"""
        schema = xlsx2json.load_schema(None)
        assert schema is None

    def test_get_named_range_values_single_cell(self, sample_xlsx):
        """Test extracting value from single cell named range"""
        wb = xlsx2json.load_workbook(sample_xlsx, data_only=True)
        defined_name = wb.defined_names["json.name.1"]
        value = xlsx2json.get_named_range_values(wb, defined_name)
        assert value == "John"

    def test_get_named_range_values_range(self, sample_xlsx):
        """Test extracting values from range named range"""
        wb = xlsx2json.load_workbook(sample_xlsx, data_only=True)
        defined_name = wb.defined_names["json.range"]
        values = xlsx2json.get_named_range_values(wb, defined_name)
        assert values == ["John", "Jane"]

    def test_is_completely_empty(self):
        """Test complete emptiness detection"""
        assert xlsx2json.is_completely_empty(None) is True
        assert xlsx2json.is_completely_empty("") is True
        assert xlsx2json.is_completely_empty([]) is True
        assert xlsx2json.is_completely_empty({}) is True
        assert xlsx2json.is_completely_empty({"a": None, "b": ""}) is True
        assert xlsx2json.is_completely_empty([None, "", {}]) is True
        assert xlsx2json.is_completely_empty({"a": "value"}) is False
        assert xlsx2json.is_completely_empty([1, 2, 3]) is False

    def test_insert_json_path_simple(self):
        """Test simple JSON path insertion"""
        root = {}
        xlsx2json.insert_json_path(root, ["name"], "John")
        assert root["name"] == "John"

    def test_insert_json_path_nested(self):
        """Test nested JSON path insertion"""
        root = {}
        xlsx2json.insert_json_path(root, ["person", "name"], "John")
        assert root["person"]["name"] == "John"

    def test_insert_json_path_array(self):
        """Test array JSON path insertion"""
        root = {}
        xlsx2json.insert_json_path(root, ["items", "1"], "first")
        xlsx2json.insert_json_path(root, ["items", "2"], "second")
        assert root["items"][0] == "first"
        assert root["items"][1] == "second"

    def test_convert_string_to_multidimensional_array(self):
        """Test string to multidimensional array conversion"""
        # 1D array
        result = xlsx2json.convert_string_to_multidimensional_array("a,b,c", [","])
        assert result == ["a", "b", "c"]

        # 2D array
        result = xlsx2json.convert_string_to_multidimensional_array(
            "a,b\nc,d", ["\n", ","]
        )
        assert result == [["a", "b"], ["c", "d"]]

        # Empty string
        result = xlsx2json.convert_string_to_multidimensional_array("", [","])
        assert result == []

        # Non-string input
        result = xlsx2json.convert_string_to_multidimensional_array(123, [","])
        assert result == 123

    def test_array_transform_rule_split(self):
        """Test ArrayTransformRule with split type"""
        rule = xlsx2json.ArrayTransformRule("test.path", "split", "split:,")
        rule._transform_func = (
            lambda x: xlsx2json.convert_string_to_multidimensional_array(x, [","])
        )

        result = rule.transform("a,b,c")
        assert result == ["a", "b", "c"]

    def test_parse_array_transform_rules(self):
        """Test parsing array transform rules"""
        rules_list = ["colors=split:,", "items=split:\n"]
        rules = xlsx2json.parse_array_transform_rules(rules_list, "json", None)

        assert "colors" in rules
        assert "items" in rules
        assert rules["colors"].transform_type == "split"
        assert rules["items"].transform_type == "split"

    def test_parse_named_ranges_with_prefix_basic(self, sample_xlsx):
        """Test basic named range parsing"""
        result = xlsx2json.parse_named_ranges_with_prefix(sample_xlsx, "json")

        assert "name" in result
        assert "surname" in result
        assert result["name"]["1"] == "John"
        assert result["name"]["2"] == "Jane"
        assert result["surname"]["1"] == "Doe"
        assert result["surname"]["2"] == "Smith"

    def test_parse_named_ranges_with_transform_rules(self, sample_xlsx):
        """Test named range parsing with transform rules"""
        transform_rules = {
            "colors.1": xlsx2json.ArrayTransformRule("colors.1", "split", "split:,"),
            "colors.2": xlsx2json.ArrayTransformRule("colors.2", "split", "split:,"),
        }

        # Set up transform functions
        for rule in transform_rules.values():
            rule._transform_func = (
                lambda x: xlsx2json.convert_string_to_multidimensional_array(x, [","])
            )

        result = xlsx2json.parse_named_ranges_with_prefix(
            sample_xlsx, "json", array_transform_rules=transform_rules
        )

        assert isinstance(result["colors"]["1"], list)
        assert result["colors"]["1"] == ["apple", "banana", "cherry"]
        assert result["colors"]["2"] == ["red", "green", "blue"]

    def test_collect_xlsx_files(self, temp_dir, sample_xlsx):
        """Test collecting xlsx files"""
        # Test with file path
        files = xlsx2json.collect_xlsx_files([str(sample_xlsx)])
        assert len(files) == 1
        assert files[0] == sample_xlsx

        # Test with directory path
        files = xlsx2json.collect_xlsx_files([str(temp_dir)])
        assert len(files) == 1
        assert sample_xlsx in files

    def test_write_json(self, temp_dir):
        """Test JSON file writing"""
        test_data = {"name": "John", "age": 30}
        output_path = temp_dir / "output.json"

        xlsx2json.write_json(test_data, output_path)

        assert output_path.exists()
        with output_path.open("r", encoding="utf-8") as f:
            written_data = json.load(f)
        assert written_data == test_data

    @patch("sys.argv")
    @patch("xlsx2json.collect_xlsx_files")
    @patch("xlsx2json.parse_named_ranges_with_prefix")
    @patch("xlsx2json.write_json")
    def test_main_basic_functionality(
        self,
        mock_write_json,
        mock_parse,
        mock_collect,
        mock_argv,
        sample_xlsx,
        temp_dir,
    ):
        """Test main function basic functionality"""
        # Setup mocks
        mock_argv.__getitem__ = lambda _, index: [
            "xlsx2json.py",
            str(sample_xlsx),
            "--output-dir",
            str(temp_dir),
        ][index]
        mock_argv.__len__ = lambda _: 4

        mock_collect.return_value = [sample_xlsx]
        mock_parse.return_value = {"name": "John", "age": 30}

        # Run main
        xlsx2json.main()

        # Verify calls
        mock_collect.assert_called_once()
        mock_parse.assert_called_once()
        mock_write_json.assert_called_once()

    @patch("sys.argv")
    def test_main_no_inputs(self, mock_argv):
        """Test main function with no inputs"""
        mock_argv.__getitem__ = lambda _, index: ["xlsx2json.py"][index]
        mock_argv.__len__ = lambda _: 1

        # Should not raise exception, but log error
        with patch("xlsx2json.logger") as mock_logger:
            xlsx2json.main()
            mock_logger.error.assert_called()

    @patch("sys.argv")
    @patch("xlsx2json.collect_xlsx_files")
    def test_main_with_schema(
        self, mock_collect, mock_argv, sample_xlsx, sample_schema, temp_dir
    ):
        """Test main function with schema validation"""
        mock_argv.__getitem__ = lambda _, index: [
            "xlsx2json.py",
            str(sample_xlsx),
            "--schema",
            str(sample_schema),
            "--output-dir",
            str(temp_dir),
        ][index]
        mock_argv.__len__ = lambda _: 6

        mock_collect.return_value = [sample_xlsx]

        with (
            patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
            patch("xlsx2json.write_json") as mock_write_json,
        ):
            mock_parse.return_value = {"name": {"1": "John"}}

            xlsx2json.main()

            # Verify schema was loaded and passed to write_json
            args, kwargs = mock_write_json.call_args
            assert len(args) >= 3  # data, output_path, schema
            assert args[2] is not None  # schema should not be None

    @patch("sys.argv")
    @patch("xlsx2json.collect_xlsx_files")
    def test_main_with_transform_rules(
        self, mock_collect, mock_argv, sample_xlsx, temp_dir
    ):
        """Test main function with transform rules"""
        mock_argv.__getitem__ = lambda _, index: [
            "xlsx2json.py",
            str(sample_xlsx),
            "--transform",
            "colors=split:,",
            "--output-dir",
            str(temp_dir),
        ][index]
        mock_argv.__len__ = lambda _: 6

        mock_collect.return_value = [sample_xlsx]

        with (
            patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
            patch("xlsx2json.write_json") as mock_write_json,
        ):
            mock_parse.return_value = {"colors": ["red", "green", "blue"]}

            xlsx2json.main()

            # Verify transform rules were parsed and passed
            mock_parse.assert_called_once()
            call_args = mock_parse.call_args
            assert "array_transform_rules" in call_args[1]
            assert call_args[1]["array_transform_rules"] is not None

    def test_reorder_json_with_schema(self):
        """Test JSON reordering according to schema"""
        data = {"age": 30, "name": "John", "city": "NYC"}
        schema = {"properties": {"name": {"type": "string"}, "age": {"type": "number"}}}

        reordered = xlsx2json.reorder_json(data, schema)

        # Should maintain schema order for properties that exist in schema
        keys = list(reordered.keys())
        assert keys.index("name") < keys.index("age")
        assert "city" in reordered  # Additional properties should be preserved

    @patch("argparse.ArgumentParser.parse_args")
    def test_argument_parsing(self, mock_parse_args):
        """Test command line argument parsing"""
        # Setup mock arguments
        mock_args = argparse.Namespace(
            inputs=["test.xlsx"],
            output_dir=Path("output"),
            schema=Path("schema.json"),
            transform=["colors=split:,"],
            config=None,
            trim=False,
            keep_empty=False,
            log_level="INFO",
            prefix="json",
        )
        mock_parse_args.return_value = mock_args

        with (
            patch("xlsx2json.collect_xlsx_files", return_value=[]),
            patch("xlsx2json.logger"),
        ):
            xlsx2json.main()

        mock_parse_args.assert_called_once()

    def test_empty_value_handling_with_keep_empty_false(self, sample_xlsx, temp_dir):
        """Test that empty values are removed when keep_empty=False"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--output-dir",
                str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 4

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json") as mock_write_json,
            ):

                mock_parse.return_value = {"name": "John", "empty": "", "null": None}

                xlsx2json.main()

                # Verify suppress_empty=True was passed to write_json
                call_args = mock_write_json.call_args
                assert call_args[1]["suppress_empty"] is True

    def test_empty_value_handling_with_keep_empty_true(self, sample_xlsx, temp_dir):
        """Test that empty values are kept when keep_empty=True"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--keep-empty",
                "--output-dir",
                str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json") as mock_write_json,
            ):

                mock_parse.return_value = {"name": "John", "empty": "", "null": None}

                xlsx2json.main()

                # Verify suppress_empty=False was passed to write_json
                call_args = mock_write_json.call_args
                assert call_args[1]["suppress_empty"] is False


class TestCommandLineOptions:
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ
    
    å„ç¨®CLIã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‹•ä½œã‚’åŒ…æ‹¬çš„ã«æ¤œè¨¼:
    - --prefix / -p ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    - --log_level ã®å„ãƒ¬ãƒ™ãƒ«
    - --trim ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    - --container ã‚ªãƒ—ã‚·ãƒ§ãƒ³  
    - --config ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
    - çŸ­ç¸®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    - ã‚ªãƒ—ã‚·ãƒ§ãƒ³çµ„ã¿åˆã‚ã›
    """

    @pytest.fixture
    def temp_dir(self):
        """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆãƒ»å‰Šé™¤"""
        temp_path = Path(tempfile.mkdtemp())
        yield temp_path
        shutil.rmtree(temp_path)

    @pytest.fixture
    def sample_xlsx(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆç”¨Excelãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        xlsx_path = temp_dir / "test.xlsx"
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "Sheet1"
        ws["A1"] = "TestData"
        ws["B1"] = "  Trimable  "
        
        # åå‰ä»˜ãç¯„å›²å®šç¾©
        wb.defined_names["json_test"] = DefinedName(name="json_test", attr_text="Sheet1!$A$1")
        wb.defined_names["json_trim_test"] = DefinedName(name="json_trim_test", attr_text="Sheet1!$B$1")
        
        wb.save(xlsx_path)
        wb.close()
        return xlsx_path

    def test_prefix_option_long_form(self, sample_xlsx, temp_dir):
        """--prefix ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--prefix", "custom",
                "--output_dir", str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json"),
            ):
                mock_parse.return_value = {"test": "data"}
                
                result = xlsx2json.main()
                assert result == 0
                
                # prefixãŒæ­£ã—ãæ¸¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_parse.assert_called_with(sample_xlsx, "custom", containers={})

    def test_prefix_option_short_form(self, sample_xlsx, temp_dir):
        """--prefix ã®çŸ­ç¸®å½¢ -p ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "-p", "short_prefix",
                "-o", str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json"),
            ):
                mock_parse.return_value = {"test": "data"}
                
                result = xlsx2json.main()
                assert result == 0
                
                # çŸ­ç¸®å½¢ã§ã‚‚prefixãŒæ­£ã—ãæ¸¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_parse.assert_called_with(sample_xlsx, "short_prefix", containers={})

    def test_log_level_debug(self, sample_xlsx, temp_dir):
        """--log_level DEBUG ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--log_level", "DEBUG",
                "--output_dir", str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json"),
                patch("logging.basicConfig") as mock_logging,
            ):
                mock_parse.return_value = {"test": "data"}
                
                result = xlsx2json.main()
                assert result == 0
                
                # DEBUGãƒ¬ãƒ™ãƒ«ãŒè¨­å®šã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_logging.assert_called_with(
                    level=logging.DEBUG, 
                    format="%(levelname)s: %(message)s"
                )

    def test_log_level_warning(self, sample_xlsx, temp_dir):
        """--log_level WARNING ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--log_level", "WARNING",
                "--output_dir", str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json"),
                patch("logging.basicConfig") as mock_logging,
            ):
                mock_parse.return_value = {"test": "data"}
                
                result = xlsx2json.main()
                assert result == 0
                
                # WARNINGãƒ¬ãƒ™ãƒ«ãŒè¨­å®šã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_logging.assert_called_with(
                    level=logging.WARNING, 
                    format="%(levelname)s: %(message)s"
                )

    def test_trim_option(self, sample_xlsx, temp_dir):
        """--trim ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--trim",
                "--output_dir", str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 4

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json"),
            ):
                mock_parse.return_value = {"test": "data"}
                
                result = xlsx2json.main()
                assert result == 0
                
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ãŒTrueã«è¨­å®šã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                assert xlsx2json._global_trim == True

    def test_container_option(self, sample_xlsx, temp_dir):
        """--container ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        container_def = '{"sales": {"range": "A1:C10", "direction": "vertical", "items": ["date", "amount"]}}'
        
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--container", container_def,
                "--output_dir", str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json"),
                patch("xlsx2json.validate_cli_containers") as mock_validate,
                patch("xlsx2json.parse_container_args") as mock_parse_containers,
            ):
                mock_parse.return_value = {"test": "data"}
                mock_parse_containers.return_value = {"sales": {"range": "A1:C10", "direction": "vertical", "items": ["date", "amount"]}}
                
                result = xlsx2json.main()
                assert result == 0
                
                # ã‚³ãƒ³ãƒ†ãƒŠã®æ¤œè¨¼ã¨è§£æãŒå‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_validate.assert_called_once()
                mock_parse_containers.assert_called_once()

    def test_schema_option_short_form(self, sample_xlsx, temp_dir):
        """--schema ã®çŸ­ç¸®å½¢ -s ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        schema_file = temp_dir / "test_schema.json"
        schema_content = {
            "type": "object",
            "properties": {
                "test": {"type": "string"}
            }
        }
        
        with schema_file.open("w", encoding="utf-8") as f:
            json.dump(schema_content, f)
        
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "-s", str(schema_file),
                "-o", str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 5

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json"),
            ):
                mock_parse.return_value = {"test": "data"}
                
                result = xlsx2json.main()
                assert result == 0
                
                # ã‚¹ã‚­ãƒ¼ãƒãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                assert xlsx2json._global_schema == schema_content

    def test_multiple_options_combination(self, sample_xlsx, temp_dir):
        """è¤‡æ•°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--prefix", "test_prefix",
                "--trim",
                "--keep_empty",
                "--log_level", "ERROR",
                "--output_dir", str(temp_dir),
            ][index]
            mock_argv.__len__ = lambda _: 9

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json") as mock_write,
                patch("logging.basicConfig") as mock_logging,
            ):
                mock_parse.return_value = {"test": "data"}
                
                result = xlsx2json.main()
                assert result == 0
                
                # å„ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæ­£ã—ãé©ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_parse.assert_called_with(sample_xlsx, "test_prefix", containers={})
                assert xlsx2json._global_trim == True
                mock_logging.assert_called_with(
                    level=logging.ERROR, 
                    format="%(levelname)s: %(message)s"
                )
                
                # keep_emptyã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ç¢ºèªï¼ˆ--keep_emptyãƒ•ãƒ©ã‚°ãŒã‚ã‚‹ã¨suppress_empty=Falseã«ãªã‚‹ï¼‰
                call_args = mock_write.call_args
                # suppress_emptyã¯ä½ç½®å¼•æ•°ã¨ã—ã¦æ¸¡ã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã®ã§ã€args[4]ã¾ãŸã¯ kwargs ã‚’ãƒã‚§ãƒƒã‚¯
                if len(call_args[0]) > 4:
                    assert call_args[0][4] is False  # suppress_empty=False (keep_empty=True)
                elif "suppress_empty" in call_args[1]:
                    assert call_args[1]["suppress_empty"] is False

    def test_config_file_option(self, sample_xlsx, temp_dir):
        """--config ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        config_file = temp_dir / "test_config.json"
        config_content = {
            "prefix": "config_prefix",
            "keep_empty": True,
            "output_dir": str(temp_dir),
            "containers": {
                "test_container": {
                    "range": "A1:B5",
                    "direction": "vertical",
                    "items": ["name", "value"]
                }
            }
        }
        
        with config_file.open("w", encoding="utf-8") as f:
            json.dump(config_content, f)
        
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(sample_xlsx),
                "--config", str(config_file),
            ][index]
            mock_argv.__len__ = lambda _: 3

            with (
                patch("xlsx2json.collect_xlsx_files", return_value=[sample_xlsx]),
                patch("xlsx2json.parse_named_ranges_with_prefix") as mock_parse,
                patch("xlsx2json.write_json") as mock_write,
            ):
                mock_parse.return_value = {"test": "data"}
                
                result = xlsx2json.main()
                assert result == 0
                
                # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®å€¤ãŒä½¿ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                # æ³¨æ„: prefixã¯ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒå„ªå…ˆã•ã‚Œã‚‹  
                mock_parse.assert_called_with(sample_xlsx, "json", containers=config_content["containers"])
                
                # keep_emptyã®è¨­å®šç¢ºèª
                call_args = mock_write.call_args
                # suppress_emptyã¯ä½ç½®å¼•æ•°ã¨ã—ã¦æ¸¡ã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã®ã§ã€args[4]ã‚’ãƒã‚§ãƒƒã‚¯
                if len(call_args[0]) > 4:
                    assert call_args[0][4] is False  # suppress_empty=False (keep_empty=True)


if __name__ == "__main__":
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®šï¼ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã®è©³ç´°æƒ…å ±è¡¨ç¤ºç”¨ï¼‰
    logging.basicConfig(level=logging.INFO)

    # pytestå®Ÿè¡Œ
    pytest.main([__file__, "-v"])
    """ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Šã®ãŸã‚ã®è¿½åŠ ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def temp_dir(self):
        """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆãƒ»å‰Šé™¤"""
        temp_path = Path(tempfile.mkdtemp())
        yield temp_path
        shutil.rmtree(temp_path)

    def test_load_schema_with_none_path(self):
        """load_schemaé–¢æ•°ã§Noneãƒ‘ã‚¹ã‚’æ¸¡ã—ãŸå ´åˆ"""
        result = xlsx2json.load_schema(None)
        assert result is None

    def test_validate_and_log_no_errors(self, temp_dir):
        """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãŒãªã„å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        # æ­£å¸¸ãªãƒ‡ãƒ¼ã‚¿
        data = {"user": {"name": "test", "email": "test@example.com"}}

        # ã‚¹ã‚­ãƒ¼ãƒ
        schema = {
            "type": "object",
            "properties": {
                "user": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "email": {"type": "string"},
                    },
                }
            },
        }
        validator = Draft7Validator(schema)

        # validate_and_logé–¢æ•°ã‚’å‘¼ã³å‡ºã— (ã‚¨ãƒ©ãƒ¼ãŒãªã„ã‚±ãƒ¼ã‚¹)
        log_dir = temp_dir / "logs"
        xlsx2json.validate_and_log(data, validator, log_dir, "test_file")

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œãªã„ã“ã¨ã‚’ç¢ºèª
        error_log = log_dir / "test_file.error.log"
        assert not error_log.exists()

    def test_reorder_json_with_schema(self):
        """reorder_jsoné–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        data = {"z_field": "last", "a_field": "first", "m_field": "middle"}

        # ã‚¹ã‚­ãƒ¼ãƒï¼ˆpropertiesé †ã«ä¸¦ã³æ›¿ãˆã‚‰ã‚Œã‚‹ï¼‰
        schema = {
            "type": "object",
            "properties": {
                "a_field": {"type": "string"},
                "m_field": {"type": "string"},
                "z_field": {"type": "string"},
            },
        }

        result = xlsx2json.reorder_json(data, schema)

        # ã‚­ãƒ¼ã®é †åºãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèª
        keys = list(result.keys())
        assert keys == ["a_field", "m_field", "z_field"]

    def test_reorder_json_with_list_items(self):
        """é…åˆ—è¦ç´ ã®ä¸¦ã³æ›¿ãˆãƒ†ã‚¹ãƒˆ"""
        data = [{"z": 3, "a": 1, "m": 2}, {"z": 6, "a": 4, "m": 5}]

        schema = {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "a": {"type": "integer"},
                    "m": {"type": "integer"},
                    "z": {"type": "integer"},
                },
            },
        }

        result = xlsx2json.reorder_json(data, schema)

        # å„è¦ç´ ã®ã‚­ãƒ¼é †åºãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèª
        for item in result:
            keys = list(item.keys())
            assert keys == ["a", "m", "z"]

    def test_reorder_json_non_dict_or_list(self):
        """è¾æ›¸ã§ã‚‚é…åˆ—ã§ã‚‚ãªã„å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        data = "simple_string"
        schema = {"type": "string"}

        result = xlsx2json.reorder_json(data, schema)
        assert result == "simple_string"

    def test_is_completely_empty_string(self):
        """å®Œå…¨ã«ç©ºã®æ–‡å­—åˆ—ãƒ†ã‚¹ãƒˆ"""
        assert xlsx2json.is_completely_empty("   ") is True
        assert xlsx2json.is_completely_empty("") is True
        assert xlsx2json.is_completely_empty("not empty") is False

    def test_write_json_with_none_data(self, temp_dir):
        """write_json ã§ data ãŒ None ã«ãªã‚‹å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        output_path = temp_dir / "test.json"

        # None ã«ãªã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆã™ã¹ã¦ç©ºï¼‰
        data = {"empty1": None, "empty2": "", "empty3": []}

        # suppress_empty=True ã§ None ã«ãªã‚‹ã‚±ãƒ¼ã‚¹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        with patch("xlsx2json.clean_empty_values", return_value=None):
            xlsx2json.write_json(data, output_path, suppress_empty=True)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã€ç©ºã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒæ›¸ã‹ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert output_path.exists()
        with output_path.open("r", encoding="utf-8") as f:
            content = json.load(f)
            assert content == {}

    def test_write_json_with_schema_validation(self, temp_dir):
        """write_json ã§ã‚¹ã‚­ãƒ¼ãƒãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãã®ãƒ†ã‚¹ãƒˆ"""
        output_path = temp_dir / "test.json"

        data = {"name": "test", "age": 25}
        schema = {
            "type": "object",
            "properties": {"name": {"type": "string"}, "age": {"type": "integer"}},
        }
        validator = Draft7Validator(schema)

        xlsx2json.write_json(data, output_path, schema=schema, validator=validator)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert output_path.exists()
        with output_path.open("r", encoding="utf-8") as f:
            result = json.load(f)
            # ã‚¹ã‚­ãƒ¼ãƒé †ã«ä¸¦ã³æ›¿ãˆã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert list(result.keys()) == ["name", "age"]

    def test_main_no_input_files(self):
        """å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv", ["xlsx2json.py"]):
            with patch("xlsx2json.logger") as mock_logger:
                result = xlsx2json.main()
                assert result is None
                # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_logger.error.assert_called()

    def test_main_no_xlsx_files_found(self):
        """xlsx ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        with patch("sys.argv", ["xlsx2json.py", "/empty/directory"]):
            with patch("xlsx2json.collect_xlsx_files", return_value=[]):
                with patch("xlsx2json.logger") as mock_logger:
                    result = xlsx2json.main()
                    assert result is None
                    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                    mock_logger.error.assert_called()

    def test_main_with_config_file_error(self, temp_dir):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
        # ä¸æ­£ãªJSONãƒ•ã‚¡ã‚¤ãƒ«
        config_file = temp_dir / "invalid_config.json"
        with config_file.open("w") as f:
            f.write("invalid json content")

        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch(
            "sys.argv", ["xlsx2json.py", "--config", str(config_file), str(test_xlsx)]
        ):
            with patch("xlsx2json.logger") as mock_logger:
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ãŒã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ç¶šè¡Œã•ã‚Œã‚‹
                xlsx2json.main()
                # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                mock_logger.error.assert_called_with(
                    unittest.mock.ANY  # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è©³ç´°ã¯å•ã‚ãªã„
                )

    def test_main_parse_exception(self, temp_dir):
        """parse_named_ranges_with_prefix ã§ã®ä¾‹å¤–å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # æœ‰åŠ¹ãªExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch("sys.argv", ["xlsx2json.py", str(test_xlsx)]):
            with patch(
                "xlsx2json.parse_named_ranges_with_prefix",
                side_effect=Exception("Test exception"),
            ):
                with patch("xlsx2json.logger") as mock_logger:
                    xlsx2json.main()
                    # ä¾‹å¤–ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                    mock_logger.exception.assert_called()

    def test_main_data_is_none(self, temp_dir):
        """ãƒ‡ãƒ¼ã‚¿ãŒNoneã®å ´åˆã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch("sys.argv", ["xlsx2json.py", str(test_xlsx)]):
            with patch("xlsx2json.parse_named_ranges_with_prefix", return_value=None):
                with patch("xlsx2json.logger") as mock_logger:
                    xlsx2json.main()
                    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                    mock_logger.error.assert_called()

    def test_main_empty_data_warning(self, temp_dir):
        """ç©ºãƒ‡ãƒ¼ã‚¿ã®è­¦å‘Šãƒ†ã‚¹ãƒˆ"""
        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch("sys.argv", ["xlsx2json.py", str(test_xlsx)]):
            with patch("xlsx2json.parse_named_ranges_with_prefix", return_value={}):
                with patch("xlsx2json.logger") as mock_logger:
                    xlsx2json.main()
                    # è­¦å‘Šãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                    mock_logger.warning.assert_called()

    def test_main_config_from_file(self, temp_dir):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®å¼•æ•°èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        # ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        schema_file = temp_dir / "schema.json"
        schema_data = {"type": "object", "properties": {"test": {"type": "string"}}}
        with schema_file.open("w", encoding="utf-8") as f:
            json.dump(schema_data, f)

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        config_file = temp_dir / "config.json"
        config_data = {
            "inputs": "test_input.xlsx",
            "output_dir": str(temp_dir / "output"),
            "schema": str(schema_file),
            "transform": ["json.test=split:,"],
        }
        with config_file.open("w", encoding="utf-8") as f:
            json.dump(config_data, f)

        # ãƒ†ã‚¹ãƒˆç”¨Excelãƒ•ã‚¡ã‚¤ãƒ«
        test_xlsx = temp_dir / "test_input.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch("sys.argv", ["xlsx2json.py", "--config", str(config_file)]):
            with patch("xlsx2json.collect_xlsx_files", return_value=[test_xlsx]):
                with patch(
                    "xlsx2json.parse_named_ranges_with_prefix",
                    return_value={"test": "data"},
                ):
                    with patch("xlsx2json.write_json") as mock_write:
                        xlsx2json.main()
                        # write_jsonãŒå‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                        mock_write.assert_called()

    def test_main_string_output_dir_conversion(self, temp_dir):
        """output_dirãŒæ–‡å­—åˆ—ã®å ´åˆã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        test_xlsx = temp_dir / "test.xlsx"
        wb = Workbook()
        wb.save(test_xlsx)

        with patch(
            "sys.argv", ["xlsx2json.py", str(test_xlsx), "--output-dir", str(temp_dir)]
        ):
            with patch(
                "xlsx2json.parse_named_ranges_with_prefix",
                return_value={"test": "data"},
            ):
                with patch("xlsx2json.write_json") as mock_write:
                    xlsx2json.main()
                    # write_jsonãŒå‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                    mock_write.assert_called()

    def test_parse_array_transform_rules_conflict_function_over_split(self):
        """functionå‹ãŒsplitå‹ã‚’ä¸Šæ›¸ãã™ã‚‹ãƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=split:,", "json.test=function:builtins:str"]

        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.parse_array_transform_rules(rules, "json")

            # functionå‹ãŒå„ªå…ˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert "test" in result  # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒé™¤å»ã•ã‚Œã‚‹
            assert result["test"].transform_type == "function"

            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            mock_logger.debug.assert_called()

    def test_parse_array_transform_rules_no_overwrite_function_by_split(self):
        """splitå‹ãŒfunctionå‹ã‚’ä¸Šæ›¸ãã—ãªã„ãƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=function:builtins:str", "json.test=split:,"]

        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.parse_array_transform_rules(rules, "json")

            # functionå‹ãŒä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert "test" in result  # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒé™¤å»ã•ã‚Œã‚‹
            assert result["test"].transform_type == "function"

            # ã‚¹ã‚­ãƒƒãƒ—ã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            mock_logger.debug.assert_called()

    def test_parse_array_transform_rules_same_type_conflict(self):
        """åŒã˜å‹ã®ãƒ«ãƒ¼ãƒ«é‡è¤‡ãƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=split:,", "json.test=split:;"]

        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.parse_array_transform_rules(rules, "json")

            # æœ€åˆã®ãƒ«ãƒ¼ãƒ«ãŒä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert "test" in result  # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒé™¤å»ã•ã‚Œã‚‹
            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            mock_logger.debug.assert_called()

    def test_parse_array_transform_rules_other_type_conflict(self):
        """ãã®ä»–ã®å‹ã®çµ„ã¿åˆã‚ã›ã§ã®ä¸Šæ›¸ããƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=command:echo", "json.test=split:,"]

        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.parse_array_transform_rules(rules, "json")

            # å¾Œã‹ã‚‰æ¥ãŸãƒ«ãƒ¼ãƒ«ã§ä¸Šæ›¸ãã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert "test" in result  # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒé™¤å»ã•ã‚Œã‚‹
            assert result["test"].transform_type == "split"

            # ä¸Šæ›¸ãã®ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            mock_logger.info.assert_called()

    def test_parse_array_transform_rules_with_schema_resolution_conflict(self):
        """ã‚¹ã‚­ãƒ¼ãƒè§£æ±ºå¾Œã®ãƒ«ãƒ¼ãƒ«ç«¶åˆãƒ†ã‚¹ãƒˆ"""
        schema = {
            "type": "object",
            "properties": {
                "user_name": {"type": "string"},
                "user_group": {"type": "string"},
            },
        }

        rules = ["json.user/*=command:echo", "json.user/*=split:,"]

        with patch("xlsx2json.logger") as mock_logger:
            xlsx2json.parse_array_transform_rules(rules, "json", schema)

            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆãƒ«ãƒ¼ãƒ«ç«¶åˆå‡¦ç†ï¼‰
            mock_logger.debug.assert_called()

    def test_transform_rule_unknown_type_warning(self):
        """ä¸æ˜ãªå¤‰æ›ã‚¿ã‚¤ãƒ—ã®è­¦å‘Šãƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=unknown_type:some_spec"]

        with patch("xlsx2json.logger") as mock_logger:
            result = xlsx2json.parse_array_transform_rules(rules, "json")

            # ä¸æ˜ãªã‚¿ã‚¤ãƒ—ã®è­¦å‘ŠãŒå‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            mock_logger.warning.assert_called()
            # ãƒ«ãƒ¼ãƒ«ãŒç™»éŒ²ã•ã‚Œãªã„ã“ã¨ã‚’ç¢ºèª
            assert "json.test" not in result

    def test_file_operations_realistic_cases(self):
        """å®Ÿç”¨çš„ãªãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãƒ†ã‚¹ãƒˆ"""
        import tempfile

        with tempfile.TemporaryDirectory() as tmpdir:
            # ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ†ã‚¹ãƒˆ
            result = xlsx2json.collect_xlsx_files([tmpdir])
            assert isinstance(result, list)
            assert len(result) == 0

            # å­˜åœ¨ã—ãªã„ãƒ‘ã‚¹ã‚’ãƒ†ã‚¹ãƒˆ
            result = xlsx2json.collect_xlsx_files(["/completely/nonexistent/path"])
            assert isinstance(result, list)
            assert len(result) == 0

    def test_array_transform_rules_with_samples(self):
        """samplesãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨ã—ãŸtransformé–¢æ•°ãƒ†ã‚¹ãƒˆ"""
        # samplesãƒ•ã‚©ãƒ«ãƒ€ã®æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        samples_dir = Path(__file__).parent / "samples"
        if samples_dir.exists():
            transform_file = samples_dir / "transform.py"
            if transform_file.exists():
                # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆ
                rules = [f"json.test=function:{transform_file}:uppercase_transform"]

                # functionæŒ‡å®šã§ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ãƒ†ã‚¹ãƒˆ
                try:
                    transform_rules = xlsx2json.parse_array_transform_rules(
                        rules, "json", None
                    )
                    if "test" in transform_rules:
                        rule = transform_rules["test"]
                        # å¤‰æ›ã‚’ãƒ†ã‚¹ãƒˆ
                        result = rule.transform("hello")
                        assert isinstance(result, str)
                except Exception:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã‚„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
                    pass

    def test_array_transform_command_error_handling(self):
        """commandå¤‰æ›ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        rules = ["json.test=command:echo"]

        transform_rules = xlsx2json.parse_array_transform_rules(rules, "json", None)

        if "test" in transform_rules:
            rule = transform_rules["test"]

            with patch("xlsx2json.logger") as mock_logger:
                # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                with patch("subprocess.run", side_effect=Exception("Command error")):
                    result = rule.transform("test_value")

                    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã€å…ƒã®å€¤ãŒè¿”ã•ã‚Œã‚‹
                    assert result == "test_value"

    def test_logging_and_debug_paths_from_coverage_boost(self):
        """ãƒ­ã‚°ã¨ãƒ‡ãƒãƒƒã‚°ãƒ‘ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

        logger = logging.getLogger("xlsx2json")
        original_level = logger.level
        try:
            for level in [logging.DEBUG, logging.INFO, logging.WARNING]:
                logger.setLevel(level)
                try:
                    xlsx2json.parse_array_transform_rules(
                        ["json.test=split:,"], "json", None
                    )
                    with patch("xlsx2json.logger.debug") as mock_debug:
                        mock_debug("Test debug message")
                    with patch("xlsx2json.logger.info") as mock_info:
                        mock_info("Test info message")
                    with patch("xlsx2json.logger.warning") as mock_warning:
                        mock_warning("Test warning message")
                except Exception:
                    pass
        finally:
            logger.setLevel(original_level)

    def test_debugging_and_logging_branches_lines_821_822_928_936_from_precision(self):
        """Test debugging and logging branches"""
        # Test with debug mode and various logging scenarios
        original_args = sys.argv
        try:
            # Simulate debug mode
            sys.argv = ["xlsx2json.py", "--debug", "test.xlsx"]

            # Test main function with debug
            with patch("xlsx2json.collect_xlsx_files") as mock_collect:
                mock_collect.return_value = []
                try:
                    xlsx2json.main()
                except SystemExit:
                    pass
        finally:
            sys.argv = original_args


class TestProcessingStats:
    """ProcessingStatsã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

    def test_processing_stats_warnings(self):
        """è­¦å‘Šæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        stats = xlsx2json.ProcessingStats()
        
        # è­¦å‘Šã‚’è¿½åŠ 
        stats.add_warning("ãƒ†ã‚¹ãƒˆè­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
        
        assert len(stats.warnings) == 1
        assert "ãƒ†ã‚¹ãƒˆè­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸" in stats.warnings

    def test_processing_stats_duration(self):
        """å‡¦ç†æ™‚é–“è¨ˆæ¸¬ã®ãƒ†ã‚¹ãƒˆ"""
        stats = xlsx2json.ProcessingStats()
        
        # æ™‚é–“è¨ˆæ¸¬ãªã—ã®å ´åˆ
        assert stats.get_duration() == 0
        
        # æ™‚é–“è¨ˆæ¸¬ã‚ã‚Šã®å ´åˆ
        stats.start_processing()
        import time
        time.sleep(0.01)  # çŸ­ã„å¾…æ©Ÿ
        stats.end_processing()
        
        duration = stats.get_duration()
        assert duration > 0

    def test_processing_stats_log_summary(self, caplog):
        """ãƒ­ã‚°ã‚µãƒãƒªãƒ¼å‡ºåŠ›ã®ãƒ†ã‚¹ãƒˆ"""
        import logging
        
        # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’INFOã«è¨­å®š
        caplog.set_level(logging.INFO)
        
        stats = xlsx2json.ProcessingStats()
        stats.containers_processed = 5
        stats.cells_generated = 100
        stats.cells_read = 150
        stats.empty_cells_skipped = 20
        
        # ã‚¨ãƒ©ãƒ¼ã¨è­¦å‘Šã‚’è¿½åŠ 
        stats.add_error("ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼")
        stats.add_warning("ãƒ†ã‚¹ãƒˆè­¦å‘Š")
        
        # æ™‚é–“ã‚’è¨­å®š
        stats.start_processing()
        stats.end_processing()
        
        # ãƒ­ã‚°ã‚µãƒãƒªãƒ¼ã‚’å®Ÿè¡Œ
        stats.log_summary()
        
        # ãƒ­ã‚°å†…å®¹ã‚’ç¢ºèªï¼ˆINFOãƒ¬ãƒ™ãƒ«ã®ãƒ­ã‚°ãŒå–å¾—ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼‰
        assert "å‡¦ç†çµ±è¨ˆã‚µãƒãƒª" in caplog.text or "å‡¦ç†çµ±è¨ˆã‚µãƒãƒªãƒ¼" in caplog.text
        assert "å‡¦ç†ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒŠæ•°: 5" in caplog.text
        assert "ã‚¨ãƒ©ãƒ¼æ•°: 1" in caplog.text
        assert "è­¦å‘Šæ•°: 1" in caplog.text


class TestSchemaErrorHandling:
    """ã‚¹ã‚­ãƒ¼ãƒé–¢é€£ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸æ”¹å–„ï¼‰"""

    def test_load_schema_missing_file(self, tmp_path):
        """å­˜åœ¨ã—ãªã„ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        missing_schema = tmp_path / "missing_schema.json"
        
        # load_schemaé–¢æ•°ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if hasattr(xlsx2json, 'load_schema'):
            try:
                result = xlsx2json.load_schema(missing_schema)
                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã®å‡¦ç†ã‚’ç¢ºèª
            except (FileNotFoundError, IOError):
                # æœŸå¾…ã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯OK
                pass
        else:
            # é–¢æ•°ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass

    def test_load_schema_invalid_json(self, tmp_path):
        """ç„¡åŠ¹ãªJSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        invalid_schema = tmp_path / "invalid_schema.json"
        invalid_schema.write_text("not valid json")
        
        if hasattr(xlsx2json, 'load_schema'):
            try:
                result = xlsx2json.load_schema(invalid_schema)
                # ç„¡åŠ¹ãªJSONã®å ´åˆã®å‡¦ç†ã‚’ç¢ºèª
            except Exception:
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯OK
                pass
        else:
            # é–¢æ•°ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass


class TestContainers:
    """ã‚³ãƒ³ãƒ†ãƒŠæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""

    def test_load_container_config_missing_file(self, tmp_path):
        """å­˜åœ¨ã—ãªã„ã‚³ãƒ³ãƒ†ãƒŠè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        missing_config = tmp_path / "missing_config.json"
        
        result = xlsx2json.load_container_config(missing_config)
        assert result == {}

    def test_load_container_config_invalid_json(self, tmp_path):
        """ç„¡åŠ¹ãªJSONã‚³ãƒ³ãƒ†ãƒŠè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        invalid_config = tmp_path / "invalid_config.json"
        invalid_config.write_text("invalid json")
        
        result = xlsx2json.load_container_config(invalid_config)
        assert result == {}

    def test_resolve_container_range_direct_range(self):
        """ç›´æ¥ç¯„å›²æŒ‡å®šã®è§£æ±ºãƒ†ã‚¹ãƒˆ"""
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ãªã—ã§ãƒ†ã‚¹ãƒˆå¯èƒ½ãªé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
        try:
            # parse_rangeãŒå­˜åœ¨ã™ã‚‹å ´åˆ
            start_coord, end_coord = xlsx2json.parse_range("B2:D4")
            assert start_coord == (2, 2)
            assert end_coord == (4, 4)
        except Exception:
            # é–¢æ•°ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass

    def test_process_containers_edge_cases(self, tmp_path):
        """ã‚³ãƒ³ãƒ†ãƒŠå‡¦ç†ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        # ç©ºã®è¨­å®šã§ã®ãƒ†ã‚¹ãƒˆ
        result = {}
        config_path = tmp_path / "nonexistent_config.json"
        
        # é–¢æ•°ãŒå­˜åœ¨ã™ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèª
        if hasattr(xlsx2json, 'process_all_containers'):
            # å­˜åœ¨ã—ãªã„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚‚æ­£å¸¸ã«å‡¦ç†ã•ã‚Œã‚‹
            try:
                xlsx2json.process_all_containers(None, config_path, result)
            except Exception:
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ãƒ†ã‚¹ãƒˆã‚’ãƒ‘ã‚¹
                pass
        else:
            # é–¢æ•°ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass


class TestJSONPath:
    """JSON pathé–¢é€£æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""

    def test_insert_json_path_empty_keys(self):
        """ç©ºã®ã‚­ãƒ¼ã§ã®JSON pathæŒ¿å…¥ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        root = {}
        
        with pytest.raises(ValueError, match="JSON.*ãƒ‘ã‚¹.*ç©º"):
            xlsx2json.insert_json_path(root, [], "value")

    def test_insert_json_path_array_conversion(self):
        """é…åˆ—ã¸ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        root = {"key": {}}
        
        # ç©ºè¾æ›¸ã‚’é…åˆ—ã«å¤‰æ›
        xlsx2json.insert_json_path(root, ["key", "1"], "value1")
        assert isinstance(root["key"], list)
        assert root["key"][0] == "value1"

    def test_insert_json_path_dict_conversion(self):
        """è¾æ›¸ã¸ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        root = {"key": []}
        
        # ç©ºé…åˆ—ã‚’è¾æ›¸ã«å¤‰æ›
        xlsx2json.insert_json_path(root, ["key", "subkey"], "value1")
        assert isinstance(root["key"], dict)
        assert root["key"]["subkey"] == "value1"


class TestArrayTransformRule:
    """é…åˆ—å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""

    def test_array_transform_rule_unknown_fallback(self):
        """ä¸æ˜ãªå¤‰æ›ã‚¿ã‚¤ãƒ—ã§ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œãƒ†ã‚¹ãƒˆ"""
        # æ—¢å­˜ã®ãƒ«ãƒ¼ãƒ«ã‚’ä¸€æ™‚çš„ã«å¤‰æ›´ã—ã¦ãƒ†ã‚¹ãƒˆ
        rule = xlsx2json.ArrayTransformRule("test.path", "split", "delimiter")
        rule.transform_type = "unknown"
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œã§å…ƒã®å€¤ã‚’è¿”ã™
        result = rule.transform("test_value")
        assert result == "test_value"


class TestParseArraySplitRules:
    """é…åˆ—åˆ†å‰²ãƒ«ãƒ¼ãƒ«è§£æã®ãƒ†ã‚¹ãƒˆ"""

    def test_parse_array_split_rules_invalid_rule_format(self):
        """ç„¡åŠ¹ãªãƒ«ãƒ¼ãƒ«å½¢å¼ã§ã®è­¦å‘Šãƒ†ã‚¹ãƒˆ"""
        result = xlsx2json.parse_array_split_rules(["invalid_rule"], "json.")
        assert result == {}

    def test_parse_array_split_rules_empty_rule(self):
        """ç©ºã®ãƒ«ãƒ¼ãƒ«ã§ã®è­¦å‘Šãƒ†ã‚¹ãƒˆ"""
        result = xlsx2json.parse_array_split_rules(["", None], "json.")
        assert result == {}


class TestUtilityExtensions:
    """ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®æ‹¡å¼µãƒ†ã‚¹ãƒˆ"""

    def test_parse_range_error_cases(self):
        """ç¯„å›²ãƒ‘ãƒ¼ã‚¹æ™‚ã®ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        # ç„¡åŠ¹ãªç¯„å›²æ–‡å­—åˆ—
        with pytest.raises(ValueError):
            xlsx2json.parse_range("invalid_range")
        
        # ç©ºæ–‡å­—åˆ—
        with pytest.raises(ValueError):
            xlsx2json.parse_range("")


class TestDataIntegrity:
    """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ãƒ†ã‚¹ãƒˆ"""

    def test_floating_point_precision_handling(self):
        """æµ®å‹•å°æ•°ç‚¹ç²¾åº¦ä¿è¨¼ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šæ•°å€¤è¨ˆç®—ã‚¨ãƒ©ãƒ¼é˜²æ­¢ï¼‰"""
        # æµ®å‹•å°æ•°ç‚¹ç²¾åº¦å•é¡Œã‚’é˜²ããƒ†ã‚¹ãƒˆ
        numeric_data = {
            "decimal_value": 999.99,
            "small_fraction": 0.08,
            "integer_count": 3
        }
        
        # Excelå½¢å¼ã§ã‚ˆãã‚ã‚‹æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
        for key, value in numeric_data.items():
            # æ•°å€¤ã®ç²¾åº¦ã‚’ç¶­æŒã—ãŸå‡¦ç†ãŒè¡Œã‚ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            result = xlsx2json.auto_convert_data_type(value)
            
            if isinstance(value, float):
                # æµ®å‹•å°æ•°ç‚¹ã®ç²¾åº¦ãŒä¿ãŸã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
                assert abs(result - value) < 1e-10
            else:
                assert result == value

    def test_datetime_data_conversion_validation(self):
        """æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®æ¤œè¨¼ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ã®æ­£ç¢ºæ€§ï¼‰"""
        from datetime import datetime, date
        
        # é‡è¦ãªæ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ã®å‹å¤‰æ›
        date_samples = [
            datetime(2024, 12, 31, 23, 59, 59),  # å®Œå…¨ãªæ—¥æ™‚
            date(2024, 4, 1),  # æ—¥ä»˜ã®ã¿
            "2024-03-31",  # æ–‡å­—åˆ—å½¢å¼ã®æ—¥ä»˜
        ]
        
        for sample_date in date_samples:
            # æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ãŒæ­£ç¢ºã«ä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            converted = xlsx2json.auto_convert_data_type(sample_date)
            
            if isinstance(sample_date, (datetime, date)):
                assert isinstance(converted, (datetime, date))
                # æ—¥ä»˜ã®å€¤ãŒå¤‰æ›´ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
                if hasattr(sample_date, 'year'):
                    assert converted.year == sample_date.year

    def test_hierarchical_json_structure_integrity(self):
        """éšå±¤JSONãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ•´åˆæ€§ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šãƒã‚¹ãƒˆæ§‹é€ ç ´ç¶»é˜²æ­¢ï¼‰"""
        root = {}
        
        # æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã§ã®æ•´åˆæ€§ç¢ºèª
        test_paths = [
            ["level1", "level2", "level3", "data1"],
            ["level1", "level2", "level4", "data2"], 
            ["level1", "other_branch", "data3"],
            ["level1", "level2", "level3", "data4"]  # åŒã˜ãƒ‘ã‚¹ã¸ã®ä¸Šæ›¸ã
        ]
        
        values = ["å€¤1", "å€¤2", "å€¤3", "å€¤4_ä¸Šæ›¸ã"]
        
        for path, value in zip(test_paths, values):
            xlsx2json.insert_json_path(root, path, value)
        
        # æ§‹é€ ã®æ•´åˆæ€§ç¢ºèª
        assert root["level1"]["level2"]["level3"]["data1"] == "å€¤1"
        assert root["level1"]["level2"]["level3"]["data4"] == "å€¤4_ä¸Šæ›¸ã"
        assert root["level1"]["level2"]["level4"]["data2"] == "å€¤2"
        assert root["level1"]["other_branch"]["data3"] == "å€¤3"
        
        # ãƒã‚¹ãƒˆæ§‹é€ ãŒå£Šã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
        assert isinstance(root["level1"]["level2"], dict)
        assert isinstance(root["level1"], dict)

    def test_excel_to_json_conversion_workflow_validation(self):
        """Excelâ†’JSONå¤‰æ›ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“ã®æ¤œè¨¼ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šå¤‰æ›ãƒ—ãƒ­ã‚»ã‚¹ä¿è¨¼ï¼‰"""
        # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®æŠ€è¡“çš„ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
        conversion_workflow_steps = [
            # Step 1: Excelç¯„å›²å®šç¾©
            {"range": "B2:D4", "direction": "vertical", "items": ["field1", "field2", "field3"]},
            
            # Step 2: ãƒ‡ãƒ¼ã‚¿ç¯„å›²è§£æ
            None,  # parse_rangeçµæœ
            
            # Step 3: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°æ¤œå‡º  
            None,  # detect_instance_countçµæœ
            
            # Step 4: ã‚»ãƒ«åç”Ÿæˆ
            None,  # generate_cell_namesçµæœ
            
            # Step 5: JSONæ§‹é€ æ§‹ç¯‰
            {}     # æœ€çµ‚JSONçµæœ
        ]
        
        # Step 2: ç¯„å›²è§£æ
        start_coord, end_coord = xlsx2json.parse_range(conversion_workflow_steps[0]["range"])
        conversion_workflow_steps[1] = (start_coord, end_coord)
        assert start_coord == (2, 2) and end_coord == (4, 4)
        
        # Step 3: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°æ¤œå‡º
        instance_count = xlsx2json.detect_instance_count(start_coord, end_coord, conversion_workflow_steps[0]["direction"])
        conversion_workflow_steps[2] = instance_count
        assert instance_count == 3  # B2:D4ã§ç¸¦æ–¹å‘ãªã®ã§3ãƒ¬ã‚³ãƒ¼ãƒ‰
        
        # Step 4: ã‚»ãƒ«åç”Ÿæˆ
        cell_names = xlsx2json.generate_cell_names(
            "dataset", start_coord, end_coord,
            conversion_workflow_steps[0]["direction"], conversion_workflow_steps[0]["items"]
        )
        conversion_workflow_steps[3] = cell_names
        assert len(cell_names) == 9  # 3ãƒ¬ã‚³ãƒ¼ãƒ‰ Ã— 3é …ç›®
        
        # Step 5: JSONæ§‹é€ æ§‹ç¯‰
        result = conversion_workflow_steps[4]
        test_data = {
            "dataset_1_field1": "2024-01-15", "dataset_1_field2": "itemA", "dataset_1_field3": 100000,
            "dataset_2_field1": "2024-01-16", "dataset_2_field2": "itemB", "dataset_2_field3": 150000,
            "dataset_3_field1": "2024-01-17", "dataset_3_field2": "itemC", "dataset_3_field3": 120000,
        }
        
        for cell_name in cell_names:
            if cell_name in test_data:
                xlsx2json.insert_json_path(result, [cell_name], test_data[cell_name])
        
        # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®å®Œå…¨æ€§ç¢ºèª
        assert result["dataset_1_field1"] == "2024-01-15"
        assert result["dataset_2_field3"] == 150000
        assert result["dataset_3_field2"] == "itemC"
        
        # æ•°å€¤åˆè¨ˆã®è¨ˆç®—ç¢ºèªï¼ˆæŠ€è¡“çš„æ¤œè¨¼ï¼‰
        total_values = sum([
            result["dataset_1_field3"], result["dataset_2_field3"], result["dataset_3_field3"]
        ])
        assert total_values == 370000  # 100000 + 150000 + 120000


class TestErrorRecovery:
    """ã‚¨ãƒ©ãƒ¼å›å¾©ã®ãƒ†ã‚¹ãƒˆ"""

    def test_corrupted_excel_data_resilience(self):
        """ç ´æExcelãƒ‡ãƒ¼ã‚¿ã§ã®å¾©æ—§åŠ›ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šã‚·ã‚¹ãƒ†ãƒ åœæ­¢é˜²æ­¢ï¼‰"""
        # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        corrupt_data_samples = [
            None,           # Nullå€¤
            "",             # ç©ºæ–‡å­—åˆ—
            float('inf'),   # ç„¡é™å¤§
            float('-inf'),  # è² ã®ç„¡é™å¤§
            float('nan'),   # NaN (Not a Number)
            "\x00\x01\x02", # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿
            "A" * 10000,    # éå¸¸ã«é•·ã„æ–‡å­—åˆ—
        ]
        
        for corrupt_data in corrupt_data_samples:
            try:
                # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã§ã‚‚ã‚·ã‚¹ãƒ†ãƒ ãŒåœæ­¢ã—ãªã„ã“ã¨ã‚’ç¢ºèª
                converted = xlsx2json.auto_convert_data_type(corrupt_data)
                
                # é–¢æ•°ãŒä½•ã‚‰ã‹ã®å€¤ã‚’è¿”ã™ã“ã¨ã‚’ç¢ºèªï¼ˆNoneã‚‚å«ã‚€ï¼‰
                # é‡è¦ãªã®ã¯ExceptionãŒç™ºç”Ÿã—ãªã„ã“ã¨
                
            except Exception as e:
                # äºˆæœŸã—ãªã„ä¾‹å¤–ã§ã‚‚ã‚·ã‚¹ãƒ†ãƒ ãŒå®Œå…¨ã«åœæ­¢ã—ãªã„ã“ã¨ã‚’ç¢ºèª
                assert isinstance(e, (ValueError, TypeError, OverflowError, AttributeError))
        
        # ç‰¹å®šã®ã‚±ãƒ¼ã‚¹ã§ã®å‹•ä½œç¢ºèª
        assert xlsx2json.auto_convert_data_type("") == ""  # ç©ºæ–‡å­—åˆ—ã¯ç©ºæ–‡å­—åˆ—
        assert xlsx2json.auto_convert_data_type("123") == 123  # æ•°å€¤æ–‡å­—åˆ—ã¯æ•°å€¤ã«å¤‰æ›
        assert xlsx2json.auto_convert_data_type("abc") == "abc"  # éæ•°å€¤æ–‡å­—åˆ—ã¯ãã®ã¾ã¾

    def test_memory_exhaustion_protection(self):
        """ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ä¿è­·ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡é˜²æ­¢ï¼‰"""
        # éå¸¸ã«å¤§ããªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å‡¦ç†
        huge_data_config = {
            "range": "A1:Z1000",  # 26åˆ— Ã— 1000è¡Œ = 26000ã‚»ãƒ«
            "direction": "vertical",
            "items": [f"ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰{chr(65+i)}" for i in range(26)]  # A-Z
        }
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒåˆ¶å¾¡å¯èƒ½ãªç¯„å›²å†…ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        start_coord, end_coord = xlsx2json.parse_range(huge_data_config["range"])
        assert start_coord == (1, 1) and end_coord == (26, 1000)
        
        instance_count = xlsx2json.detect_instance_count(start_coord, end_coord, huge_data_config["direction"])
        assert instance_count == 1000
        
        # ã‚»ãƒ«åç”Ÿæˆã‚’å°ã•ãªãƒãƒƒãƒã§å®Ÿè¡Œï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç¢ºèªï¼‰
        small_batch = xlsx2json.generate_cell_names(
            "å·¨å¤§ãƒ†ãƒ¼ãƒ–ãƒ«", (1, 1), (5, 10),  # 5åˆ— Ã— 10è¡Œã«ç¸®å°
            huge_data_config["direction"], huge_data_config["items"][:5]
        )
        
        # ãƒãƒƒãƒå‡¦ç†ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(small_batch) == 50  # 5é …ç›® Ã— 10è¡Œ

    def test_infinite_recursion_prevention(self):
        """ç„¡é™å†å¸°é˜²æ­¢ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šã‚¹ã‚¿ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢ï¼‰"""
        # æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã§ã®ã‚¹ã‚¿ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢
        deep_root = {}
        
        # éå¸¸ã«æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã‚’ä½œæˆï¼ˆ1000éšå±¤ï¼‰
        current_level = deep_root
        for level in range(100):  # ã‚¹ã‚¿ãƒƒã‚¯åˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚100éšå±¤ã«èª¿æ•´
            level_key = f"level_{level}"
            current_level[level_key] = {}
            current_level = current_level[level_key]
        
        # æœ€æ·±éƒ¨ã«å€¤ã‚’è¨­å®š
        current_level["deep_value"] = "æœ€æ·±éƒ¨ã®å€¤"
        
        # æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        try:
            # clean_empty_valuesãŒæ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã‚’å‡¦ç†ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª
            cleaned = xlsx2json.clean_empty_values(deep_root)
            
            # å€¤ãŒä¿æŒã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            current_check = cleaned
            for level in range(100):
                level_key = f"level_{level}"
                assert level_key in current_check
                current_check = current_check[level_key]
            
            assert current_check["deep_value"] == "æœ€æ·±éƒ¨ã®å€¤"
            
        except RecursionError:
            # ã‚¹ã‚¿ãƒƒã‚¯åˆ¶é™ã«é”ã—ãŸå ´åˆã‚‚é©åˆ‡ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            pass  # æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ


class TestTransformationRules:
    """å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""

    def test_custom_function_integration_reliability(self):
        """ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°çµ±åˆã®ä¿¡é ¼æ€§ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šå¤–éƒ¨é–¢æ•°ã®å®‰å…¨å®Ÿè¡Œï¼‰"""
        import tempfile
        import os
        
        # ã‚«ã‚¹ã‚¿ãƒ å¤‰æ›é–¢æ•°ã‚’å®šç¾©
        custom_function_code = '''
def numeric_calculator(amount_str):
    """æ•°å€¤è¨ˆç®—å‡¦ç†é–¢æ•°"""
    try:
        amount = float(amount_str)
        multiplier = 1.10  # 10%å¢—åŠ 
        return int(amount * multiplier)
    except (ValueError, TypeError):
        return 0

def format_identifier(id_str):
    """è­˜åˆ¥å­ã‚’æ¨™æº–å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if not isinstance(id_str, str):
        return ""
    
    # ãƒã‚¤ãƒ•ãƒ³ã¨ç©ºç™½ã‚’é™¤å»
    cleaned = id_str.replace("-", "").replace(" ", "")
    
    # 11æ¡ã®å ´åˆã¯ XXX-XXXX-XXXX å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    if len(cleaned) == 11 and cleaned.isdigit():
        return f"{cleaned[:3]}-{cleaned[3:7]}-{cleaned[7:]}"
    
    return id_str

def safe_division(input_str):
    """å®‰å…¨ãªé™¤ç®—ï¼ˆã‚¼ãƒ­é™¤ç®—ã‚¨ãƒ©ãƒ¼å›é¿ï¼‰"""
    try:
        parts = input_str.split(",")
        if len(parts) != 2:
            return "ERROR: Invalid format"
        
        num = float(parts[0])
        den = float(parts[1])
        if den == 0:
            return "ERROR: Division by zero"
        return round(num / den, 2)
    except (ValueError, TypeError):
        return "ERROR: Invalid input"
'''
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢æ•°ã‚’ä¿å­˜
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8') as f:
            f.write(custom_function_code)
            temp_function_file = f.name
        
        try:
            # æ•°å€¤è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ
            rule_calc = xlsx2json.ArrayTransformRule(
                "value", "function", f"{temp_function_file}:numeric_calculator"
            )
            
            test_amounts = ["1000", "2500.50", "0", "invalid"]
            expected_results = [1100, 2750, 0, 0]  # 10%åŠ ç®— + ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆæµ®å‹•å°æ•°ç‚¹èª¤å·®è€ƒæ…®ï¼‰
            
            for amount, expected in zip(test_amounts, expected_results):
                result = rule_calc.transform(amount)
                assert result == expected, f"æ•°å€¤è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {amount} -> {result} (æœŸå¾…å€¤: {expected})"            # è­˜åˆ¥å­ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆ
            rule_format = xlsx2json.ArrayTransformRule(
                "identifier", "function", f"{temp_function_file}:format_identifier"
            )
            
            format_tests = [
                ("09012345678", "090-1234-5678"),
                ("090-1234-5678", "090-1234-5678"),  # æ—¢ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿
                ("123", "123"),  # çŸ­ã™ãã‚‹å ´åˆã¯ãã®ã¾ã¾
                (None, ""),      # Nullå€¤ã®å‡¦ç†
            ]
            
            for format_input, expected in format_tests:
                result = rule_format.transform(format_input)
                assert result == expected, f"è­˜åˆ¥å­ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {format_input} -> {result}"
            
            # å®‰å…¨é™¤ç®—ã®ãƒ†ã‚¹ãƒˆ
            rule_division = xlsx2json.ArrayTransformRule(
                "ratio", "function", f"{temp_function_file}:safe_division"
            )
            
            # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ•°å€¤ãƒšã‚¢ã§é™¤ç®—ã‚’ãƒ†ã‚¹ãƒˆ
            division_tests = [
                ("10,2", 5.0),
                ("7,3", 2.33),
                ("5,0", "ERROR: Division by zero"),  # ã‚¼ãƒ­é™¤ç®—
                ("abc,def", "ERROR: Invalid input"),  # ç„¡åŠ¹å…¥åŠ›
            ]
            
            for input_pair, expected in division_tests:
                result = rule_division.transform(input_pair)
                assert result == expected, f"é™¤ç®—ã‚¨ãƒ©ãƒ¼: {input_pair} -> {result}"
                
        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            os.unlink(temp_function_file)

    def test_array_transformation_complex_scenarios(self):
        """é…åˆ—å¤‰æ›ã®è¤‡é›‘ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®æŸ”è»Ÿæ€§ï¼‰"""
        # è¤‡é›‘ãªåŒºåˆ‡ã‚Šæ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³
        complex_split_patterns = [
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: è¤‡æ•°åŒºåˆ‡ã‚Šæ–‡å­—
            ("apple,banana;orange|grape", [","]),
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ç©ºç™½ã¨ã‚¿ãƒ–æ··åˆ  
            ("item1\titem2 item3\t\titem4", ["\t"]),
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ã‚«ã‚¹ã‚¿ãƒ åŒºåˆ‡ã‚Šæ–‡å­—
            ("data::part1::part2::part3", ["::"]),
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³4: æ”¹è¡ŒåŒºåˆ‡ã‚Š
            ("line1\nline2\nline3\r\nline4", ["\n"]),
        ]
        
        for input_data, delimiters in complex_split_patterns:
            for delimiter in delimiters:
                try:
                    rule = xlsx2json.ArrayTransformRule("test_path", "split", delimiter)
                    result = rule.transform(input_data)
                    
                    # åˆ†å‰²çµæœãŒé…åˆ—ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                    assert isinstance(result, list), f"åˆ†å‰²çµæœãŒé…åˆ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {result}"
                    
                    # åˆ†å‰²ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªï¼ˆç©ºè¦ç´ ã¯é™¤å¤–ï¼‰
                    non_empty_result = [item for item in result if item.strip()]
                    assert len(non_empty_result) > 0, f"æœ‰åŠ¹ãªåˆ†å‰²çµæœãŒã‚ã‚Šã¾ã›ã‚“: {result}"
                    
                except Exception as e:
                    # ArrayTransformRuleã®åˆæœŸåŒ–ã‚„å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã¯æƒ³å®šå†…
                    assert "callable" in str(e) or "transform" in str(e), f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}"

    def test_container_definition_validation_comprehensive(self):
        """ã‚³ãƒ³ãƒ†ãƒŠå®šç¾©æ¤œè¨¼ã®åŒ…æ‹¬ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šè¨­å®šã‚¨ãƒ©ãƒ¼ã®æ—©æœŸç™ºè¦‹ï¼‰"""
        # æ­£å¸¸ãªã‚³ãƒ³ãƒ†ãƒŠè¨­å®š
        valid_containers = [
            {
                "name": "sales_table",
                "type": "table",
                "range": "A1:C10",
                "direction": "vertical",
                "items": ["date", "customer", "amount"]
            },
            {
                "name": "card_layout", 
                "type": "card",
                "range": "A1:A3",
                "direction": "horizontal",
                "increment": 5,
                "items": ["name", "phone", "address"]
            }
        ]
        
        # ç•°å¸¸ãªã‚³ãƒ³ãƒ†ãƒŠè¨­å®š
        invalid_containers = [
            # å¿…é ˆé …ç›®ä¸è¶³
            {"name": "incomplete", "type": "table"},
            
            # ç„¡åŠ¹ãªç¯„å›²æŒ‡å®š
            {"name": "invalid_range", "type": "table", "range": "INVALID", "items": ["a"]},
            
            # ç©ºã®é …ç›®ãƒªã‚¹ãƒˆ
            {"name": "empty_items", "type": "table", "range": "A1:B2", "items": []},
            
            # ç„¡åŠ¹ãªæ–¹å‘æŒ‡å®š
            {"name": "invalid_direction", "type": "table", "range": "A1:B2", 
             "direction": "diagonal", "items": ["a", "b"]},
        ]
        
        # æ­£å¸¸ãªè¨­å®šã®ãƒ†ã‚¹ãƒˆ
        for container in valid_containers:
            try:
                # åŸºæœ¬çš„ãªæ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯
                assert "name" in container
                assert "type" in container
                assert "range" in container or container.get("type") == "custom"
                assert "items" in container
                assert len(container["items"]) > 0
                
                # ç¯„å›²è§£æãƒ†ã‚¹ãƒˆ
                if "range" in container:
                    start_coord, end_coord = xlsx2json.parse_range(container["range"])
                    assert start_coord[0] > 0 and start_coord[1] > 0
                    assert end_coord[0] >= start_coord[0]
                    assert end_coord[1] >= start_coord[1]
                    
            except Exception as e:
                pytest.fail(f"æ­£å¸¸ãªã‚³ãƒ³ãƒ†ãƒŠè¨­å®šã§ã‚¨ãƒ©ãƒ¼: {container['name']} - {e}")
        
        # ç•°å¸¸ãªè¨­å®šã®ãƒ†ã‚¹ãƒˆ
        for container in invalid_containers:
            validation_errors = []
            
            # å¿…é ˆé …ç›®ãƒã‚§ãƒƒã‚¯
            if "name" not in container:
                validation_errors.append("name missing")
            if "type" not in container:
                validation_errors.append("type missing")
            if "items" not in container or len(container.get("items", [])) == 0:
                validation_errors.append("items missing or empty")
            
            # ç¯„å›²ãƒã‚§ãƒƒã‚¯
            if "range" in container:
                try:
                    xlsx2json.parse_range(container["range"])
                except ValueError:
                    validation_errors.append("invalid range")
            
            # directionæ¤œè¨¼ãƒã‚§ãƒƒã‚¯
            if "direction" in container:
                valid_directions = ["vertical", "horizontal", "column"]
                if container["direction"] not in valid_directions:
                    validation_errors.append("invalid direction")
            
            # ä½•ã‚‰ã‹ã®æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert len(validation_errors) > 0, f"ç„¡åŠ¹ãªè¨­å®šãŒæ¤œè¨¼ã‚’ãƒ‘ã‚¹: {container}"

    def test_json_schema_validation_data_rules(self):
        """JSONã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆï¼ˆé‡è¦ï¼šãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼ï¼‰"""
        import tempfile
        import json
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒ«ç”¨ã®JSONã‚¹ã‚­ãƒ¼ãƒ
        data_schema = {
            "type": "object",
            "properties": {
                "customer": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string", "minLength": 1},
                        "age": {"type": "integer", "minimum": 0, "maximum": 150},
                        "email": {"type": "string", "pattern": r"^[^@]+@[^@]+\.[^@]+$"}
                    },
                    "required": ["name", "age"]
                },
                "orders": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "amount": {"type": "number", "minimum": 0},
                            "date": {"type": "string"}
                        },
                        "required": ["amount", "date"]
                    },
                    "minItems": 1
                }
            },
            "required": ["customer", "orders"]
        }
        
        # ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False, encoding='utf-8') as f:
            json.dump(data_schema, f, ensure_ascii=False)
            schema_file = f.name
        
        try:
            # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚¹ãƒˆ
            valid_business_data = {
                "customer": {
                    "name": "ç”°ä¸­å¤ªéƒ",
                    "age": 35,
                    "email": "tanaka@example.com"
                },
                "orders": [
                    {"amount": 1500.0, "date": "2024-01-15"},
                    {"amount": 2800.0, "date": "2024-01-20"}
                ]
            }
            
            # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚¹ãƒˆ
            invalid_business_data_samples = [
                # é¡§å®¢åãªã—
                {
                    "customer": {"age": 35},
                    "orders": [{"amount": 1000, "date": "2024-01-01"}]
                },
                
                # å¹´é½¢ãŒç¯„å›²å¤–
                {
                    "customer": {"name": "å±±ç”°èŠ±å­", "age": 200},
                    "orders": [{"amount": 1000, "date": "2024-01-01"}]
                },
                
                # ã‚¨ãƒ³ãƒˆãƒªé‡‘é¡ãŒãƒã‚¤ãƒŠã‚¹
                {
                    "customer": {"name": "ä½è—¤æ¬¡éƒ", "age": 40},
                    "orders": [{"amount": -500, "date": "2024-01-01"}]
                },
                
                # å¿…é ˆé …ç›®ä¸è¶³
                {
                    "customer": {"name": "éˆ´æœ¨ä¸‰éƒ", "age": 25}
                    # orders ãªã—
                }
            ]
            
            # JSONSchemaæ¤œè¨¼ã¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¾å­˜ãªã®ã§ã€åŸºæœ¬çš„ãªæ§‹é€ ãƒã‚§ãƒƒã‚¯ã®ã¿å®Ÿè¡Œ
            def validate_data_rules(data):
                """ç°¡æ˜“ç‰ˆã®ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒ«æ¤œè¨¼"""
                errors = []
                
                # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æƒ…å ±ãƒã‚§ãƒƒã‚¯
                if "customer" not in data:
                    errors.append("customer missing")
                else:
                    customer = data["customer"]
                    if "name" not in customer or not customer["name"]:
                        errors.append("customer name missing")
                    if "age" not in customer:
                        errors.append("customer age missing")
                    elif not isinstance(customer["age"], int) or customer["age"] < 0 or customer["age"] > 150:
                        errors.append("customer age invalid")
                
                # ã‚¨ãƒ³ãƒˆãƒªæƒ…å ±ãƒã‚§ãƒƒã‚¯
                if "orders" not in data:
                    errors.append("orders missing")
                else:
                    orders = data["orders"]
                    if not isinstance(orders, list) or len(orders) == 0:
                        errors.append("orders empty")
                    else:
                        for i, order in enumerate(orders):
                            if "amount" not in order:
                                errors.append(f"order {i} amount missing")
                            elif not isinstance(order["amount"], (int, float)) or order["amount"] < 0:
                                errors.append(f"order {i} amount invalid")
                
                return errors
            
            # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
            valid_errors = validate_data_rules(valid_business_data)
            assert len(valid_errors) == 0, f"æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {valid_errors}"
            
            # ç„¡åŠ¹ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
            for i, invalid_data in enumerate(invalid_business_data_samples):
                invalid_errors = validate_data_rules(invalid_data)
                assert len(invalid_errors) > 0, f"ç„¡åŠ¹ãƒ‡ãƒ¼ã‚¿{i}ãŒæ¤œè¨¼ã‚’ãƒ‘ã‚¹: {invalid_data}"
                
        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            import os
            os.unlink(schema_file)


class TestUtilityFunctions:
    """ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
    
    ã‚³ã‚¢ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®å‹•ä½œã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’æ¤œè¨¼
    """

    @pytest.fixture
    def temp_dir(self):
        """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆãƒ»å‰Šé™¤"""
        temp_path = Path(tempfile.mkdtemp())
        yield temp_path
        shutil.rmtree(temp_path)

    @pytest.fixture
    def sample_workbook(self, temp_dir):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ä½œæˆ"""
        xlsx_path = temp_dir / "coverage_test.xlsx"
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "TestSheet"
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è¨­å®š
        ws["A1"] = "Name"
        ws["B1"] = "Value"
        ws["A2"] = "Test1"
        ws["B2"] = "100"
        ws["A3"] = "Test2"
        ws["B3"] = "200"
        
        # åå‰ä»˜ãç¯„å›²å®šç¾©
        wb.defined_names["test_range"] = DefinedName(name="test_range", attr_text="TestSheet!$A$1:$B$3")
        wb.defined_names["single_cell"] = DefinedName(name="single_cell", attr_text="TestSheet!$A$1")
        
        wb.save(xlsx_path)
        wb.close()
        return xlsx_path

    def test_load_container_config_file_not_found(self, temp_dir):
        """load_container_config: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        non_existent_path = temp_dir / "non_existent_config.json"
        result = xlsx2json.load_container_config(non_existent_path)
        assert result == {}

    def test_load_container_config_invalid_json(self, temp_dir):
        """load_container_config: ç„¡åŠ¹ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        invalid_json_path = temp_dir / "invalid_config.json"
        with invalid_json_path.open("w", encoding="utf-8") as f:
            f.write("{ invalid json }")
        
        result = xlsx2json.load_container_config(invalid_json_path)
        assert result == {}

    def test_load_container_config_no_containers_key(self, temp_dir):
        """load_container_config: containersã‚­ãƒ¼ãŒãªã„å ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        config_path = temp_dir / "no_containers_config.json"
        config_content = {"other_key": "value"}
        
        with config_path.open("w", encoding="utf-8") as f:
            json.dump(config_content, f)
        
        result = xlsx2json.load_container_config(config_path)
        assert result == {}

    def test_load_container_config_valid_file(self, temp_dir):
        """load_container_config: æ­£å¸¸ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        config_path = temp_dir / "valid_config.json"
        config_content = {
            "containers": {
                "test_container": {
                    "range": "A1:B2",
                    "direction": "vertical",
                    "items": ["name", "value"]
                }
            }
        }
        
        with config_path.open("w", encoding="utf-8") as f:
            json.dump(config_content, f)
        
        result = xlsx2json.load_container_config(config_path)
        expected = config_content["containers"]
        assert result == expected

    def test_resolve_container_range_named_range(self, sample_workbook):
        """resolve_container_range: åå‰ä»˜ãç¯„å›²ã®è§£æ±ºãƒ†ã‚¹ãƒˆ"""
        wb = openpyxl.load_workbook(sample_workbook)
        
        # åå‰ä»˜ãç¯„å›²ã®è§£æ±º
        result = xlsx2json.resolve_container_range(wb, "test_range")
        expected = ((1, 1), (2, 3))  # A1:B3
        assert result == expected
        
        wb.close()

    def test_resolve_container_range_cell_reference(self, sample_workbook):
        """resolve_container_range: ã‚»ãƒ«å‚ç…§æ–‡å­—åˆ—ã®è§£æ±ºãƒ†ã‚¹ãƒˆ"""
        wb = openpyxl.load_workbook(sample_workbook)
        
        # ç›´æ¥ç¯„å›²æŒ‡å®š
        result = xlsx2json.resolve_container_range(wb, "A1:C5")
        expected = ((1, 1), (3, 5))
        assert result == expected
        
        wb.close()

    def test_resolve_container_range_invalid_range(self, sample_workbook):
        """resolve_container_range: ç„¡åŠ¹ãªç¯„å›²æŒ‡å®šã®ãƒ†ã‚¹ãƒˆ"""
        wb = openpyxl.load_workbook(sample_workbook)
        
        with pytest.raises(ValueError, match="ç„¡åŠ¹ãªç¯„å›²æŒ‡å®š"):
            xlsx2json.resolve_container_range(wb, "INVALID_RANGE")
        
        wb.close()

    def test_convert_string_to_array_various_types(self):
        """convert_string_to_array: æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        # æ–‡å­—åˆ—ã®åˆ†å‰²
        assert xlsx2json.convert_string_to_array("a,b,c", ",") == ["a", "b", "c"]
        
        # æ•°å€¤ï¼ˆéæ–‡å­—åˆ—ï¼‰
        assert xlsx2json.convert_string_to_array(123, ",") == 123
        
        # None
        assert xlsx2json.convert_string_to_array(None, ",") == None
        
        # ç©ºæ–‡å­—åˆ—
        assert xlsx2json.convert_string_to_array("", ",") == []

    def test_convert_string_to_multidimensional_array_edge_cases(self):
        """convert_string_to_multidimensional_array: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # è¤‡æ•°ãƒ‡ãƒªãƒŸã‚¿ã§ã®åˆ†å‰²
        result = xlsx2json.convert_string_to_multidimensional_array("a,b|c,d", ["|", ","])
        expected = [["a", "b"], ["c", "d"]]
        assert result == expected
        
        # ç©ºæ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array("", [","])
        assert result == []
        
        # éæ–‡å­—åˆ—
        result = xlsx2json.convert_string_to_multidimensional_array(123, [","])
        assert result == 123

    def test_is_empty_value_edge_cases(self):
        """is_empty_value: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # ç©ºã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_empty_value("") == True
        assert xlsx2json.is_empty_value(None) == True
        assert xlsx2json.is_empty_value([]) == True
        assert xlsx2json.is_empty_value({}) == True
        assert xlsx2json.is_empty_value("   ") == True  # ç©ºç™½ã®ã¿
        
        # ç©ºã§ã¯ãªã„ã¨åˆ¤å®šã•ã‚Œã‚‹ã¹ãå€¤
        assert xlsx2json.is_empty_value("0") == False
        assert xlsx2json.is_empty_value(0) == False  # 0ã¯ç©ºå€¤ã§ã¯ãªã„
        assert xlsx2json.is_empty_value(False) == False  # Falseã¯ç©ºå€¤ã§ã¯ãªã„
        assert xlsx2json.is_empty_value([0]) == False
        assert xlsx2json.is_empty_value({"key": "value"}) == False

    def test_is_completely_empty_edge_cases(self):
        """is_completely_empty: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # å®Œå…¨ã«ç©ºã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        assert xlsx2json.is_completely_empty({}) == True
        assert xlsx2json.is_completely_empty([]) == True
        assert xlsx2json.is_completely_empty({"empty": {}, "null": None}) == True
        
        # ç©ºã§ã¯ãªã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        assert xlsx2json.is_completely_empty({"value": "test"}) == False
        assert xlsx2json.is_completely_empty([1, 2, 3]) == False
        assert xlsx2json.is_completely_empty("string") == False

    def test_clean_empty_arrays_contextually(self):
        """clean_empty_arrays_contextually: é…åˆ—ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        # suppress_empty=True ã®å ´åˆ
        data_with_empty = {
            "valid_array": [1, 2, 3],
            "empty_array": [],
            "mixed_array": [1, "", None, 2],
            "nested": {
                "empty_nested_array": [],
                "valid_nested": [4, 5]
            }
        }
        
        result = xlsx2json.clean_empty_arrays_contextually(data_with_empty, suppress_empty=True)
        assert "empty_array" not in result
        assert result["valid_array"] == [1, 2, 3]
        assert "empty_nested_array" not in result["nested"]
        assert result["nested"]["valid_nested"] == [4, 5]
        
        # suppress_empty=False ã®å ´åˆ
        result = xlsx2json.clean_empty_arrays_contextually(data_with_empty, suppress_empty=False)
        assert result == data_with_empty  # å¤‰æ›´ã•ã‚Œãªã„

    def test_insert_json_path_complex(self):
        """insert_json_path: è¤‡é›‘ãªJSONãƒ‘ã‚¹æŒ¿å…¥ãƒ†ã‚¹ãƒˆ"""
        result = {}
        
        # åŸºæœ¬çš„ãªãƒ‘ã‚¹
        xlsx2json.insert_json_path(result, ["level1", "level2", "field"], "value")
        expected = {"level1": {"level2": {"field": "value"}}}
        assert result == expected
        
        # é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ1-basedï¼‰
        result = {}
        xlsx2json.insert_json_path(result, ["array", "1"], "first")
        xlsx2json.insert_json_path(result, ["array", "2"], "second")
        assert result["array"][0] == "first"
        assert result["array"][1] == "second"

    def test_parse_range_single_cell_edge_cases(self):
        """parse_range: å˜ä¸€ã‚»ãƒ«ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # parse_rangeã¯ç¯„å›²å½¢å¼ï¼ˆA1:B2ï¼‰ã‚’æœŸå¾…ã™ã‚‹ã®ã§ã€å˜ä¸€ã‚»ãƒ«ã®å ´åˆã¯åˆ¥ã®é–¢æ•°ã‚’ä½¿ã†
        # ä»£ã‚ã‚Šã«ã€ç¯„å›²æ–‡å­—åˆ—ã§ã®ãƒ†ã‚¹ãƒˆã‚’è¡Œã†
        result = xlsx2json.parse_range("A1:A1")
        assert result == ((1, 1), (1, 1))
        
        # å¤§ããªç¯„å›²
        result = xlsx2json.parse_range("AA100:AB101")
        assert result == ((27, 100), (28, 101))  # AA=27, AB=28
        
        # ç„¡åŠ¹ãªå½¢å¼
        with pytest.raises(ValueError):
            xlsx2json.parse_range("INVALID")
        
        with pytest.raises(ValueError):
            xlsx2json.parse_range("A1:INVALID")

    def test_ArrayTransformRule_safe_operations(self):
        """ArrayTransformRule: å®‰å…¨ãªæ“ä½œã®ãƒ†ã‚¹ãƒˆ"""
        # æ­£å¸¸ãªsplitå¤‰æ›
        rule = xlsx2json.ArrayTransformRule("test", "split", ",")
        rule._transform_func = lambda x: x.split(",") if isinstance(x, str) else x
        
        # æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
        result = rule.transform("a,b,c")
        assert result == ["a", "b", "c"]
        
        # éæ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        result = rule.transform(123)
        assert result == 123
        
        result = rule.transform(None)
        assert result == None
        
        # ãƒªã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
        result = rule.transform(["a,b", "c,d"])
        assert result == [["a", "b"], ["c", "d"]]


class TestCoreWorkflowCoverage:
    """ã‚³ã‚¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚«ãƒãƒ¬ãƒƒã‚¸æ”¹å–„ãƒ†ã‚¹ãƒˆ
    
    ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®é‡è¦ãªéƒ¨åˆ†ã‚’ãƒ†ã‚¹ãƒˆ
    """

    @pytest.fixture
    def temp_dir(self):
        """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆãƒ»å‰Šé™¤"""
        temp_path = Path(tempfile.mkdtemp())
        yield temp_path
        shutil.rmtree(temp_path)

    @pytest.fixture
    def complex_workbook(self, temp_dir):
        """è¤‡é›‘ãªãƒ†ã‚¹ãƒˆç”¨ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ä½œæˆ"""
        xlsx_path = temp_dir / "advanced_test.xlsx"
        wb = openpyxl.Workbook()
        
        # ãƒ¡ã‚¤ãƒ³ã‚·ãƒ¼ãƒˆ
        ws = wb.active
        ws.title = "MainSheet"
        
        # è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ 
        ws["A1"] = "ID"
        ws["B1"] = "Name"
        ws["C1"] = "Data"
        ws["A2"] = "1"
        ws["B2"] = "Test1"
        ws["C2"] = "a,b,c"
        ws["A3"] = "2"
        ws["B3"] = "Test2"
        ws["C3"] = "x,y,z"
        
        # åˆ¥ã‚·ãƒ¼ãƒˆè¿½åŠ 
        ws2 = wb.create_sheet("SecondSheet")
        ws2["A1"] = "SecondData"
        ws2["B1"] = "Value"
        
        # åå‰ä»˜ãç¯„å›²å®šç¾©
        wb.defined_names["json_main_data"] = DefinedName(name="json_main_data", attr_text="MainSheet!$A$1:$C$3")
        wb.defined_names["json_second_data"] = DefinedName(name="json_second_data", attr_text="SecondSheet!$A$1:$B$1")
        wb.defined_names["json_transform_test"] = DefinedName(name="json_transform_test", attr_text="MainSheet!$C$2")
        
        wb.save(xlsx_path)
        wb.close()
        return xlsx_path

    def test_load_schema_error_handling(self, temp_dir):
        """load_schema: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
        # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«
        non_existent = temp_dir / "non_existent.json"
        with pytest.raises(FileNotFoundError):
            xlsx2json.load_schema(non_existent)
        
        # ç„¡åŠ¹ãªJSON
        invalid_json = temp_dir / "invalid.json"
        with invalid_json.open("w") as f:
            f.write("{ invalid json }")
        
        with pytest.raises(json.JSONDecodeError):
            xlsx2json.load_schema(invalid_json)

    def test_write_json_scenarios(self, temp_dir):
        """write_json: æ§˜ã€…ãªã‚·ãƒŠãƒªã‚ªã®ãƒ†ã‚¹ãƒˆ"""
        # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿
        output_path = temp_dir / "output.json"
        test_data = {"name": "test", "value": 123}
        
        xlsx2json.write_json(test_data, output_path, suppress_empty=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert output_path.exists()
        
        # å†…å®¹ã®ç¢ºèª
        with output_path.open("r", encoding="utf-8") as f:
            loaded_data = json.load(f)
        assert loaded_data == test_data

    def test_parse_named_ranges_with_transform_rules(self, complex_workbook, temp_dir):
        """parse_named_ranges_with_prefix: å¤‰æ›ãƒ«ãƒ¼ãƒ«ä»˜ããƒ†ã‚¹ãƒˆ"""
        # å¤‰æ›ãƒ«ãƒ¼ãƒ«é©ç”¨ã§ã®è§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(
            complex_workbook, "json", containers={}
        )
        
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªï¼ˆãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã«å®šç¾©ã•ã‚ŒãŸåå‰ä»˜ãç¯„å›²ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼‰
        # å®Ÿéš›ã®çµæœã«åŸºã¥ã„ã¦æœŸå¾…å€¤ã‚’èª¿æ•´
        assert isinstance(result, dict)

    def test_validate_cli_containers_error_cases(self):
        """validate_cli_containers: ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # ç„¡åŠ¹ãªJSON
        with pytest.raises(ValueError, match="ç„¡åŠ¹ãªJSONå½¢å¼"):
            xlsx2json.validate_cli_containers(["{ invalid json }"])
        
        # æ–‡å­—åˆ—ã§ã¯ãªã„å ´åˆ
        with pytest.raises(TypeError):
            xlsx2json.validate_cli_containers([123])

    def test_parse_container_args_complex(self):
        """parse_container_args: è¤‡é›‘ãªå¼•æ•°è§£æãƒ†ã‚¹ãƒˆ"""
        container_args = [
            '{"table1": {"range": "A1:C5", "direction": "vertical", "items": ["id", "name"]}}',
            '{"table2": {"range": "D1:F3", "direction": "horizontal", "items": ["col1", "col2"]}}'
        ]
        
        result = xlsx2json.parse_container_args(container_args)
        
        expected = {
            "table1": {"range": "A1:C5", "direction": "vertical", "items": ["id", "name"]},
            "table2": {"range": "D1:F3", "direction": "horizontal", "items": ["col1", "col2"]}
        }
        
        assert result == expected

    def test_collect_xlsx_files_comprehensive(self, temp_dir):
        """collect_xlsx_files: åŒ…æ‹¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«åé›†ãƒ†ã‚¹ãƒˆ"""
        # æ§˜ã€…ãªãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        xlsx1 = temp_dir / "file1.xlsx"
        xlsx2 = temp_dir / "file2.xlsx"
        xlsm = temp_dir / "macro.xlsm"
        txt = temp_dir / "text.txt"
        
        for file in [xlsx1, xlsx2, xlsm, txt]:
            file.touch()
        
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        subdir = temp_dir / "subdir"
        subdir.mkdir()
        sub_xlsx = subdir / "sub.xlsx"
        sub_xlsx.touch()
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæŒ‡å®šã§ã®åé›†
        files = xlsx2json.collect_xlsx_files([str(temp_dir)])
        file_names = [f.name for f in files]
        
        # XLSXãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãŒåé›†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert "file1.xlsx" in file_names
        assert "file2.xlsx" in file_names
        assert "text.txt" not in file_names
        assert "sub.xlsx" not in file_names  # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯é™¤å¤–
        
        # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®š
        files = xlsx2json.collect_xlsx_files([str(xlsx1), str(xlsx2)])
        assert len(files) == 2
        assert xlsx1 in files
        assert xlsx2 in files


class TestCoverageEnhancement:
    """ã‚«ãƒãƒ¬ãƒƒã‚¸å¼·åŒ–ã®ãŸã‚ã®è¿½åŠ ãƒ†ã‚¹ãƒˆ
    
    æœªã‚«ãƒãƒ¼é ˜åŸŸã®ç¶²ç¾…çš„ãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹90%ã‚«ãƒãƒ¬ãƒƒã‚¸é”æˆã‚’ç›®æŒ‡ã™
    """

    @pytest.fixture
    def temp_dir(self):
        """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
        temp_path = Path(tempfile.mkdtemp())
        yield temp_path
        shutil.rmtree(temp_path)

    @pytest.fixture  
    def mock_workbook(self, temp_dir):
        """ãƒ¢ãƒƒã‚¯ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ä½œæˆ"""
        xlsx_path = temp_dir / "test.xlsx"
        wb = openpyxl.Workbook()
        ws = wb.active
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
        ws["A1"] = "Header1"
        ws["B1"] = "Header2"
        ws["A2"] = "Data1"
        ws["B2"] = "Data2"
        ws["A3"] = "Data3"
        ws["B3"] = "Data4"
        
        wb.save(xlsx_path)
        wb.close()
        return xlsx_path

    def test_main_function_coverage(self, mock_workbook, temp_dir):
        """mainé–¢æ•°ã®å®Ÿè¡Œãƒ‘ã‚¹ã‚’ãƒ†ã‚¹ãƒˆ"""
        output_dir = temp_dir / "output"
        
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(mock_workbook),
                "--output_dir", str(output_dir)
            ][index]
            mock_argv.__len__ = lambda _: 4
            
            result = xlsx2json.main()
            assert result == 0

    def test_container_processing_workflow(self, mock_workbook, temp_dir):
        """ã‚³ãƒ³ãƒ†ãƒŠå‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
        wb = openpyxl.load_workbook(mock_workbook)
        
        # ãƒ‘ãƒ–ãƒªãƒƒã‚¯é–¢æ•°çµŒç”±ã§ã‚³ãƒ³ãƒ†ãƒŠå‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        config = {
            "containers": {
                "test_container": {
                    "range": "A1:B3",
                    "direction": "row", 
                    "items": ["col1", "col2"]
                }
            }
        }
        
        config_path = temp_dir / "config.json"
        with config_path.open("w", encoding="utf-8") as f:
            json.dump(config, f)
        
        # parse_named_ranges_with_prefixçµŒç”±ã§ã‚³ãƒ³ãƒ†ãƒŠå‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        result = xlsx2json.parse_named_ranges_with_prefix(
            mock_workbook, "json", containers=config["containers"]
        )
        
        assert isinstance(result, dict)
        wb.close()

    def test_json_path_container_functionality(self):
        """JSONãƒ‘ã‚¹ã‚³ãƒ³ãƒ†ãƒŠæ©Ÿèƒ½ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
        # ã‚ˆã‚Šç›´æ¥çš„ãªãƒ†ã‚¹ãƒˆï¼šåŸºæœ¬çš„ãªãƒ‘ã‚¹æŒ¿å…¥ã®ãƒ†ã‚¹ãƒˆ
        root = {}
        
        # é€šå¸¸ã®JSONãƒ‘ã‚¹æŒ¿å…¥ã§åŸºæœ¬å‹•ä½œã‚’ãƒ†ã‚¹ãƒˆ
        xlsx2json.insert_json_path(root, ["data", "items", "1"], "first")
        xlsx2json.insert_json_path(root, ["data", "items", "2"], "second")
        
        assert isinstance(root["data"]["items"], list)
        assert root["data"]["items"][0] == "first"
        assert root["data"]["items"][1] == "second"

    def test_json_path_complex_nesting(self):
        """JSONãƒ‘ã‚¹ã®è¤‡é›‘ãªãƒã‚¹ãƒˆæ§‹é€ ãƒ†ã‚¹ãƒˆ"""
        root = {}
        
        # æ·±ã„ãƒã‚¹ãƒˆæ§‹é€ ã®æ§‹ç¯‰
        xlsx2json.insert_json_path(
            root, ["level1", "level2", "level3", "data"], "deep_value"
        )
        
        # é…åˆ—ã¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ··åœ¨
        xlsx2json.insert_json_path(root, ["items", "1", "id"], 1)
        xlsx2json.insert_json_path(root, ["items", "1", "name"], "item1")
        xlsx2json.insert_json_path(root, ["items", "2", "id"], 2)
        xlsx2json.insert_json_path(root, ["items", "2", "name"], "item2")
        
        assert root["level1"]["level2"]["level3"]["data"] == "deep_value"
        assert isinstance(root["items"], list)
        assert len(root["items"]) == 2
        assert root["items"][0]["id"] == 1
        assert root["items"][1]["name"] == "item2"

    def test_array_transformation_edge_cases(self):
        """é…åˆ—å¤‰æ›ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹"""
        # ArrayTransformRuleã®ãƒ†ã‚¹ãƒˆï¼ˆæ­£ã—ã„ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
        rule = xlsx2json.ArrayTransformRule("test", "split", "split:,")
        rule._transform_func = lambda x: x.split(",") if isinstance(x, str) else x
        
        # æ§˜ã€…ãªå…¥åŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³
        test_cases = [
            ("", [""]),
            ("single", ["single"]),
            ("a,b,c", ["a", "b", "c"]),
            ("a,,c", ["a", "", "c"]),  # ç©ºè¦ç´ ã‚’å«ã‚€
            (",a,", ["", "a", ""]),   # å‰å¾Œã«ç©ºè¦ç´ 
        ]
        
        for input_val, expected in test_cases:
            result = rule.transform(input_val)
            assert result == expected, f"Input: {input_val}, Expected: {expected}, Got: {result}"

    def test_unicode_and_special_characters(self):
        """Unicodeæ–‡å­—ã¨ç‰¹æ®Šæ–‡å­—ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        root = {}
        
        # Unicodeæ–‡å­—ã‚’å«ã‚€ãƒ‘ã‚¹
        xlsx2json.insert_json_path(root, ["æ—¥æœ¬èª", "ãƒ‡ãƒ¼ã‚¿"], "å€¤")
        xlsx2json.insert_json_path(root, ["emoji", "ğŸ˜€"], "smile")
        xlsx2json.insert_json_path(root, ["special", "key with spaces"], "spaced")
        
        assert root["æ—¥æœ¬èª"]["ãƒ‡ãƒ¼ã‚¿"] == "å€¤"
        assert root["emoji"]["ğŸ˜€"] == "smile"
        assert root["special"]["key with spaces"] == "spaced"

    def test_large_data_structures(self):
        """å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        root = {}
        
        # å¤šæ•°ã®è¦ç´ ã‚’æŒã¤é…åˆ—
        for i in range(50):  # é©åº¦ãªã‚µã‚¤ã‚ºã«èª¿æ•´
            xlsx2json.insert_json_path(root, ["items", str(i+1)], f"item_{i}")
        
        assert isinstance(root["items"], list)
        assert len(root["items"]) == 50
        assert root["items"][0] == "item_0"
        assert root["items"][49] == "item_49"

    def test_data_cleaning_comprehensive(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
        # è¤‡é›‘ãªãƒã‚¹ãƒˆæ§‹é€ ã§ã®ç©ºé…åˆ—ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        test_data = {
            "level1": {
                "empty_array": [],
                "mixed_array": ["", None, "data"],
                "nested": {
                    "completely_empty": ["", "", ""],
                    "has_data": ["value"]
                }
            },
            "root_empty": []
        }
        
        cleaned = xlsx2json.clean_empty_arrays_contextually(test_data)
        
        # å®Œå…¨ã«ç©ºã®é…åˆ—ã¯å‰Šé™¤ã•ã‚Œã‚‹
        assert "empty_array" not in cleaned["level1"]
        assert "root_empty" not in cleaned
        
        # ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹é…åˆ—ã¯ä¿æŒã•ã‚Œã‚‹
        assert "mixed_array" in cleaned["level1"]
        assert "has_data" in cleaned["level1"]["nested"]

    def test_main_function_error_scenarios(self, temp_dir):
        """mainé–¢æ•°ã®ã‚¨ãƒ©ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«
        with patch("sys.argv") as mock_argv:
            mock_argv.__getitem__ = lambda _, index: [
                "xlsx2json.py",
                str(temp_dir / "nonexistent.xlsx")
            ][index]
            mock_argv.__len__ = lambda _: 2
            
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®å‡¦ç†ã‚’ç¢ºèª
            try:
                result = xlsx2json.main()
                # ã‚¨ãƒ©ãƒ¼å‡¦ç†ã«ã‚ˆã‚Šæ­£å¸¸ã«å‡¦ç†ãŒç¶™ç¶šã•ã‚Œã‚‹å ´åˆã¯0ã‚’è¿”ã™
                assert result in [0, 1], f"äºˆæœŸã—ãªã„æˆ»ã‚Šå€¤: {result}"
            except SystemExit as e:
                # argparseã®ã‚¨ãƒ©ãƒ¼ã§SystemExitãŒç™ºç”Ÿã™ã‚‹å ´åˆ
                assert e.code in [0, 1, 2], f"äºˆæœŸã—ãªã„exit code: {e.code}"

    def test_container_validation_comprehensive(self):
        """ã‚³ãƒ³ãƒ†ãƒŠè¨­å®šã®åŒ…æ‹¬çš„æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        # æ­£å¸¸ãªã‚³ãƒ³ãƒ†ãƒŠè¨­å®š
        valid_containers = {
            "json.table": {
                "range": "A1:C5",
                "direction": "row",
                "items": ["id", "name", "value"]
            }
        }
        
        # validate_container_configé–¢æ•°ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
        if hasattr(xlsx2json, 'validate_container_config'):
            errors = xlsx2json.validate_container_config(valid_containers)
            assert len(errors) == 0

    def test_processing_stats_functionality(self):
        """å‡¦ç†çµ±è¨ˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        stats = xlsx2json.processing_stats
        
        # ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½
        stats.reset()
        
        # ã‚¨ãƒ©ãƒ¼è¿½åŠ æ©Ÿèƒ½
        stats.add_error("Test error 1")
        stats.add_error("Test error 2")
        
        assert len(stats.errors) == 2
        assert "Test error 1" in stats.errors
        assert "Test error 2" in stats.errors

    def test_advanced_array_transform_scenarios(self):
        """é«˜åº¦ãªé…åˆ—å¤‰æ›ã‚·ãƒŠãƒªã‚ªã®ãƒ†ã‚¹ãƒˆ"""
        # ã‚³ãƒãƒ³ãƒ‰å¤‰æ›ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆï¼ˆæ­£ã—ã„ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
        command_rule = xlsx2json.ArrayTransformRule("test", "command", "echo")
        
        # å®‰å…¨ãªã‚³ãƒãƒ³ãƒ‰ã§ã®ãƒ†ã‚¹ãƒˆ
        result = command_rule.transform("hello")
        # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã®çµæœã¯å®Ÿè£…ã«ä¾å­˜
        assert result is not None

    def test_error_handling_robustness(self, temp_dir):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å …ç‰¢æ€§ãƒ†ã‚¹ãƒˆ"""
        # ç ´æã—ãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
        broken_json = temp_dir / "broken.json"
        with broken_json.open("w") as f:
            f.write("{ broken json")
        
        # é–¢æ•°ãŒä¾‹å¤–ã‚’é©åˆ‡ã«å‡¦ç†ã™ã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ
        try:
            xlsx2json.load_schema(broken_json)
            assert False, "Should have raised an exception"
        except (json.JSONDecodeError, ValueError):
            # æœŸå¾…ã•ã‚Œã‚‹ä¾‹å¤–
            pass

    def test_file_path_edge_cases(self, temp_dir):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # æ§˜ã€…ãªæ‹¡å¼µå­ã®ãƒ•ã‚¡ã‚¤ãƒ«
        files_to_create = [
            "test.xlsx",
            "macro.xlsm", 
            "template.xltx",
            "old_format.xls",
            "not_excel.txt",
            "data.csv"
        ]
        
        for filename in files_to_create:
            (temp_dir / filename).touch()
        
        # collect_xlsx_filesã®å‹•ä½œç¢ºèª
        collected = xlsx2json.collect_xlsx_files([str(temp_dir)])
        collected_names = [f.name for f in collected]
        
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãŒåé›†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert "test.xlsx" in collected_names
        assert "not_excel.txt" not in collected_names
        assert "data.csv" not in collected_names

    def test_container_instance_processing_coverage(self, mock_workbook):
        """ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å‡¦ç†ã®è©³ç´°ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼ˆLines 1819-1903ï¼‰"""
        wb = mock_workbook
        
        # generate_container_cell_namesé–¢æ•°ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ†ã‚¹ãƒˆ
        container_name = "json.test_table"
        container_def = {
            "range": "A1:C5",
            "direction": "row",
            "increment": 1,
            "items": ["id", "name", "value"]
        }
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
        direction = container_def.get("direction", "row")
        increment = container_def.get("increment", 1)
        items = container_def.get("items", [])
        
        assert direction == "row"
        assert increment == 1
        assert len(items) == 3
        
        # æ–¹å‘ãƒãƒƒãƒ”ãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ
        direction_map = {"row": "vertical", "column": "horizontal"}
        internal_direction = direction_map.get(direction, direction)
        assert internal_direction == "vertical"

    def test_array_split_and_transform_integration(self):
        """é…åˆ—åˆ†å‰²ã¨å¤‰æ›ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # splitè¦å‰‡ã®ãƒ†ã‚¹ãƒˆ
        split_rules = ["json.data=split:,", "json.items=split:;"]
        parsed_split = xlsx2json.parse_array_split_rules(split_rules, "json.")
        
        assert "data" in parsed_split
        assert "items" in parsed_split
        
        # transformè¦å‰‡ã®ãƒ†ã‚¹ãƒˆ
        transform_rules = ["json.data=function:json:loads", "json.items=command:echo"]
        parsed_transform = xlsx2json.parse_array_transform_rules(transform_rules, "json.")
        
        assert "data" in parsed_transform
        assert "items" in parsed_transform

    def test_error_boundary_conditions(self):
        """ã‚¨ãƒ©ãƒ¼å¢ƒç•Œæ¡ä»¶ã®ãƒ†ã‚¹ãƒˆ"""
        # ç©ºã‚­ãƒ¼ã§ã®JSONãƒ‘ã‚¹æŒ¿å…¥
        try:
            root = {}
            xlsx2json.insert_json_path(root, [], "value")
            assert False, "Should raise ValueError"
        except ValueError:
            pass
        
        # ç„¡åŠ¹ãªã‚¿ã‚¤ãƒ—ã§ã®insert_json_pathï¼ˆé€šå¸¸ã®insert_json_pathã§ãƒ†ã‚¹ãƒˆï¼‰
        try:
            root = "not_dict"
            xlsx2json.insert_json_path(root, ["key"], "value")
            assert False, "Should raise TypeError"
        except TypeError:
            pass

    def test_schema_validation_comprehensive(self, temp_dir):
        """ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ã®åŒ…æ‹¬ãƒ†ã‚¹ãƒˆ"""
        # ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        schema_data = {
            "type": "object",
            "properties": {
                "name": {"type": "string"},
                "age": {"type": "number"},
                "items": {
                    "type": "array",
                    "items": {"type": "string"}
                }
            },
            "required": ["name"]
        }
        
        schema_file = temp_dir / "test_schema.json"
        with schema_file.open("w") as f:
            json.dump(schema_data, f)
        
        # ã‚¹ã‚­ãƒ¼ãƒãƒ­ãƒ¼ãƒ‰
        schema = xlsx2json.load_schema(schema_file)
        assert schema is not None
        assert schema["type"] == "object"

    def test_workbook_operations_coverage(self, mock_workbook):
        """ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯æ“ä½œã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ†ã‚¹ãƒˆ"""
        # mock_workbookã¯å®Ÿéš›ã«ã¯ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ãªããƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãªã®ã§
        # å®Ÿéš›ã®ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’é–‹ã„ã¦ãƒ†ã‚¹ãƒˆã™ã‚‹
        try:
            wb = openpyxl.load_workbook(mock_workbook)
        except Exception:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            return
        
        # get_cell_position_from_nameé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
        if hasattr(xlsx2json, 'get_cell_position_from_name'):
            position = xlsx2json.get_cell_position_from_name("json.test.1.name", wb)
            # positionã¯Noneã¾ãŸã¯ã‚¿ãƒ—ãƒ«
            assert position is None or isinstance(position, tuple)
        
        # read_cell_valueé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
        if hasattr(xlsx2json, 'read_cell_value'):
            ws = wb.active
            value = xlsx2json.read_cell_value((1, 1), ws)
            # å€¤ã¯ä½•ã§ã‚‚ï¼ˆNoneå«ã‚€ï¼‰
            assert value is not None or value is None

    def test_configuration_parsing_edge_cases(self):
        """è¨­å®šè§£æã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹"""
        # ç„¡åŠ¹ãªã‚³ãƒ³ãƒ†ãƒŠå¼•æ•°
        invalid_containers = [
            "invalid_json",
            '{"incomplete": {"range":}',
            '{"valid": {"range": "A1:B2", "items": ["a", "b"]}}'
        ]
        
        # parse_container_argsé–¢æ•°ã®ãƒ†ã‚¹ãƒˆï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        if hasattr(xlsx2json, 'parse_container_args'):
            try:
                result = xlsx2json.parse_container_args(invalid_containers)
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã‹ã€é©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹
                assert isinstance(result, dict) or result is None
            except (json.JSONDecodeError, ValueError):
                # æœŸå¾…ã•ã‚Œã‚‹ä¾‹å¤–
                pass


class TestDataIntegration:
    """å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ãŸçµ±åˆãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def test_data_dir(self):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹"""
        return Path(__file__).parent / "tests" / "data"

    @pytest.fixture
    def output_dir(self, tmp_path):
        """ä¸€æ™‚å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"""
        return tmp_path / "output"

    def test_table1_integration(self, test_data_dir, output_dir):
        """table1.xlsxã¨table1_config.jsonã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        config_file = test_data_dir / "table1_config.json"
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Excel ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        xlsx_file = test_data_dir / "table1.xlsx"
        
        # Excelè§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(
            xlsx_file, 
            config["prefix"], 
            containers=config["containers"]
        )
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        output_file = output_dir / "table1.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        assert output_file.exists()

        # å‡ºåŠ›å†…å®¹ã®ç¢ºèª
        with open(output_file, 'r', encoding='utf-8') as f:
            result = json.load(f)

        # æœŸå¾…ã•ã‚Œã‚‹æ§‹é€ ã®ç¢ºèª
        assert "json" in result
        assert "è¡¨1" in result["json"]
        assert isinstance(result["json"]["è¡¨1"], list)
        assert len(result["json"]["è¡¨1"]) > 0

        # ãƒ‡ãƒ¼ã‚¿å†…å®¹ã®ç¢ºèª
        first_row = result["json"]["è¡¨1"][0]
        assert "åˆ—A" in first_row
        assert "åˆ—B" in first_row
        assert "åˆ—C" in first_row

    def test_list1_integration(self, test_data_dir, output_dir):
        """list1.xlsxã¨list1_config.jsonã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        config_file = test_data_dir / "list1_config.json"
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Excel ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        xlsx_file = test_data_dir / "list1.xlsx"
        
        # Excelè§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(
            xlsx_file, 
            config["prefix"], 
            containers=config["containers"]
        )
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        output_file = output_dir / "list1.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        assert output_file.exists()

        # å‡ºåŠ›å†…å®¹ã®ç¢ºèª
        with open(output_file, 'r', encoding='utf-8') as f:
            result = json.load(f)

        # æœŸå¾…ã•ã‚Œã‚‹æ§‹é€ ã®ç¢ºèª
        assert "json" in result
        assert "ãƒªã‚¹ãƒˆ1" in result["json"]
        assert isinstance(result["json"]["ãƒªã‚¹ãƒˆ1"], list)

        # ãƒ‡ãƒ¼ã‚¿å†…å®¹ã®ç¢ºèª
        if len(result["json"]["ãƒªã‚¹ãƒˆ1"]) > 0:
            first_row = result["json"]["ãƒªã‚¹ãƒˆ1"][0]
            assert "aaaåç§°" in first_row
            assert "aaaã‚³ãƒ¼ãƒ‰" in first_row
            assert "bbbåç§°" in first_row
            assert "bbbã‚³ãƒ¼ãƒ‰" in first_row

    def test_tree1_integration(self, test_data_dir, output_dir):
        """tree1.xlsxã¨tree1_config.jsonã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        config_file = test_data_dir / "tree1_config.json"
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Excel ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        xlsx_file = test_data_dir / "tree1.xlsx"
        
        # Excelè§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(
            xlsx_file, 
            config["prefix"], 
            containers=config["containers"]
        )
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        output_file = output_dir / "tree1.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        assert output_file.exists()

        # å‡ºåŠ›å†…å®¹ã®ç¢ºèª
        with open(output_file, 'r', encoding='utf-8') as f:
            result = json.load(f)

        # ãƒ„ãƒªãƒ¼æ§‹é€ ã®ç¢ºèª
        assert "ãƒ„ãƒªãƒ¼1" in result
        if "lv1" in result["ãƒ„ãƒªãƒ¼1"]:
            lv1_items = result["ãƒ„ãƒªãƒ¼1"]["lv1"]
            assert isinstance(lv1_items, list)
            
            if len(lv1_items) > 0:
                first_item = lv1_items[0]
                assert "A" in first_item
                assert "seq" in first_item
                
                # ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã®ç¢ºèª
                if "lv2" in first_item:
                    lv2_items = first_item["lv2"]
                    assert isinstance(lv2_items, list)

    def test_card1_integration(self, test_data_dir, output_dir):
        """card1.xlsxã¨card1_config.jsonã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        config_file = test_data_dir / "card1_config.json"
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Excel ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        xlsx_file = test_data_dir / "card1.xlsx"
        
        # Excelè§£æ
        result = xlsx2json.parse_named_ranges_with_prefix(
            xlsx_file, 
            config["prefix"], 
            containers=config["containers"]
        )
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        output_file = output_dir / "card1.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        assert output_file.exists()

        # å‡ºåŠ›å†…å®¹ã®ç¢ºèª
        with open(output_file, 'r', encoding='utf-8') as f:
            result = json.load(f)

        # ã‚«ãƒ¼ãƒ‰æ§‹é€ ã®ç¢ºèª
        assert "json" in result
        assert "card" in result["json"]
        assert isinstance(result["json"]["card"], list)

        # ãƒ‡ãƒ¼ã‚¿å†…å®¹ã®ç¢ºèª
        if len(result["json"]["card"]) > 0:
            first_card = result["json"]["card"][0]
            assert "customer_name" in first_card
            assert "address" in first_card
            assert "tel" in first_card

    def test_all_test_data_files_exist(self, test_data_dir):
        """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        test_files = [
            "table1.xlsx", "table1_config.json",
            "list1.xlsx", "list1_config.json", 
            "tree1.xlsx", "tree1_config.json",
            "card1.xlsx", "card1_config.json"
        ]
        
        for file_name in test_files:
            file_path = test_data_dir / file_name
            assert file_path.exists(), f"ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« {file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

    def test_expected_output_files_exist(self, test_data_dir):
        """æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        output_dir = test_data_dir / "output-json"
        expected_files = [
            "table1.json", "list1.json", "tree1.json", "card1.json"
        ]
        
        for file_name in expected_files:
            file_path = output_dir / file_name
            assert file_path.exists(), f"æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

    def test_config_validation(self, test_data_dir):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å¦¥å½“æ€§ã‚’ç¢ºèª"""
        config_files = [
            "table1_config.json", "list1_config.json", 
            "tree1_config.json", "card1_config.json"
        ]
        
        for config_file in config_files:
            config_path = test_data_dir / config_file
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
            assert "containers" in config
            assert "output_dir" in config
            assert "prefix" in config
            assert isinstance(config["containers"], dict)
            assert len(config["containers"]) > 0

    def test_process_all_test_files_comprehensive(self, test_data_dir, output_dir):
        """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†ã—ã¦çµæœã‚’ç¢ºèª"""
        test_cases = [
            ("table1.xlsx", "table1_config.json"),
            ("list1.xlsx", "list1_config.json"),
            ("tree1.xlsx", "tree1_config.json"),
            ("card1.xlsx", "card1_config.json")
        ]
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        output_dir.mkdir(parents=True, exist_ok=True)
        results = {}
        
        for xlsx_file, config_file in test_cases:
            # è¨­å®šèª­ã¿è¾¼ã¿
            config_path = test_data_dir / config_file
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # Excel ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            xlsx_path = test_data_dir / xlsx_file
            
            # å‡¦ç†å®Ÿè¡Œ
            try:
                result = xlsx2json.parse_named_ranges_with_prefix(
                    xlsx_path, 
                    config["prefix"], 
                    containers=config["containers"]
                )
                
                # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
                output_file = output_dir / xlsx_file.replace('.xlsx', '.json')
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                
                if output_file.exists():
                    results[xlsx_file] = {
                        "success": True,
                        "data": result,
                        "file_size": output_file.stat().st_size
                    }
                else:
                    results[xlsx_file] = {
                        "success": False,
                        "error": "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
                    }
                    
            except Exception as e:
                results[xlsx_file] = {
                    "success": False,
                    "error": str(e)
                }
        
        # ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        for xlsx_file, result in results.items():
            assert result["success"], f"{xlsx_file}ã®å‡¦ç†ãŒå¤±æ•—: {result.get('error', 'Unknown error')}"
            assert result["file_size"] > 0, f"{xlsx_file}ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™"


if __name__ == "__main__":
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®šï¼ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã®è©³ç´°æƒ…å ±è¡¨ç¤ºç”¨ï¼‰
    logging.basicConfig(level=logging.INFO)

    # pytestå®Ÿè¡Œ
    pytest.main([__file__, "-v"])
